{"episode_reward_max": 87.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 4.11, "episode_len_mean": 24.55, "episode_media": {}, "episodes_this_iter": 40, "policy_reward_min": {"shared_policy": -12.200000000000001}, "policy_reward_max": {"shared_policy": 98.7}, "policy_reward_mean": {"shared_policy": 2.0549999999999997}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 22, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 23, 25, 25, 25, 25, 14, 25, 25, 23, 25, 25, 25, 25, 25, 25, 25, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3468961998967841, "mean_inference_ms": 1.8837416526114588, "mean_action_processing_ms": 0.09754294216042698, "mean_env_wait_ms": 0.08764455814172725, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 1000, "timesteps_this_iter": 0, "agent_timesteps_total": 2000, "timers": {"sample_time_ms": 410.938, "sample_throughput": 2433.458, "load_time_ms": 1.057, "load_throughput": 946154.748, "learn_time_ms": 158.753, "learn_throughput": 6299.106, "update_time_ms": 3.072}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 0.2, "cur_lr": 0.0005000000000000001, "total_loss": 336.0434295654297, "policy_loss": -0.0035388402640819548, "vf_loss": 336.0626678466797, "vf_explained_var": -9.458661079406739e-05, "kl": 0.001848931651591079, "entropy": 1.607785713672638, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 1000, "num_agent_steps_sampled": 2000, "num_steps_trained": 1000, "num_agent_steps_trained": 2000}, "done": false, "episodes_total": 40, "training_iteration": 1, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-36", "timestamp": 1749778536, "time_this_iter_s": 0.4555473327636719, "time_total_s": 0.4555473327636719, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018319dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 0.4555473327636719, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 34.9, "ram_util_percent": 92.7}}
{"episode_reward_max": 88.2, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 4.192500000000001, "episode_len_mean": 24.1375, "episode_media": {}, "episodes_this_iter": 40, "policy_reward_min": {"shared_policy": -12.200000000000001}, "policy_reward_max": {"shared_policy": 99.1}, "policy_reward_mean": {"shared_policy": 2.09625}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 22, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 23, 25, 25, 25, 25, 14, 25, 25, 23, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 14, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 15, 25, 25, 25, 25, 25, 25, 25, 10, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 10], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.343330589622519, "mean_inference_ms": 1.8290061350790925, "mean_action_processing_ms": 0.09561354559305577, "mean_env_wait_ms": 0.08924908429188985, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 2000, "timesteps_this_iter": 0, "agent_timesteps_total": 4000, "timers": {"sample_time_ms": 514.176, "sample_throughput": 1944.861, "load_time_ms": 1.093, "load_throughput": 915287.289, "learn_time_ms": 126.09, "learn_throughput": 7930.832, "update_time_ms": 3.205}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 0.1, "cur_lr": 0.0005000000000000001, "total_loss": 219.3862747192383, "policy_loss": -0.0018209081143140792, "vf_loss": 219.40401458740234, "vf_explained_var": 0.0001414179801940918, "kl": 0.0008679918942953613, "entropy": 1.6013604283332825, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 2000, "num_agent_steps_sampled": 4000, "num_steps_trained": 2000, "num_agent_steps_trained": 4000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 80, "training_iteration": 2, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-36", "timestamp": 1749778536, "time_this_iter_s": 0.37319302558898926, "time_total_s": 0.8287403583526611, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182f43a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 0.8287403583526611, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 45.2, "ram_util_percent": 92.5}}
{"episode_reward_max": 88.6, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 8.777999999999999, "episode_len_mean": 23.76, "episode_media": {}, "episodes_this_iter": 41, "policy_reward_min": {"shared_policy": -12.3}, "policy_reward_max": {"shared_policy": 99.3}, "policy_reward_mean": {"shared_policy": 4.388999999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, 87.0, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998], "episode_lengths": [25, 25, 23, 25, 25, 25, 25, 14, 25, 25, 23, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 14, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 15, 25, 25, 25, 25, 25, 25, 25, 10, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 10, 25, 18, 25, 25, 25, 25, 25, 25, 17, 25, 25, 25, 25, 25, 25, 25, 25, 25, 15, 25, 25, 23, 25, 25, 25, 25, 25, 24, 16, 25, 8, 25, 25, 25, 21, 25, 25, 25, 25, 25, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -11.5, 98.5, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3348278028607837, "mean_inference_ms": 1.741873815566717, "mean_action_processing_ms": 0.09244028010951279, "mean_env_wait_ms": 0.08857184896322799, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 3000, "timesteps_this_iter": 0, "agent_timesteps_total": 6000, "timers": {"sample_time_ms": 486.103, "sample_throughput": 2057.178, "load_time_ms": 1.263, "load_throughput": 791676.859, "learn_time_ms": 118.29, "learn_throughput": 8453.781, "update_time_ms": 3.676}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 0.05, "cur_lr": 0.0005000000000000001, "total_loss": 533.4900634765625, "policy_loss": -0.0022287894040346145, "vf_loss": 533.5081909179687, "vf_explained_var": 0.0003531694412231445, "kl": 0.0009058261792061039, "entropy": 1.595828914642334, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 3000, "num_agent_steps_sampled": 6000, "num_steps_trained": 3000, "num_agent_steps_trained": 6000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 121, "training_iteration": 3, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-37", "timestamp": 1749778537, "time_this_iter_s": 0.3662295341491699, "time_total_s": 1.194969892501831, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182f4dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1.194969892501831, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 65.8, "ram_util_percent": 92.4}}
{"episode_reward_max": 88.6, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 9.722, "episode_len_mean": 23.55, "episode_media": {}, "episodes_this_iter": 40, "policy_reward_min": {"shared_policy": -12.3}, "policy_reward_max": {"shared_policy": 99.3}, "policy_reward_mean": {"shared_policy": 4.861}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, 87.0, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.8, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998], "episode_lengths": [25, 25, 25, 10, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 10, 25, 18, 25, 25, 25, 25, 25, 25, 17, 25, 25, 25, 25, 25, 25, 25, 25, 25, 15, 25, 25, 23, 25, 25, 25, 25, 25, 24, 16, 25, 8, 25, 25, 25, 21, 25, 25, 25, 25, 25, 25, 12, 21, 25, 25, 25, 25, 25, 25, 25, 25, 25, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 9, 25, 25, 18, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 9, 25, 25, 25, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -11.5, 98.5, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3330863939685784, "mean_inference_ms": 1.7021008145557817, "mean_action_processing_ms": 0.09105108908623788, "mean_env_wait_ms": 0.08789263942970223, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 4000, "timesteps_this_iter": 0, "agent_timesteps_total": 8000, "timers": {"sample_time_ms": 463.763, "sample_throughput": 2156.276, "load_time_ms": 1.165, "load_throughput": 858476.999, "learn_time_ms": 115.319, "learn_throughput": 8671.601, "update_time_ms": 3.46}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 0.025, "cur_lr": 0.0005000000000000001, "total_loss": 296.1247833251953, "policy_loss": -0.0034261882305145265, "vf_loss": 296.1440399169922, "vf_explained_var": 0.00013976693153381348, "kl": 0.001908392096621614, "entropy": 1.5876208424568177, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 4000, "num_agent_steps_sampled": 8000, "num_steps_trained": 4000, "num_agent_steps_trained": 8000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 161, "training_iteration": 4, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-37", "timestamp": 1749778537, "time_this_iter_s": 0.3638434410095215, "time_total_s": 1.5588133335113525, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c9b80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1.5588133335113525, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {}}
{"episode_reward_max": 88.6, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 12.468, "episode_len_mean": 23.35, "episode_media": {}, "episodes_this_iter": 44, "policy_reward_min": {"shared_policy": -12.3}, "policy_reward_max": {"shared_policy": 99.3}, "policy_reward_mean": {"shared_policy": 6.234000000000001}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, 85.4, 87.0, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.8, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 85.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, 87.6, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998], "episode_lengths": [25, 25, 24, 16, 25, 8, 25, 25, 25, 21, 25, 25, 25, 25, 25, 25, 12, 21, 25, 25, 25, 25, 25, 25, 25, 25, 25, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 9, 25, 25, 18, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 9, 25, 25, 25, 25, 25, 25, 25, 25, 25, 17, 23, 25, 25, 25, 25, 19, 25, 25, 25, 25, 25, 25, 25, 16, 25, 25, 25, 11, 21, 25, 25, 25, 25, 14, 13, 25, 14, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -11.5, 98.5, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.4, -11.6, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -11.2, 98.8, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3333891837538936, "mean_inference_ms": 1.6869646550690647, "mean_action_processing_ms": 0.09071930445494679, "mean_env_wait_ms": 0.08743077902058694, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 5000, "timesteps_this_iter": 0, "agent_timesteps_total": 10000, "timers": {"sample_time_ms": 452.826, "sample_throughput": 2208.356, "load_time_ms": 1.11, "load_throughput": 901225.612, "learn_time_ms": 112.263, "learn_throughput": 8907.691, "update_time_ms": 3.136}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 0.0125, "cur_lr": 0.0005000000000000001, "total_loss": 613.0075622558594, "policy_loss": -0.0023129921704821755, "vf_loss": 613.0254638671875, "vf_explained_var": -0.00024716854095458985, "kl": 0.0019770076154483453, "entropy": 1.5622267723083496, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 5000, "num_agent_steps_sampled": 10000, "num_steps_trained": 5000, "num_agent_steps_trained": 10000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 205, "training_iteration": 5, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-38", "timestamp": 1749778538, "time_this_iter_s": 0.3654465675354004, "time_total_s": 1.924259901046753, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c9a60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1.924259901046753, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 59.4, "ram_util_percent": 92.3}}
{"episode_reward_max": 88.8, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 20.781999999999996, "episode_len_mean": 22.37, "episode_media": {}, "episodes_this_iter": 47, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.4}, "policy_reward_mean": {"shared_policy": 10.390999999999998}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 85.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, 87.6, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.8, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, 88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.2, 88.0, -4.999999999999998, 88.2, 85.8, 87.8, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, 86.0, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, -4.999999999999998], "episode_lengths": [25, 25, 25, 25, 9, 25, 25, 25, 25, 25, 25, 25, 25, 25, 17, 23, 25, 25, 25, 25, 19, 25, 25, 25, 25, 25, 25, 25, 16, 25, 25, 25, 11, 21, 25, 25, 25, 25, 14, 13, 25, 14, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 12, 14, 25, 25, 25, 25, 24, 17, 25, 25, 25, 25, 22, 7, 25, 25, 25, 25, 11, 25, 10, 22, 12, 25, 11, 25, 25, 25, 25, 13, 14, 25, 25, 25, 25, 25, 17, 25, 21, 25, 8, 25, 25, 20, 25, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.4, -11.6, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -11.2, 98.8, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.4, 97.6, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 97.9, -12.100000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3360857909964784, "mean_inference_ms": 1.6921367865533794, "mean_action_processing_ms": 0.09127718332978657, "mean_env_wait_ms": 0.08754044881975329, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 6000, "timesteps_this_iter": 0, "agent_timesteps_total": 12000, "timers": {"sample_time_ms": 469.109, "sample_throughput": 2131.699, "load_time_ms": 1.071, "load_throughput": 933623.595, "learn_time_ms": 110.507, "learn_throughput": 9049.232, "update_time_ms": 3.121}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 0.00625, "cur_lr": 0.0005000000000000001, "total_loss": 1119.8907836914063, "policy_loss": -0.004989265650510788, "vf_loss": 1119.9109497070312, "vf_explained_var": 0.00014269351959228516, "kl": 0.007382092616485014, "entropy": 1.519001030921936, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 6000, "num_agent_steps_sampled": 12000, "num_steps_trained": 6000, "num_agent_steps_trained": 12000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 252, "training_iteration": 6, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-38", "timestamp": 1749778538, "time_this_iter_s": 0.5204546451568604, "time_total_s": 2.4447145462036133, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018319dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2.4447145462036133, "timesteps_since_restore": 0, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 49.9, "ram_util_percent": 92.3}}
{"episode_reward_max": 89.2, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 30.070000000000004, "episode_len_mean": 21.03, "episode_media": {}, "episodes_this_iter": 51, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.6}, "policy_reward_mean": {"shared_policy": 15.035}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, -4.999999999999998, 87.8, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, 88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.2, 88.0, -4.999999999999998, 88.2, 85.8, 87.8, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, 86.0, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 88.8, 85.6, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, 86.6, -4.999999999999998, 87.8, 86.2, -4.999999999999998, -4.999999999999998, 87.4, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.0, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.2, -4.999999999999998, 86.6, -4.999999999999998, 89.2, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 87.6], "episode_lengths": [25, 25, 25, 12, 14, 25, 25, 25, 25, 24, 17, 25, 25, 25, 25, 22, 7, 25, 25, 25, 25, 11, 25, 10, 22, 12, 25, 11, 25, 25, 25, 25, 13, 14, 25, 25, 25, 25, 25, 17, 25, 21, 25, 8, 25, 25, 20, 25, 25, 25, 17, 7, 23, 25, 21, 25, 25, 18, 25, 12, 20, 25, 25, 14, 14, 25, 25, 25, 21, 25, 9, 25, 25, 25, 16, 9, 25, 25, 25, 25, 25, 6, 25, 25, 25, 5, 25, 18, 25, 5, 25, 8, 25, 25, 25, 25, 25, 25, 17, 13], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.4, 97.6, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 97.9, -12.100000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 99.4, -10.6, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -11.2, 98.8]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3370581148975249, "mean_inference_ms": 1.6810731433652872, "mean_action_processing_ms": 0.09106400006050266, "mean_env_wait_ms": 0.08731339812224309, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 7000, "timesteps_this_iter": 0, "agent_timesteps_total": 14000, "timers": {"sample_time_ms": 456.556, "sample_throughput": 2190.31, "load_time_ms": 1.096, "load_throughput": 912116.81, "learn_time_ms": 109.196, "learn_throughput": 9157.815, "update_time_ms": 3.093}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 0.00625, "cur_lr": 0.0005000000000000001, "total_loss": 1066.4401062011718, "policy_loss": -0.0035581767559051515, "vf_loss": 1066.4581726074218, "vf_explained_var": 0.00015308260917663575, "kl": 0.001176132179384215, "entropy": 1.4497755289077758, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 7000, "num_agent_steps_sampled": 14000, "num_steps_trained": 7000, "num_agent_steps_trained": 14000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 303, "training_iteration": 7, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-39", "timestamp": 1749778539, "time_this_iter_s": 0.34915685653686523, "time_total_s": 2.7938714027404785, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182f4ca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2.7938714027404785, "timesteps_since_restore": 0, "iterations_since_restore": 7, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 33.95, "episode_len_mean": 19.67, "episode_media": {}, "episodes_this_iter": 53, "policy_reward_min": {"shared_policy": -12.3}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 16.975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, 86.6, -4.999999999999998, 87.8, 86.2, -4.999999999999998, -4.999999999999998, 87.4, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.0, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.2, -4.999999999999998, 86.6, -4.999999999999998, 89.2, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, 87.6, 88.6, 85.4, -4.999999999999998, 86.4, 86.8, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, 89.4, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, 88.8, 89.4, -4.999999999999998, 88.8, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, 86.4, 87.6, -4.999999999999998, -4.999999999999998, 88.8, 88.0, -4.999999999999998, -4.999999999999998, 89.0, 89.2, 87.4, 87.8, -4.999999999999998, -4.999999999999998], "episode_lengths": [25, 21, 25, 25, 18, 25, 12, 20, 25, 25, 14, 14, 25, 25, 25, 21, 25, 9, 25, 25, 25, 16, 9, 25, 25, 25, 25, 25, 6, 25, 25, 25, 5, 25, 18, 25, 5, 25, 8, 25, 25, 25, 25, 25, 25, 17, 13, 25, 25, 25, 11, 13, 8, 24, 25, 19, 17, 25, 21, 25, 25, 25, 4, 25, 25, 23, 25, 4, 25, 15, 25, 25, 25, 25, 9, 7, 4, 25, 7, 8, 25, 25, 25, 25, 25, 10, 19, 13, 25, 25, 7, 11, 25, 25, 6, 5, 14, 12, 25, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -11.2, 98.8, 99.3, -10.7, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -10.6, 99.4, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -11.8, 98.2, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -10.4, 99.6, -11.3, 98.7, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.34026838666543285, "mean_inference_ms": 1.689461396097312, "mean_action_processing_ms": 0.09179346876504767, "mean_env_wait_ms": 0.08796268637554096, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 8000, "timesteps_this_iter": 0, "agent_timesteps_total": 16000, "timers": {"sample_time_ms": 452.311, "sample_throughput": 2210.866, "load_time_ms": 1.095, "load_throughput": 912921.562, "learn_time_ms": 109.51, "learn_throughput": 9131.591, "update_time_ms": 3.39}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 0.003125, "cur_lr": 0.0005000000000000001, "total_loss": 1108.06142578125, "policy_loss": -0.0038903804495930673, "vf_loss": 1108.079345703125, "vf_explained_var": 0.0001943528652191162, "kl": 0.003893313152822042, "entropy": 1.3994790315628052, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 8000, "num_agent_steps_sampled": 16000, "num_steps_trained": 8000, "num_agent_steps_trained": 16000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 356, "training_iteration": 8, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-39", "timestamp": 1749778539, "time_this_iter_s": 0.3994331359863281, "time_total_s": 3.1933045387268066, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c9a60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3.1933045387268066, "timesteps_since_restore": 0, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 67.5, "ram_util_percent": 92.2}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 39.534, "episode_len_mean": 18.81, "episode_media": {}, "episodes_this_iter": 53, "policy_reward_min": {"shared_policy": -12.3}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 19.767}, "custom_metrics": {}, "hist_stats": {"episode_reward": [85.4, -4.999999999999998, 86.4, 86.8, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, 89.4, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, 88.8, 89.4, -4.999999999999998, 88.8, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, 86.4, 87.6, -4.999999999999998, -4.999999999999998, 88.8, 88.0, -4.999999999999998, -4.999999999999998, 89.0, 89.2, 87.4, 87.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, 88.6, 86.2, -4.999999999999998, 86.2, 88.6, 87.0, -4.999999999999998, 89.0, -4.999999999999998, -4.999999999999998, 88.4, 87.0, -4.999999999999998, 87.2, -4.999999999999998, 86.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, -4.999999999999998, 85.8, 89.4, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.2, 87.6, 85.8, 88.4, 89.4, 89.2, -4.999999999999998, 86.4, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.0, -4.999999999999998, 86.6, -4.999999999999998], "episode_lengths": [24, 25, 19, 17, 25, 21, 25, 25, 25, 4, 25, 25, 23, 25, 4, 25, 15, 25, 25, 25, 25, 9, 7, 4, 25, 7, 8, 25, 25, 25, 25, 25, 10, 19, 13, 25, 25, 7, 11, 25, 25, 6, 5, 14, 12, 25, 25, 25, 25, 9, 25, 8, 20, 25, 20, 8, 16, 25, 6, 25, 25, 9, 16, 25, 15, 25, 19, 4, 25, 25, 25, 20, 25, 25, 22, 4, 25, 8, 25, 25, 25, 5, 13, 22, 9, 4, 5, 25, 19, 17, 25, 25, 25, 25, 25, 25, 6, 25, 18, 25], "policy_shared_policy_reward": [-12.3, 97.7, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -10.6, 99.4, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -11.8, 98.2, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -10.4, 99.6, -11.3, 98.7, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -10.7, 99.3, 98.1, -11.9, -2.500000000000001, -2.500000000000001, -11.9, 98.1, 99.3, -10.7, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -11.2, 98.8, -12.100000000000001, 97.9, -10.8, 99.2, -10.3, 99.7, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.34676288867007643, "mean_inference_ms": 1.711387964277007, "mean_action_processing_ms": 0.09372410113934311, "mean_env_wait_ms": 0.08873699343700807, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 9000, "timesteps_this_iter": 0, "agent_timesteps_total": 18000, "timers": {"sample_time_ms": 453.847, "sample_throughput": 2203.384, "load_time_ms": 1.161, "load_throughput": 861410.616, "learn_time_ms": 108.233, "learn_throughput": 9239.328, "update_time_ms": 3.32}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 0.0015625, "cur_lr": 0.0005000000000000001, "total_loss": 1244.5594970703125, "policy_loss": -0.00319851404055953, "vf_loss": 1244.5763061523437, "vf_explained_var": 0.0001804828643798828, "kl": 0.00550501124041265, "entropy": 1.3611793041229248, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 9000, "num_agent_steps_sampled": 18000, "num_steps_trained": 9000, "num_agent_steps_trained": 18000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 409, "training_iteration": 9, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-39", "timestamp": 1749778539, "time_this_iter_s": 0.4064595699310303, "time_total_s": 3.599764108657837, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182f43a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3.599764108657837, "timesteps_since_restore": 0, "iterations_since_restore": 9, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 46.12, "episode_len_mean": 17.45, "episode_media": {}, "episodes_this_iter": 59, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 23.06}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, 88.4, 87.0, -4.999999999999998, 87.2, -4.999999999999998, 86.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, -4.999999999999998, 85.8, 89.4, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.2, 87.6, 85.8, 88.4, 89.4, 89.2, -4.999999999999998, 86.4, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.0, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, 89.4, 85.8, 88.6, 85.4, 89.4, 89.4, -4.999999999999998, 86.0, 86.8, 89.0, -4.999999999999998, 88.0, 89.4, 88.6, 85.8, -4.999999999999998, 86.6, 89.0, 88.4, 89.4, 87.2, -4.999999999999998, 87.0, 88.8, 89.4, -4.999999999999998, -4.999999999999998, 87.6, 86.4, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, -4.999999999999998, 88.2, 89.4, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 88.4, 89.4, 88.8, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 88.6], "episode_lengths": [25, 25, 9, 16, 25, 15, 25, 19, 4, 25, 25, 25, 20, 25, 25, 22, 4, 25, 8, 25, 25, 25, 5, 13, 22, 9, 4, 5, 25, 19, 17, 25, 25, 25, 25, 25, 25, 6, 25, 18, 25, 25, 25, 25, 25, 13, 4, 22, 8, 24, 4, 4, 25, 21, 17, 6, 25, 11, 4, 8, 22, 25, 18, 6, 9, 4, 15, 25, 16, 7, 4, 25, 25, 13, 19, 25, 25, 25, 25, 13, 25, 10, 4, 25, 14, 25, 25, 25, 25, 4, 9, 4, 7, 4, 25, 25, 25, 25, 4, 8], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -11.2, 98.8, -12.100000000000001, 97.9, -10.8, 99.2, -10.3, 99.7, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -10.3, 99.7, -12.100000000000001, 97.9, -10.7, 99.3, -12.3, 97.7, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -11.6, 98.4, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -10.3, 99.7, -10.7, 99.3, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -10.5, 99.5, -10.8, 99.2, -10.3, 99.7, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -10.6, 99.4, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -11.8, 98.2, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.8, 99.2, -10.3, 99.7, 99.4, -10.6, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.7, 99.3]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3501783388777318, "mean_inference_ms": 1.719500176708462, "mean_action_processing_ms": 0.0947059816140751, "mean_env_wait_ms": 0.08869913676712037, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 10000, "timesteps_this_iter": 0, "agent_timesteps_total": 20000, "timers": {"sample_time_ms": 446.867, "sample_throughput": 2237.801, "load_time_ms": 1.126, "load_throughput": 888266.164, "learn_time_ms": 107.821, "learn_throughput": 9274.663, "update_time_ms": 3.313}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 0.0015625, "cur_lr": 0.0005000000000000001, "total_loss": 1422.6175415039063, "policy_loss": -0.0034827210009098055, "vf_loss": 1422.6334228515625, "vf_explained_var": 5.8156251907348636e-05, "kl": 0.004482950906836813, "entropy": 1.2386093497276307, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 10000, "num_agent_steps_sampled": 20000, "num_steps_trained": 10000, "num_agent_steps_trained": 20000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 468, "training_iteration": 10, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-40", "timestamp": 1749778540, "time_this_iter_s": 0.3593733310699463, "time_total_s": 3.959137439727783, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3.959137439727783, "timesteps_since_restore": 0, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 59.2, "ram_util_percent": 92.1}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 53.675999999999995, "episode_len_mean": 15.75, "episode_media": {}, "episodes_this_iter": 69, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 26.838}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.8, 89.4, -4.999999999999998, -4.999999999999998, 87.6, 86.4, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, -4.999999999999998, 88.2, 89.4, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 88.4, 89.4, 88.8, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 88.6, 85.2, -4.999999999999998, 89.4, 89.4, 85.4, -4.999999999999998, 85.4, 85.2, 86.8, 89.2, 89.4, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 88.6, 86.8, 85.4, -4.999999999999998, 89.4, 87.8, -4.999999999999998, -4.999999999999998, 88.8, 89.2, 88.0, -4.999999999999998, 88.4, 89.4, 89.2, 86.2, 89.4, 89.2, -4.999999999999998, 89.4, -4.999999999999998, 87.8, -4.999999999999998, 89.4, 88.6, 88.0, -4.999999999999998, 89.0, -4.999999999999998, 89.2, -4.999999999999998, 89.4, 89.4, 89.4, 85.2, -4.999999999999998, 87.2, 87.6, 89.0, 85.6, 85.8, 89.0, -4.999999999999998, -4.999999999999998, 89.4, 89.4, 86.2, 89.4, -4.999999999999998, 89.4], "episode_lengths": [7, 4, 25, 25, 13, 19, 25, 25, 25, 25, 13, 25, 10, 4, 25, 14, 25, 25, 25, 25, 4, 9, 4, 7, 4, 25, 25, 25, 25, 4, 8, 25, 25, 4, 4, 24, 25, 24, 25, 17, 5, 4, 25, 22, 25, 25, 25, 25, 25, 4, 8, 17, 24, 25, 4, 12, 25, 25, 7, 5, 11, 25, 9, 4, 5, 20, 4, 5, 25, 4, 25, 12, 25, 4, 8, 11, 25, 6, 25, 5, 25, 4, 4, 4, 25, 25, 15, 13, 6, 23, 22, 6, 25, 25, 4, 4, 20, 4, 25, 4], "policy_shared_policy_reward": [-10.6, 99.4, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -11.8, 98.2, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.8, 99.2, -10.3, 99.7, 99.4, -10.6, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.7, 99.3, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -12.4, 97.6, -11.6, 98.4, -10.4, 99.6, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.7, 99.3, -11.6, 98.4, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -10.4, 99.6, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -10.3, 99.7, -10.4, 99.6, -11.9, 98.1, -10.3, 99.7, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.7, 99.3, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -11.2, 98.8, 99.5, -10.5, -12.200000000000001, 97.8, -12.100000000000001, 97.9, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -11.9, 98.1, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3530933528485003, "mean_inference_ms": 1.704163433148957, "mean_action_processing_ms": 0.09406435681226431, "mean_env_wait_ms": 0.08790252048410627, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 11000, "timesteps_this_iter": 0, "agent_timesteps_total": 22000, "timers": {"sample_time_ms": 446.872, "sample_throughput": 2237.776, "load_time_ms": 1.106, "load_throughput": 904139.685, "learn_time_ms": 101.874, "learn_throughput": 9816.036, "update_time_ms": 3.283}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 0.00078125, "cur_lr": 0.0005000000000000001, "total_loss": 1846.40224609375, "policy_loss": -0.0051503203809261325, "vf_loss": 1846.4193481445313, "vf_explained_var": -3.63469123840332e-05, "kl": 0.007204992776167973, "entropy": 1.194035804271698, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 11000, "num_agent_steps_sampled": 22000, "num_steps_trained": 11000, "num_agent_steps_trained": 22000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 537, "training_iteration": 11, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-40", "timestamp": 1749778540, "time_this_iter_s": 0.3672959804534912, "time_total_s": 4.326433420181274, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f54c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4.326433420181274, "timesteps_since_restore": 0, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 61.6, "ram_util_percent": 92.0}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 75.082, "episode_len_mean": 12.45, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 37.541000000000004}, "custom_metrics": {}, "hist_stats": {"episode_reward": [89.4, 89.4, 89.4, 85.2, -4.999999999999998, 87.2, 87.6, 89.0, 85.6, 85.8, 89.0, -4.999999999999998, -4.999999999999998, 89.4, 89.4, 86.2, 89.4, -4.999999999999998, 89.4, 85.2, 89.4, 89.2, -4.999999999999998, 87.8, 89.4, -4.999999999999998, 87.6, 89.4, 88.4, 87.4, 89.2, 89.4, 89.4, 88.2, 85.2, 87.8, 88.2, 87.6, 88.4, 89.0, -4.999999999999998, 89.4, 87.0, 85.8, 89.4, 89.2, 85.6, 89.4, 87.2, 88.8, 86.4, 87.6, -4.999999999999998, 88.8, 85.2, 89.4, -4.999999999999998, 85.4, 86.4, 86.0, 89.2, 88.0, -4.999999999999998, 87.6, 88.8, 88.4, -4.999999999999998, 88.4, 89.4, -4.999999999999998, 86.4, 89.4, -4.999999999999998, 89.4, 87.6, 89.2, 88.0, 87.8, 88.2, 89.0, 86.2, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.0, 89.0, 89.4, 85.8, 88.8, 85.8, 89.4, 89.4, 85.8, 89.4, 87.6, 89.4, 88.4, 87.8], "episode_lengths": [4, 4, 4, 25, 25, 15, 13, 6, 23, 22, 6, 25, 25, 4, 4, 20, 4, 25, 4, 25, 4, 5, 25, 12, 4, 25, 13, 4, 9, 14, 5, 4, 4, 10, 25, 12, 10, 13, 9, 6, 25, 4, 16, 22, 4, 5, 23, 4, 15, 7, 19, 13, 25, 7, 25, 4, 25, 24, 19, 21, 5, 11, 25, 13, 7, 9, 25, 9, 4, 25, 19, 4, 25, 4, 13, 5, 11, 12, 10, 6, 20, 4, 4, 25, 4, 4, 6, 6, 4, 22, 7, 22, 4, 4, 22, 4, 13, 4, 9, 12], "policy_shared_policy_reward": [-10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -11.2, 98.8, 99.5, -10.5, -12.200000000000001, 97.8, -12.100000000000001, 97.9, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -11.9, 98.1, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -12.4, 97.6, -10.3, 99.7, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -10.3, 99.7, -10.8, 99.2, -11.3, 98.7, -10.4, 99.6, -10.3, 99.7, -10.3, 99.7, -10.9, 99.1, -12.4, 97.6, -11.1, 98.9, -10.9, 99.1, -11.2, 98.8, -10.8, 99.2, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.5, 98.5, -12.100000000000001, 97.9, -10.3, 99.7, -10.4, 99.6, -12.200000000000001, 97.8, -10.3, 99.7, -11.4, 98.6, -10.6, 99.4, -11.8, 98.2, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -12.4, 97.6, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -11.8, 98.2, -12.0, 98.0, -10.4, 99.6, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -10.6, 99.4, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -10.8, 99.2, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.2, 98.8, -10.4, 99.6, -11.0, 99.0, -11.1, 98.9, -10.9, 99.1, -10.5, 99.5, -11.9, 98.1, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -10.5, 99.5, -10.5, 99.5, -10.3, 99.7, -12.100000000000001, 97.9, -10.6, 99.4, -12.100000000000001, 97.9, -10.3, 99.7, -10.3, 99.7, -12.100000000000001, 97.9, -10.3, 99.7, -11.2, 98.8, -10.3, 99.7, -10.8, 99.2, -11.1, 98.9]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.35649500755980723, "mean_inference_ms": 1.6965688523866265, "mean_action_processing_ms": 0.09253652399316105, "mean_env_wait_ms": 0.0880296568474337, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 12000, "timesteps_this_iter": 0, "agent_timesteps_total": 24000, "timers": {"sample_time_ms": 423.71, "sample_throughput": 2360.106, "load_time_ms": 1.085, "load_throughput": 921420.035, "learn_time_ms": 102.764, "learn_throughput": 9731.063, "update_time_ms": 3.256}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 0.00078125, "cur_lr": 0.0005000000000000001, "total_loss": 2539.3270751953123, "policy_loss": -0.0025255509652197363, "vf_loss": 2539.341162109375, "vf_explained_var": -1.704692840576172e-05, "kl": 0.008500349384796203, "entropy": 1.158749485015869, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 12000, "num_agent_steps_sampled": 24000, "num_steps_trained": 12000, "num_agent_steps_trained": 24000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 618, "training_iteration": 12, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-41", "timestamp": 1749778541, "time_this_iter_s": 0.35651135444641113, "time_total_s": 4.6829447746276855, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4.6829447746276855, "timesteps_since_restore": 0, "iterations_since_restore": 12, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 67.70200000000001, "episode_len_mean": 13.27, "episode_media": {}, "episodes_this_iter": 69, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 33.851000000000006}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 86.4, 89.4, -4.999999999999998, 89.4, 87.6, 89.2, 88.0, 87.8, 88.2, 89.0, 86.2, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.0, 89.0, 89.4, 85.8, 88.8, 85.8, 89.4, 89.4, 85.8, 89.4, 87.6, 89.4, 88.4, 87.8, -4.999999999999998, -4.999999999999998, 86.4, 85.8, 89.4, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 86.4, 89.2, 86.6, 89.4, 87.4, -4.999999999999998, 86.0, 89.4, 89.4, 86.2, 88.8, 88.8, 89.2, 88.2, -4.999999999999998, 89.4, 87.6, 89.0, 89.0, 88.8, -4.999999999999998, 88.8, 86.6, 89.4, 87.2, 88.4, 87.4, -4.999999999999998, 89.2, 87.0, 85.2, 88.6, 89.4, 89.4, 89.4, 86.4, 88.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 87.4, 88.8, 88.4, 86.0, 89.4, -4.999999999999998, 89.4, -4.999999999999998, 89.4, 87.4, 89.4, 87.4, -4.999999999999998, -4.999999999999998, 86.6, -4.999999999999998, 87.0, -4.999999999999998], "episode_lengths": [25, 19, 4, 25, 4, 13, 5, 11, 12, 10, 6, 20, 4, 4, 25, 4, 4, 6, 6, 4, 22, 7, 22, 4, 4, 22, 4, 13, 4, 9, 12, 25, 25, 19, 22, 4, 25, 4, 25, 25, 19, 5, 18, 4, 14, 25, 21, 4, 4, 20, 7, 7, 5, 10, 25, 4, 13, 6, 6, 7, 25, 7, 18, 4, 15, 9, 14, 25, 5, 16, 25, 8, 4, 4, 4, 19, 10, 25, 25, 25, 4, 25, 14, 7, 9, 21, 4, 25, 4, 25, 4, 14, 4, 14, 25, 25, 18, 25, 16, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -11.8, 98.2, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.2, 98.8, -10.4, 99.6, -11.0, 99.0, -11.1, 98.9, -10.9, 99.1, -10.5, 99.5, -11.9, 98.1, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -10.5, 99.5, -10.5, 99.5, -10.3, 99.7, -12.100000000000001, 97.9, -10.6, 99.4, -12.100000000000001, 97.9, -10.3, 99.7, -10.3, 99.7, -12.100000000000001, 97.9, -10.3, 99.7, -11.2, 98.8, -10.3, 99.7, -10.8, 99.2, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -12.100000000000001, 97.9, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -10.4, 99.6, -11.700000000000001, 98.3, -10.3, 99.7, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -10.3, 99.7, -10.3, 99.7, -11.9, 98.1, -10.6, 99.4, -10.6, 99.4, -10.4, 99.6, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.2, 98.8, -10.5, 99.5, -10.5, 99.5, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -11.700000000000001, 98.3, -10.3, 99.7, -11.4, 98.6, -10.8, 99.2, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -11.5, 98.5, -12.4, 97.6, -10.7, 99.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -11.8, 98.2, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -10.6, 99.4, -10.8, 99.2, -12.0, 98.0, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.3, 98.7, -10.3, 99.7, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3585786592852928, "mean_inference_ms": 1.6928844887508874, "mean_action_processing_ms": 0.09243874487667882, "mean_env_wait_ms": 0.08780140882022089, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 13000, "timesteps_this_iter": 0, "agent_timesteps_total": 26000, "timers": {"sample_time_ms": 422.005, "sample_throughput": 2369.639, "load_time_ms": 1.078, "load_throughput": 927984.424, "learn_time_ms": 102.26, "learn_throughput": 9778.993, "update_time_ms": 3.077}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 0.00078125, "cur_lr": 0.0005000000000000001, "total_loss": 1863.1145874023437, "policy_loss": -0.0030223872512578965, "vf_loss": 1863.1283203125, "vf_explained_var": -3.0243396759033202e-05, "kl": 0.011468964154776185, "entropy": 1.0740729451179505, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 13000, "num_agent_steps_sampled": 26000, "num_steps_trained": 13000, "num_agent_steps_trained": 26000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 687, "training_iteration": 13, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-41", "timestamp": 1749778541, "time_this_iter_s": 0.36969947814941406, "time_total_s": 5.0526442527771, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5.0526442527771, "timesteps_since_restore": 0, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 65.9, "ram_util_percent": 92.0}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 63.099999999999994, "episode_len_mean": 13.73, "episode_media": {}, "episodes_this_iter": 76, "policy_reward_min": {"shared_policy": -12.3}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 31.55}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 87.4, 88.8, 88.4, 86.0, 89.4, -4.999999999999998, 89.4, -4.999999999999998, 89.4, 87.4, 89.4, 87.4, -4.999999999999998, -4.999999999999998, 86.6, -4.999999999999998, 87.0, -4.999999999999998, 86.0, 89.4, -4.999999999999998, 89.4, 89.4, 86.2, -4.999999999999998, -4.999999999999998, 88.2, 89.4, 89.4, 88.6, 87.6, 89.0, -4.999999999999998, 89.4, 87.6, 88.0, 89.4, -4.999999999999998, -4.999999999999998, 89.4, 86.2, -4.999999999999998, 89.4, 89.2, -4.999999999999998, 89.0, 87.4, 89.4, 88.8, 89.0, 88.4, -4.999999999999998, 88.6, -4.999999999999998, 85.4, 88.4, -4.999999999999998, 89.2, 89.4, 86.8, 85.4, 87.0, 87.8, 89.4, 89.4, 88.6, 87.0, 88.8, 87.2, -4.999999999999998, 89.4, 87.2, -4.999999999999998, 88.6, 89.4, 87.6, 89.0, -4.999999999999998, 88.4, -4.999999999999998, 89.0, 86.6, 86.2, 88.8, 86.2, 89.4, 89.4, 89.4, -4.999999999999998, 88.6, 89.4, 87.2, -4.999999999999998, 89.4], "episode_lengths": [10, 25, 25, 25, 4, 25, 14, 7, 9, 21, 4, 25, 4, 25, 4, 14, 4, 14, 25, 25, 18, 25, 16, 25, 21, 4, 25, 4, 4, 20, 25, 25, 10, 4, 4, 8, 13, 6, 25, 4, 13, 11, 4, 25, 25, 4, 20, 25, 4, 5, 25, 6, 14, 4, 7, 6, 9, 25, 8, 25, 24, 9, 25, 5, 4, 17, 24, 16, 12, 4, 4, 8, 16, 7, 15, 25, 4, 15, 25, 8, 4, 13, 6, 25, 9, 25, 6, 18, 20, 7, 20, 4, 4, 4, 25, 8, 4, 15, 25, 4], "policy_shared_policy_reward": [-10.9, 99.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -10.6, 99.4, -10.8, 99.2, -12.0, 98.0, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.3, 98.7, -10.3, 99.7, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -10.3, 99.7, -10.3, 99.7, -10.7, 99.3, -11.2, 98.8, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.2, 98.8, -11.0, 99.0, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -11.3, 98.7, -10.3, 99.7, -10.6, 99.4, -10.5, 99.5, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -10.3, 99.7, -11.6, 98.4, -12.3, 97.7, -11.5, 98.5, -11.1, 98.9, -10.3, 99.7, -10.3, 99.7, -10.7, 99.3, -11.5, 98.5, -10.6, 99.4, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -10.3, 99.7, -11.2, 98.8, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -11.700000000000001, 98.3, -11.9, 98.1, -10.6, 99.4, -11.9, 98.1, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -10.3, 99.7, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -10.3, 99.7]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.36095647044702056, "mean_inference_ms": 1.6862459057862247, "mean_action_processing_ms": 0.09171294976714489, "mean_env_wait_ms": 0.08746623502400812, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 14000, "timesteps_this_iter": 0, "agent_timesteps_total": 28000, "timers": {"sample_time_ms": 421.678, "sample_throughput": 2371.475, "load_time_ms": 1.1, "load_throughput": 909097.687, "learn_time_ms": 100.911, "learn_throughput": 9909.709, "update_time_ms": 3.004}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 0.00078125, "cur_lr": 0.0005000000000000001, "total_loss": 2007.674658203125, "policy_loss": -0.004164686426520348, "vf_loss": 2007.689111328125, "vf_explained_var": -5.4323673248291014e-05, "kl": 0.004620942463618505, "entropy": 1.0273504495620727, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 14000, "num_agent_steps_sampled": 28000, "num_steps_trained": 14000, "num_agent_steps_trained": 28000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 763, "training_iteration": 14, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-41", "timestamp": 1749778541, "time_this_iter_s": 0.35178112983703613, "time_total_s": 5.404425382614136, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb01b0b38b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5.404425382614136, "timesteps_since_restore": 0, "iterations_since_restore": 14, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 70.68599999999998, "episode_len_mean": 11.88, "episode_media": {}, "episodes_this_iter": 87, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 35.343}, "custom_metrics": {}, "hist_stats": {"episode_reward": [86.6, 86.2, 88.8, 86.2, 89.4, 89.4, 89.4, -4.999999999999998, 88.6, 89.4, 87.2, -4.999999999999998, 89.4, 87.8, 89.4, -4.999999999999998, 88.8, -4.999999999999998, 87.4, 87.2, 87.0, 88.8, 86.0, -4.999999999999998, 86.2, 89.4, 89.4, 89.0, -4.999999999999998, -4.999999999999998, 87.0, 89.4, 89.4, 85.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 89.4, 89.2, 87.8, 89.4, 87.6, 86.8, -4.999999999999998, 88.8, 89.2, 88.4, 89.0, 89.4, -4.999999999999998, 89.4, 89.4, -4.999999999999998, 89.4, 85.8, 88.6, -4.999999999999998, 89.2, 89.4, 89.4, 88.4, 87.4, 89.2, 88.4, 89.4, -4.999999999999998, 89.4, 89.4, 88.8, -4.999999999999998, 89.2, 89.2, 89.4, 87.0, 87.4, 86.6, -4.999999999999998, 89.0, 89.4, 85.2, 89.4, 87.4, 88.2, 89.0, 87.0, 89.4, -4.999999999999998, 86.8, 89.4, 89.4, 89.4, 87.6, 89.2, 88.2, 89.0, -4.999999999999998], "episode_lengths": [18, 20, 7, 20, 4, 4, 4, 25, 8, 4, 15, 25, 4, 12, 4, 25, 7, 25, 14, 15, 16, 7, 21, 25, 20, 4, 4, 6, 25, 25, 16, 4, 4, 24, 4, 4, 4, 25, 4, 25, 25, 4, 5, 12, 4, 13, 17, 25, 7, 5, 9, 6, 4, 25, 4, 4, 25, 4, 22, 8, 25, 5, 4, 4, 9, 14, 5, 9, 4, 25, 4, 4, 7, 25, 5, 5, 4, 16, 14, 18, 25, 6, 4, 25, 4, 14, 10, 6, 16, 4, 25, 17, 4, 4, 4, 13, 5, 10, 6, 25], "policy_shared_policy_reward": [-11.700000000000001, 98.3, -11.9, 98.1, -10.6, 99.4, -11.9, 98.1, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -10.3, 99.7, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.1, 98.9, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -11.4, 98.6, -11.5, 98.5, -10.6, 99.4, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -10.3, 99.7, -10.3, 99.7, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -10.3, 99.7, -10.3, 99.7, -12.3, 97.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.4, 99.6, 98.9, -11.1, -10.3, 99.7, -11.2, 98.8, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -10.4, 99.6, -10.8, 99.2, -10.5, 99.5, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -12.100000000000001, 97.9, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -10.3, 99.7, -10.3, 99.7, -10.8, 99.2, -11.3, 98.7, -10.4, 99.6, -10.8, 99.2, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -10.4, 99.6, -10.3, 99.7, -11.5, 98.5, -11.3, 98.7, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -10.3, 99.7, -12.4, 97.6, -10.3, 99.7, -11.3, 98.7, -10.9, 99.1, -10.5, 99.5, -11.5, 98.5, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -11.2, 98.8, -10.4, 99.6, -10.9, 99.1, -10.5, 99.5, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3644823699508072, "mean_inference_ms": 1.677719721628312, "mean_action_processing_ms": 0.0912034492116503, "mean_env_wait_ms": 0.08705381013122232, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 15000, "timesteps_this_iter": 0, "agent_timesteps_total": 30000, "timers": {"sample_time_ms": 418.982, "sample_throughput": 2386.735, "load_time_ms": 1.117, "load_throughput": 895052.176, "learn_time_ms": 100.917, "learn_throughput": 9909.102, "update_time_ms": 3.033}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 0.000390625, "cur_lr": 0.0005000000000000001, "total_loss": 2196.800146484375, "policy_loss": -0.001593223214149475, "vf_loss": 2196.8099609375, "vf_explained_var": -7.336139678955078e-05, "kl": 0.008222808620403633, "entropy": 0.8214056193828583, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 15000, "num_agent_steps_sampled": 30000, "num_steps_trained": 15000, "num_agent_steps_trained": 30000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 850, "training_iteration": 15, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-42", "timestamp": 1749778542, "time_this_iter_s": 0.360471248626709, "time_total_s": 5.764896631240845, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5.764896631240845, "timesteps_since_restore": 0, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 60.3, "ram_util_percent": 92.0}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 69.79, "episode_len_mean": 11.85, "episode_media": {}, "episodes_this_iter": 84, "policy_reward_min": {"shared_policy": -12.200000000000001}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 34.895}, "custom_metrics": {}, "hist_stats": {"episode_reward": [89.4, 87.4, 88.2, 89.0, 87.0, 89.4, -4.999999999999998, 86.8, 89.4, 89.4, 89.4, 87.6, 89.2, 88.2, 89.0, -4.999999999999998, 85.6, -4.999999999999998, 88.2, 87.0, 87.2, 88.8, 89.4, 89.4, 87.2, 89.4, 89.4, -4.999999999999998, 89.4, 89.2, 89.4, 89.0, 88.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.2, 87.2, 86.0, 87.0, 87.2, 87.4, 89.4, 88.6, 89.4, 89.4, 89.4, -4.999999999999998, 88.2, 89.4, -4.999999999999998, 89.4, 88.8, 89.4, 89.4, 88.4, 88.0, 89.4, -4.999999999999998, 88.6, -4.999999999999998, 85.6, 87.0, -4.999999999999998, 87.2, 86.6, 89.4, -4.999999999999998, 88.4, -4.999999999999998, 89.4, 89.4, 89.2, 86.2, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, 87.2, 89.4, 87.6, 88.2, 88.8, -4.999999999999998, -4.999999999999998, 89.4, 87.4, 89.4, 89.4, -4.999999999999998, 89.4, 85.6, 89.4, -4.999999999999998, 89.4, 88.6], "episode_lengths": [4, 14, 10, 6, 16, 4, 25, 17, 4, 4, 4, 13, 5, 10, 6, 25, 23, 25, 10, 16, 15, 7, 4, 4, 15, 4, 4, 25, 4, 5, 4, 6, 9, 4, 25, 4, 4, 4, 4, 25, 5, 15, 21, 16, 15, 14, 4, 8, 4, 4, 4, 25, 10, 4, 25, 4, 7, 4, 4, 9, 11, 4, 25, 8, 25, 23, 16, 25, 15, 18, 4, 25, 9, 25, 4, 4, 5, 20, 25, 25, 7, 25, 15, 4, 13, 10, 7, 25, 25, 4, 14, 4, 4, 25, 4, 23, 4, 25, 4, 8], "policy_shared_policy_reward": [-10.3, 99.7, -11.3, 98.7, -10.9, 99.1, -10.5, 99.5, -11.5, 98.5, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -11.2, 98.8, -10.4, 99.6, -10.9, 99.1, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -11.5, 98.5, -11.4, 98.6, -10.6, 99.4, -10.3, 99.7, -10.3, 99.7, -11.4, 98.6, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.4, 99.6, -10.3, 99.7, -10.5, 99.5, -10.8, 99.2, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -11.4, 98.6, -12.0, 98.0, -11.5, 98.5, -11.4, 98.6, -11.3, 98.7, -10.3, 99.7, -10.7, 99.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.6, 99.4, -10.3, 99.7, 99.7, -10.3, -10.8, 99.2, -11.0, 99.0, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -11.700000000000001, 98.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -10.4, 99.6, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -10.3, 99.7, -11.2, 98.8, -10.9, 99.1, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.3, 98.7, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -12.200000000000001, 97.8, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.7, 99.3]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.36849660219334285, "mean_inference_ms": 1.6769434778853605, "mean_action_processing_ms": 0.0909957829871444, "mean_env_wait_ms": 0.08707132990873617, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 16000, "timesteps_this_iter": 0, "agent_timesteps_total": 32000, "timers": {"sample_time_ms": 404.062, "sample_throughput": 2474.868, "load_time_ms": 1.196, "load_throughput": 836318.392, "learn_time_ms": 100.706, "learn_throughput": 9929.937, "update_time_ms": 2.932}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 0.000390625, "cur_lr": 0.0005000000000000001, "total_loss": 2027.3963256835937, "policy_loss": -0.00027378201484680177, "vf_loss": 2027.4051391601563, "vf_explained_var": -4.562139511108398e-05, "kl": 0.0010976984740244471, "entropy": 0.8574256598949432, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 16000, "num_agent_steps_sampled": 32000, "num_steps_trained": 16000, "num_agent_steps_trained": 32000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 934, "training_iteration": 16, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-42", "timestamp": 1749778542, "time_this_iter_s": 0.3659703731536865, "time_total_s": 6.130867004394531, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6.130867004394531, "timesteps_since_restore": 0, "iterations_since_restore": 16, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 67.03599999999999, "episode_len_mean": 12.09, "episode_media": {}, "episodes_this_iter": 82, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 33.518}, "custom_metrics": {}, "hist_stats": {"episode_reward": [87.2, 89.4, 87.6, 88.2, 88.8, -4.999999999999998, -4.999999999999998, 89.4, 87.4, 89.4, 89.4, -4.999999999999998, 89.4, 85.6, 89.4, -4.999999999999998, 89.4, 88.6, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, -4.999999999999998, 89.4, 88.2, -4.999999999999998, -4.999999999999998, 87.4, 89.4, 89.4, 89.4, 87.0, 89.4, 89.4, -4.999999999999998, 86.4, 89.4, 85.8, 89.2, -4.999999999999998, 89.4, 88.4, 88.8, 89.0, 89.0, 89.4, 85.8, 88.8, 89.4, 89.4, 87.4, -4.999999999999998, 89.4, -4.999999999999998, 88.4, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, 88.8, 89.4, 85.2, -4.999999999999998, 89.4, 88.0, 89.4, 89.4, 86.4, 87.6, 86.8, 89.4, 89.4, 87.2, 88.6, 89.2, -4.999999999999998, 89.2, 89.4, 89.4, -4.999999999999998, 86.4, 89.4, -4.999999999999998, 86.0, 89.4, 89.4, -4.999999999999998, 88.6, -4.999999999999998, 89.4, -4.999999999999998, 87.2, 87.4, 89.4, 89.4, -4.999999999999998, 89.4], "episode_lengths": [15, 4, 13, 10, 7, 25, 25, 4, 14, 4, 4, 25, 4, 23, 4, 25, 4, 8, 4, 4, 4, 4, 25, 4, 25, 4, 10, 25, 25, 14, 4, 4, 4, 16, 4, 4, 25, 19, 4, 22, 5, 25, 4, 9, 7, 6, 6, 4, 22, 7, 4, 4, 14, 25, 4, 25, 9, 9, 25, 25, 25, 11, 7, 4, 25, 25, 4, 11, 4, 4, 19, 13, 17, 4, 4, 15, 8, 5, 25, 5, 4, 4, 25, 19, 4, 25, 21, 4, 4, 25, 8, 25, 4, 25, 15, 14, 4, 4, 25, 4], "policy_shared_policy_reward": [-11.4, 98.6, -10.3, 99.7, -11.2, 98.8, -10.9, 99.1, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.3, 98.7, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -12.200000000000001, 97.8, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.7, 99.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -11.5, 98.5, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -10.3, 99.7, -12.100000000000001, 97.9, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.8, 99.2, -10.6, 99.4, -10.5, 99.5, -10.5, 99.5, -10.3, 99.7, -12.100000000000001, 97.9, -10.6, 99.4, -10.3, 99.7, -10.3, 99.7, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -10.6, 99.4, -10.3, 99.7, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.0, 99.0, -10.3, 99.7, -10.3, 99.7, -11.8, 98.2, -11.2, 98.8, -11.6, 98.4, -10.3, 99.7, -10.3, 99.7, -11.4, 98.6, -10.7, 99.3, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -11.3, 98.7, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3704760345611322, "mean_inference_ms": 1.6730529097668438, "mean_action_processing_ms": 0.09085816191853455, "mean_env_wait_ms": 0.08694254126322645, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 17000, "timesteps_this_iter": 0, "agent_timesteps_total": 34000, "timers": {"sample_time_ms": 404.892, "sample_throughput": 2469.796, "load_time_ms": 1.249, "load_throughput": 800837.057, "learn_time_ms": 99.497, "learn_throughput": 10050.599, "update_time_ms": 2.831}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 0.0001953125, "cur_lr": 0.0005000000000000001, "total_loss": 1882.3367553710937, "policy_loss": -0.0031077537685632707, "vf_loss": 1882.3470458984375, "vf_explained_var": -7.768869400024415e-05, "kl": 0.006026657972859811, "entropy": 0.7214479327201844, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 17000, "num_agent_steps_sampled": 34000, "num_steps_trained": 17000, "num_agent_steps_trained": 34000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1016, "training_iteration": 17, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-43", "timestamp": 1749778543, "time_this_iter_s": 0.3463935852050781, "time_total_s": 6.477260589599609, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6.477260589599609, "timesteps_since_restore": 0, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 57.9, "ram_util_percent": 92.1}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 67.01599999999999, "episode_len_mean": 12.19, "episode_media": {}, "episodes_this_iter": 85, "policy_reward_min": {"shared_policy": -12.3}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 33.508}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 86.0, 89.4, 89.4, -4.999999999999998, 88.6, -4.999999999999998, 89.4, -4.999999999999998, 87.2, 87.4, 89.4, 89.4, -4.999999999999998, 89.4, -4.999999999999998, 89.4, 87.2, 89.4, 89.4, -4.999999999999998, 89.0, -4.999999999999998, 89.4, 89.4, -4.999999999999998, 89.4, 87.6, 87.2, 89.4, 87.8, 88.8, 89.4, 89.4, -4.999999999999998, 88.6, 89.2, -4.999999999999998, 89.4, 89.2, -4.999999999999998, 87.6, 89.4, 89.2, 86.4, -4.999999999999998, -4.999999999999998, 89.4, 89.4, 89.4, 86.0, 89.4, 87.8, 89.4, 89.4, 87.2, 88.4, 89.4, -4.999999999999998, 89.4, -4.999999999999998, 88.6, -4.999999999999998, 88.8, 87.4, 87.4, 87.2, -4.999999999999998, 87.4, -4.999999999999998, 89.4, -4.999999999999998, 89.4, -4.999999999999998, 87.4, 88.4, 87.6, 88.8, 89.4, 88.4, 89.0, -4.999999999999998, 87.4, 89.4, 89.4, 89.4, 89.2, 89.4, 85.4, 89.4, 87.4, 86.4, 87.6, 88.6, 89.4, 88.0, -4.999999999999998, 89.4, 86.2, 88.6], "episode_lengths": [25, 21, 4, 4, 25, 8, 25, 4, 25, 15, 14, 4, 4, 25, 4, 25, 4, 15, 4, 4, 25, 6, 25, 4, 4, 25, 4, 13, 15, 4, 12, 7, 4, 4, 25, 8, 5, 25, 4, 5, 25, 13, 4, 5, 19, 25, 25, 4, 4, 4, 21, 4, 12, 4, 4, 15, 9, 4, 25, 4, 25, 8, 25, 7, 14, 14, 15, 25, 14, 25, 4, 25, 4, 25, 14, 9, 13, 7, 4, 9, 6, 25, 14, 4, 4, 4, 5, 4, 24, 4, 14, 19, 13, 8, 4, 11, 25, 4, 20, 8], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -12.0, 98.0, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -11.3, 98.7, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.4, 98.6, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.2, 98.8, -11.4, 98.6, -10.3, 99.7, -11.1, 98.9, -10.6, 99.4, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -10.3, 99.7, -10.4, 99.6, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -12.0, 98.0, -10.3, 99.7, -11.1, 98.9, -10.3, 99.7, -10.3, 99.7, -11.4, 98.6, -10.8, 99.2, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -11.3, 98.7, -11.3, 98.7, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -10.8, 99.2, -11.2, 98.8, -10.6, 99.4, -10.3, 99.7, -10.8, 99.2, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.4, 99.6, -10.3, 99.7, -12.3, 97.7, -10.3, 99.7, -11.3, 98.7, -11.8, 98.2, -11.2, 98.8, -10.7, 99.3, -10.3, 99.7, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.9, 98.1, -10.7, 99.3]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3719705387920258, "mean_inference_ms": 1.6655028681224031, "mean_action_processing_ms": 0.09032712324152305, "mean_env_wait_ms": 0.0867184726107709, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 18000, "timesteps_this_iter": 0, "agent_timesteps_total": 36000, "timers": {"sample_time_ms": 401.14, "sample_throughput": 2492.895, "load_time_ms": 1.224, "load_throughput": 817109.349, "learn_time_ms": 98.235, "learn_throughput": 10179.668, "update_time_ms": 2.482}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 0.0001953125, "cur_lr": 0.0005000000000000001, "total_loss": 1975.7673217773438, "policy_loss": -0.0003855708986520767, "vf_loss": 1975.77509765625, "vf_explained_var": -5.296468734741211e-05, "kl": 0.003733646245666478, "entropy": 0.7398286163806915, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 18000, "num_agent_steps_sampled": 36000, "num_steps_trained": 18000, "num_agent_steps_trained": 36000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1101, "training_iteration": 18, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-43", "timestamp": 1749778543, "time_this_iter_s": 0.35773396492004395, "time_total_s": 6.834994554519653, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182f48b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6.834994554519653, "timesteps_since_restore": 0, "iterations_since_restore": 18, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 76.02912621359222, "episode_len_mean": 9.553398058252426, "episode_media": {}, "episodes_this_iter": 103, "policy_reward_min": {"shared_policy": -12.100000000000001}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 38.01456310679612}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.6, -4.999999999999998, 89.4, 89.2, 88.8, 89.4, 89.0, 89.0, 89.4, 89.4, 87.8, 88.4, 89.4, 85.8, 89.4, 89.4, 89.4, 89.2, 88.6, 87.6, 88.8, 89.4, 86.0, 89.4, -4.999999999999998, 88.6, 89.4, -4.999999999999998, 89.4, 89.2, 89.2, 89.4, 89.4, -4.999999999999998, 88.8, 88.8, -4.999999999999998, 89.2, 89.4, 88.2, 89.4, 86.0, -4.999999999999998, -4.999999999999998, 89.4, 89.4, 87.8, 89.4, 87.8, 89.4, 86.4, 89.0, 89.4, -4.999999999999998, 89.2, 88.6, 88.0, 89.4, -4.999999999999998, 86.2, 87.8, 89.4, 89.4, 89.2, 88.6, 89.4, 89.4, 87.2, -4.999999999999998, 88.4, 89.4, 89.4, 85.8, 89.4, 89.2, 89.4, 89.4, 89.4, 87.8, 89.4, 89.2, 89.2, 89.4, 86.8, 89.2, 89.4, 88.4, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, -4.999999999999998, 86.6, 89.4, 89.4, 89.4, -4.999999999999998, 86.8, 89.4, 89.4, -4.999999999999998], "episode_lengths": [8, 25, 4, 5, 7, 4, 6, 6, 4, 4, 12, 9, 4, 22, 4, 4, 4, 5, 8, 13, 7, 4, 21, 4, 25, 8, 4, 25, 4, 5, 5, 4, 4, 25, 7, 7, 25, 5, 4, 10, 4, 21, 25, 25, 4, 4, 12, 4, 12, 4, 19, 6, 4, 25, 5, 8, 11, 4, 25, 20, 12, 4, 4, 5, 8, 4, 4, 15, 25, 9, 4, 4, 22, 4, 5, 4, 4, 4, 12, 4, 5, 5, 4, 17, 5, 4, 9, 4, 4, 4, 4, 4, 25, 25, 18, 4, 4, 4, 25, 17, 4, 4, 25], "policy_shared_policy_reward": [-10.7, 99.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.4, 99.6, -10.6, 99.4, -10.3, 99.7, -10.5, 99.5, -10.5, 99.5, -10.3, 99.7, -10.3, 99.7, -11.1, 98.9, -10.8, 99.2, -10.3, 99.7, -12.100000000000001, 97.9, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.4, 99.6, 99.3, -10.7, -11.2, 98.8, -10.6, 99.4, -10.3, 99.7, -12.0, 98.0, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.4, 99.6, -10.4, 99.6, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -10.3, 99.7, -10.9, 99.1, -10.3, 99.7, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -11.1, 98.9, -10.3, 99.7, -11.1, 98.9, -10.3, 99.7, -11.8, 98.2, -10.5, 99.5, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -10.7, 99.3, -11.0, 99.0, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -11.1, 98.9, -10.3, 99.7, -10.3, 99.7, -10.4, 99.6, -10.7, 99.3, -10.3, 99.7, -10.3, 99.7, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -10.3, 99.7, -10.3, 99.7, -12.100000000000001, 97.9, -10.3, 99.7, -10.4, 99.6, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -11.1, 98.9, -10.3, 99.7, -10.4, 99.6, -10.4, 99.6, -10.3, 99.7, -11.6, 98.4, -10.4, 99.6, -10.3, 99.7, -10.8, 99.2, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.37568001125085143, "mean_inference_ms": 1.6645293939261134, "mean_action_processing_ms": 0.09008743234231906, "mean_env_wait_ms": 0.08641519225683637, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 19000, "timesteps_this_iter": 0, "agent_timesteps_total": 38000, "timers": {"sample_time_ms": 394.145, "sample_throughput": 2537.139, "load_time_ms": 1.154, "load_throughput": 866359.036, "learn_time_ms": 99.149, "learn_throughput": 10085.802, "update_time_ms": 2.499}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 9.765625e-05, "cur_lr": 0.0005000000000000001, "total_loss": 2283.6630615234376, "policy_loss": -0.0034401839599013328, "vf_loss": 2283.6729248046877, "vf_explained_var": -6.232261657714843e-05, "kl": 0.007492047702093174, "entropy": 0.6457982540130616, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 19000, "num_agent_steps_sampled": 38000, "num_steps_trained": 19000, "num_agent_steps_trained": 38000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1204, "training_iteration": 19, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-43", "timestamp": 1749778543, "time_this_iter_s": 0.37442469596862793, "time_total_s": 7.209419250488281, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182f4670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7.209419250488281, "timesteps_since_restore": 0, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 60.3, "ram_util_percent": 92.1}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 67.17799999999998, "episode_len_mean": 11.38, "episode_media": {}, "episodes_this_iter": 87, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 33.589}, "custom_metrics": {}, "hist_stats": {"episode_reward": [89.4, 89.4, -4.999999999999998, -4.999999999999998, 86.6, 89.4, 89.4, 89.4, -4.999999999999998, 86.8, 89.4, 89.4, -4.999999999999998, 89.4, 86.2, 88.8, 89.4, 89.4, 89.0, -4.999999999999998, 89.0, 89.2, 88.6, 87.0, 89.0, 89.4, 85.8, 89.4, -4.999999999999998, 88.8, -4.999999999999998, 87.6, 88.0, 89.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 87.6, -4.999999999999998, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 86.8, 89.0, 89.0, 88.2, -4.999999999999998, 89.4, 88.6, 89.4, 88.4, -4.999999999999998, 88.8, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 87.0, 89.4, 89.4, -4.999999999999998, 89.0, 89.4, 88.4, -4.999999999999998, 89.4, 89.0, 89.4, 88.6, 86.4, 89.4, 87.0, 88.0, 89.4, -4.999999999999998, 87.2, 89.4, 89.4, 87.0, 89.4, -4.999999999999998, -4.999999999999998, 85.2, 89.2, 89.4, 89.4, 89.2], "episode_lengths": [4, 4, 25, 25, 18, 4, 4, 4, 25, 17, 4, 4, 25, 4, 20, 7, 4, 4, 6, 25, 6, 5, 8, 16, 6, 4, 22, 4, 25, 7, 25, 13, 11, 4, 4, 25, 25, 25, 25, 4, 25, 4, 4, 25, 4, 4, 4, 13, 25, 25, 4, 4, 4, 4, 17, 6, 6, 10, 25, 4, 8, 4, 9, 25, 7, 4, 4, 4, 25, 4, 16, 4, 4, 25, 6, 4, 9, 25, 4, 6, 4, 8, 19, 4, 16, 11, 4, 25, 15, 4, 4, 16, 4, 25, 25, 25, 5, 4, 4, 5], "policy_shared_policy_reward": [-10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.9, 98.1, -10.6, 99.4, -10.3, 99.7, -10.3, 99.7, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -10.4, 99.6, -10.7, 99.3, -11.5, 98.5, -10.5, 99.5, -10.3, 99.7, -12.100000000000001, 97.9, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -11.0, 99.0, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -11.6, 98.4, -10.5, 99.5, -10.5, 99.5, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.7, 99.3, -10.3, 99.7, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.5, 98.5, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -10.3, 99.7, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.5, 99.5, -10.3, 99.7, -10.7, 99.3, -11.8, 98.2, -10.3, 99.7, -11.5, 98.5, -11.0, 99.0, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -10.3, 99.7, -10.3, 99.7, -11.5, 98.5, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -10.4, 99.6, -10.3, 99.7, -10.3, 99.7, -10.4, 99.6]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.37709513849096, "mean_inference_ms": 1.662311206098708, "mean_action_processing_ms": 0.09029769746496182, "mean_env_wait_ms": 0.08641067867354671, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 20000, "timesteps_this_iter": 0, "agent_timesteps_total": 40000, "timers": {"sample_time_ms": 395.031, "sample_throughput": 2531.449, "load_time_ms": 1.166, "load_throughput": 857432.794, "learn_time_ms": 97.219, "learn_throughput": 10286.028, "update_time_ms": 2.478}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 9.765625e-05, "cur_lr": 0.0005000000000000001, "total_loss": 1742.46025390625, "policy_loss": -0.0004866190254688263, "vf_loss": 1742.4682739257812, "vf_explained_var": -5.065202713012695e-05, "kl": 0.006981881231082387, "entropy": 0.7542017638683319, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 20000, "num_agent_steps_sampled": 40000, "num_steps_trained": 20000, "num_agent_steps_trained": 40000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1291, "training_iteration": 20, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-44", "timestamp": 1749778544, "time_this_iter_s": 0.3420543670654297, "time_total_s": 7.551473617553711, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c9ee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7.551473617553711, "timesteps_since_restore": 0, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 65.7, "ram_util_percent": 91.9}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 67.87599999999999, "episode_len_mean": 12.4, "episode_media": {}, "episodes_this_iter": 80, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 33.938}, "custom_metrics": {}, "hist_stats": {"episode_reward": [89.4, 88.6, 86.4, 89.4, 87.0, 88.0, 89.4, -4.999999999999998, 87.2, 89.4, 89.4, 87.0, 89.4, -4.999999999999998, -4.999999999999998, 85.2, 89.2, 89.4, 89.4, 89.2, -4.999999999999998, 89.4, 89.4, 85.6, 89.4, -4.999999999999998, 88.2, 89.4, -4.999999999999998, 89.4, -4.999999999999998, 89.4, -4.999999999999998, 87.2, -4.999999999999998, 87.0, 89.4, 89.4, 89.4, 89.4, 87.4, -4.999999999999998, 89.4, 86.4, 89.4, -4.999999999999998, 89.4, 87.4, 89.4, 85.8, 89.4, 89.4, 88.2, 86.0, -4.999999999999998, 88.2, 88.0, -4.999999999999998, 88.4, 88.8, 88.0, 89.4, -4.999999999999998, 89.4, 88.6, 87.0, 89.4, -4.999999999999998, 88.4, -4.999999999999998, 86.6, 87.6, 87.4, 89.4, 89.4, 87.4, 89.4, 88.8, 89.4, 87.8, -4.999999999999998, 86.2, 89.4, 87.0, 89.4, 87.8, -4.999999999999998, 89.0, 89.4, 89.4, -4.999999999999998, -4.999999999999998, 89.4, 89.0, -4.999999999999998, 89.4, -4.999999999999998, 89.4, 86.4, 87.0], "episode_lengths": [4, 8, 19, 4, 16, 11, 4, 25, 15, 4, 4, 16, 4, 25, 25, 25, 5, 4, 4, 5, 25, 4, 4, 23, 4, 25, 10, 4, 25, 4, 25, 4, 25, 15, 25, 16, 4, 4, 4, 4, 14, 25, 4, 19, 4, 25, 4, 14, 4, 22, 4, 4, 10, 21, 25, 10, 11, 25, 9, 7, 11, 4, 25, 4, 8, 16, 4, 25, 9, 25, 18, 13, 14, 4, 4, 14, 4, 7, 4, 12, 25, 20, 4, 16, 4, 12, 25, 6, 4, 4, 25, 25, 4, 6, 25, 4, 25, 4, 19, 16], "policy_shared_policy_reward": [-10.3, 99.7, -10.7, 99.3, -11.8, 98.2, -10.3, 99.7, -11.5, 98.5, -11.0, 99.0, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -10.3, 99.7, -10.3, 99.7, -11.5, 98.5, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -10.4, 99.6, -10.3, 99.7, -10.3, 99.7, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -12.200000000000001, 97.8, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.8, 98.2, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.3, 98.7, -10.3, 99.7, -12.100000000000001, 97.9, -10.3, 99.7, -10.3, 99.7, -10.9, 99.1, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -10.6, 99.4, -11.0, 99.0, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.7, 99.3, -11.5, 98.5, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -11.2, 98.8, -11.3, 98.7, -10.3, 99.7, -10.3, 99.7, -11.3, 98.7, -10.3, 99.7, -10.6, 99.4, -10.3, 99.7, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -10.3, 99.7, -11.5, 98.5, -10.3, 99.7, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.8, 98.2, -11.5, 98.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3784873752894386, "mean_inference_ms": 1.6614850051479326, "mean_action_processing_ms": 0.09002757560996587, "mean_env_wait_ms": 0.08730988885504408, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 21000, "timesteps_this_iter": 0, "agent_timesteps_total": 42000, "timers": {"sample_time_ms": 393.617, "sample_throughput": 2540.543, "load_time_ms": 1.258, "load_throughput": 794842.426, "learn_time_ms": 96.682, "learn_throughput": 10343.159, "update_time_ms": 2.489}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 9.765625e-05, "cur_lr": 0.0005000000000000001, "total_loss": 1866.684912109375, "policy_loss": -0.002451941184699535, "vf_loss": 1866.6932983398438, "vf_explained_var": -6.165504455566407e-05, "kl": 0.006568551786449284, "entropy": 0.598975419998169, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 21000, "num_agent_steps_sampled": 42000, "num_steps_trained": 21000, "num_agent_steps_trained": 42000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1371, "training_iteration": 21, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-44", "timestamp": 1749778544, "time_this_iter_s": 0.37375473976135254, "time_total_s": 7.9252283573150635, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c9c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7.9252283573150635, "timesteps_since_restore": 0, "iterations_since_restore": 21, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 64.11399999999999, "episode_len_mean": 13.17, "episode_media": {}, "episodes_this_iter": 78, "policy_reward_min": {"shared_policy": -12.200000000000001}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 32.057}, "custom_metrics": {}, "hist_stats": {"episode_reward": [89.4, 87.8, -4.999999999999998, 86.2, 89.4, 87.0, 89.4, 87.8, -4.999999999999998, 89.0, 89.4, 89.4, -4.999999999999998, -4.999999999999998, 89.4, 89.0, -4.999999999999998, 89.4, -4.999999999999998, 89.4, 86.4, 87.0, -4.999999999999998, 89.4, 88.8, 89.4, 89.4, -4.999999999999998, 86.6, 89.4, 86.0, 89.4, 87.4, 89.4, 89.4, 89.4, 89.4, 87.0, 85.6, 86.0, -4.999999999999998, -4.999999999999998, 88.4, 89.4, -4.999999999999998, -4.999999999999998, 87.0, 87.0, 89.2, 89.4, 89.0, 89.2, 89.0, -4.999999999999998, 88.6, 89.4, 88.8, 87.8, -4.999999999999998, 87.0, 89.2, 88.6, 89.0, 89.4, -4.999999999999998, 86.2, 89.4, -4.999999999999998, 89.2, 89.4, -4.999999999999998, -4.999999999999998, 89.4, 89.2, 87.2, 86.0, 88.6, 88.6, -4.999999999999998, 87.2, 89.4, -4.999999999999998, -4.999999999999998, 89.2, -4.999999999999998, 89.4, 89.4, 87.8, -4.999999999999998, 89.4, -4.999999999999998, 87.2, 86.8, 88.0, -4.999999999999998, 87.8, 89.4, 87.2, 87.2, -4.999999999999998], "episode_lengths": [4, 12, 25, 20, 4, 16, 4, 12, 25, 6, 4, 4, 25, 25, 4, 6, 25, 4, 25, 4, 19, 16, 25, 4, 7, 4, 4, 25, 18, 4, 21, 4, 14, 4, 4, 4, 4, 16, 23, 21, 25, 25, 9, 4, 25, 25, 16, 16, 5, 4, 6, 5, 6, 25, 8, 4, 7, 12, 25, 16, 5, 8, 6, 4, 25, 20, 4, 25, 5, 4, 25, 25, 4, 5, 15, 21, 8, 8, 25, 15, 4, 25, 25, 5, 25, 4, 4, 12, 25, 4, 25, 15, 17, 11, 25, 12, 4, 15, 15, 25], "policy_shared_policy_reward": [-10.3, 99.7, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -10.3, 99.7, -11.5, 98.5, -10.3, 99.7, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.8, 98.2, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.4, -10.6, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -10.3, 99.7, -12.0, 98.0, -10.3, 99.7, -11.3, 98.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -11.5, 98.5, -12.200000000000001, 97.8, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -11.5, 98.5, -10.4, 99.6, -10.3, 99.7, -10.5, 99.5, -10.4, 99.6, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -10.3, 99.7, -10.6, 99.4, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -10.4, 99.6, -10.7, 99.3, -10.5, 99.5, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.4, 99.6, -11.4, 98.6, -12.0, 98.0, -10.7, 99.3, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -11.6, 98.4, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -10.3, 99.7, -11.4, 98.6, -11.4, 98.6, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3804639142449271, "mean_inference_ms": 1.6616562207738546, "mean_action_processing_ms": 0.09013383803514362, "mean_env_wait_ms": 0.08757250179087109, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 22000, "timesteps_this_iter": 0, "agent_timesteps_total": 44000, "timers": {"sample_time_ms": 394.744, "sample_throughput": 2533.285, "load_time_ms": 1.249, "load_throughput": 800684.178, "learn_time_ms": 96.275, "learn_throughput": 10386.89, "update_time_ms": 2.466}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 9.765625e-05, "cur_lr": 0.0005000000000000001, "total_loss": 1844.4627685546875, "policy_loss": -0.0026518717408180238, "vf_loss": 1844.4727172851562, "vf_explained_var": -4.987716674804687e-05, "kl": 0.012218598408012583, "entropy": 0.7269785463809967, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 22000, "num_agent_steps_sampled": 44000, "num_steps_trained": 22000, "num_agent_steps_trained": 44000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1449, "training_iteration": 22, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-45", "timestamp": 1749778545, "time_this_iter_s": 0.36368870735168457, "time_total_s": 8.288917064666748, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018319ee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 8.288917064666748, "timesteps_since_restore": 0, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 66.3, "ram_util_percent": 92.0}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 68.85999999999999, "episode_len_mean": 11.99, "episode_media": {}, "episodes_this_iter": 88, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 34.43}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 89.4, -4.999999999999998, 87.2, 86.8, 88.0, -4.999999999999998, 87.8, 89.4, 87.2, 87.2, -4.999999999999998, 86.8, 89.4, 86.0, -4.999999999999998, 89.4, 85.2, 89.4, 88.6, -4.999999999999998, 87.8, 87.2, 89.4, 86.0, 89.4, 88.6, -4.999999999999998, 89.4, 88.6, 89.4, -4.999999999999998, 86.6, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.2, -4.999999999999998, 85.4, 88.8, 89.4, 89.4, 85.4, -4.999999999999998, 89.4, -4.999999999999998, 89.4, 87.0, 87.6, 89.4, 89.4, 89.4, 87.6, 89.4, 89.4, 89.4, 88.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 89.4, 87.6, -4.999999999999998, 89.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.0, 89.4, 87.8, 88.2, -4.999999999999998, 89.4, 89.0, 88.0, 88.4, 88.4, 89.4, 89.4, 89.4, 89.4, 88.2, 86.6, -4.999999999999998, 85.2, 87.6, 89.4, 89.4, 89.4, -4.999999999999998, 89.4], "episode_lengths": [25, 4, 25, 15, 17, 11, 25, 12, 4, 15, 15, 25, 17, 4, 21, 25, 4, 25, 4, 8, 25, 12, 15, 4, 21, 4, 8, 25, 4, 8, 4, 25, 18, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 25, 24, 7, 4, 4, 24, 25, 4, 25, 4, 16, 13, 4, 4, 4, 13, 4, 4, 4, 10, 25, 25, 25, 4, 4, 13, 25, 4, 4, 25, 25, 25, 16, 4, 12, 10, 25, 4, 6, 11, 9, 9, 4, 4, 4, 4, 10, 18, 25, 25, 13, 4, 4, 4, 25, 4], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -11.6, 98.4, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -10.3, 99.7, -11.4, 98.6, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -10.3, 99.7, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -12.4, 97.6, -10.3, 99.7, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -11.4, 98.6, -10.3, 99.7, -12.0, 98.0, -10.3, 99.7, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.7, 99.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -10.6, 99.4, -10.3, 99.7, -10.3, 99.7, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.5, 98.5, -11.2, 98.8, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -11.2, 98.8, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -10.3, 99.7, -11.1, 98.9, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.5, 99.5, -11.0, 99.0, -10.8, 99.2, -10.8, 99.2, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.9, 99.1, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -11.2, 98.8, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.38239869360385825, "mean_inference_ms": 1.6621289824896082, "mean_action_processing_ms": 0.090222566442442, "mean_env_wait_ms": 0.08800810399994927, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 23000, "timesteps_this_iter": 0, "agent_timesteps_total": 46000, "timers": {"sample_time_ms": 393.553, "sample_throughput": 2540.955, "load_time_ms": 1.19, "load_throughput": 840020.028, "learn_time_ms": 96.803, "learn_throughput": 10330.261, "update_time_ms": 2.668}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 9.765625e-05, "cur_lr": 0.0005000000000000001, "total_loss": 2000.9873779296875, "policy_loss": -0.0021270040422677996, "vf_loss": 2000.9957641601563, "vf_explained_var": -1.6391277313232422e-05, "kl": 0.0053103559234649374, "entropy": 0.6242749273777009, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 23000, "num_agent_steps_sampled": 46000, "num_steps_trained": 23000, "num_agent_steps_trained": 46000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1537, "training_iteration": 23, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-45", "timestamp": 1749778545, "time_this_iter_s": 0.3712282180786133, "time_total_s": 8.660145282745361, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c9550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 8.660145282745361, "timesteps_since_restore": 0, "iterations_since_restore": 23, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 75.582, "episode_len_mean": 9.95, "episode_media": {}, "episodes_this_iter": 98, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 37.791000000000004}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 89.4, 85.6, 87.8, 89.4, 89.4, 89.4, 88.8, 89.4, 89.4, 89.4, 89.4, 89.4, 89.2, -4.999999999999998, 87.4, 87.2, 89.4, 88.4, 85.2, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 89.4, -4.999999999999998, 89.4, -4.999999999999998, 87.8, 89.4, 89.4, 89.4, 89.4, 89.2, 89.4, 87.2, 89.4, 89.4, 88.0, 89.4, 89.4, 89.4, 89.2, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 87.8, 87.2, 89.4, 88.0, 89.4, 89.2, 89.0, 87.2, 89.4, 89.4, -4.999999999999998, 86.6, 86.4, -4.999999999999998, 89.0, 88.2, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 86.2, 89.4, 86.2, 89.4, 86.4, 89.0, 89.4, 89.4, 88.2, 87.2, 89.4, 89.4, 87.0, 89.4, 86.6, 89.0, 87.2, 89.4, 88.2, 89.4, 89.4, 88.0, 89.4, -4.999999999999998, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, -4.999999999999998], "episode_lengths": [25, 4, 23, 12, 4, 4, 4, 7, 4, 4, 4, 4, 4, 5, 25, 14, 15, 4, 9, 25, 25, 25, 4, 25, 4, 25, 4, 25, 12, 4, 4, 4, 4, 5, 4, 15, 4, 4, 11, 4, 4, 4, 5, 25, 4, 4, 4, 4, 12, 15, 4, 11, 4, 5, 6, 15, 4, 4, 25, 18, 19, 25, 6, 10, 4, 4, 4, 25, 4, 4, 20, 4, 20, 4, 19, 6, 4, 4, 10, 15, 4, 4, 16, 4, 18, 6, 15, 4, 10, 4, 4, 11, 4, 25, 4, 25, 4, 4, 4, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -10.3, 99.7, -12.200000000000001, 97.8, -11.1, 98.9, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.6, 99.4, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -11.4, 98.6, -10.3, 99.7, -10.8, 99.2, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.1, 98.9, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.4, 99.6, -10.3, 99.7, -11.4, 98.6, -10.3, 99.7, -10.3, 99.7, -11.0, 99.0, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.6, -10.4, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -11.1, 98.9, -11.4, 98.6, -10.3, 99.7, -11.0, 99.0, -10.3, 99.7, -10.4, 99.6, -10.5, 99.5, -11.4, 98.6, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -10.9, 99.1, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -11.9, 98.1, -10.3, 99.7, -11.9, 98.1, -10.3, 99.7, -11.8, 98.2, -10.5, 99.5, -10.3, 99.7, -10.3, 99.7, -10.9, 99.1, -11.4, 98.6, -10.3, 99.7, -10.3, 99.7, -11.5, 98.5, -10.3, 99.7, -11.700000000000001, 98.3, -10.5, 99.5, 98.6, -11.4, -10.3, 99.7, -10.9, 99.1, -10.3, 99.7, -10.3, 99.7, -11.0, 99.0, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.38365204790522817, "mean_inference_ms": 1.6568730866727817, "mean_action_processing_ms": 0.0898906379984555, "mean_env_wait_ms": 0.08724583385991541, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 24000, "timesteps_this_iter": 0, "agent_timesteps_total": 48000, "timers": {"sample_time_ms": 393.854, "sample_throughput": 2539.011, "load_time_ms": 1.162, "load_throughput": 860299.463, "learn_time_ms": 96.046, "learn_throughput": 10411.671, "update_time_ms": 2.711}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 9.765625e-05, "cur_lr": 0.0005000000000000001, "total_loss": 2132.0491333007812, "policy_loss": -0.0022629321552813052, "vf_loss": 2132.058447265625, "vf_explained_var": -6.061792373657227e-06, "kl": 0.008470166284442814, "entropy": 0.6931086301803588, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 24000, "num_agent_steps_sampled": 48000, "num_steps_trained": 24000, "num_agent_steps_trained": 48000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1635, "training_iteration": 24, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-45", "timestamp": 1749778545, "time_this_iter_s": 0.33652210235595703, "time_total_s": 8.996667385101318, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018319f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 8.996667385101318, "timesteps_since_restore": 0, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 57.1, "ram_util_percent": 92.0}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 71.378431372549, "episode_len_mean": 10.098039215686274, "episode_media": {}, "episodes_this_iter": 102, "policy_reward_min": {"shared_policy": -12.3}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 35.68921568627451}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, 89.4, 88.4, 88.4, 89.4, 89.4, 87.6, 89.4, 88.8, 89.4, 89.4, -4.999999999999998, 89.4, 88.0, 87.2, 89.2, 89.4, -4.999999999999998, 85.4, 87.2, 89.4, 86.2, 87.8, -4.999999999999998, 89.4, 85.6, 87.8, 89.4, 89.4, 89.4, 89.0, 89.4, 87.2, 89.4, 89.4, 89.4, 89.4, 89.2, 89.4, 87.0, 89.4, 88.0, 89.4, 89.4, 89.4, 88.4, 89.4, 89.4, 89.2, -4.999999999999998, 88.2, -4.999999999999998, 89.4, 88.8, -4.999999999999998, 89.4, 89.4, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, 89.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 85.4, -4.999999999999998, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, -4.999999999999998, 89.4, 89.4, 89.4, 89.2, 89.4, 89.4, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 89.4, 89.4, 88.4, 89.4, 87.0, 89.0, 89.4, 89.0, 89.4, -4.999999999999998], "episode_lengths": [25, 25, 4, 9, 9, 4, 4, 13, 4, 7, 4, 4, 25, 4, 11, 15, 5, 4, 25, 24, 15, 4, 20, 12, 25, 4, 23, 12, 4, 4, 4, 6, 4, 15, 4, 4, 4, 4, 5, 4, 16, 4, 11, 4, 4, 4, 9, 4, 4, 5, 25, 10, 25, 4, 7, 25, 4, 4, 25, 13, 25, 25, 5, 4, 4, 4, 4, 4, 4, 4, 24, 25, 4, 25, 4, 4, 4, 4, 4, 4, 25, 25, 4, 4, 4, 5, 4, 4, 25, 4, 25, 25, 4, 4, 9, 4, 16, 6, 4, 6, 4, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.8, 99.2, -10.8, 99.2, -10.3, 99.7, -10.3, 99.7, -11.2, 98.8, -10.3, 99.7, -10.6, 99.4, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.0, -11.0, -11.4, 98.6, -10.4, 99.6, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -11.4, 98.6, -10.3, 99.7, -11.9, 98.1, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -12.200000000000001, 97.8, -11.1, 98.9, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.5, -10.5, -10.3, 99.7, -11.4, 98.6, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.4, 99.6, 99.7, -10.3, -11.5, 98.5, -10.3, 99.7, 99.0, -11.0, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.8, 99.2, -10.3, 99.7, 99.7, -10.3, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.6, -10.4, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.4, 99.6, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -10.8, 99.2, -10.3, 99.7, -11.5, 98.5, 99.5, -10.5, -10.3, 99.7, -10.5, 99.5, -10.3, 99.7, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.38687857645745694, "mean_inference_ms": 1.6537057458169797, "mean_action_processing_ms": 0.08957352053446108, "mean_env_wait_ms": 0.08757308003647309, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 25000, "timesteps_this_iter": 0, "agent_timesteps_total": 50000, "timers": {"sample_time_ms": 394.528, "sample_throughput": 2534.676, "load_time_ms": 1.178, "load_throughput": 849204.106, "learn_time_ms": 95.67, "learn_throughput": 10452.597, "update_time_ms": 2.804}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 9.765625e-05, "cur_lr": 0.0005000000000000001, "total_loss": 1966.8223388671875, "policy_loss": -0.0028800681233406068, "vf_loss": 1966.83203125, "vf_explained_var": 1.2952089309692383e-05, "kl": 0.002047800840346259, "entropy": 0.6795939087867737, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 25000, "num_agent_steps_sampled": 50000, "num_steps_trained": 25000, "num_agent_steps_trained": 50000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1737, "training_iteration": 25, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-46", "timestamp": 1749778546, "time_this_iter_s": 0.3681457042694092, "time_total_s": 9.364813089370728, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182f44c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 9.364813089370728, "timesteps_since_restore": 0, "iterations_since_restore": 25, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 74.85742574257424, "episode_len_mean": 9.732673267326733, "episode_media": {}, "episodes_this_iter": 101, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 37.42871287128713}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 88.2, 89.4, 88.2, 89.4, 89.4, 86.2, -4.999999999999998, 88.6, 89.0, 88.8, 89.0, 89.4, 89.4, 87.8, -4.999999999999998, 89.4, 89.4, 85.8, -4.999999999999998, 89.4, 89.4, 89.4, 88.6, 89.4, 86.4, 89.4, 89.0, -4.999999999999998, 87.4, 89.4, 89.4, 89.4, 89.4, 89.4, 88.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 85.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 88.0, -4.999999999999998, 89.4, -4.999999999999998, 89.4, -4.999999999999998, 89.2, 89.4, 89.4, 89.2, 88.2, 88.4, 89.4, 89.4, 89.4, 89.4, 87.2, 89.4, 89.2, 86.2, -4.999999999999998, 89.4, 89.4, 89.4, 85.8, 89.4, 89.4, 88.6, 89.4, 88.6, 89.0, 89.2, 89.4, 86.4, -4.999999999999998, 89.4, 89.2, 86.6, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 88.0, 89.4, 86.4, -4.999999999999998, 89.4, 89.4, 86.8, 89.4, 89.4], "episode_lengths": [25, 10, 4, 10, 4, 4, 20, 25, 8, 6, 7, 6, 4, 4, 12, 25, 4, 4, 22, 25, 4, 4, 4, 8, 4, 19, 4, 6, 25, 14, 4, 4, 4, 4, 4, 9, 4, 25, 25, 25, 4, 25, 4, 4, 4, 4, 4, 4, 11, 25, 4, 25, 4, 25, 5, 4, 4, 5, 10, 9, 4, 4, 4, 4, 15, 4, 5, 20, 25, 4, 4, 4, 22, 4, 4, 8, 4, 8, 6, 5, 4, 19, 25, 4, 5, 18, 4, 4, 25, 4, 4, 4, 11, 4, 19, 25, 4, 4, 17, 4, 4], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -10.9, 99.1, -10.3, 99.7, -10.9, 99.1, -10.3, 99.7, -10.3, 99.7, 98.1, -11.9, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -10.5, 99.5, -10.6, 99.4, 99.5, -10.5, 99.7, -10.3, -10.3, 99.7, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.3, -10.7, -10.3, 99.7, -11.8, 98.2, -10.3, 99.7, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.8, 99.2, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -12.4, 97.6, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -11.0, 99.0, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -10.3, 99.7, -10.3, 99.7, -10.4, 99.6, -10.9, 99.1, -10.8, 99.2, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -11.4, 98.6, -10.3, 99.7, 99.6, -10.4, -11.9, 98.1, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -12.100000000000001, 97.9, -10.3, 99.7, -10.3, 99.7, -10.7, 99.3, -10.3, 99.7, -10.7, 99.3, -10.5, 99.5, 99.6, -10.4, -10.3, 99.7, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.4, 99.6, -11.700000000000001, 98.3, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -11.0, 99.0, 99.7, -10.3, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, 98.4, -11.6, 99.7, -10.3, -10.3, 99.7]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.39025278400112107, "mean_inference_ms": 1.65978375192951, "mean_action_processing_ms": 0.08968014462457093, "mean_env_wait_ms": 0.08725173312691693, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 26000, "timesteps_this_iter": 0, "agent_timesteps_total": 52000, "timers": {"sample_time_ms": 395.481, "sample_throughput": 2528.565, "load_time_ms": 1.123, "load_throughput": 890699.512, "learn_time_ms": 96.407, "learn_throughput": 10372.667, "update_time_ms": 2.877}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 4.8828125e-05, "cur_lr": 0.0005000000000000001, "total_loss": 2085.6815795898438, "policy_loss": -0.004866343550384044, "vf_loss": 2085.6943237304686, "vf_explained_var": 1.4770030975341798e-05, "kl": 0.008210708465584934, "entropy": 0.7941803514957428, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 26000, "num_agent_steps_sampled": 52000, "num_steps_trained": 26000, "num_agent_steps_trained": 52000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1838, "training_iteration": 26, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-46", "timestamp": 1749778546, "time_this_iter_s": 0.38524746894836426, "time_total_s": 9.750060558319092, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182f4e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 9.750060558319092, "timesteps_since_restore": 0, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 59.9, "ram_util_percent": 92.0}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 79.02926829268293, "episode_len_mean": 8.1869918699187, "episode_media": {}, "episodes_this_iter": 123, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 39.51463414634147}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 88.4, -4.999999999999998, 89.4, 85.2, 89.4, 88.6, 89.4, 88.8, -4.999999999999998, 89.4, 88.4, 89.4, -4.999999999999998, 88.6, 89.4, 89.4, 89.4, 89.0, -4.999999999999998, 89.4, 89.0, 89.4, 89.0, 89.4, 89.4, 89.4, 89.4, 89.0, -4.999999999999998, 89.4, 89.4, 89.4, 86.2, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 88.6, 89.4, 89.0, 89.4, 89.4, 89.4, 89.4, 89.4, 86.6, 89.2, 89.4, 89.4, 89.4, 89.0, 89.0, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 87.2, 89.4, 89.2, -4.999999999999998, -4.999999999999998, 89.4, 89.4, 89.4, 88.0, 89.4, 89.4, 85.4, 87.2, 89.4, 86.2, 88.0, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.0, 87.0, 87.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.0, 89.4, 89.4, 88.8, 89.4, 89.4, 89.4, 88.8, -4.999999999999998, 89.4, 88.6, 89.4, 89.4, 87.4, 89.4, 85.6, 89.4, 88.6, 87.8], "episode_lengths": [25, 9, 25, 4, 25, 4, 8, 4, 7, 25, 4, 9, 4, 25, 8, 4, 4, 4, 6, 25, 4, 6, 4, 6, 4, 4, 4, 4, 6, 25, 4, 4, 4, 20, 4, 4, 4, 25, 4, 4, 4, 4, 8, 4, 6, 4, 4, 4, 4, 4, 18, 5, 4, 4, 4, 6, 6, 4, 4, 4, 4, 25, 25, 4, 25, 15, 4, 5, 25, 25, 4, 4, 4, 11, 4, 4, 24, 15, 4, 20, 11, 4, 4, 4, 4, 4, 4, 4, 4, 6, 16, 15, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 4, 4, 7, 4, 4, 4, 7, 25, 4, 8, 4, 4, 14, 4, 23, 4, 8, 12], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -12.4, 97.6, -10.3, 99.7, 99.3, -10.7, -10.3, 99.7, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.8, 99.2, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.5, 99.5, 99.7, -10.3, -10.5, 99.5, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -11.9, 98.1, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.3, -10.7, -10.3, 99.7, -10.5, 99.5, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -11.700000000000001, 98.3, 99.6, -10.4, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.5, 99.5, 99.5, -10.5, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -10.3, 99.7, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.0, -11.0, -10.3, 99.7, -10.3, 99.7, -12.3, 97.7, -11.4, 98.6, -10.3, 99.7, 98.1, -11.9, -11.0, 99.0, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.5, 99.5, -11.5, 98.5, -11.4, 98.6, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.5, 99.5, -10.3, 99.7, -10.3, 99.7, -10.6, 99.4, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.7, 99.3, -10.3, 99.7, -10.3, 99.7, -11.3, 98.7, -10.3, 99.7, -12.200000000000001, 97.8, -10.3, 99.7, 99.3, -10.7, -11.1, 98.9]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3946326406133739, "mean_inference_ms": 1.6547371120920609, "mean_action_processing_ms": 0.08950507370680702, "mean_env_wait_ms": 0.08746580806405883, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 27000, "timesteps_this_iter": 0, "agent_timesteps_total": 54000, "timers": {"sample_time_ms": 397.999, "sample_throughput": 2512.57, "load_time_ms": 1.116, "load_throughput": 896142.21, "learn_time_ms": 97.268, "learn_throughput": 10280.895, "update_time_ms": 2.927}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 4.8828125e-05, "cur_lr": 0.0005000000000000001, "total_loss": 2304.2376708984375, "policy_loss": -0.007282891124486923, "vf_loss": 2304.2525146484377, "vf_explained_var": 4.3284893035888675e-05, "kl": 0.014247334999761297, "entropy": 0.754820317029953, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 27000, "num_agent_steps_sampled": 54000, "num_steps_trained": 27000, "num_agent_steps_trained": 54000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1961, "training_iteration": 27, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-47", "timestamp": 1749778547, "time_this_iter_s": 0.37297964096069336, "time_total_s": 10.123040199279785, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182f48b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 10.123040199279785, "timesteps_since_restore": 0, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 65.3, "ram_util_percent": 91.9}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 75.36752136752133, "episode_len_mean": 8.632478632478632, "episode_media": {}, "episodes_this_iter": 117, "policy_reward_min": {"shared_policy": -12.3}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 37.68376068376068}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.4, 89.2, -4.999999999999998, -4.999999999999998, 89.0, 86.2, 89.4, -4.999999999999998, 88.4, -4.999999999999998, 89.4, 89.4, 89.4, -4.999999999999998, 85.6, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.4, 89.2, 89.4, 89.4, -4.999999999999998, 89.4, -4.999999999999998, 89.4, 86.8, 89.4, 89.0, 89.4, 89.4, -4.999999999999998, 87.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.2, 88.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 88.6, -4.999999999999998, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 87.8, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 88.6, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 87.4, -4.999999999999998, 88.8, 89.4, 89.4, 89.4, 87.2, 88.8, 89.4, 88.8, 88.0, 89.4, 89.0, 89.4, 89.4, 89.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.2, -4.999999999999998, 89.4, 89.4, 88.8, 88.4, 89.4, 89.0, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 85.4, 89.4, 88.8, 86.4], "episode_lengths": [9, 5, 25, 25, 6, 20, 4, 25, 9, 25, 4, 4, 4, 25, 23, 25, 4, 4, 4, 4, 4, 5, 4, 4, 25, 4, 25, 4, 17, 4, 6, 4, 4, 25, 14, 25, 4, 4, 4, 5, 9, 25, 4, 4, 4, 4, 8, 25, 4, 4, 4, 25, 4, 4, 4, 12, 4, 4, 4, 4, 4, 4, 25, 8, 4, 4, 4, 4, 4, 25, 4, 4, 4, 14, 25, 7, 4, 4, 4, 15, 7, 4, 7, 11, 4, 6, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 25, 4, 4, 7, 9, 4, 6, 4, 4, 4, 4, 4, 4, 24, 4, 7, 19], "policy_shared_policy_reward": [-10.8, 99.2, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.5, 99.5, 98.1, -11.9, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.4, 99.6, -10.3, 99.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 98.4, -11.6, -10.3, 99.7, 99.5, -10.5, 99.7, -10.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.4, 99.6, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -11.1, 98.9, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -11.4, 98.6, 99.4, -10.6, -10.3, 99.7, 99.4, -10.6, 99.0, -11.0, -10.3, 99.7, 99.5, -10.5, -10.3, 99.7, -10.3, 99.7, 99.6, -10.4, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.6, -10.4, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.7, -10.3, 99.4, -10.6, -10.8, 99.2, -10.3, 99.7, 99.5, -10.5, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 97.7, -12.3, -10.3, 99.7, 99.4, -10.6, -11.8, 98.2]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.39820456435926244, "mean_inference_ms": 1.661158305863286, "mean_action_processing_ms": 0.0899255592376619, "mean_env_wait_ms": 0.08709480012727984, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 28000, "timesteps_this_iter": 0, "agent_timesteps_total": 56000, "timers": {"sample_time_ms": 400.903, "sample_throughput": 2494.369, "load_time_ms": 1.257, "load_throughput": 795686.832, "learn_time_ms": 97.828, "learn_throughput": 10222.052, "update_time_ms": 2.994}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 4.8828125e-05, "cur_lr": 0.0005000000000000001, "total_loss": 2048.5164184570312, "policy_loss": -0.0012640058994293213, "vf_loss": 2048.5245361328125, "vf_explained_var": -1.8799304962158202e-05, "kl": 0.0036879735732219033, "entropy": 0.6882280826568603, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 28000, "num_agent_steps_sampled": 56000, "num_steps_trained": 28000, "num_agent_steps_trained": 56000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2078, "training_iteration": 28, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-47", "timestamp": 1749778547, "time_this_iter_s": 0.38483715057373047, "time_total_s": 10.507877349853516, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c9c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 10.507877349853516, "timesteps_since_restore": 0, "iterations_since_restore": 28, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 79.60923076923076, "episode_len_mean": 7.8538461538461535, "episode_media": {}, "episodes_this_iter": 130, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 39.80461538461538}, "custom_metrics": {}, "hist_stats": {"episode_reward": [86.0, 89.4, 89.4, 89.4, 89.4, 88.0, 89.4, 88.6, -4.999999999999998, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.0, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 88.8, 89.4, 89.4, 89.4, 89.2, 89.4, 85.6, 89.4, 87.6, 89.4, 89.4, 87.8, 89.4, 89.4, 89.4, -4.999999999999998, 85.8, 89.4, -4.999999999999998, 86.8, 87.6, 89.4, 89.4, 89.0, 89.4, 89.4, 88.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 86.2, 89.4, 89.4, 88.4, 88.4, 89.4, 86.6, 89.4, 89.4, -4.999999999999998, 85.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.2, 89.4, 89.4, -4.999999999999998, 89.4, 85.8, 89.4, 89.4, 89.4, 89.4, 89.2, 89.4, 89.4, 89.4, 89.4, 89.0, -4.999999999999998, 89.4, 89.4, 88.0, 89.4, 89.2, 89.4, 89.4, 86.2, 89.4, 89.4, 89.4, 89.0, 89.4, -4.999999999999998, -4.999999999999998, 89.2, 89.4, 89.4], "episode_lengths": [21, 4, 4, 4, 4, 11, 4, 8, 25, 25, 4, 4, 4, 4, 4, 4, 4, 6, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 5, 4, 23, 4, 13, 4, 4, 12, 4, 4, 4, 25, 22, 4, 25, 17, 13, 4, 4, 6, 4, 4, 9, 4, 4, 25, 4, 4, 4, 4, 4, 4, 4, 25, 20, 4, 4, 9, 9, 4, 18, 4, 4, 25, 25, 4, 4, 4, 4, 4, 4, 4, 25, 4, 4, 4, 4, 25, 4, 5, 4, 4, 25, 4, 22, 4, 4, 4, 4, 5, 4, 4, 4, 4, 6, 25, 4, 4, 11, 4, 5, 4, 4, 20, 4, 4, 4, 6, 4, 25, 25, 5, 4, 4], "policy_shared_policy_reward": [98.0, -12.0, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -11.0, 99.0, -10.3, 99.7, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.5, -10.5, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.4, 99.6, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.4, -10.6, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.4, 99.6, -10.3, 99.7, -12.200000000000001, 97.8, 99.7, -10.3, -11.2, 98.8, 99.7, -10.3, -10.3, 99.7, 98.9, -11.1, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 98.8, -11.2, 99.7, -10.3, -10.3, 99.7, -10.5, 99.5, -10.3, 99.7, 99.7, -10.3, 99.2, -10.8, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 98.1, -11.9, -10.3, 99.7, -10.3, 99.7, 99.2, -10.8, -10.8, 99.2, -10.3, 99.7, 98.3, -11.700000000000001, 99.7, -10.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -12.4, 97.6, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.6, -10.4, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 97.9, -12.100000000000001, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.6, -10.4, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.5, 99.5, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -10.3, 99.7, 99.0, -11.0, 99.7, -10.3, 99.6, -10.4, -10.3, 99.7, -10.3, 99.7, -11.9, 98.1, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.5, -10.5, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.6, -10.4, -10.3, 99.7, -10.3, 99.7]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4016744124179106, "mean_inference_ms": 1.658058756339067, "mean_action_processing_ms": 0.08931346469792463, "mean_env_wait_ms": 0.08651793747488387, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 29000, "timesteps_this_iter": 0, "agent_timesteps_total": 58000, "timers": {"sample_time_ms": 402.813, "sample_throughput": 2482.543, "load_time_ms": 1.259, "load_throughput": 794135.111, "learn_time_ms": 97.25, "learn_throughput": 10282.735, "update_time_ms": 2.954}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 2.44140625e-05, "cur_lr": 0.0005000000000000001, "total_loss": 2331.3703125, "policy_loss": -0.004136276803910733, "vf_loss": 2331.3817138671875, "vf_explained_var": 0.0001106560230255127, "kl": 0.009666575387635134, "entropy": 0.7277648329734803, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 29000, "num_agent_steps_sampled": 58000, "num_steps_trained": 29000, "num_agent_steps_trained": 58000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2208, "training_iteration": 29, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-47", "timestamp": 1749778547, "time_this_iter_s": 0.3787996768951416, "time_total_s": 10.886677026748657, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018319ee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 10.886677026748657, "timesteps_since_restore": 0, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 65.9, "ram_util_percent": 91.9}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 83.70451612903224, "episode_len_mean": 6.290322580645161, "episode_media": {}, "episodes_this_iter": 155, "policy_reward_min": {"shared_policy": -12.200000000000001}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 41.85225806451613}, "custom_metrics": {}, "hist_stats": {"episode_reward": [89.4, 89.4, 89.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 88.6, 89.4, -4.999999999999998, 89.4, 86.6, 89.4, 89.4, 88.6, 89.4, 89.4, 89.4, 87.6, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.2, 89.4, -4.999999999999998, 85.6, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.2, 89.2, 88.2, 89.4, 89.4, 89.0, 89.4, 89.4, 86.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.0, 89.4, 89.4, 89.4, -4.999999999999998, 86.8, 88.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 88.6, 89.4, 88.6, 89.4, 89.4, 89.4, 89.4, 89.4, 88.2, 89.2, 89.4, 89.4, 89.2, 89.4, 89.4, 89.4, 86.4, 89.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 86.6, 89.4, 89.4, 89.0, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.2, 89.4, 89.4, 89.0, 89.4, 89.4, 89.2, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 88.0, 89.4, 89.4, 87.8, -4.999999999999998], "episode_lengths": [4, 4, 5, 4, 4, 4, 4, 4, 4, 8, 4, 25, 4, 18, 4, 4, 8, 4, 4, 4, 13, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 25, 23, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 25, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 10, 4, 4, 6, 4, 4, 20, 4, 4, 4, 4, 4, 4, 4, 25, 6, 4, 4, 4, 25, 17, 10, 4, 4, 4, 4, 4, 4, 4, 4, 8, 4, 8, 4, 4, 4, 4, 4, 10, 5, 4, 4, 5, 4, 4, 4, 19, 5, 4, 4, 4, 4, 4, 4, 4, 18, 4, 4, 6, 4, 4, 4, 4, 25, 5, 4, 4, 6, 4, 4, 5, 4, 25, 4, 4, 4, 4, 4, 4, 4, 25, 4, 11, 4, 4, 12, 25], "policy_shared_policy_reward": [-10.3, 99.7, -10.3, 99.7, -10.4, 99.6, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.3, -10.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.700000000000001, 98.3, -10.3, 99.7, -10.3, 99.7, 99.3, -10.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 98.8, -11.2, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.4, 99.6, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.6, -10.4, -10.4, 99.6, 99.1, -10.9, -10.3, 99.7, 99.7, -10.3, 99.5, -10.5, -10.3, 99.7, -10.3, 99.7, 98.1, -11.9, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 98.4, -11.6, 99.1, -10.9, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.7, 99.3, 99.7, -10.3, 99.3, -10.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.9, 99.1, -10.4, 99.6, -10.3, 99.7, 99.7, -10.3, -10.4, 99.6, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -11.8, 98.2, -10.4, 99.6, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -11.700000000000001, 98.3, -10.3, 99.7, 99.7, -10.3, 99.5, -10.5, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.4, 99.6, 99.7, -10.3, 99.7, -10.3, -10.5, 99.5, -10.3, 99.7, -10.3, 99.7, 99.6, -10.4, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.0, 99.0, 99.7, -10.3, -10.3, 99.7, 98.9, -11.1, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.40630046532314534, "mean_inference_ms": 1.65634093869076, "mean_action_processing_ms": 0.08930293290048781, "mean_env_wait_ms": 0.08731458894201659, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 30000, "timesteps_this_iter": 0, "agent_timesteps_total": 60000, "timers": {"sample_time_ms": 405.382, "sample_throughput": 2466.807, "load_time_ms": 1.273, "load_throughput": 785523.738, "learn_time_ms": 98.636, "learn_throughput": 10138.239, "update_time_ms": 3.007}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 2.44140625e-05, "cur_lr": 0.0005000000000000001, "total_loss": 2584.3946044921877, "policy_loss": -0.0047574426978826525, "vf_loss": 2584.40556640625, "vf_explained_var": 0.0003603696823120117, "kl": 0.0017968435490498757, "entropy": 0.6208442568778991, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 30000, "num_agent_steps_sampled": 60000, "num_steps_trained": 30000, "num_agent_steps_trained": 60000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2363, "training_iteration": 30, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-48", "timestamp": 1749778548, "time_this_iter_s": 0.3759148120880127, "time_total_s": 11.26259183883667, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182f48b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 11.26259183883667, "timesteps_since_restore": 0, "iterations_since_restore": 30, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 82.70884353741496, "episode_len_mean": 6.775510204081633, "episode_media": {}, "episodes_this_iter": 147, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 41.35442176870748}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 89.4, -4.999999999999998, 89.4, 89.4, 88.8, 87.0, 89.4, 89.4, 89.4, 88.0, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.0, 89.4, 89.4, 89.2, 89.4, 89.4, 89.4, 85.2, 86.6, 89.4, 89.4, 89.4, 88.2, 89.4, 88.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.0, -4.999999999999998, 89.0, 89.4, 89.4, 88.0, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.2, 89.4, -4.999999999999998, 89.0, 89.4, 89.4, 89.4, 85.8, 89.4, 89.4, 89.4, 89.4, 89.0, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 88.8, -4.999999999999998, 89.4, 89.0, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 85.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.2, 89.0, 89.4, 89.4, 89.4, 89.4, 85.6, 89.4, 89.4, 89.4, 89.4, 89.4, 85.8, 89.4, 89.4, 89.4, 89.4, 88.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.0, 89.4, 89.4, 89.4, 85.6, 89.4], "episode_lengths": [25, 4, 25, 4, 4, 7, 16, 4, 4, 4, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 25, 4, 4, 4, 6, 4, 4, 5, 4, 4, 4, 25, 18, 4, 4, 4, 10, 4, 10, 4, 4, 4, 4, 4, 4, 4, 6, 25, 6, 4, 4, 11, 4, 25, 4, 4, 4, 4, 5, 4, 25, 6, 4, 4, 4, 22, 4, 4, 4, 4, 6, 4, 25, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 25, 4, 6, 25, 4, 4, 4, 4, 25, 4, 4, 4, 4, 4, 4, 4, 4, 5, 6, 4, 4, 4, 4, 23, 4, 4, 4, 4, 4, 22, 4, 4, 4, 4, 9, 4, 4, 4, 4, 4, 4, 25, 4, 4, 6, 4, 4, 4, 23, 4], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, 99.4, -10.6, 98.5, -11.5, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.0, -11.0, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.5, -10.5, 99.7, -10.3, 99.7, -10.3, 99.6, -10.4, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 97.6, -12.4, 98.3, -11.700000000000001, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.1, -10.9, -10.3, 99.7, -10.9, 99.1, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -10.5, 99.5, 99.7, -10.3, 99.7, -10.3, -11.0, 99.0, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.6, -10.4, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.5, 99.5, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 97.9, -12.100000000000001, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.5, -10.5, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.5, -10.5, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 97.6, -12.4, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.4, 99.6, 99.5, -10.5, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 97.8, -12.200000000000001, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 97.9, -12.100000000000001, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.2, -10.8, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.7, -10.3, -10.5, 99.5, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -12.200000000000001, 97.8, -10.3, 99.7]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4091594790699577, "mean_inference_ms": 1.655550818779738, "mean_action_processing_ms": 0.08955804033653925, "mean_env_wait_ms": 0.0868683854319145, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 31000, "timesteps_this_iter": 0, "agent_timesteps_total": 62000, "timers": {"sample_time_ms": 406.945, "sample_throughput": 2457.337, "load_time_ms": 1.179, "load_throughput": 848499.757, "learn_time_ms": 99.379, "learn_throughput": 10062.511, "update_time_ms": 3.066}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.220703125e-05, "cur_lr": 0.0005000000000000001, "total_loss": 2417.3185791015626, "policy_loss": -0.0035360919311642645, "vf_loss": 2417.32822265625, "vf_explained_var": 0.00024762749671936035, "kl": 0.0095871169260203, "entropy": 0.6016852200031281, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 31000, "num_agent_steps_sampled": 62000, "num_steps_trained": 31000, "num_agent_steps_trained": 62000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2510, "training_iteration": 31, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-48", "timestamp": 1749778548, "time_this_iter_s": 0.38155341148376465, "time_total_s": 11.644145250320435, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 11.644145250320435, "timesteps_since_restore": 0, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 56.1, "ram_util_percent": 91.9}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 83.27374999999999, "episode_len_mean": 6.44375, "episode_media": {}, "episodes_this_iter": 160, "policy_reward_min": {"shared_policy": -12.3}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 41.636874999999996}, "custom_metrics": {}, "hist_stats": {"episode_reward": [85.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 87.6, 89.4, 88.6, 85.8, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.2, 87.4, 89.4, 89.0, 89.4, -4.999999999999998, -4.999999999999998, 89.2, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.0, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 88.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.0, -4.999999999999998, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.2, 89.4, 89.4, 89.2, 89.4, 89.4, 89.4, 89.4, 89.4, 87.0, 89.4, 89.4, 87.6, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 87.8, -4.999999999999998, 89.2, 89.4, 89.4, 89.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 88.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 86.39999999999999, 89.2, 89.0, 89.2, 89.0, -4.999999999999998, 87.2, 86.0, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.2, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 86.0, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4], "episode_lengths": [24, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 13, 4, 8, 22, 4, 4, 4, 4, 4, 4, 4, 4, 25, 4, 4, 4, 4, 4, 4, 4, 4, 5, 14, 4, 6, 4, 25, 25, 5, 4, 4, 4, 4, 4, 25, 4, 6, 4, 4, 4, 4, 4, 4, 4, 10, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 25, 4, 4, 25, 4, 4, 4, 4, 4, 4, 5, 4, 4, 5, 4, 4, 4, 4, 4, 16, 4, 4, 13, 4, 4, 4, 4, 4, 4, 25, 4, 12, 25, 5, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 10, 4, 4, 4, 4, 4, 4, 4, 4, 19, 5, 6, 5, 6, 25, 15, 21, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 25, 4, 4, 4, 4, 4, 4, 4, 4, 4, 21, 4, 4, 4, 4, 4, 4], "policy_shared_policy_reward": [-12.3, 97.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 98.8, -11.2, -10.3, 99.7, -10.7, 99.3, -12.100000000000001, 97.9, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.4, 99.6, 98.7, -11.3, -10.3, 99.7, -10.5, 99.5, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.6, -10.4, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.5, -10.5, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.1, -10.9, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.6, -10.4, -10.3, 99.7, 99.7, -10.3, -10.4, 99.6, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -11.5, 98.5, 99.7, -10.3, 99.7, -10.3, 98.8, -11.2, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.1, 98.9, -2.500000000000001, -2.500000000000001, 99.6, -10.4, 99.7, -10.3, 99.7, -10.3, -10.4, 99.6, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.1, -10.9, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 98.2, -11.8, -10.4, 99.6, -10.5, 99.5, 99.6, -10.4, -10.5, 99.5, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -12.0, 98.0, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.6, -10.4, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -12.0, 98.0, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4136673419485238, "mean_inference_ms": 1.6521181963600615, "mean_action_processing_ms": 0.08934998057924633, "mean_env_wait_ms": 0.08698398342210031, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 32000, "timesteps_this_iter": 0, "agent_timesteps_total": 64000, "timers": {"sample_time_ms": 409.413, "sample_throughput": 2442.519, "load_time_ms": 1.302, "load_throughput": 767779.751, "learn_time_ms": 99.516, "learn_throughput": 10048.68, "update_time_ms": 3.006}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.220703125e-05, "cur_lr": 0.0005000000000000001, "total_loss": 2595.8091064453124, "policy_loss": -0.0012808013707399368, "vf_loss": 2595.8161865234374, "vf_explained_var": 0.0012560486793518066, "kl": 0.0039515815140150675, "entropy": 0.5775443971157074, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 32000, "num_agent_steps_sampled": 64000, "num_steps_trained": 32000, "num_agent_steps_trained": 64000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2670, "training_iteration": 32, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-49", "timestamp": 1749778549, "time_this_iter_s": 0.380551815032959, "time_total_s": 12.024697065353394, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182f4670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 12.024697065353394, "timesteps_since_restore": 0, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 63.5, "ram_util_percent": 91.9}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 86.38549222797927, "episode_len_mean": 5.051813471502591, "episode_media": {}, "episodes_this_iter": 193, "policy_reward_min": {"shared_policy": -11.6}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 43.19274611398964}, "custom_metrics": {}, "hist_stats": {"episode_reward": [89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.0, 89.4, 89.4, 87.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.0, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.2, 89.4, 89.4, 89.0, 89.4, 89.4, 89.4, 89.4, 87.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.0, 89.4, 89.4, 89.4, 89.4, 89.4, 88.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 88.8, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.0, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.0, 89.4, 89.4, 89.4, 89.4, 89.4, 86.8, 89.4, 89.4, 89.4, 89.4, 88.8, 89.4, 89.4, 87.6, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 88.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.0, 89.4, 89.4], "episode_lengths": [4, 4, 4, 4, 4, 25, 4, 4, 4, 4, 4, 4, 4, 4, 6, 4, 4, 15, 4, 4, 4, 4, 4, 6, 4, 4, 4, 4, 4, 4, 25, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 6, 4, 4, 4, 4, 15, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 4, 4, 4, 4, 4, 10, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 25, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 25, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 4, 4, 4, 4, 4, 17, 4, 4, 4, 4, 7, 4, 4, 13, 4, 4, 25, 4, 4, 4, 4, 4, 25, 9, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 4, 4], "policy_shared_policy_reward": [-10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.5, 99.5, -10.3, 99.7, 99.7, -10.3, 98.6, -11.4, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.5, -10.5, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.6, -10.4, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.6, -10.4, 99.7, -10.3, 99.7, -10.3, -10.5, 99.5, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 98.6, -11.4, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.5, -10.5, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.9, 99.1, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.4, -10.6, 99.7, -10.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.5, -10.5, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.5, -10.5, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 98.4, -11.6, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.6, 99.4, -10.3, 99.7, -10.3, 99.7, -11.2, 98.8, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.2, -10.8, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.5, -10.5, -10.3, 99.7, 99.7, -10.3]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4202459605349729, "mean_inference_ms": 1.656229973185143, "mean_action_processing_ms": 0.08955260318404193, "mean_env_wait_ms": 0.08704340325270846, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 33000, "timesteps_this_iter": 0, "agent_timesteps_total": 66000, "timers": {"sample_time_ms": 412.517, "sample_throughput": 2424.143, "load_time_ms": 1.292, "load_throughput": 773885.383, "learn_time_ms": 98.649, "learn_throughput": 10136.965, "update_time_ms": 2.793}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 6.103515625e-06, "cur_lr": 0.0005000000000000001, "total_loss": 2744.739794921875, "policy_loss": -0.002733457274734974, "vf_loss": 2744.748193359375, "vf_explained_var": 0.002469426393508911, "kl": 0.008005765061311542, "entropy": 0.564873319864273, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 33000, "num_agent_steps_sampled": 66000, "num_steps_trained": 33000, "num_agent_steps_trained": 66000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2863, "training_iteration": 33, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-49", "timestamp": 1749778549, "time_this_iter_s": 0.39614033699035645, "time_total_s": 12.42083740234375, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c9c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 12.42083740234375, "timesteps_since_restore": 0, "iterations_since_restore": 33, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 86.34666666666666, "episode_len_mean": 5.38974358974359, "episode_media": {}, "episodes_this_iter": 195, "policy_reward_min": {"shared_policy": -12.200000000000001}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 43.17333333333333}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 86.39999999999999, 89.4, 89.4, 89.4, 86.39999999999999, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 86.2, 89.4, 89.4, 89.4, 89.4, 88.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.2, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.2, 89.4, 89.4, 89.4, 89.4, 89.4, 88.6, 89.4, 89.4, 89.4, 89.4, 89.0, 89.0, 89.0, 89.4, 89.4, 88.0, 89.4, 89.0, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.2, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.0, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.2, 85.8, 88.8, 89.4, 89.4, 88.6, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 87.0, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 87.8, 89.4, 89.4, 89.0, 89.4, 85.6, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4], "episode_lengths": [25, 19, 4, 4, 4, 19, 4, 4, 4, 4, 4, 4, 4, 4, 4, 25, 20, 4, 4, 4, 4, 9, 4, 4, 4, 4, 4, 5, 4, 25, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 8, 4, 4, 4, 4, 6, 6, 6, 4, 4, 11, 4, 6, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 25, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 25, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 22, 7, 4, 4, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 16, 4, 4, 4, 4, 4, 4, 12, 4, 4, 6, 4, 23, 4, 4, 4, 25, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, 98.2, -11.8, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 98.2, -11.8, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 98.1, -11.9, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.8, 99.2, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.6, -10.4, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.4, 99.6, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.6, -10.4, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.7, 99.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.5, -10.5, 99.5, -10.5, -10.5, 99.5, 99.7, -10.3, -10.3, 99.7, -11.0, 99.0, 99.7, -10.3, -10.5, 99.5, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.4, 99.6, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.6, -10.4, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.5, -10.5, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.6, -10.4, -12.100000000000001, 97.9, -10.6, 99.4, -10.3, 99.7, 99.7, -10.3, 99.3, -10.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.4, 99.6, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -11.5, 98.5, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 98.9, -11.1, 99.7, -10.3, -10.3, 99.7, -10.5, 99.5, 99.7, -10.3, -12.200000000000001, 97.8, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.42697980781213324, "mean_inference_ms": 1.6568110050443028, "mean_action_processing_ms": 0.08954909403613757, "mean_env_wait_ms": 0.08706829694360341, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 34000, "timesteps_this_iter": 0, "agent_timesteps_total": 68000, "timers": {"sample_time_ms": 413.966, "sample_throughput": 2415.655, "load_time_ms": 1.305, "load_throughput": 766334.868, "learn_time_ms": 100.133, "learn_throughput": 9986.759, "update_time_ms": 2.903}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 6.103515625e-06, "cur_lr": 0.0005000000000000001, "total_loss": 2906.1428466796874, "policy_loss": -0.005730370432138443, "vf_loss": 2906.1542236328123, "vf_explained_var": 0.003396683931350708, "kl": 0.013053154598772387, "entropy": 0.5599461197853088, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 34000, "num_agent_steps_sampled": 68000, "num_steps_trained": 34000, "num_agent_steps_trained": 68000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3058, "training_iteration": 34, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-50", "timestamp": 1749778550, "time_this_iter_s": 0.38263916969299316, "time_total_s": 12.803476572036743, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 12.803476572036743, "timesteps_since_restore": 0, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 68.5, "ram_util_percent": 91.8}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 86.07374301675976, "episode_len_mean": 5.5139664804469275, "episode_media": {}, "episodes_this_iter": 179, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 43.03687150837988}, "custom_metrics": {}, "hist_stats": {"episode_reward": [89.2, 89.4, 89.4, 89.4, 89.4, 88.0, 86.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 87.6, 89.4, 89.4, 87.8, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 88.8, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.0, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 88.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.2, 89.4, 89.4, 89.4, 89.4, 89.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.0, 89.4, 87.0, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 88.0, 89.4, 89.4, 89.4, 89.4, 89.4, 88.2, 89.4, 89.4, -4.999999999999998, 89.0, 89.4, 89.4, 89.4, 88.6, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 85.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 85.8, 89.4, 89.2, 89.4, -4.999999999999998, 89.4, 89.4, 88.8, 89.4, 86.39999999999999, 89.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4], "episode_lengths": [5, 4, 4, 4, 4, 11, 20, 4, 4, 4, 4, 4, 4, 13, 4, 4, 12, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 25, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 25, 4, 4, 4, 4, 4, 4, 4, 4, 6, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 9, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 6, 4, 16, 4, 25, 4, 4, 4, 4, 11, 4, 4, 4, 4, 4, 10, 4, 4, 25, 6, 4, 4, 4, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 25, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 25, 22, 4, 5, 4, 25, 4, 4, 7, 4, 19, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4], "policy_shared_policy_reward": [-10.4, 99.6, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.0, -11.0, -11.9, 98.1, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 98.8, -11.2, -10.3, 99.7, 99.7, -10.3, 98.9, -11.1, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.4, -10.6, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.5, -10.5, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.2, -10.8, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.6, -10.4, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.6, -10.4, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.5, 99.5, 99.7, -10.3, 98.5, -11.5, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -11.0, 99.0, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.1, -10.9, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.5, -10.5, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.3, -10.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -12.4, 97.6, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -10.3, 99.7, 99.6, -10.4, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, -10.6, 99.4, -10.3, 99.7, 98.2, -11.8, 99.6, -10.4, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4312092614882778, "mean_inference_ms": 1.6542066500432882, "mean_action_processing_ms": 0.08936868765767174, "mean_env_wait_ms": 0.08690385152134922, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 35000, "timesteps_this_iter": 0, "agent_timesteps_total": 70000, "timers": {"sample_time_ms": 416.863, "sample_throughput": 2398.867, "load_time_ms": 1.264, "load_throughput": 791363.182, "learn_time_ms": 100.196, "learn_throughput": 9980.462, "update_time_ms": 2.852}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 6.103515625e-06, "cur_lr": 0.0005000000000000001, "total_loss": 2741.5271728515627, "policy_loss": -0.0033454112708568573, "vf_loss": 2741.535888671875, "vf_explained_var": 0.006620842218399048, "kl": 0.007161905509695643, "entropy": 0.5445680856704712, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 35000, "num_agent_steps_sampled": 70000, "num_steps_trained": 35000, "num_agent_steps_trained": 70000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3237, "training_iteration": 35, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-50", "timestamp": 1749778550, "time_this_iter_s": 0.37741875648498535, "time_total_s": 13.180895328521729, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 13.180895328521729, "timesteps_since_restore": 0, "iterations_since_restore": 35, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 85.10165745856352, "episode_len_mean": 5.558011049723757, "episode_media": {}, "episodes_this_iter": 181, "policy_reward_min": {"shared_policy": -12.0}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 42.550828729281776}, "custom_metrics": {}, "hist_stats": {"episode_reward": [89.4, 89.4, 89.4, 89.4, 89.4, 89.2, 89.4, 89.4, 89.4, 88.2, 89.4, 89.4, 89.4, 89.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 86.8, 89.2, 88.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 86.6, 89.4, 89.4, 89.4, 86.0, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.0, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.2, 89.4, 89.4, 87.6, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 87.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.0, 89.0, 87.8, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 88.8, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.2, 89.0, 89.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 87.0, 89.4, 89.2, 89.4, -4.999999999999998, 89.4], "episode_lengths": [4, 4, 4, 4, 4, 5, 4, 4, 4, 10, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 17, 5, 9, 4, 4, 4, 25, 4, 4, 18, 4, 4, 4, 21, 4, 4, 4, 4, 4, 4, 6, 4, 4, 4, 4, 4, 25, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 13, 4, 4, 4, 25, 4, 15, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 25, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 6, 12, 4, 4, 25, 4, 4, 4, 4, 4, 4, 4, 25, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 25, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 5, 6, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 16, 4, 5, 4, 25, 4], "policy_shared_policy_reward": [-10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.6, -10.4, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.9, 99.1, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.6, -10.4, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.4, 99.6, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -11.6, 98.4, -10.4, 99.6, -10.8, 99.2, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, 98.3, -11.700000000000001, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -12.0, 98.0, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.5, 99.5, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.6, -10.4, 99.7, -10.3, -10.3, 99.7, -11.2, 98.8, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.6, -11.4, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.5, 99.5, -10.5, 99.5, 98.9, -11.1, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.4, -10.6, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.4, 99.6, -10.5, 99.5, -10.4, 99.6, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 98.5, -11.5, -10.3, 99.7, 99.6, -10.4, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4352916476420292, "mean_inference_ms": 1.649991138072926, "mean_action_processing_ms": 0.08912042891304638, "mean_env_wait_ms": 0.08697646214675182, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 36000, "timesteps_this_iter": 0, "agent_timesteps_total": 72000, "timers": {"sample_time_ms": 418.02, "sample_throughput": 2392.23, "load_time_ms": 1.233, "load_throughput": 811120.48, "learn_time_ms": 99.829, "learn_throughput": 10017.133, "update_time_ms": 2.781}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 6.103515625e-06, "cur_lr": 0.0005000000000000001, "total_loss": 2630.5908447265624, "policy_loss": -0.002021106891334057, "vf_loss": 2630.5984375, "vf_explained_var": 0.019677329063415527, "kl": 0.004117630024121755, "entropy": 0.5589711129665375, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 36000, "num_agent_steps_sampled": 72000, "num_steps_trained": 36000, "num_agent_steps_trained": 72000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3418, "training_iteration": 36, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-50", "timestamp": 1749778550, "time_this_iter_s": 0.3959076404571533, "time_total_s": 13.576802968978882, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 13.576802968978882, "timesteps_since_restore": 0, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 59.3, "ram_util_percent": 91.8}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 82.92847682119204, "episode_len_mean": 6.490066225165563, "episode_media": {}, "episodes_this_iter": 151, "policy_reward_min": {"shared_policy": -12.200000000000001}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 41.464238410596025}, "custom_metrics": {}, "hist_stats": {"episode_reward": [89.4, 89.4, -4.999999999999998, 89.0, 89.4, 89.4, 89.4, 87.6, 88.0, 89.4, 89.4, 89.4, 89.4, 87.2, -4.999999999999998, 89.4, -4.999999999999998, 89.4, 89.4, 86.8, 89.4, 89.4, 89.4, 89.4, 89.4, 87.2, 89.4, 89.0, 89.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 85.8, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 88.6, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 86.6, 89.4, 89.4, 89.4, 89.4, 85.8, 89.4, 89.4, 89.4, 85.6, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.2, 89.4, 89.4, 89.2, 89.4, 89.4, 89.4, 87.6, 86.2, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 87.6, 89.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4], "episode_lengths": [4, 4, 25, 6, 4, 4, 4, 13, 11, 4, 4, 4, 4, 15, 25, 4, 25, 4, 4, 17, 4, 4, 4, 4, 4, 15, 4, 6, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 25, 4, 4, 4, 4, 4, 25, 4, 4, 22, 4, 4, 4, 4, 4, 4, 4, 4, 4, 25, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 25, 4, 4, 25, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 8, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 4, 4, 4, 22, 4, 4, 4, 23, 4, 4, 4, 25, 4, 4, 4, 4, 5, 4, 4, 5, 4, 4, 4, 13, 20, 25, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 13, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4], "policy_shared_policy_reward": [-10.3, 99.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -11.2, 98.8, 99.0, -11.0, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 98.6, -11.4, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, 98.4, -11.6, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 98.6, -11.4, -10.3, 99.7, 99.5, -10.5, -10.4, 99.6, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, 97.9, -12.100000000000001, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.7, 99.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -11.700000000000001, 98.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 97.9, -12.100000000000001, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -12.200000000000001, 97.8, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.6, -10.4, 99.7, -10.3, 99.7, -10.3, 99.6, -10.4, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 98.8, -11.2, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 98.8, -11.2, -10.4, 99.6, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.43718017248662994, "mean_inference_ms": 1.6550942475104733, "mean_action_processing_ms": 0.0893788373620627, "mean_env_wait_ms": 0.08724049082715357, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 37000, "timesteps_this_iter": 0, "agent_timesteps_total": 74000, "timers": {"sample_time_ms": 418.607, "sample_throughput": 2388.874, "load_time_ms": 1.159, "load_throughput": 862475.376, "learn_time_ms": 100.101, "learn_throughput": 9989.932, "update_time_ms": 2.736}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 3.0517578125e-06, "cur_lr": 0.0005000000000000001, "total_loss": 2368.5734130859373, "policy_loss": -0.0044259242713451385, "vf_loss": 2368.58388671875, "vf_explained_var": 0.021691906452178954, "kl": 0.00719183753750059, "entropy": 0.60228191614151, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 37000, "num_agent_steps_sampled": 74000, "num_steps_trained": 37000, "num_agent_steps_trained": 74000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3569, "training_iteration": 37, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-51", "timestamp": 1749778551, "time_this_iter_s": 0.38264989852905273, "time_total_s": 13.959452867507935, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb01b0b38b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 13.959452867507935, "timesteps_since_restore": 0, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 62.5, "ram_util_percent": 91.7}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 84.11029411764706, "episode_len_mean": 7.235294117647059, "episode_media": {}, "episodes_this_iter": 136, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 42.05514705882353}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 86.6, 89.4, 86.0, 89.4, 89.4, 89.4, 89.4, 89.4, 85.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 85.6, 89.4, 89.4, 89.4, -4.999999999999998, -4.999999999999998, 89.4, 89.4, 89.4, 87.8, 89.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 85.2, 89.4, 89.0, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 88.2, 89.4, 88.0, 87.4, 88.6, 87.8, 87.4, 88.0, 89.4, 89.4, 86.8, 89.4, 89.4, 89.4, 88.4, 89.4, 88.6, 89.4, 86.6, 89.4, 89.4, 89.4, 88.2, 89.4, 89.4, 88.6, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 88.8, 89.4, 89.4, 89.4, -4.999999999999998, 89.2, 89.4, 87.8, 89.4, 89.2, 89.4, 89.4, 87.2, 87.2, 89.4, 89.4, 89.4, 89.4, 87.2, 89.4, 89.4, 89.4, 87.0, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 89.4, 89.4, 86.8, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 87.4, 87.8, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 88.4, 89.4, 89.4], "episode_lengths": [25, 4, 4, 4, 4, 4, 25, 18, 4, 21, 4, 4, 4, 4, 4, 24, 4, 4, 4, 4, 4, 4, 23, 4, 4, 4, 25, 25, 4, 4, 4, 12, 4, 4, 4, 4, 4, 25, 4, 4, 4, 25, 4, 6, 4, 4, 4, 4, 4, 4, 4, 4, 4, 10, 4, 11, 14, 8, 12, 14, 11, 4, 4, 17, 4, 4, 4, 9, 4, 8, 4, 18, 4, 4, 4, 10, 4, 4, 8, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 25, 5, 4, 12, 4, 5, 4, 4, 15, 15, 4, 4, 4, 4, 15, 4, 4, 4, 16, 4, 25, 4, 4, 4, 4, 4, 17, 4, 4, 4, 4, 4, 4, 14, 12, 4, 4, 4, 4, 4, 4, 4, 4, 9, 4, 4], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, 99.7, -10.3, -12.0, 98.0, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -12.3, 97.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -12.200000000000001, 97.8, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 98.9, -11.1, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -12.4, 97.6, 99.7, -10.3, 99.5, -10.5, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.1, -10.9, -10.3, 99.7, 99.0, -11.0, 98.7, -11.3, 99.3, -10.7, 98.9, -11.1, -11.3, 98.7, 99.0, -11.0, 99.7, -10.3, 99.7, -10.3, -11.6, 98.4, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.8, 99.2, -10.3, 99.7, -10.7, 99.3, -10.3, 99.7, -11.700000000000001, 98.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.9, 99.1, -10.3, 99.7, -10.3, 99.7, 99.3, -10.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.6, 99.4, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.6, -10.4, 99.7, -10.3, -11.1, 98.9, 99.7, -10.3, 99.6, -10.4, -10.3, 99.7, -10.3, 99.7, 98.6, -11.4, 98.6, -11.4, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 98.6, -11.4, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 98.5, -11.5, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 98.4, -11.6, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 98.7, -11.3, 98.9, -11.1, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.2, -10.8, -10.3, 99.7, -10.3, 99.7]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.44061162060478254, "mean_inference_ms": 1.6529516767196941, "mean_action_processing_ms": 0.08928015751340351, "mean_env_wait_ms": 0.08707229417389162, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 38000, "timesteps_this_iter": 0, "agent_timesteps_total": 76000, "timers": {"sample_time_ms": 420.316, "sample_throughput": 2379.161, "load_time_ms": 1.043, "load_throughput": 958873.394, "learn_time_ms": 99.853, "learn_throughput": 10014.677, "update_time_ms": 2.677}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 3.0517578125e-06, "cur_lr": 0.0005000000000000001, "total_loss": 2530.515869140625, "policy_loss": -0.005789647996425629, "vf_loss": 2530.5281494140627, "vf_explained_var": 0.005700349807739258, "kl": 0.005989937676905166, "entropy": 0.64336878657341, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 38000, "num_agent_steps_sampled": 76000, "num_steps_trained": 38000, "num_agent_steps_trained": 76000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3705, "training_iteration": 38, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-51", "timestamp": 1749778551, "time_this_iter_s": 0.39806318283081055, "time_total_s": 14.357516050338745, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 14.357516050338745, "timesteps_since_restore": 0, "iterations_since_restore": 38, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 82.56833333333334, "episode_len_mean": 8.091666666666667, "episode_media": {}, "episodes_this_iter": 120, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 41.28416666666667}, "custom_metrics": {}, "hist_stats": {"episode_reward": [89.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 86.8, 88.2, 89.4, 89.4, 87.6, 88.8, 88.0, 89.4, 89.4, 88.2, 87.6, 89.4, 89.4, 89.0, 87.8, 89.4, 88.2, 89.4, 89.4, 89.4, 89.4, 85.6, 89.4, 89.4, 85.2, 89.4, 85.2, 89.4, 89.4, 89.4, -4.999999999999998, 88.0, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 87.2, 89.4, 88.2, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, 88.6, 89.4, -4.999999999999998, 89.0, 89.4, 89.4, 89.4, 89.4, 88.2, 89.4, 85.2, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 85.2, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 89.4, 86.2, 86.8, 89.4, 89.4, -4.999999999999998, 88.4, 89.4, 89.4, 88.6, 89.4, 88.6, -4.999999999999998, 89.4, 89.4, 88.0, 89.4, 89.4, 89.4, 89.4, 89.0, 89.0, 89.4, 87.8, 89.2, 89.4, 89.4, 89.4, 85.6, 89.4, 89.4, 89.4, 86.8, -4.999999999999998, 87.0, 89.4, 89.4, 88.0, 89.0, 89.4, 89.4, 89.4], "episode_lengths": [4, 4, 4, 25, 4, 4, 4, 17, 10, 4, 4, 13, 7, 11, 4, 4, 10, 13, 4, 4, 6, 12, 4, 10, 4, 4, 4, 4, 23, 4, 4, 25, 4, 25, 4, 4, 4, 25, 11, 4, 4, 4, 4, 4, 4, 4, 4, 15, 4, 10, 4, 4, 4, 4, 25, 8, 4, 25, 6, 4, 4, 4, 4, 10, 4, 25, 4, 25, 4, 4, 4, 25, 4, 4, 4, 4, 4, 4, 4, 20, 17, 4, 4, 25, 9, 4, 4, 8, 4, 8, 25, 4, 4, 11, 4, 4, 4, 4, 6, 6, 4, 12, 5, 4, 4, 4, 23, 4, 4, 4, 17, 25, 16, 4, 4, 11, 6, 4, 4, 4], "policy_shared_policy_reward": [99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -11.6, 98.4, -10.9, 99.1, -10.3, 99.7, 99.7, -10.3, 98.8, -11.2, -10.6, 99.4, 99.0, -11.0, 99.7, -10.3, 99.7, -10.3, 99.1, -10.9, -11.2, 98.8, 99.7, -10.3, 99.7, -10.3, -10.5, 99.5, 98.9, -11.1, 99.7, -10.3, 99.1, -10.9, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -12.200000000000001, 97.8, -10.3, 99.7, -10.3, 99.7, 97.6, -12.4, 99.7, -10.3, 97.6, -12.4, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.0, -11.0, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -11.4, 98.6, -10.3, 99.7, 99.1, -10.9, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.5, -10.5, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, 99.1, -10.9, -10.3, 99.7, 97.6, -12.4, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -12.4, 97.6, 99.7, -10.3, -10.3, 99.7, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 98.1, -11.9, 98.4, -11.6, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -10.3, 99.7, 99.7, -10.3, -10.7, 99.3, 99.7, -10.3, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.7, -10.3, 99.0, -11.0, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.5, -10.5, 99.5, -10.5, -10.3, 99.7, 98.9, -11.1, -10.4, 99.6, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 97.8, -12.200000000000001, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 98.4, -11.6, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -10.3, 99.7, 99.7, -10.3, 99.0, -11.0, 99.5, -10.5, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.442146308135041, "mean_inference_ms": 1.6502079454984444, "mean_action_processing_ms": 0.089112157181146, "mean_env_wait_ms": 0.08700001415998153, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 39000, "timesteps_this_iter": 0, "agent_timesteps_total": 78000, "timers": {"sample_time_ms": 419.744, "sample_throughput": 2382.405, "load_time_ms": 1.113, "load_throughput": 898234.072, "learn_time_ms": 98.978, "learn_throughput": 10103.3, "update_time_ms": 2.626}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 3.0517578125e-06, "cur_lr": 0.0005000000000000001, "total_loss": 2330.6529296875, "policy_loss": -0.0061913427023682745, "vf_loss": 2330.6657958984374, "vf_explained_var": 0.01294562816619873, "kl": 0.005808151398253081, "entropy": 0.6687566459178924, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 39000, "num_agent_steps_sampled": 78000, "num_steps_trained": 39000, "num_agent_steps_trained": 78000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3825, "training_iteration": 39, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-52", "timestamp": 1749778552, "time_this_iter_s": 0.3599822521209717, "time_total_s": 14.717498302459717, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f58b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 14.717498302459717, "timesteps_since_restore": 0, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 65.7, "ram_util_percent": 91.7}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 78.34495412844035, "episode_len_mean": 9.623853211009175, "episode_media": {}, "episodes_this_iter": 109, "policy_reward_min": {"shared_policy": -12.3}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 39.17247706422018}, "custom_metrics": {}, "hist_stats": {"episode_reward": [85.4, 89.0, 88.6, -4.999999999999998, 87.4, 87.6, 85.4, -4.999999999999998, 89.4, 85.8, 89.4, 89.4, 88.2, 89.4, 88.2, 87.0, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 88.6, 89.4, 89.4, 88.6, 89.4, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 87.6, 89.4, -4.999999999999998, 89.4, 88.6, 88.0, 87.0, 88.6, 87.4, -4.999999999999998, 89.4, -4.999999999999998, 87.4, -4.999999999999998, 89.2, 89.4, 89.4, 89.4, 89.4, 89.2, 89.4, 88.6, 89.4, 88.2, 89.4, -4.999999999999998, 89.2, 89.4, 89.4, 88.4, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, 88.0, 87.4, 89.4, 88.0, 89.4, 89.4, 87.8, 89.4, 89.4, 89.4, 89.4, 89.4, 86.6, 89.4, 89.4, 89.4, 88.6, -4.999999999999998, 89.4, 88.2, 89.4, 86.4, -4.999999999999998, 89.4, 87.8, 86.2, 88.6, 89.2, 88.0, 86.39999999999999, 89.4, 89.4, 89.4, 89.0, 86.39999999999999, 85.6, 89.4, 88.4, 89.4, 89.4, 87.6], "episode_lengths": [24, 6, 8, 25, 14, 13, 24, 25, 4, 22, 4, 4, 10, 4, 10, 16, 4, 4, 4, 25, 4, 4, 4, 8, 4, 4, 8, 4, 4, 25, 4, 4, 4, 13, 4, 25, 4, 8, 11, 16, 8, 14, 25, 4, 25, 14, 25, 5, 4, 4, 4, 4, 5, 4, 8, 4, 10, 4, 25, 5, 4, 4, 9, 4, 4, 4, 25, 4, 11, 14, 4, 11, 4, 4, 12, 4, 4, 4, 4, 4, 18, 4, 4, 4, 8, 25, 4, 10, 4, 19, 25, 4, 12, 20, 8, 5, 11, 19, 4, 4, 4, 6, 19, 23, 4, 9, 4, 4, 13], "policy_shared_policy_reward": [-12.3, 97.7, -10.5, 99.5, 99.3, -10.7, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -11.2, 98.8, 97.7, -12.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 97.9, -12.100000000000001, 99.7, -10.3, 99.7, -10.3, 99.1, -10.9, 99.7, -10.3, 99.1, -10.9, 98.5, -11.5, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.3, -10.7, 99.7, -10.3, 99.7, -10.3, 99.3, -10.7, -10.3, 99.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 98.8, -11.2, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.3, -10.7, 99.0, -11.0, 98.5, -11.5, -10.7, 99.3, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, 99.6, -10.4, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.6, -10.4, -10.3, 99.7, 99.3, -10.7, 99.7, -10.3, -10.9, 99.1, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.6, -10.4, 99.7, -10.3, 99.7, -10.3, -10.8, 99.2, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.0, -11.0, 98.7, -11.3, 99.7, -10.3, 99.0, -11.0, 99.7, -10.3, 99.7, -10.3, -11.1, 98.9, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 98.3, -11.700000000000001, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -10.7, 99.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.1, -10.9, 99.7, -10.3, -11.8, 98.2, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.9, -11.1, 98.1, -11.9, -10.7, 99.3, 99.6, -10.4, 99.0, -11.0, 98.2, -11.8, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.5, -10.5, 98.2, -11.8, -12.200000000000001, 97.8, 99.7, -10.3, -10.8, 99.2, 99.7, -10.3, 99.7, -10.3, -11.2, 98.8]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.44256506244366767, "mean_inference_ms": 1.654721379777309, "mean_action_processing_ms": 0.0893521473290091, "mean_env_wait_ms": 0.08691054107613606, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 40000, "timesteps_this_iter": 0, "agent_timesteps_total": 80000, "timers": {"sample_time_ms": 417.975, "sample_throughput": 2392.486, "load_time_ms": 1.173, "load_throughput": 852708.791, "learn_time_ms": 98.827, "learn_throughput": 10118.653, "update_time_ms": 2.52}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 3.0517578125e-06, "cur_lr": 0.0005000000000000001, "total_loss": 2289.3349365234376, "policy_loss": -0.00781699102371931, "vf_loss": 2289.3498046875, "vf_explained_var": 0.015284836292266846, "kl": 0.008832442589244937, "entropy": 0.711147916316986, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 40000, "num_agent_steps_sampled": 80000, "num_steps_trained": 40000, "num_agent_steps_trained": 80000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3934, "training_iteration": 40, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-52", "timestamp": 1749778552, "time_this_iter_s": 0.3687410354614258, "time_total_s": 15.086239337921143, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182f4040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 15.086239337921143, "timesteps_since_restore": 0, "iterations_since_restore": 40, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 73.36599999999999, "episode_len_mean": 12.01, "episode_media": {}, "episodes_this_iter": 80, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 36.683}, "custom_metrics": {}, "hist_stats": {"episode_reward": [86.4, -4.999999999999998, 89.4, 87.8, 86.2, 88.6, 89.2, 88.0, 86.39999999999999, 89.4, 89.4, 89.4, 89.0, 86.39999999999999, 85.6, 89.4, 88.4, 89.4, 89.4, 87.6, 87.2, 85.4, 89.2, -4.999999999999998, 89.4, 88.2, 87.6, -4.999999999999998, 85.4, 86.8, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, 89.4, 88.0, 88.0, 89.4, 89.4, -4.999999999999998, 88.2, 88.2, 88.8, 87.6, 89.4, 85.4, 89.4, 89.4, -4.999999999999998, 89.4, 89.2, 89.4, 89.4, 89.4, 89.4, 88.2, -4.999999999999998, 89.0, 87.8, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 87.6, -4.999999999999998, 88.2, 89.4, 89.4, -4.999999999999998, 86.6, -4.999999999999998, 85.2, 89.4, 89.4, 89.4, 88.2, 89.4, 89.4, 88.0, 88.4, 89.4, 86.2, 85.6, 89.4, -4.999999999999998, 89.4, 85.4, 86.8, 86.6, 89.4, 89.4, 89.2, 89.4, -4.999999999999998, 88.6, -4.999999999999998, 86.39999999999999, 89.4, 88.2], "episode_lengths": [19, 25, 4, 12, 20, 8, 5, 11, 19, 4, 4, 4, 6, 19, 23, 4, 9, 4, 4, 13, 15, 24, 5, 25, 4, 10, 13, 25, 24, 17, 25, 25, 22, 25, 4, 11, 11, 4, 4, 25, 10, 10, 7, 13, 4, 24, 4, 4, 25, 4, 5, 4, 4, 4, 4, 10, 25, 6, 12, 4, 25, 4, 4, 4, 13, 25, 10, 4, 4, 25, 18, 25, 25, 4, 4, 4, 10, 4, 4, 11, 9, 4, 20, 23, 4, 25, 4, 24, 17, 18, 4, 4, 5, 4, 25, 8, 25, 19, 4, 10], "policy_shared_policy_reward": [-11.8, 98.2, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.9, -11.1, 98.1, -11.9, -10.7, 99.3, 99.6, -10.4, 99.0, -11.0, 98.2, -11.8, -10.3, 99.7, 99.7, -10.3, -10.3, 99.7, 99.5, -10.5, 98.2, -11.8, -12.200000000000001, 97.8, 99.7, -10.3, -10.8, 99.2, 99.7, -10.3, 99.7, -10.3, -11.2, 98.8, 98.6, -11.4, 97.7, -12.3, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.1, -10.9, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -12.3, 97.7, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.0, -11.0, 99.0, -11.0, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 99.1, -10.9, -10.6, 99.4, 98.8, -11.2, 99.7, -10.3, 97.7, -12.3, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.6, -10.4, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -10.5, 99.5, 98.9, -11.1, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, 98.8, -11.2, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -12.4, 97.6, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 99.1, -10.9, 99.7, -10.3, 99.7, -10.3, 99.0, -11.0, 99.2, -10.8, 99.7, -10.3, 98.1, -11.9, -12.200000000000001, 97.8, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 97.7, -12.3, 98.4, -11.6, 98.3, -11.700000000000001, 99.7, -10.3, -10.3, 99.7, 99.6, -10.4, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, 98.2, -11.8, 99.7, -10.3, 99.1, -10.9]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.44077223899233575, "mean_inference_ms": 1.651064361017061, "mean_action_processing_ms": 0.08949185029233693, "mean_env_wait_ms": 0.0869449413244833, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 41000, "timesteps_this_iter": 0, "agent_timesteps_total": 82000, "timers": {"sample_time_ms": 416.182, "sample_throughput": 2402.796, "load_time_ms": 1.174, "load_throughput": 851583.457, "learn_time_ms": 98.455, "learn_throughput": 10156.974, "update_time_ms": 2.467}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 3.0517578125e-06, "cur_lr": 0.0005000000000000001, "total_loss": 1903.1182983398437, "policy_loss": -0.006010208837687969, "vf_loss": 1903.1314086914062, "vf_explained_var": 0.037733012437820436, "kl": 0.014342811586983473, "entropy": 0.7122542679309845, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 41000, "num_agent_steps_sampled": 82000, "num_steps_trained": 41000, "num_agent_steps_trained": 82000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 4014, "training_iteration": 41, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-52", "timestamp": 1749778552, "time_this_iter_s": 0.36753368377685547, "time_total_s": 15.453773021697998, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182f4160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 15.453773021697998, "timesteps_since_restore": 0, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 59.4, "ram_util_percent": 91.7}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 67.814, "episode_len_mean": 12.71, "episode_media": {}, "episodes_this_iter": 80, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 33.907}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.4, 89.4, 86.2, 85.6, 89.4, -4.999999999999998, 89.4, 85.4, 86.8, 86.6, 89.4, 89.4, 89.2, 89.4, -4.999999999999998, 88.6, -4.999999999999998, 86.39999999999999, 89.4, 88.2, 88.0, 89.0, 89.4, 86.8, 89.4, 89.4, 89.4, -4.999999999999998, 89.4, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 89.4, 88.2, 88.6, 89.4, 89.4, -4.999999999999998, 89.4, 85.6, 85.4, 85.2, 86.39999999999999, 87.4, 89.4, 87.8, 89.4, 89.4, 88.6, 89.4, 89.0, 86.6, 89.4, 89.4, 86.8, -4.999999999999998, 88.6, -4.999999999999998, 89.4, -4.999999999999998, 88.4, 89.4, -4.999999999999998, 87.4, 86.6, -4.999999999999998, -4.999999999999998, 89.4, 86.39999999999999, 89.4, 88.2, 89.2, 89.4, 89.4, 89.4, 87.4, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 88.8, 89.4, 89.4, 89.4, 89.4, 85.8, 87.6, 88.2, -4.999999999999998, 89.4, 88.2, -4.999999999999998, -4.999999999999998, 89.2, 89.4, 86.0, -4.999999999999998], "episode_lengths": [9, 4, 20, 23, 4, 25, 4, 24, 17, 18, 4, 4, 5, 4, 25, 8, 25, 19, 4, 10, 11, 6, 4, 17, 4, 4, 4, 25, 4, 25, 4, 25, 25, 25, 17, 4, 10, 8, 4, 4, 25, 4, 23, 24, 25, 19, 14, 4, 12, 4, 4, 8, 4, 6, 18, 4, 4, 17, 25, 8, 25, 4, 25, 9, 4, 25, 14, 18, 25, 25, 4, 19, 4, 10, 5, 4, 4, 4, 14, 25, 25, 4, 25, 7, 4, 4, 4, 4, 22, 13, 10, 25, 4, 10, 25, 25, 5, 4, 21, 25], "policy_shared_policy_reward": [99.2, -10.8, 99.7, -10.3, 98.1, -11.9, -12.200000000000001, 97.8, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 97.7, -12.3, 98.4, -11.6, 98.3, -11.700000000000001, 99.7, -10.3, -10.3, 99.7, 99.6, -10.4, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, 98.2, -11.8, 99.7, -10.3, 99.1, -10.9, 99.0, -11.0, 99.5, -10.5, -10.3, 99.7, 98.4, -11.6, 99.7, -10.3, -10.3, 99.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -10.3, 99.7, -10.9, 99.1, -10.7, 99.3, 99.7, -10.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 97.8, -12.200000000000001, 97.7, -12.3, -12.4, 97.6, 98.2, -11.8, 98.7, -11.3, 99.7, -10.3, 98.9, -11.1, -10.3, 99.7, 99.7, -10.3, 99.3, -10.7, 99.7, -10.3, -10.5, 99.5, -11.700000000000001, 98.3, 99.7, -10.3, 99.7, -10.3, 98.4, -11.6, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.2, -10.8, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.3, 98.7, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.2, -11.8, -10.3, 99.7, 99.1, -10.9, -10.4, 99.6, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -12.100000000000001, 97.9, -11.2, 98.8, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.6, -10.4, 99.7, -10.3, 98.0, -12.0, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4394712772880737, "mean_inference_ms": 1.6452657810211457, "mean_action_processing_ms": 0.08890920085315163, "mean_env_wait_ms": 0.08666438483655535, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 42000, "timesteps_this_iter": 0, "agent_timesteps_total": 84000, "timers": {"sample_time_ms": 413.323, "sample_throughput": 2419.413, "load_time_ms": 1.103, "load_throughput": 906778.51, "learn_time_ms": 99.418, "learn_throughput": 10058.558, "update_time_ms": 2.575}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 3.0517578125e-06, "cur_lr": 0.0005000000000000001, "total_loss": 1788.6384399414062, "policy_loss": -0.0023922599852085114, "vf_loss": 1788.6479614257812, "vf_explained_var": 0.02480294108390808, "kl": 0.00693866250717261, "entropy": 0.710649573802948, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 42000, "num_agent_steps_sampled": 84000, "num_steps_trained": 42000, "num_agent_steps_trained": 84000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 4094, "training_iteration": 42, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-53", "timestamp": 1749778553, "time_this_iter_s": 0.37558650970458984, "time_total_s": 15.829359531402588, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb01b0b38b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 15.829359531402588, "timesteps_since_restore": 0, "iterations_since_restore": 42, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 61.20399999999999, "episode_len_mean": 14.19, "episode_media": {}, "episodes_this_iter": 67, "policy_reward_min": {"shared_policy": -12.200000000000001}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 30.601999999999997}, "custom_metrics": {}, "hist_stats": {"episode_reward": [86.6, -4.999999999999998, -4.999999999999998, 89.4, 86.39999999999999, 89.4, 88.2, 89.2, 89.4, 89.4, 89.4, 87.4, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 88.8, 89.4, 89.4, 89.4, 89.4, 85.8, 87.6, 88.2, -4.999999999999998, 89.4, 88.2, -4.999999999999998, -4.999999999999998, 89.2, 89.4, 86.0, -4.999999999999998, 86.4, 88.4, 89.4, 87.8, -4.999999999999998, -4.999999999999998, 87.8, 87.8, -4.999999999999998, 89.2, -4.999999999999998, 86.4, 89.4, -4.999999999999998, 86.2, 87.2, -4.999999999999998, 88.2, 87.4, 87.8, -4.999999999999998, 85.8, -4.999999999999998, 89.4, 87.6, 88.0, 88.0, -4.999999999999998, 88.0, 89.4, -4.999999999999998, 89.4, 89.4, 89.4, 85.6, 89.4, -4.999999999999998, -4.999999999999998, 88.6, -4.999999999999998, 89.4, 89.4, -4.999999999999998, 88.4, -4.999999999999998, 87.2, 89.4, -4.999999999999998, 89.4, 85.8, 86.6, 89.4, 86.6, -4.999999999999998, 89.4, 86.6, 89.4, -4.999999999999998, -4.999999999999998, 89.4, 88.6, 85.8, 89.4, -4.999999999999998, 88.2, 85.8, 89.4], "episode_lengths": [18, 25, 25, 4, 19, 4, 10, 5, 4, 4, 4, 14, 25, 25, 4, 25, 7, 4, 4, 4, 4, 22, 13, 10, 25, 4, 10, 25, 25, 5, 4, 21, 25, 19, 9, 4, 12, 25, 25, 12, 12, 25, 5, 25, 19, 4, 25, 20, 15, 25, 10, 14, 12, 25, 22, 25, 4, 13, 11, 11, 25, 11, 4, 25, 4, 4, 4, 23, 4, 25, 25, 8, 25, 4, 4, 25, 9, 25, 15, 4, 25, 4, 22, 18, 4, 18, 25, 4, 18, 4, 25, 25, 4, 8, 22, 4, 25, 10, 22, 4], "policy_shared_policy_reward": [98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.2, -11.8, -10.3, 99.7, 99.1, -10.9, -10.4, 99.6, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -12.100000000000001, 97.9, -11.2, 98.8, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.6, -10.4, 99.7, -10.3, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -11.8, 98.2, 99.2, -10.8, 99.7, -10.3, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.9, 98.1, 98.6, -11.4, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 98.7, -11.3, 98.9, -11.1, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.8, -11.2, -11.0, 99.0, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 99.0, -11.0, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, 99.7, -10.3, -12.200000000000001, 97.8, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, 98.6, -11.4, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 97.9, -12.100000000000001, 98.3, -11.700000000000001, 99.7, -10.3, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.3, -11.700000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.3, -10.7, 97.9, -12.100000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 97.9, -12.100000000000001, 99.7, -10.3]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.43941610534384734, "mean_inference_ms": 1.6502916822673754, "mean_action_processing_ms": 0.08909284415000189, "mean_env_wait_ms": 0.08651639614759095, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 43000, "timesteps_this_iter": 0, "agent_timesteps_total": 86000, "timers": {"sample_time_ms": 410.795, "sample_throughput": 2434.303, "load_time_ms": 1.112, "load_throughput": 899486.168, "learn_time_ms": 100.24, "learn_throughput": 9976.096, "update_time_ms": 2.502}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 3.0517578125e-06, "cur_lr": 0.0005000000000000001, "total_loss": 1647.6274658203124, "policy_loss": -0.0039847100153565405, "vf_loss": 1647.6388305664063, "vf_explained_var": 0.033233237266540525, "kl": 0.004901184614175219, "entropy": 0.7340609490871429, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 43000, "num_agent_steps_sampled": 86000, "num_steps_trained": 43000, "num_agent_steps_trained": 86000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 4161, "training_iteration": 43, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-53", "timestamp": 1749778553, "time_this_iter_s": 0.36542725563049316, "time_total_s": 16.19478678703308, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c9af0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 16.19478678703308, "timesteps_since_restore": 0, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 57.1, "ram_util_percent": 91.5}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 61.06199999999999, "episode_len_mean": 14.9, "episode_media": {}, "episodes_this_iter": 65, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 30.531000000000002}, "custom_metrics": {}, "hist_stats": {"episode_reward": [89.4, 89.4, 85.6, 89.4, -4.999999999999998, -4.999999999999998, 88.6, -4.999999999999998, 89.4, 89.4, -4.999999999999998, 88.4, -4.999999999999998, 87.2, 89.4, -4.999999999999998, 89.4, 85.8, 86.6, 89.4, 86.6, -4.999999999999998, 89.4, 86.6, 89.4, -4.999999999999998, -4.999999999999998, 89.4, 88.6, 85.8, 89.4, -4.999999999999998, 88.2, 85.8, 89.4, 87.2, 89.4, 86.6, 89.4, -4.999999999999998, 88.2, 88.2, 86.39999999999999, 89.4, 88.2, 87.2, 89.4, -4.999999999999998, 89.4, 85.2, 89.4, 87.4, 88.8, 85.8, 89.4, 89.4, 87.2, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 86.2, 88.0, -4.999999999999998, -4.999999999999998, 85.2, -4.999999999999998, 89.4, -4.999999999999998, 89.4, 89.4, 86.0, 88.8, 85.4, 87.4, 87.8, -4.999999999999998, 86.0, 89.2, -4.999999999999998, 89.4, 89.4, 85.4, -4.999999999999998, 85.6, -4.999999999999998, 89.4, 89.4, -4.999999999999998, 87.4, 85.4, 89.4, 89.4, -4.999999999999998], "episode_lengths": [4, 4, 23, 4, 25, 25, 8, 25, 4, 4, 25, 9, 25, 15, 4, 25, 4, 22, 18, 4, 18, 25, 4, 18, 4, 25, 25, 4, 8, 22, 4, 25, 10, 22, 4, 15, 4, 18, 4, 25, 10, 10, 19, 4, 10, 15, 4, 25, 4, 25, 4, 14, 7, 22, 4, 4, 15, 25, 8, 25, 25, 15, 25, 25, 4, 25, 25, 20, 11, 25, 25, 25, 25, 4, 25, 4, 4, 21, 7, 24, 14, 12, 25, 21, 5, 25, 4, 4, 24, 25, 23, 25, 4, 4, 25, 14, 24, 4, 4, 25], "policy_shared_policy_reward": [99.7, -10.3, 99.7, -10.3, -12.200000000000001, 97.8, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, 98.6, -11.4, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 97.9, -12.100000000000001, 98.3, -11.700000000000001, 99.7, -10.3, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.3, -11.700000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.3, -10.7, 97.9, -12.100000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 97.9, -12.100000000000001, 99.7, -10.3, 98.6, -11.4, 99.7, -10.3, -11.700000000000001, 98.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -10.9, 99.1, 98.2, -11.8, 99.7, -10.3, -10.9, 99.1, -11.4, 98.6, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 97.6, -12.4, 99.7, -10.3, 98.7, -11.3, -10.6, 99.4, 97.9, -12.100000000000001, 99.7, -10.3, 99.7, -10.3, 98.6, -11.4, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.1, -11.9, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.7, -10.3, 98.0, -12.0, 99.4, -10.6, -12.3, 97.7, 98.7, -11.3, -11.1, 98.9, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -10.4, 99.6, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, 97.7, -12.3, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.3, 98.7, 97.7, -12.3, 99.7, -10.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.43735706499557153, "mean_inference_ms": 1.6496256256773176, "mean_action_processing_ms": 0.08907295619999829, "mean_env_wait_ms": 0.08638651157782036, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 44000, "timesteps_this_iter": 0, "agent_timesteps_total": 88000, "timers": {"sample_time_ms": 408.594, "sample_throughput": 2447.419, "load_time_ms": 1.216, "load_throughput": 822251.323, "learn_time_ms": 100.487, "learn_throughput": 9951.574, "update_time_ms": 2.441}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.52587890625e-06, "cur_lr": 0.0005000000000000001, "total_loss": 1663.1395141601563, "policy_loss": -0.002468825131654739, "vf_loss": 1663.149755859375, "vf_explained_var": 0.02320755124092102, "kl": 0.005418133872652664, "entropy": 0.7799733877182007, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 44000, "num_agent_steps_sampled": 88000, "num_steps_trained": 44000, "num_agent_steps_trained": 88000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 4226, "training_iteration": 44, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-54", "timestamp": 1749778554, "time_this_iter_s": 0.35938549041748047, "time_total_s": 16.55417227745056, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c9d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 16.55417227745056, "timesteps_since_restore": 0, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 65.3, "ram_util_percent": 91.5}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 53.574, "episode_len_mean": 16.26, "episode_media": {}, "episodes_this_iter": 58, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 26.787}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.6, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 86.2, 88.0, -4.999999999999998, -4.999999999999998, 85.2, -4.999999999999998, 89.4, -4.999999999999998, 89.4, 89.4, 86.0, 88.8, 85.4, 87.4, 87.8, -4.999999999999998, 86.0, 89.2, -4.999999999999998, 89.4, 89.4, 85.4, -4.999999999999998, 85.6, -4.999999999999998, 89.4, 89.4, -4.999999999999998, 87.4, 85.4, 89.4, 89.4, -4.999999999999998, 88.0, 89.4, -4.999999999999998, 88.6, 87.6, -4.999999999999998, 89.4, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, 89.4, 85.2, 89.4, 86.8, 89.4, 86.8, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 85.8, 87.2, -4.999999999999998, 89.4, 87.0, -4.999999999999998, 89.4, 85.8, 87.8, -4.999999999999998, -4.999999999999998, 89.0, 87.6, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 89.4, 89.4, 88.0, -4.999999999999998, 89.4, -4.999999999999998, 86.8, 86.2, 87.2, 86.4, 86.4, 89.4, 87.6, -4.999999999999998, 88.4, -4.999999999999998], "episode_lengths": [8, 25, 25, 15, 25, 25, 4, 25, 25, 20, 11, 25, 25, 25, 25, 4, 25, 4, 4, 21, 7, 24, 14, 12, 25, 21, 5, 25, 4, 4, 24, 25, 23, 25, 4, 4, 25, 14, 24, 4, 4, 25, 11, 4, 25, 8, 13, 25, 4, 25, 4, 25, 25, 9, 25, 4, 25, 4, 17, 4, 17, 25, 4, 25, 25, 22, 15, 25, 4, 16, 25, 4, 22, 12, 25, 25, 6, 13, 25, 8, 25, 25, 4, 25, 4, 4, 11, 25, 4, 25, 17, 20, 15, 19, 19, 4, 13, 25, 9, 25], "policy_shared_policy_reward": [99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.1, -11.9, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.7, -10.3, 98.0, -12.0, 99.4, -10.6, -12.3, 97.7, 98.7, -11.3, -11.1, 98.9, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -10.4, 99.6, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, 97.7, -12.3, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.3, 98.7, 97.7, -12.3, 99.7, -10.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.0, -11.0, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -11.2, 98.8, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -12.4, 97.6, 99.7, -10.3, -11.6, 98.4, 99.7, -10.3, -11.6, 98.4, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, 98.6, -11.4, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.5, 98.5, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -12.100000000000001, 97.9, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.5, 99.5, 98.8, -11.2, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -11.9, 98.1, -11.4, 98.6, -11.8, 98.2, -11.8, 98.2, -10.3, 99.7, -11.2, 98.8, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.436739387398687, "mean_inference_ms": 1.6504323741917246, "mean_action_processing_ms": 0.08940489274462429, "mean_env_wait_ms": 0.08686178263397382, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 45000, "timesteps_this_iter": 0, "agent_timesteps_total": 90000, "timers": {"sample_time_ms": 407.392, "sample_throughput": 2454.636, "load_time_ms": 1.243, "load_throughput": 804492.865, "learn_time_ms": 101.183, "learn_throughput": 9883.087, "update_time_ms": 2.437}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.52587890625e-06, "cur_lr": 0.0005000000000000001, "total_loss": 1425.033154296875, "policy_loss": -0.0050788841675966975, "vf_loss": 1425.04599609375, "vf_explained_var": -0.008774399757385254, "kl": 0.006337647723592443, "entropy": 0.7772038578987122, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 45000, "num_agent_steps_sampled": 90000, "num_steps_trained": 45000, "num_agent_steps_trained": 90000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 4284, "training_iteration": 45, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-54", "timestamp": 1749778554, "time_this_iter_s": 0.3637263774871826, "time_total_s": 16.917898654937744, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 16.917898654937744, "timesteps_since_restore": 0, "iterations_since_restore": 45, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 48.843999999999994, "episode_len_mean": 17.36, "episode_media": {}, "episodes_this_iter": 55, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 24.421999999999997}, "custom_metrics": {}, "hist_stats": {"episode_reward": [89.4, 85.2, 89.4, 86.8, 89.4, 86.8, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 85.8, 87.2, -4.999999999999998, 89.4, 87.0, -4.999999999999998, 89.4, 85.8, 87.8, -4.999999999999998, -4.999999999999998, 89.0, 87.6, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 89.4, 89.4, 88.0, -4.999999999999998, 89.4, -4.999999999999998, 86.8, 86.2, 87.2, 86.4, 86.4, 89.4, 87.6, -4.999999999999998, 88.4, -4.999999999999998, 85.2, 89.4, 87.4, 89.4, 86.39999999999999, 89.4, 86.6, 87.2, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 85.4, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 86.8, 87.4, -4.999999999999998, -4.999999999999998, 87.0, 86.8, -4.999999999999998, -4.999999999999998, 89.4, 85.2, 89.4, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 89.2, 89.4, -4.999999999999998, -4.999999999999998, 86.8, 87.6, 87.2, -4.999999999999998, -4.999999999999998, 87.8, -4.999999999999998, 88.2, -4.999999999999998, -4.999999999999998, -4.999999999999998], "episode_lengths": [4, 25, 4, 17, 4, 17, 25, 4, 25, 25, 22, 15, 25, 4, 16, 25, 4, 22, 12, 25, 25, 6, 13, 25, 8, 25, 25, 4, 25, 4, 4, 11, 25, 4, 25, 17, 20, 15, 19, 19, 4, 13, 25, 9, 25, 25, 4, 14, 4, 19, 4, 18, 15, 25, 25, 4, 25, 24, 25, 17, 25, 25, 25, 25, 25, 17, 25, 25, 4, 25, 17, 14, 25, 25, 16, 17, 25, 25, 4, 25, 4, 25, 4, 25, 25, 5, 4, 25, 25, 17, 13, 15, 25, 25, 12, 25, 10, 25, 25, 25], "policy_shared_policy_reward": [99.7, -10.3, -12.4, 97.6, 99.7, -10.3, -11.6, 98.4, 99.7, -10.3, -11.6, 98.4, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, 98.6, -11.4, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.5, 98.5, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -12.100000000000001, 97.9, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.5, 99.5, 98.8, -11.2, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -11.9, 98.1, -11.4, 98.6, -11.8, 98.2, -11.8, 98.2, -10.3, 99.7, -11.2, 98.8, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -10.3, 99.7, 98.7, -11.3, 99.7, -10.3, 98.2, -11.8, 99.7, -10.3, 98.3, -11.700000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.4, -11.6, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.5, -11.5, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 97.6, -12.4, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.6, -10.4, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 98.8, -11.2, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.43481634368135164, "mean_inference_ms": 1.650031387518025, "mean_action_processing_ms": 0.08928000409591595, "mean_env_wait_ms": 0.08672013337265003, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 46000, "timesteps_this_iter": 0, "agent_timesteps_total": 92000, "timers": {"sample_time_ms": 403.735, "sample_throughput": 2476.873, "load_time_ms": 1.255, "load_throughput": 796669.199, "learn_time_ms": 99.941, "learn_throughput": 10005.88, "update_time_ms": 2.496}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.52587890625e-06, "cur_lr": 0.0005000000000000001, "total_loss": 1164.4926879882812, "policy_loss": -0.0018719963729381562, "vf_loss": 1164.5018920898438, "vf_explained_var": 0.016372931003570557, "kl": 0.002686616964730426, "entropy": 0.7312604784965515, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 46000, "num_agent_steps_sampled": 92000, "num_steps_trained": 46000, "num_agent_steps_trained": 92000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 4339, "training_iteration": 46, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-54", "timestamp": 1749778554, "time_this_iter_s": 0.34627389907836914, "time_total_s": 17.264172554016113, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c9790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 17.264172554016113, "timesteps_since_restore": 0, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 65.4, "ram_util_percent": 91.5}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 36.82000000000001, "episode_len_mean": 18.85, "episode_media": {}, "episodes_this_iter": 56, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 18.41}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 85.4, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 86.8, 87.4, -4.999999999999998, -4.999999999999998, 87.0, 86.8, -4.999999999999998, -4.999999999999998, 89.4, 85.2, 89.4, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 89.2, 89.4, -4.999999999999998, -4.999999999999998, 86.8, 87.6, 87.2, -4.999999999999998, -4.999999999999998, 87.8, -4.999999999999998, 88.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 89.4, 85.6, 88.8, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, 89.4, 87.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 89.4, 85.4, -4.999999999999998, 85.4, 87.8, 89.4, 85.4, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 88.8, 89.4, -4.999999999999998, -4.999999999999998, 89.4, 89.2, 88.8, 89.4, -4.999999999999998, 88.0], "episode_lengths": [25, 24, 25, 17, 25, 25, 25, 25, 25, 17, 25, 25, 4, 25, 17, 14, 25, 25, 16, 17, 25, 25, 4, 25, 4, 25, 4, 25, 25, 5, 4, 25, 25, 17, 13, 15, 25, 25, 12, 25, 10, 25, 25, 25, 17, 4, 23, 7, 11, 25, 25, 25, 9, 4, 16, 25, 25, 25, 25, 25, 25, 25, 4, 4, 24, 25, 24, 12, 4, 24, 13, 25, 25, 25, 25, 25, 25, 21, 4, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 4, 7, 4, 25, 25, 4, 5, 7, 4, 25, 11], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, 97.7, -12.3, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.4, -11.6, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.5, -11.5, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 97.6, -12.4, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.6, -10.4, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 98.8, -11.2, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 99.7, -10.3, -12.200000000000001, 97.8, -10.6, 99.4, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -10.3, 99.7, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, 97.7, -12.3, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -11.1, 98.9, -10.3, 99.7, -12.3, 97.7, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -10.6, 99.4, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.6, -10.4, 99.4, -10.6, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.0, -11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4335733508735188, "mean_inference_ms": 1.6504182643130207, "mean_action_processing_ms": 0.0893396648977288, "mean_env_wait_ms": 0.08680219625219138, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 47000, "timesteps_this_iter": 0, "agent_timesteps_total": 94000, "timers": {"sample_time_ms": 399.2, "sample_throughput": 2505.011, "load_time_ms": 1.266, "load_throughput": 789828.262, "learn_time_ms": 100.93, "learn_throughput": 9907.81, "update_time_ms": 2.601}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 7.62939453125e-07, "cur_lr": 0.0005000000000000001, "total_loss": 985.405908203125, "policy_loss": -0.002677541971206665, "vf_loss": 985.4165466308593, "vf_explained_var": 0.029282820224761964, "kl": 0.004760090387727978, "entropy": 0.794790244102478, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 47000, "num_agent_steps_sampled": 94000, "num_steps_trained": 47000, "num_agent_steps_trained": 94000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 4395, "training_iteration": 47, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-55", "timestamp": 1749778555, "time_this_iter_s": 0.36696481704711914, "time_total_s": 17.631137371063232, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c99d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 17.631137371063232, "timesteps_since_restore": 0, "iterations_since_restore": 47, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 33.065999999999995, "episode_len_mean": 19.58, "episode_media": {}, "episodes_this_iter": 46, "policy_reward_min": {"shared_policy": -12.3}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 16.533}, "custom_metrics": {}, "hist_stats": {"episode_reward": [85.6, 88.8, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, 89.4, 87.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 89.4, 85.4, -4.999999999999998, 85.4, 87.8, 89.4, 85.4, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 88.8, 89.4, -4.999999999999998, -4.999999999999998, 89.4, 89.2, 88.8, 89.4, -4.999999999999998, 88.0, -4.999999999999998, 85.4, 88.4, -4.999999999999998, 86.6, -4.999999999999998, 86.4, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, 89.4, 86.2, -4.999999999999998, 86.8, 89.4, 87.0, 88.0, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 87.6, 86.4, -4.999999999999998, -4.999999999999998], "episode_lengths": [23, 7, 11, 25, 25, 25, 9, 4, 16, 25, 25, 25, 25, 25, 25, 25, 4, 4, 24, 25, 24, 12, 4, 24, 13, 25, 25, 25, 25, 25, 25, 21, 4, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 4, 7, 4, 25, 25, 4, 5, 7, 4, 25, 11, 25, 24, 9, 25, 18, 25, 19, 25, 25, 7, 25, 25, 25, 25, 25, 25, 20, 25, 25, 25, 25, 25, 25, 25, 25, 8, 25, 25, 25, 25, 20, 4, 20, 25, 17, 4, 16, 11, 25, 4, 25, 25, 13, 19, 25, 25], "policy_shared_policy_reward": [-12.200000000000001, 97.8, -10.6, 99.4, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -10.3, 99.7, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, 97.7, -12.3, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -11.1, 98.9, -10.3, 99.7, -12.3, 97.7, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -10.6, 99.4, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.6, -10.4, 99.4, -10.6, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -12.3, 97.7, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, 99.7, -10.3, 98.1, -11.9, -2.500000000000001, -2.500000000000001, 98.4, -11.6, 99.7, -10.3, 98.5, -11.5, -11.0, 99.0, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4310888282161575, "mean_inference_ms": 1.646293682284118, "mean_action_processing_ms": 0.08909983968486693, "mean_env_wait_ms": 0.08668879416836024, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 48000, "timesteps_this_iter": 0, "agent_timesteps_total": 96000, "timers": {"sample_time_ms": 395.726, "sample_throughput": 2526.999, "load_time_ms": 1.316, "load_throughput": 759658.776, "learn_time_ms": 100.298, "learn_throughput": 9970.277, "update_time_ms": 2.669}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 3.814697265625e-07, "cur_lr": 0.0005000000000000001, "total_loss": 847.8830749511719, "policy_loss": -0.0035930782556533813, "vf_loss": 847.8937866210938, "vf_explained_var": 0.02420569658279419, "kl": 0.0069917113582386396, "entropy": 0.7151568233966827, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 48000, "num_agent_steps_sampled": 96000, "num_steps_trained": 48000, "num_agent_steps_trained": 96000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 4441, "training_iteration": 48, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-55", "timestamp": 1749778555, "time_this_iter_s": 0.34940314292907715, "time_total_s": 17.98054051399231, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182f4af0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 17.98054051399231, "timesteps_since_restore": 0, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 59.0, "ram_util_percent": 91.6}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 30.268, "episode_len_mean": 20.04, "episode_media": {}, "episodes_this_iter": 53, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 15.134}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.0, -4.999999999999998, 85.4, 88.4, -4.999999999999998, 86.6, -4.999999999999998, 86.4, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, 89.4, 86.2, -4.999999999999998, 86.8, 89.4, 87.0, 88.0, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 87.6, 86.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 86.2, 86.2, 89.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 89.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 88.6, 86.8, 87.0, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, 87.2, 88.4], "episode_lengths": [11, 25, 24, 9, 25, 18, 25, 19, 25, 25, 7, 25, 25, 25, 25, 25, 25, 20, 25, 25, 25, 25, 25, 25, 25, 25, 8, 25, 25, 25, 25, 20, 4, 20, 25, 17, 4, 16, 11, 25, 4, 25, 25, 13, 19, 25, 25, 25, 4, 25, 25, 25, 25, 4, 20, 20, 4, 4, 25, 25, 25, 25, 4, 5, 25, 25, 25, 25, 25, 25, 15, 11, 25, 25, 25, 25, 25, 25, 25, 25, 25, 4, 8, 17, 16, 4, 25, 25, 25, 25, 25, 25, 10, 25, 25, 11, 25, 25, 15, 9], "policy_shared_policy_reward": [99.0, -11.0, -2.500000000000001, -2.500000000000001, -12.3, 97.7, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, 99.7, -10.3, 98.1, -11.9, -2.500000000000001, -2.500000000000001, 98.4, -11.6, 99.7, -10.3, 98.5, -11.5, -11.0, 99.0, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.1, -11.9, 98.1, -11.9, 99.7, -10.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.6, -10.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.6, -11.4, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.3, -10.7, -11.6, 98.4, 98.5, -11.5, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -10.8, 99.2]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.42890330520813646, "mean_inference_ms": 1.6444716850678156, "mean_action_processing_ms": 0.08888058252816247, "mean_env_wait_ms": 0.0864758433552005, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 49000, "timesteps_this_iter": 0, "agent_timesteps_total": 98000, "timers": {"sample_time_ms": 392.225, "sample_throughput": 2549.556, "load_time_ms": 1.228, "load_throughput": 814491.223, "learn_time_ms": 100.178, "learn_throughput": 9982.184, "update_time_ms": 2.719}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 3.814697265625e-07, "cur_lr": 0.0005000000000000001, "total_loss": 809.6894714355469, "policy_loss": -0.0022357205860316755, "vf_loss": 809.6989196777344, "vf_explained_var": 0.017685127258300782, "kl": 0.0045032116382278, "entropy": 0.722966730594635, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 49000, "num_agent_steps_sampled": 98000, "num_steps_trained": 49000, "num_agent_steps_trained": 98000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 4494, "training_iteration": 49, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-56", "timestamp": 1749778556, "time_this_iter_s": 0.33800363540649414, "time_total_s": 18.318544149398804, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018319e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 18.318544149398804, "timesteps_since_restore": 0, "iterations_since_restore": 49, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 30.274, "episode_len_mean": 20.01, "episode_media": {}, "episodes_this_iter": 50, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 15.136999999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 86.2, 86.2, 89.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 89.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 88.6, 86.8, 87.0, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, 87.2, 88.4, -4.999999999999998, 87.6, 89.4, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.0, 89.4, 85.4, -4.999999999999998, -4.999999999999998, 89.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, -4.999999999999998, 86.6, 86.0, 86.6, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0], "episode_lengths": [25, 25, 25, 4, 20, 20, 4, 4, 25, 25, 25, 25, 4, 5, 25, 25, 25, 25, 25, 25, 15, 11, 25, 25, 25, 25, 25, 25, 25, 25, 25, 4, 8, 17, 16, 4, 25, 25, 25, 25, 25, 25, 10, 25, 25, 11, 25, 25, 15, 9, 25, 13, 4, 25, 25, 25, 25, 6, 4, 24, 25, 25, 4, 4, 25, 25, 25, 25, 25, 20, 25, 25, 18, 21, 18, 21, 25, 25, 25, 4, 25, 7, 25, 25, 25, 7, 13, 25, 25, 25, 25, 25, 25, 25, 21, 25, 25, 25, 25, 11], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.1, -11.9, 98.1, -11.9, 99.7, -10.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.6, -10.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.6, -11.4, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.3, -10.7, -11.6, 98.4, 98.5, -11.5, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -10.8, 99.2, -2.500000000000001, -2.500000000000001, 98.8, -11.2, 99.7, -10.3, 97.6, -12.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -10.3, 99.7, 97.7, -12.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.1, -11.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, 98.0, -12.0, -11.700000000000001, 98.3, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.6, 99.4, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.428113904565039, "mean_inference_ms": 1.645905624117629, "mean_action_processing_ms": 0.0888979351116026, "mean_env_wait_ms": 0.08642336478957638, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 50000, "timesteps_this_iter": 0, "agent_timesteps_total": 100000, "timers": {"sample_time_ms": 389.6, "sample_throughput": 2566.738, "load_time_ms": 1.213, "load_throughput": 824271.2, "learn_time_ms": 100.507, "learn_throughput": 9949.544, "update_time_ms": 2.742}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.9073486328125e-07, "cur_lr": 0.0005000000000000001, "total_loss": 912.5224304199219, "policy_loss": -0.0036906689405441285, "vf_loss": 912.53359375, "vf_explained_var": 0.02210579514503479, "kl": 0.011029278177140256, "entropy": 0.7467342853546143, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 50000, "num_agent_steps_sampled": 100000, "num_steps_trained": 50000, "num_agent_steps_trained": 100000, "num_steps_trained_this_iter": 0}, "evaluation": {"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 22.98, "episode_len_mean": 20.4, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"shared_policy": -11.700000000000001}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 11.49}, "custom_metrics": {}, "hist_stats": {"episode_reward": [86.6, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998], "episode_lengths": [18, 25, 4, 25, 25, 7, 25, 25, 25, 25], "policy_shared_policy_reward": [98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1919513795433975, "mean_inference_ms": 1.3053056670398246, "mean_action_processing_ms": 0.045781019257336124, "mean_env_wait_ms": 0.0414348230129335, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "done": false, "episodes_total": 4544, "training_iteration": 50, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-56", "timestamp": 1749778556, "time_this_iter_s": 0.704796314239502, "time_total_s": 19.023340463638306, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c9ca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 19.023340463638306, "timesteps_since_restore": 0, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 60.7, "ram_util_percent": 91.6}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 31.126000000000005, "episode_len_mean": 20.26, "episode_media": {}, "episodes_this_iter": 50, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 15.563000000000002}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 87.6, 89.4, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.0, 89.4, 85.4, -4.999999999999998, -4.999999999999998, 89.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, -4.999999999999998, 86.6, 86.0, 86.6, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, 89.4, -4.999999999999998, 87.8, 88.8, -4.999999999999998, 85.4, -4.999999999999998, -4.999999999999998, 85.4, 87.2, -4.999999999999998, 88.8, 86.2, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, 88.8, 88.6, -4.999999999999998, 87.8, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, 85.8, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.8, 88.0, -4.999999999999998], "episode_lengths": [25, 13, 4, 25, 25, 25, 25, 6, 4, 24, 25, 25, 4, 4, 25, 25, 25, 25, 25, 20, 25, 25, 18, 21, 18, 21, 25, 25, 25, 4, 25, 7, 25, 25, 25, 7, 13, 25, 25, 25, 25, 25, 25, 25, 21, 25, 25, 25, 25, 11, 25, 4, 25, 12, 7, 25, 24, 25, 25, 24, 15, 25, 7, 20, 25, 25, 25, 25, 21, 25, 7, 8, 25, 12, 25, 25, 9, 25, 22, 4, 25, 25, 25, 4, 25, 25, 25, 25, 25, 25, 25, 25, 8, 25, 25, 25, 25, 12, 11, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, 98.8, -11.2, 99.7, -10.3, 97.6, -12.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -10.3, 99.7, 97.7, -12.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.1, -11.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, 98.0, -12.0, -11.700000000000001, 98.3, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.6, 99.4, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -11.4, 98.6, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 98.1, -11.9, 97.6, -12.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -11.0, 99.0, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.42543169538878467, "mean_inference_ms": 1.6431454387347577, "mean_action_processing_ms": 0.08886143438941461, "mean_env_wait_ms": 0.08632427137084112, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 51000, "timesteps_this_iter": 0, "agent_timesteps_total": 102000, "timers": {"sample_time_ms": 429.995, "sample_throughput": 2325.607, "load_time_ms": 1.295, "load_throughput": 772232.574, "learn_time_ms": 101.291, "learn_throughput": 9872.537, "update_time_ms": 2.736}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.9073486328125e-07, "cur_lr": 0.0005000000000000001, "total_loss": 926.8708129882813, "policy_loss": -0.0027292907238006593, "vf_loss": 926.8814453125, "vf_explained_var": 0.027091532945632935, "kl": 0.012458243332561025, "entropy": 0.7920559406280517, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 51000, "num_agent_steps_sampled": 102000, "num_steps_trained": 51000, "num_agent_steps_trained": 102000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 4594, "training_iteration": 51, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-57", "timestamp": 1749778557, "time_this_iter_s": 0.35459160804748535, "time_total_s": 19.37793207168579, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c9790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 19.37793207168579, "timesteps_since_restore": 0, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 34.7, "ram_util_percent": 91.5}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 34.00800000000001, "episode_len_mean": 19.38, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 17.004}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.8, -4.999999999999998, 85.4, -4.999999999999998, -4.999999999999998, 85.4, 87.2, -4.999999999999998, 88.8, 86.2, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, 88.8, 88.6, -4.999999999999998, 87.8, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, 85.8, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.8, 88.0, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, 89.0, 87.2, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 89.4, 88.2, -4.999999999999998, 89.4, 89.4, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.2, -4.999999999999998, 87.6, 86.39999999999999, -4.999999999999998, -4.999999999999998, 85.2, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, 88.0, 87.0, 87.4, 89.4, 88.4, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, 89.4], "episode_lengths": [7, 25, 24, 25, 25, 24, 15, 25, 7, 20, 25, 25, 25, 25, 21, 25, 7, 8, 25, 12, 25, 25, 9, 25, 22, 4, 25, 25, 25, 4, 25, 25, 25, 25, 25, 25, 25, 25, 8, 25, 25, 25, 25, 12, 11, 25, 15, 25, 25, 4, 25, 25, 25, 25, 25, 25, 7, 25, 6, 15, 14, 25, 25, 25, 25, 4, 4, 10, 25, 4, 4, 25, 25, 9, 25, 25, 25, 25, 5, 25, 13, 19, 25, 25, 25, 25, 18, 25, 25, 11, 16, 14, 4, 9, 25, 25, 14, 25, 25, 4], "policy_shared_policy_reward": [99.4, -10.6, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -11.4, 98.6, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 98.1, -11.9, 97.6, -12.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -11.0, 99.0, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -11.4, 98.6, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -11.2, 98.8, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -11.5, 98.5, -11.3, 98.7, -10.3, 99.7, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4252234600320542, "mean_inference_ms": 1.648197076426002, "mean_action_processing_ms": 0.08928367089407202, "mean_env_wait_ms": 0.08686711571179416, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 52000, "timesteps_this_iter": 0, "agent_timesteps_total": 104000, "timers": {"sample_time_ms": 433.307, "sample_throughput": 2307.83, "load_time_ms": 1.362, "load_throughput": 734451.215, "learn_time_ms": 100.447, "learn_throughput": 9955.469, "update_time_ms": 2.7}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.9073486328125e-07, "cur_lr": 0.0005000000000000001, "total_loss": 938.4029052734375, "policy_loss": -0.001368457078933716, "vf_loss": 938.4123901367187, "vf_explained_var": 0.04325205683708191, "kl": 0.0009255771290240134, "entropy": 0.8105557918548584, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 52000, "num_agent_steps_sampled": 104000, "num_steps_trained": 52000, "num_agent_steps_trained": 104000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 4648, "training_iteration": 52, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-57", "timestamp": 1749778557, "time_this_iter_s": 0.38991236686706543, "time_total_s": 19.767844438552856, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5a60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 19.767844438552856, "timesteps_since_restore": 0, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 68.0, "ram_util_percent": 91.3}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 35.85, "episode_len_mean": 19.19, "episode_media": {}, "episodes_this_iter": 50, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 17.924999999999997}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, 89.0, 87.2, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 89.4, 88.2, -4.999999999999998, 89.4, 89.4, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.2, -4.999999999999998, 87.6, 86.39999999999999, -4.999999999999998, -4.999999999999998, 85.2, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, 88.0, 87.0, 87.4, 89.4, 88.4, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 87.8, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.0, 86.0, -4.999999999999998, 87.8, 85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.6, 88.4, 86.4, 86.2, 86.2, 85.4, 89.4, 89.2, -4.999999999999998, 88.0, -4.999999999999998, 89.4, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, -4.999999999999998, 85.4, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998], "episode_lengths": [25, 25, 25, 25, 25, 25, 7, 25, 6, 15, 14, 25, 25, 25, 25, 4, 4, 10, 25, 4, 4, 25, 25, 9, 25, 25, 25, 25, 5, 25, 13, 19, 25, 25, 25, 25, 18, 25, 25, 11, 16, 14, 4, 9, 25, 25, 14, 25, 25, 4, 25, 12, 4, 25, 25, 25, 6, 21, 25, 12, 22, 25, 25, 25, 23, 25, 25, 25, 25, 25, 25, 25, 8, 9, 19, 20, 20, 24, 4, 5, 25, 11, 25, 4, 25, 18, 25, 25, 25, 7, 25, 25, 24, 13, 25, 25, 25, 25, 4, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -11.4, 98.6, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -11.2, 98.8, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -11.5, 98.5, -11.3, 98.7, -10.3, 99.7, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.5, 99.5, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -10.8, 99.2, -11.8, 98.2, 98.1, -11.9, 98.1, -11.9, 97.7, -12.3, 99.7, -10.3, -10.4, 99.6, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4248985843456971, "mean_inference_ms": 1.6518114615891113, "mean_action_processing_ms": 0.089421651215096, "mean_env_wait_ms": 0.08691448816201146, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 53000, "timesteps_this_iter": 0, "agent_timesteps_total": 106000, "timers": {"sample_time_ms": 435.544, "sample_throughput": 2295.977, "load_time_ms": 1.351, "load_throughput": 740389.056, "learn_time_ms": 101.138, "learn_throughput": 9887.474, "update_time_ms": 2.772}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 9.5367431640625e-08, "cur_lr": 0.0005000000000000001, "total_loss": 1056.271746826172, "policy_loss": -0.0033022321760654448, "vf_loss": 1056.2837890625, "vf_explained_var": 0.034326189756393434, "kl": 0.008259303008878227, "entropy": 0.8729409098625183, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 53000, "num_agent_steps_sampled": 106000, "num_steps_trained": 53000, "num_agent_steps_trained": 106000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 4698, "training_iteration": 53, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-58", "timestamp": 1749778558, "time_this_iter_s": 0.39975953102111816, "time_total_s": 20.167603969573975, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5af0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 20.167603969573975, "timesteps_since_restore": 0, "iterations_since_restore": 53, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 33.004, "episode_len_mean": 19.89, "episode_media": {}, "episodes_this_iter": 50, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 16.502}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 87.8, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.0, 86.0, -4.999999999999998, 87.8, 85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.6, 88.4, 86.4, 86.2, 86.2, 85.4, 89.4, 89.2, -4.999999999999998, 88.0, -4.999999999999998, 89.4, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, -4.999999999999998, 85.4, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 85.8, -4.999999999999998, 87.0, -4.999999999999998, 88.8, -4.999999999999998, -4.999999999999998, 87.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, 85.2, 89.4, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.6, 87.8, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.6, 86.4, 89.4, -4.999999999999998], "episode_lengths": [25, 12, 4, 25, 25, 25, 6, 21, 25, 12, 22, 25, 25, 25, 23, 25, 25, 25, 25, 25, 25, 25, 8, 9, 19, 20, 20, 24, 4, 5, 25, 11, 25, 4, 25, 18, 25, 25, 25, 7, 25, 25, 24, 13, 25, 25, 25, 25, 4, 25, 25, 25, 4, 22, 25, 16, 25, 7, 25, 25, 12, 25, 25, 25, 10, 25, 4, 25, 22, 25, 25, 25, 25, 8, 12, 9, 25, 25, 25, 4, 25, 25, 25, 4, 25, 25, 25, 25, 25, 25, 20, 25, 4, 25, 25, 25, 18, 19, 4, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, 98.9, -11.1, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.5, 99.5, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -10.8, 99.2, -11.8, 98.2, 98.1, -11.9, 98.1, -11.9, 97.7, -12.3, 99.7, -10.3, -10.4, 99.6, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 97.6, -12.4, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 98.9, -11.1, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -11.8, 98.2, -10.3, 99.7, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.42270308048575955, "mean_inference_ms": 1.6500346164669957, "mean_action_processing_ms": 0.0893156262131226, "mean_env_wait_ms": 0.08662926536532875, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 54000, "timesteps_this_iter": 0, "agent_timesteps_total": 108000, "timers": {"sample_time_ms": 438.872, "sample_throughput": 2278.57, "load_time_ms": 1.327, "load_throughput": 753666.355, "learn_time_ms": 101.454, "learn_throughput": 9856.689, "update_time_ms": 2.733}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 9.5367431640625e-08, "cur_lr": 0.0005000000000000001, "total_loss": 836.6580627441406, "policy_loss": -0.0056089848279953, "vf_loss": 836.6725952148438, "vf_explained_var": 0.0540617048740387, "kl": 0.010310397035953645, "entropy": 0.8903999567031861, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 54000, "num_agent_steps_sampled": 108000, "num_steps_trained": 54000, "num_agent_steps_trained": 108000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 4748, "training_iteration": 54, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-58", "timestamp": 1749778558, "time_this_iter_s": 0.38730907440185547, "time_total_s": 20.55491304397583, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018319670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 20.55491304397583, "timesteps_since_restore": 0, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 66.5, "ram_util_percent": 90.8}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 34.028, "episode_len_mean": 19.28, "episode_media": {}, "episodes_this_iter": 51, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 17.014}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 89.4, 85.8, -4.999999999999998, 87.0, -4.999999999999998, 88.8, -4.999999999999998, -4.999999999999998, 87.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, 85.2, 89.4, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.6, 87.8, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.6, 86.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.6, 88.0, 89.4, -4.999999999999998, -4.999999999999998, 88.8, 89.4, 86.6, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 87.4, 88.4, 85.2, 87.0, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 85.2, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 87.8, 87.0, -4.999999999999998, 88.6, -4.999999999999998, 89.4, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998], "episode_lengths": [25, 4, 22, 25, 16, 25, 7, 25, 25, 12, 25, 25, 25, 10, 25, 4, 25, 22, 25, 25, 25, 25, 8, 12, 9, 25, 25, 25, 4, 25, 25, 25, 4, 25, 25, 25, 25, 25, 25, 20, 25, 4, 25, 25, 25, 18, 19, 4, 25, 25, 25, 23, 11, 4, 25, 25, 7, 4, 18, 9, 25, 25, 25, 25, 4, 14, 9, 25, 16, 25, 4, 25, 25, 25, 4, 25, 25, 25, 25, 25, 4, 12, 16, 25, 8, 25, 4, 15, 25, 25, 25, 25, 25, 25, 25, 4, 14, 25, 25, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, 99.7, -10.3, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 97.6, -12.4, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 98.9, -11.1, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -11.8, 98.2, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, 99.0, -11.0, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.6, 99.4, 99.7, -10.3, 98.3, -11.700000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.3, 98.7, 99.2, -10.8, -12.4, 97.6, 98.5, -11.5, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.4, 97.6, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.1, 98.9, -11.5, 98.5, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.42174115754776964, "mean_inference_ms": 1.6512600472180015, "mean_action_processing_ms": 0.08936078584200083, "mean_env_wait_ms": 0.08675752540102016, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 55000, "timesteps_this_iter": 0, "agent_timesteps_total": 110000, "timers": {"sample_time_ms": 438.288, "sample_throughput": 2281.605, "load_time_ms": 1.315, "load_throughput": 760636.901, "learn_time_ms": 100.779, "learn_throughput": 9922.671, "update_time_ms": 2.947}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 9.5367431640625e-08, "cur_lr": 0.0005000000000000001, "total_loss": 891.3703369140625, "policy_loss": -0.003963664174079895, "vf_loss": 891.3828491210937, "vf_explained_var": 0.06786406636238099, "kl": 0.01088960329880404, "entropy": 0.8552858114242554, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 55000, "num_agent_steps_sampled": 110000, "num_steps_trained": 55000, "num_agent_steps_trained": 110000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 4799, "training_iteration": 55, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-58", "timestamp": 1749778558, "time_this_iter_s": 0.357738733291626, "time_total_s": 20.912651777267456, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5a60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 20.912651777267456, "timesteps_since_restore": 0, "iterations_since_restore": 55, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 34.96, "episode_len_mean": 19.13, "episode_media": {}, "episodes_this_iter": 52, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 17.48}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.0, 89.4, -4.999999999999998, -4.999999999999998, 88.8, 89.4, 86.6, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 87.4, 88.4, 85.2, 87.0, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 85.2, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 87.8, 87.0, -4.999999999999998, 88.6, -4.999999999999998, 89.4, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, 87.6, 86.0, -4.999999999999998, 85.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, -4.999999999999998, 85.6, -4.999999999999998, 89.4, 86.8, 85.6, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, 89.4, 87.6, 88.4, -4.999999999999998, 88.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 87.2, 85.6, 89.4, 89.4, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998], "episode_lengths": [11, 4, 25, 25, 7, 4, 18, 9, 25, 25, 25, 25, 4, 14, 9, 25, 16, 25, 4, 25, 25, 25, 4, 25, 25, 25, 25, 25, 4, 12, 16, 25, 8, 25, 4, 15, 25, 25, 25, 25, 25, 25, 25, 4, 14, 25, 25, 25, 13, 25, 25, 13, 21, 25, 23, 25, 25, 25, 25, 25, 25, 25, 25, 25, 13, 25, 23, 25, 4, 17, 23, 25, 13, 25, 25, 4, 13, 9, 25, 10, 25, 25, 25, 25, 4, 15, 23, 4, 4, 25, 4, 25, 25, 25, 25, 25, 4, 25, 25, 25], "policy_shared_policy_reward": [99.0, -11.0, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.6, 99.4, 99.7, -10.3, 98.3, -11.700000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.3, 98.7, 99.2, -10.8, -12.4, 97.6, 98.5, -11.5, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.4, 97.6, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.1, 98.9, -11.5, 98.5, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.8, -11.2, 98.0, -12.0, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.6, 98.4, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.2, 98.8, -10.8, 99.2, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.6, -11.4, 97.8, -12.200000000000001, -10.3, 99.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.42117527534316, "mean_inference_ms": 1.653567562711105, "mean_action_processing_ms": 0.08951633942260097, "mean_env_wait_ms": 0.08675688813991717, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 56000, "timesteps_this_iter": 0, "agent_timesteps_total": 112000, "timers": {"sample_time_ms": 437.542, "sample_throughput": 2285.493, "load_time_ms": 1.368, "load_throughput": 731058.86, "learn_time_ms": 101.082, "learn_throughput": 9892.929, "update_time_ms": 3.15}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 9.5367431640625e-08, "cur_lr": 0.0005000000000000001, "total_loss": 925.0103820800781, "policy_loss": -0.0021801982074975967, "vf_loss": 925.0206665039062, "vf_explained_var": 0.038384413719177245, "kl": 0.006963533979566705, "entropy": 0.8108059227466583, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 56000, "num_agent_steps_sampled": 112000, "num_steps_trained": 56000, "num_agent_steps_trained": 112000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 4851, "training_iteration": 56, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-59", "timestamp": 1749778559, "time_this_iter_s": 0.3439023494720459, "time_total_s": 21.256554126739502, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018319160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 21.256554126739502, "timesteps_since_restore": 0, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 57.7, "ram_util_percent": 90.7}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 29.272, "episode_len_mean": 20.51, "episode_media": {}, "episodes_this_iter": 48, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 14.636}, "custom_metrics": {}, "hist_stats": {"episode_reward": [87.6, -4.999999999999998, -4.999999999999998, 87.6, 86.0, -4.999999999999998, 85.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, -4.999999999999998, 85.6, -4.999999999999998, 89.4, 86.8, 85.6, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, 89.4, 87.6, 88.4, -4.999999999999998, 88.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 87.2, 85.6, 89.4, 89.4, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, 89.4, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.39999999999999, 87.4, 89.4, 87.0, -4.999999999999998, 88.0, -4.999999999999998, 89.4, 85.4, -4.999999999999998, -4.999999999999998, 85.4, 89.4, -4.999999999999998, -4.999999999999998], "episode_lengths": [13, 25, 25, 13, 21, 25, 23, 25, 25, 25, 25, 25, 25, 25, 25, 25, 13, 25, 23, 25, 4, 17, 23, 25, 13, 25, 25, 4, 13, 9, 25, 10, 25, 25, 25, 25, 4, 15, 23, 4, 4, 25, 4, 25, 25, 25, 25, 25, 4, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 5, 25, 25, 25, 25, 25, 20, 4, 25, 25, 20, 25, 25, 4, 25, 21, 25, 25, 25, 25, 25, 25, 25, 19, 14, 4, 16, 25, 11, 25, 4, 24, 25, 25, 24, 4, 25, 25], "policy_shared_policy_reward": [-11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.8, -11.2, 98.0, -12.0, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.6, 98.4, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.2, 98.8, -10.8, 99.2, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.6, -11.4, 97.8, -12.200000000000001, -10.3, 99.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.6, -10.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.1, -11.9, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.1, -11.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.2, -11.8, 98.7, -11.3, 99.7, -10.3, 98.5, -11.5, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.419395522867911, "mean_inference_ms": 1.6513581691190395, "mean_action_processing_ms": 0.08948005550468675, "mean_env_wait_ms": 0.0867280376685838, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 57000, "timesteps_this_iter": 0, "agent_timesteps_total": 114000, "timers": {"sample_time_ms": 437.661, "sample_throughput": 2284.875, "load_time_ms": 1.345, "load_throughput": 743236.05, "learn_time_ms": 99.507, "learn_throughput": 10049.576, "update_time_ms": 3.058}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 9.5367431640625e-08, "cur_lr": 0.0005000000000000001, "total_loss": 830.7439056396485, "policy_loss": -0.0011506423354148865, "vf_loss": 830.7524627685547, "vf_explained_var": 0.015272021293640137, "kl": 0.0022702231240410596, "entropy": 0.7425372838973999, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 57000, "num_agent_steps_sampled": 114000, "num_steps_trained": 57000, "num_agent_steps_trained": 114000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 4899, "training_iteration": 57, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-35-59", "timestamp": 1749778559, "time_this_iter_s": 0.3388097286224365, "time_total_s": 21.59536385536194, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018319670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 21.59536385536194, "timesteps_since_restore": 0, "iterations_since_restore": 57, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 25.578000000000003, "episode_len_mean": 20.94, "episode_media": {}, "episodes_this_iter": 47, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 12.789000000000001}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, 89.4, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.39999999999999, 87.4, 89.4, 87.0, -4.999999999999998, 88.0, -4.999999999999998, 89.4, 85.4, -4.999999999999998, -4.999999999999998, 85.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 89.4, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, 87.8, 88.6, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 87.6, 86.2, 85.2, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.2, -4.999999999999998, -4.999999999999998], "episode_lengths": [25, 4, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 5, 25, 25, 25, 25, 25, 20, 4, 25, 25, 20, 25, 25, 4, 25, 21, 25, 25, 25, 25, 25, 25, 25, 19, 14, 4, 16, 25, 11, 25, 4, 24, 25, 25, 24, 4, 25, 25, 25, 25, 25, 25, 4, 4, 25, 4, 25, 25, 4, 25, 25, 17, 25, 25, 25, 25, 21, 25, 25, 25, 25, 25, 25, 22, 25, 25, 12, 8, 25, 25, 9, 25, 4, 25, 25, 13, 20, 25, 4, 25, 25, 25, 25, 25, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.6, -10.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.1, -11.9, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.1, -11.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.2, -11.8, 98.7, -11.3, 99.7, -10.3, 98.5, -11.5, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.8, -11.2, 98.1, -11.9, -12.4, 97.6, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.41755992809992776, "mean_inference_ms": 1.6486165545609734, "mean_action_processing_ms": 0.08925433135812126, "mean_env_wait_ms": 0.08666180430398823, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 58000, "timesteps_this_iter": 0, "agent_timesteps_total": 116000, "timers": {"sample_time_ms": 437.444, "sample_throughput": 2286.008, "load_time_ms": 1.307, "load_throughput": 765342.043, "learn_time_ms": 101.277, "learn_throughput": 9873.871, "update_time_ms": 3.104}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 4.76837158203125e-08, "cur_lr": 0.0005000000000000001, "total_loss": 682.9626312255859, "policy_loss": -0.003374817222356796, "vf_loss": 682.9734344482422, "vf_explained_var": 0.044855141639709474, "kl": 0.0056089492093299494, "entropy": 0.7412214815616608, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 58000, "num_agent_steps_sampled": 116000, "num_steps_trained": 58000, "num_agent_steps_trained": 116000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 4946, "training_iteration": 58, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-00", "timestamp": 1749778560, "time_this_iter_s": 0.37778258323669434, "time_total_s": 21.973146438598633, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018212d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 21.973146438598633, "timesteps_since_restore": 0, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 62.8, "ram_util_percent": 90.7}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 23.774, "episode_len_mean": 20.94, "episode_media": {}, "episodes_this_iter": 48, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 11.887}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 85.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 89.4, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, 87.8, 88.6, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 87.6, 86.2, 85.2, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, 89.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 87.2, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 88.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998], "episode_lengths": [25, 24, 4, 25, 25, 25, 25, 25, 25, 4, 4, 25, 4, 25, 25, 4, 25, 25, 17, 25, 25, 25, 25, 21, 25, 25, 25, 25, 25, 25, 22, 25, 25, 12, 8, 25, 25, 9, 25, 4, 25, 25, 13, 20, 25, 4, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 13, 25, 25, 6, 25, 25, 25, 4, 25, 25, 25, 25, 25, 17, 15, 11, 25, 25, 25, 22, 25, 25, 11, 25, 17, 25, 25, 11, 25, 4, 25, 25, 25, 25, 25, 25, 25, 4, 25, 10, 25, 25, 25, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, 97.7, -12.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.8, -11.2, 98.1, -11.9, -12.4, 97.6, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -11.4, 98.6, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.416375529644105, "mean_inference_ms": 1.6476470632609528, "mean_action_processing_ms": 0.08919659821466405, "mean_env_wait_ms": 0.08664185304584887, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 59000, "timesteps_this_iter": 0, "agent_timesteps_total": 118000, "timers": {"sample_time_ms": 438.934, "sample_throughput": 2278.245, "load_time_ms": 1.307, "load_throughput": 765230.337, "learn_time_ms": 102.07, "learn_throughput": 9797.159, "update_time_ms": 3.06}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 4.76837158203125e-08, "cur_lr": 0.0005000000000000001, "total_loss": 559.8528442382812, "policy_loss": -0.002205429971218109, "vf_loss": 559.8625854492187, "vf_explained_var": 0.028061187267303465, "kl": 0.0036530305411393016, "entropy": 0.7558855831623077, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 59000, "num_agent_steps_sampled": 118000, "num_steps_trained": 59000, "num_agent_steps_trained": 118000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 4994, "training_iteration": 59, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-00", "timestamp": 1749778560, "time_this_iter_s": 0.3402831554412842, "time_total_s": 22.313429594039917, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018212f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 22.313429594039917, "timesteps_since_restore": 0, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 64.6, "ram_util_percent": 90.7}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 27.574, "episode_len_mean": 19.98, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 13.787}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, 89.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 87.2, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 88.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, 88.0, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.2, 87.2, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, -4.999999999999998, 86.2, 86.2, 87.8, 89.4, -4.999999999999998, 87.8, 87.2, 88.6, 88.2, -4.999999999999998, 88.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998], "episode_lengths": [25, 25, 13, 25, 25, 6, 25, 25, 25, 4, 25, 25, 25, 25, 25, 17, 15, 11, 25, 25, 25, 22, 25, 25, 11, 25, 17, 25, 25, 11, 25, 4, 25, 25, 25, 25, 25, 25, 25, 4, 25, 10, 25, 25, 25, 25, 25, 25, 25, 25, 25, 14, 25, 25, 11, 4, 25, 25, 25, 25, 25, 25, 25, 4, 4, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 5, 15, 25, 25, 20, 25, 25, 20, 20, 12, 4, 25, 12, 15, 8, 10, 25, 9, 4, 4, 4, 4, 25, 25, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -11.4, 98.6, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.6, -10.4, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.1, -11.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.1, -11.9, 98.1, -11.9, 98.9, -11.1, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 98.6, -11.4, 99.3, -10.7, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.41619682965458993, "mean_inference_ms": 1.649312973493146, "mean_action_processing_ms": 0.08936954426312106, "mean_env_wait_ms": 0.08685116600420105, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 60000, "timesteps_this_iter": 0, "agent_timesteps_total": 120000, "timers": {"sample_time_ms": 440.568, "sample_throughput": 2269.798, "load_time_ms": 1.372, "load_throughput": 728949.756, "learn_time_ms": 103.057, "learn_throughput": 9703.361, "update_time_ms": 3.094}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 2.384185791015625e-08, "cur_lr": 0.0005000000000000001, "total_loss": 897.8826751708984, "policy_loss": -0.00249800980091095, "vf_loss": 897.8926544189453, "vf_explained_var": 0.038447332382202146, "kl": 0.007428143196403147, "entropy": 0.7489240825176239, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 60000, "num_agent_steps_sampled": 120000, "num_steps_trained": 60000, "num_agent_steps_trained": 120000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 5048, "training_iteration": 60, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-00", "timestamp": 1749778560, "time_this_iter_s": 0.3696441650390625, "time_total_s": 22.68307375907898, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018212820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 22.68307375907898, "timesteps_since_restore": 0, "iterations_since_restore": 60, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 37.69800000000001, "episode_len_mean": 18.97, "episode_media": {}, "episodes_this_iter": 49, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 18.849}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, 88.0, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.2, 87.2, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, -4.999999999999998, 86.2, 86.2, 87.8, 89.4, -4.999999999999998, 87.8, 87.2, 88.6, 88.2, -4.999999999999998, 88.4, 89.4, 89.4, 89.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, 86.6, 87.8, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 86.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 89.4, -4.999999999999998, 87.6, -4.999999999999998, 88.6, 86.8, 89.4, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, 85.2, -4.999999999999998, 85.2, 89.4, 89.4, 89.4, -4.999999999999998, 85.2, -4.999999999999998, 88.4, 89.4, 85.4], "episode_lengths": [25, 25, 14, 25, 25, 11, 4, 25, 25, 25, 25, 25, 25, 25, 4, 4, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 5, 15, 25, 25, 20, 25, 25, 20, 20, 12, 4, 25, 12, 15, 8, 10, 25, 9, 4, 4, 4, 4, 25, 25, 25, 11, 25, 25, 11, 25, 25, 18, 12, 18, 25, 25, 25, 25, 25, 17, 19, 25, 25, 25, 25, 4, 4, 25, 13, 25, 8, 17, 4, 25, 18, 25, 25, 25, 25, 25, 25, 21, 25, 25, 25, 4, 4, 4, 25, 25, 25, 9, 4, 24], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.6, -10.4, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.1, -11.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.1, -11.9, 98.1, -11.9, 98.9, -11.1, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 98.6, -11.4, 99.3, -10.7, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, 98.9, -11.1, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -10.7, 99.3, 98.4, -11.6, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -12.4, 97.6, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -10.8, 99.2, 99.7, -10.3, 97.7, -12.3]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.41504860878157407, "mean_inference_ms": 1.6493961643339006, "mean_action_processing_ms": 0.08942891100498056, "mean_env_wait_ms": 0.08681971614205203, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 61000, "timesteps_this_iter": 0, "agent_timesteps_total": 122000, "timers": {"sample_time_ms": 401.036, "sample_throughput": 2493.543, "load_time_ms": 1.309, "load_throughput": 763822.844, "learn_time_ms": 102.607, "learn_throughput": 9745.88, "update_time_ms": 3.125}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 2.384185791015625e-08, "cur_lr": 0.0005000000000000001, "total_loss": 1081.6506286621093, "policy_loss": -0.0035256996750831606, "vf_loss": 1081.6617858886718, "vf_explained_var": 0.061072373390197755, "kl": 0.009437100368795193, "entropy": 0.7609052658081055, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 61000, "num_agent_steps_sampled": 122000, "num_steps_trained": 61000, "num_agent_steps_trained": 122000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 5097, "training_iteration": 61, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-01", "timestamp": 1749778561, "time_this_iter_s": 0.36063623428344727, "time_total_s": 23.043709993362427, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018319160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 23.043709993362427, "timesteps_since_restore": 0, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 63.9, "ram_util_percent": 90.5}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 33.852000000000004, "episode_len_mean": 20.16, "episode_media": {}, "episodes_this_iter": 50, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 16.926}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, 86.6, 87.8, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 86.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 89.4, -4.999999999999998, 87.6, -4.999999999999998, 88.6, 86.8, 89.4, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, 85.2, -4.999999999999998, 85.2, 89.4, 89.4, 89.4, -4.999999999999998, 85.2, -4.999999999999998, 88.4, 89.4, 85.4, 87.2, -4.999999999999998, 85.4, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, 85.8, 89.4, 88.6, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, 85.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 86.2, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 88.8, 89.4, -4.999999999999998, 87.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.4, -4.999999999999998, -4.999999999999998], "episode_lengths": [25, 11, 25, 25, 11, 25, 25, 18, 12, 18, 25, 25, 25, 25, 25, 17, 19, 25, 25, 25, 25, 4, 4, 25, 13, 25, 8, 17, 4, 25, 18, 25, 25, 25, 25, 25, 25, 21, 25, 25, 25, 4, 4, 4, 25, 25, 25, 9, 4, 24, 15, 25, 24, 25, 18, 25, 25, 22, 4, 8, 25, 25, 4, 25, 25, 14, 25, 25, 23, 25, 24, 25, 25, 25, 17, 20, 25, 25, 4, 25, 25, 25, 25, 4, 7, 4, 25, 16, 25, 25, 25, 25, 25, 25, 25, 25, 25, 19, 25, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, 98.9, -11.1, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -10.7, 99.3, 98.4, -11.6, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -12.4, 97.6, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -10.3, 99.7, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -10.8, 99.2, 99.7, -10.3, 97.7, -12.3, 98.6, -11.4, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, 99.7, -10.3, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 98.1, -11.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.4, -10.6, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4131815596279674, "mean_inference_ms": 1.648019506541736, "mean_action_processing_ms": 0.08933216321660602, "mean_env_wait_ms": 0.08676375244293738, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 62000, "timesteps_this_iter": 0, "agent_timesteps_total": 124000, "timers": {"sample_time_ms": 397.844, "sample_throughput": 2513.55, "load_time_ms": 1.28, "load_throughput": 781542.475, "learn_time_ms": 102.375, "learn_throughput": 9768.027, "update_time_ms": 3.102}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 2.384185791015625e-08, "cur_lr": 0.0005000000000000001, "total_loss": 883.6895263671875, "policy_loss": -0.002436557412147522, "vf_loss": 883.6992797851562, "vf_explained_var": 0.03808133006095886, "kl": 0.0073120483960029455, "entropy": 0.7331045150756836, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 62000, "num_agent_steps_sampled": 124000, "num_steps_trained": 62000, "num_agent_steps_trained": 124000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 5147, "training_iteration": 62, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-01", "timestamp": 1749778561, "time_this_iter_s": 0.35797715187072754, "time_total_s": 23.401687145233154, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018319670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 23.401687145233154, "timesteps_since_restore": 0, "iterations_since_restore": 62, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 26.464000000000002, "episode_len_mean": 21.02, "episode_media": {}, "episodes_this_iter": 45, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 13.231999999999998}, "custom_metrics": {}, "hist_stats": {"episode_reward": [85.2, -4.999999999999998, 88.4, 89.4, 85.4, 87.2, -4.999999999999998, 85.4, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, 85.8, 89.4, 88.6, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, 85.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 86.2, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 88.8, 89.4, -4.999999999999998, 87.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, 88.2, -4.999999999999998, 89.0, -4.999999999999998, 86.4, -4.999999999999998, 88.4, -4.999999999999998, 87.2, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, 87.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, 87.6], "episode_lengths": [25, 25, 9, 4, 24, 15, 25, 24, 25, 18, 25, 25, 22, 4, 8, 25, 25, 4, 25, 25, 14, 25, 25, 23, 25, 24, 25, 25, 25, 17, 20, 25, 25, 4, 25, 25, 25, 25, 4, 7, 4, 25, 16, 25, 25, 25, 25, 25, 25, 25, 25, 25, 19, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 11, 25, 10, 25, 6, 25, 19, 25, 9, 25, 15, 25, 9, 25, 25, 25, 25, 25, 25, 25, 8, 25, 25, 12, 25, 25, 25, 25, 25, 9, 25, 25, 25, 22, 25, 25, 13], "policy_shared_policy_reward": [-12.4, 97.6, -2.500000000000001, -2.500000000000001, -10.8, 99.2, 99.7, -10.3, 97.7, -12.3, 98.6, -11.4, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, 99.7, -10.3, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 98.1, -11.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.4, -10.6, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.8, -11.2]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.41198681951677757, "mean_inference_ms": 1.6475747944022192, "mean_action_processing_ms": 0.08935689839648468, "mean_env_wait_ms": 0.08687473616798645, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 63000, "timesteps_this_iter": 0, "agent_timesteps_total": 126000, "timers": {"sample_time_ms": 393.446, "sample_throughput": 2541.646, "load_time_ms": 1.294, "load_throughput": 772986.86, "learn_time_ms": 101.79, "learn_throughput": 9824.116, "update_time_ms": 3.105}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 2.384185791015625e-08, "cur_lr": 0.0005000000000000001, "total_loss": 529.2032104492188, "policy_loss": -0.0027367379516363144, "vf_loss": 529.2133605957031, "vf_explained_var": 0.07471070885658264, "kl": 0.01141205035253966, "entropy": 0.7426519274711609, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 63000, "num_agent_steps_sampled": 126000, "num_steps_trained": 63000, "num_agent_steps_trained": 126000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 5192, "training_iteration": 63, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-02", "timestamp": 1749778562, "time_this_iter_s": 0.36055731773376465, "time_total_s": 23.76224446296692, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018212820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 23.76224446296692, "timesteps_since_restore": 0, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 58.1, "ram_util_percent": 90.5}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 16.314, "episode_len_mean": 22.16, "episode_media": {}, "episodes_this_iter": 45, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 8.157}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, 88.2, -4.999999999999998, 89.0, -4.999999999999998, 86.4, -4.999999999999998, 88.4, -4.999999999999998, 87.2, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, 87.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, 85.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.8], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 19, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 11, 25, 10, 25, 6, 25, 19, 25, 9, 25, 15, 25, 9, 25, 25, 25, 25, 25, 25, 25, 8, 25, 25, 12, 25, 25, 25, 25, 25, 9, 25, 25, 25, 22, 25, 25, 13, 25, 25, 25, 25, 25, 25, 21, 25, 25, 25, 11, 25, 25, 25, 25, 25, 4, 25, 25, 4, 25, 15, 25, 25, 25, 25, 10, 23, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 4, 25, 25, 25, 25, 25, 12], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.41089754399631157, "mean_inference_ms": 1.6464375872484849, "mean_action_processing_ms": 0.08938858926572514, "mean_env_wait_ms": 0.08692151279149947, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 64000, "timesteps_this_iter": 0, "agent_timesteps_total": 128000, "timers": {"sample_time_ms": 389.909, "sample_throughput": 2564.702, "load_time_ms": 1.269, "load_throughput": 788151.155, "learn_time_ms": 100.766, "learn_throughput": 9924.028, "update_time_ms": 3.118}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 2.384185791015625e-08, "cur_lr": 0.0005000000000000001, "total_loss": 460.5901153564453, "policy_loss": -0.0044546729885041715, "vf_loss": 460.60247192382815, "vf_explained_var": 0.08143051862716674, "kl": 0.004878090939121593, "entropy": 0.7893155753612519, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 64000, "num_agent_steps_sampled": 128000, "num_steps_trained": 64000, "num_agent_steps_trained": 128000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 5237, "training_iteration": 64, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-02", "timestamp": 1749778562, "time_this_iter_s": 0.33983683586120605, "time_total_s": 24.102081298828125, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018212790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 24.102081298828125, "timesteps_since_restore": 0, "iterations_since_restore": 64, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 20.945999999999998, "episode_len_mean": 21.55, "episode_media": {}, "episodes_this_iter": 48, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 10.473000000000003}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, 85.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.8, -4.999999999999998, -4.999999999999998, 86.8, 87.4, -4.999999999999998, 88.0, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 87.2, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 86.6, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, -4.999999999999998, 88.6, -4.999999999999998, 89.4, 86.39999999999999, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6], "episode_lengths": [25, 25, 25, 22, 25, 25, 13, 25, 25, 25, 25, 25, 25, 21, 25, 25, 25, 11, 25, 25, 25, 25, 25, 4, 25, 25, 4, 25, 15, 25, 25, 25, 25, 10, 23, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 4, 25, 25, 25, 25, 25, 12, 25, 25, 17, 14, 25, 11, 8, 25, 25, 25, 25, 25, 4, 25, 15, 25, 4, 25, 25, 18, 25, 13, 25, 25, 22, 25, 25, 25, 25, 11, 25, 25, 25, 25, 25, 25, 25, 10, 25, 25, 8, 25, 4, 19, 25, 25, 25, 13], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -11.0, 99.0, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4093947098632411, "mean_inference_ms": 1.6455339841487497, "mean_action_processing_ms": 0.08935645172323312, "mean_env_wait_ms": 0.08697504458481736, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 65000, "timesteps_this_iter": 0, "agent_timesteps_total": 130000, "timers": {"sample_time_ms": 388.297, "sample_throughput": 2575.35, "load_time_ms": 1.271, "load_throughput": 786702.429, "learn_time_ms": 101.45, "learn_throughput": 9857.101, "update_time_ms": 2.939}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.1920928955078126e-08, "cur_lr": 0.0005000000000000001, "total_loss": 711.2878204345703, "policy_loss": -0.006887030601501465, "vf_loss": 711.3020629882812, "vf_explained_var": 0.07300166487693786, "kl": 0.01714069117794157, "entropy": 0.7365526616573334, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 65000, "num_agent_steps_sampled": 130000, "num_steps_trained": 65000, "num_agent_steps_trained": 130000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 5285, "training_iteration": 65, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-02", "timestamp": 1749778562, "time_this_iter_s": 0.35709285736083984, "time_total_s": 24.459174156188965, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018301e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 24.459174156188965, "timesteps_since_restore": 0, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 56.5, "ram_util_percent": 90.5}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 24.64, "episode_len_mean": 21.12, "episode_media": {}, "episodes_this_iter": 48, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 12.32}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, -4.999999999999998, 87.8, -4.999999999999998, -4.999999999999998, 86.8, 87.4, -4.999999999999998, 88.0, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 87.2, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 86.6, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, -4.999999999999998, 88.6, -4.999999999999998, 89.4, 86.39999999999999, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, -4.999999999999998, 89.4, -4.999999999999998, 86.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, 86.8, 85.2, -4.999999999999998, -4.999999999999998, 87.4, 89.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, 88.0, 88.0, 87.0, -4.999999999999998, -4.999999999999998, -4.999999999999998], "episode_lengths": [25, 25, 25, 12, 25, 25, 17, 14, 25, 11, 8, 25, 25, 25, 25, 25, 4, 25, 15, 25, 4, 25, 25, 18, 25, 13, 25, 25, 22, 25, 25, 25, 25, 11, 25, 25, 25, 25, 25, 25, 25, 10, 25, 25, 8, 25, 4, 19, 25, 25, 25, 13, 25, 4, 25, 19, 25, 25, 25, 25, 25, 11, 25, 25, 25, 25, 25, 25, 21, 25, 25, 11, 25, 17, 25, 25, 25, 14, 5, 25, 25, 25, 25, 4, 25, 25, 25, 25, 25, 25, 25, 25, 25, 15, 11, 11, 16, 25, 25, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -11.0, 99.0, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -11.0, 99.0, 99.0, -11.0, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.40853985513033675, "mean_inference_ms": 1.6451174336244214, "mean_action_processing_ms": 0.0893007173582209, "mean_env_wait_ms": 0.08689603730791251, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 66000, "timesteps_this_iter": 0, "agent_timesteps_total": 132000, "timers": {"sample_time_ms": 390.014, "sample_throughput": 2564.014, "load_time_ms": 1.209, "load_throughput": 827262.579, "learn_time_ms": 102.721, "learn_throughput": 9735.085, "update_time_ms": 2.746}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.1920928955078126e-08, "cur_lr": 0.0005000000000000001, "total_loss": 765.7629577636719, "policy_loss": -0.0018686503171920776, "vf_loss": 765.7720458984375, "vf_explained_var": 0.06648001670837403, "kl": 0.0044315314276720755, "entropy": 0.7245182693004608, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 66000, "num_agent_steps_sampled": 132000, "num_steps_trained": 66000, "num_agent_steps_trained": 132000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 5333, "training_iteration": 66, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-03", "timestamp": 1749778563, "time_this_iter_s": 0.3585836887359619, "time_total_s": 24.817757844924927, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018301d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 24.817757844924927, "timesteps_since_restore": 0, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 61.9, "ram_util_percent": 90.5}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 33.023999999999994, "episode_len_mean": 19.79, "episode_media": {}, "episodes_this_iter": 52, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 16.512000000000004}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 89.4, -4.999999999999998, 86.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, 86.8, 85.2, -4.999999999999998, -4.999999999999998, 87.4, 89.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, 88.0, 88.0, 87.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 89.4, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, 87.0, -4.999999999999998, 89.4, 88.0, 85.8, -4.999999999999998, 85.4, 87.6, -4.999999999999998, -4.999999999999998, 85.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, 89.4, 87.2, -4.999999999999998, -4.999999999999998, 88.4, 89.0, 89.4, 88.2, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, 89.0, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, 86.0, 87.2, 87.8, -4.999999999999998], "episode_lengths": [25, 4, 25, 19, 25, 25, 25, 25, 25, 11, 25, 25, 25, 25, 25, 25, 21, 25, 25, 11, 25, 17, 25, 25, 25, 14, 5, 25, 25, 25, 25, 4, 25, 25, 25, 25, 25, 25, 25, 25, 25, 15, 11, 11, 16, 25, 25, 25, 25, 25, 4, 25, 4, 25, 9, 25, 25, 25, 9, 16, 25, 4, 11, 22, 25, 24, 13, 25, 25, 24, 4, 25, 25, 25, 25, 15, 4, 15, 25, 25, 9, 6, 4, 10, 25, 8, 25, 25, 6, 25, 11, 25, 25, 25, 15, 25, 21, 15, 12, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -11.0, 99.0, 99.0, -11.0, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -11.5, 98.5, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.0, 99.0, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.6, -11.4, 99.7, -10.3, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.8, 99.2, 99.5, -10.5, 99.7, -10.3, -10.9, 99.1, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -11.4, 98.6, -11.1, 98.9, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.40780383873303366, "mean_inference_ms": 1.6435076411275378, "mean_action_processing_ms": 0.089113779685074, "mean_env_wait_ms": 0.08668623620273916, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 67000, "timesteps_this_iter": 0, "agent_timesteps_total": 134000, "timers": {"sample_time_ms": 391.978, "sample_throughput": 2551.163, "load_time_ms": 1.307, "load_throughput": 765020.975, "learn_time_ms": 103.48, "learn_throughput": 9663.729, "update_time_ms": 2.928}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 5.960464477539063e-09, "cur_lr": 0.0005000000000000001, "total_loss": 1083.1408203125, "policy_loss": -0.002805398777127266, "vf_loss": 1083.1507568359375, "vf_explained_var": 0.0187721312046051, "kl": 0.004312045241806395, "entropy": 0.7129430532455444, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 67000, "num_agent_steps_sampled": 134000, "num_steps_trained": 67000, "num_agent_steps_trained": 134000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 5385, "training_iteration": 67, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-03", "timestamp": 1749778563, "time_this_iter_s": 0.35763025283813477, "time_total_s": 25.17538809776306, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb01b0b3b80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 25.17538809776306, "timesteps_since_restore": 0, "iterations_since_restore": 67, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 39.538000000000004, "episode_len_mean": 18.79, "episode_media": {}, "episodes_this_iter": 51, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 19.769000000000002}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 89.4, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, 87.0, -4.999999999999998, 89.4, 88.0, 85.8, -4.999999999999998, 85.4, 87.6, -4.999999999999998, -4.999999999999998, 85.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, 89.4, 87.2, -4.999999999999998, -4.999999999999998, 88.4, 89.0, 89.4, 88.2, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, 89.0, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, 86.0, 87.2, 87.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, 85.4, -4.999999999999998, 86.39999999999999, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.2, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 87.0, -4.999999999999998, -4.999999999999998, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 89.4, -4.999999999999998, 89.0, 86.8, 89.4, -4.999999999999998, 87.6, -4.999999999999998, 89.0, -4.999999999999998, 88.8, 86.2, 88.8, -4.999999999999998, -4.999999999999998, 87.0, -4.999999999999998, -4.999999999999998, 86.8, 88.6, 86.4], "episode_lengths": [25, 4, 25, 9, 25, 25, 25, 9, 16, 25, 4, 11, 22, 25, 24, 13, 25, 25, 24, 4, 25, 25, 25, 25, 15, 4, 15, 25, 25, 9, 6, 4, 10, 25, 8, 25, 25, 6, 25, 11, 25, 25, 25, 15, 25, 21, 15, 12, 25, 25, 25, 25, 9, 25, 24, 25, 19, 25, 25, 25, 5, 11, 25, 25, 25, 4, 16, 25, 25, 25, 25, 25, 25, 14, 25, 25, 25, 25, 17, 4, 25, 6, 17, 4, 25, 13, 25, 6, 25, 7, 20, 7, 25, 25, 16, 25, 25, 17, 8, 19], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -11.5, 98.5, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.0, 99.0, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.6, -11.4, 99.7, -10.3, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.8, 99.2, 99.5, -10.5, 99.7, -10.3, -10.9, 99.1, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -11.4, 98.6, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.4, 99.6, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.5, 99.5, 98.4, -11.6, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -10.6, 99.4, 98.1, -11.9, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 99.3, -10.7, -11.8, 98.2]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.40741677205009497, "mean_inference_ms": 1.645500572648947, "mean_action_processing_ms": 0.08925267356330466, "mean_env_wait_ms": 0.08686031829753492, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 68000, "timesteps_this_iter": 0, "agent_timesteps_total": 136000, "timers": {"sample_time_ms": 392.116, "sample_throughput": 2550.267, "load_time_ms": 1.311, "load_throughput": 762753.278, "learn_time_ms": 101.267, "learn_throughput": 9874.929, "update_time_ms": 2.894}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 2.9802322387695314e-09, "cur_lr": 0.0005000000000000001, "total_loss": 1018.3845886230469, "policy_loss": -0.0028589604422450065, "vf_loss": 1018.3945678710937, "vf_explained_var": 0.038997286558151247, "kl": 0.0028312000114542268, "entropy": 0.7127503633499146, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 68000, "num_agent_steps_sampled": 136000, "num_steps_trained": 68000, "num_agent_steps_trained": 136000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 5436, "training_iteration": 68, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-03", "timestamp": 1749778563, "time_this_iter_s": 0.3530745506286621, "time_total_s": 25.528462648391724, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 25.528462648391724, "timesteps_since_restore": 0, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 66.8, "ram_util_percent": 90.6}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 34.918000000000006, "episode_len_mean": 19.34, "episode_media": {}, "episodes_this_iter": 51, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 17.459}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 88.4, -4.999999999999998, 85.4, -4.999999999999998, 86.39999999999999, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.2, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 87.0, -4.999999999999998, -4.999999999999998, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 89.4, -4.999999999999998, 89.0, 86.8, 89.4, -4.999999999999998, 87.6, -4.999999999999998, 89.0, -4.999999999999998, 88.8, 86.2, 88.8, -4.999999999999998, -4.999999999999998, 87.0, -4.999999999999998, -4.999999999999998, 86.8, 88.6, 86.4, -4.999999999999998, -4.999999999999998, 87.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, 88.2, 87.2, -4.999999999999998, 87.6, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 89.4, -4.999999999999998, 86.6, 89.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, 88.6, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 85.6, 86.2, 88.4, -4.999999999999998, 88.6, 88.8, -4.999999999999998, 88.8], "episode_lengths": [25, 9, 25, 24, 25, 19, 25, 25, 25, 5, 11, 25, 25, 25, 4, 16, 25, 25, 25, 25, 25, 25, 14, 25, 25, 25, 25, 17, 4, 25, 6, 17, 4, 25, 13, 25, 6, 25, 7, 20, 7, 25, 25, 16, 25, 25, 17, 8, 19, 25, 25, 12, 25, 25, 25, 25, 11, 25, 10, 15, 25, 13, 13, 25, 25, 25, 25, 25, 4, 25, 4, 25, 18, 6, 25, 25, 25, 21, 25, 25, 8, 25, 8, 25, 25, 25, 25, 25, 25, 25, 25, 4, 23, 20, 9, 25, 8, 7, 25, 7], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.4, 99.6, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.5, 99.5, 98.4, -11.6, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -10.6, 99.4, 98.1, -11.9, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 99.3, -10.7, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -12.200000000000001, 97.8, -11.9, 98.1, -10.8, 99.2, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -10.6, 99.4]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4065082310179982, "mean_inference_ms": 1.6450116051910992, "mean_action_processing_ms": 0.08935965600932594, "mean_env_wait_ms": 0.08696402824121552, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 69000, "timesteps_this_iter": 0, "agent_timesteps_total": 138000, "timers": {"sample_time_ms": 389.738, "sample_throughput": 2565.826, "load_time_ms": 1.321, "load_throughput": 757094.585, "learn_time_ms": 100.672, "learn_throughput": 9933.243, "update_time_ms": 3.14}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.4901161193847657e-09, "cur_lr": 0.0005000000000000001, "total_loss": 822.0552795410156, "policy_loss": -0.0021486843936145304, "vf_loss": 822.0645263671875, "vf_explained_var": 0.06579700112342834, "kl": 0.0059606316759753, "entropy": 0.7115207850933075, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 69000, "num_agent_steps_sampled": 138000, "num_steps_trained": 69000, "num_agent_steps_trained": 138000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 5487, "training_iteration": 69, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-04", "timestamp": 1749778564, "time_this_iter_s": 0.33255481719970703, "time_total_s": 25.86101746559143, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 25.86101746559143, "timesteps_since_restore": 0, "iterations_since_restore": 69, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 32.886, "episode_len_mean": 20.48, "episode_media": {}, "episodes_this_iter": 50, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 16.442999999999998}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 87.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, 88.2, 87.2, -4.999999999999998, 87.6, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 89.4, -4.999999999999998, 86.6, 89.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, 88.6, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 85.6, 86.2, 88.4, -4.999999999999998, 88.6, 88.8, -4.999999999999998, 88.8, 87.4, 85.8, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, 86.4, 85.8, -4.999999999999998, 87.0, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, 85.6, 87.6, 85.4, 87.0, -4.999999999999998, 89.4, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.6, 85.2, -4.999999999999998, -4.999999999999998, 86.2, 89.4, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998], "episode_lengths": [25, 12, 25, 25, 25, 25, 11, 25, 10, 15, 25, 13, 13, 25, 25, 25, 25, 25, 4, 25, 4, 25, 18, 6, 25, 25, 25, 21, 25, 25, 8, 25, 8, 25, 25, 25, 25, 25, 25, 25, 25, 4, 23, 20, 9, 25, 8, 7, 25, 7, 14, 22, 25, 25, 20, 25, 25, 25, 25, 21, 19, 22, 25, 16, 25, 25, 11, 25, 25, 25, 14, 25, 23, 13, 24, 16, 25, 4, 25, 21, 25, 25, 25, 8, 25, 25, 25, 20, 4, 17, 25, 25, 25, 25, 25, 18, 25, 25, 25, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -12.200000000000001, 97.8, -11.9, 98.1, -10.8, 99.2, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -11.3, 98.7, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.1, -11.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -11.8, 98.2, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -11.2, 98.8, 97.7, -12.3, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, 99.7, -10.3, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4052406925315739, "mean_inference_ms": 1.6431472865121197, "mean_action_processing_ms": 0.08927977377456683, "mean_env_wait_ms": 0.08683534854842767, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 70000, "timesteps_this_iter": 0, "agent_timesteps_total": 140000, "timers": {"sample_time_ms": 388.439, "sample_throughput": 2574.408, "load_time_ms": 1.277, "load_throughput": 783103.809, "learn_time_ms": 98.113, "learn_throughput": 10192.313, "update_time_ms": 3.087}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.4901161193847657e-09, "cur_lr": 0.0005000000000000001, "total_loss": 1128.39091796875, "policy_loss": -0.0008904807269573212, "vf_loss": 1128.3994201660157, "vf_explained_var": 0.03532203435897827, "kl": 0.0020127234000344883, "entropy": 0.7578395068645477, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 70000, "num_agent_steps_sampled": 140000, "num_steps_trained": 70000, "num_agent_steps_trained": 140000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 5537, "training_iteration": 70, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-04", "timestamp": 1749778564, "time_this_iter_s": 0.33360934257507324, "time_total_s": 26.194626808166504, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c9d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 26.194626808166504, "timesteps_since_restore": 0, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 56.1, "ram_util_percent": 90.6}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 30.974, "episode_len_mean": 21.02, "episode_media": {}, "episodes_this_iter": 46, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 15.487}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.6, 88.8, -4.999999999999998, 88.8, 87.4, 85.8, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, 86.4, 85.8, -4.999999999999998, 87.0, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, 85.6, 87.6, 85.4, 87.0, -4.999999999999998, 89.4, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.6, 85.2, -4.999999999999998, -4.999999999999998, 86.2, 89.4, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, 89.4, 85.6, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 88.0, -4.999999999999998, 88.2, -4.999999999999998, 87.2, 87.4, 88.4, 86.2, -4.999999999999998, -4.999999999999998, 89.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998], "episode_lengths": [8, 7, 25, 7, 14, 22, 25, 25, 20, 25, 25, 25, 25, 21, 19, 22, 25, 16, 25, 25, 11, 25, 25, 25, 14, 25, 23, 13, 24, 16, 25, 4, 25, 21, 25, 25, 25, 8, 25, 25, 25, 20, 4, 17, 25, 25, 25, 25, 25, 18, 25, 25, 25, 25, 25, 25, 25, 25, 25, 10, 25, 25, 25, 22, 25, 25, 4, 23, 25, 25, 4, 25, 11, 25, 10, 25, 15, 14, 9, 20, 25, 25, 6, 25, 25, 25, 10, 25, 25, 25, 24, 25, 25, 25, 25, 25, 21, 25, 25, 25], "policy_shared_policy_reward": [99.3, -10.7, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -11.3, 98.7, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.1, -11.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -11.8, 98.2, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -11.2, 98.8, 97.7, -12.3, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, 99.7, -10.3, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -11.4, 98.6, 98.7, -11.3, 99.2, -10.8, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4041036424816046, "mean_inference_ms": 1.642045817079253, "mean_action_processing_ms": 0.08926115915690548, "mean_env_wait_ms": 0.08678006834052054, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 71000, "timesteps_this_iter": 0, "agent_timesteps_total": 142000, "timers": {"sample_time_ms": 383.819, "sample_throughput": 2605.393, "load_time_ms": 1.25, "load_throughput": 800180.094, "learn_time_ms": 96.553, "learn_throughput": 10356.994, "update_time_ms": 2.982}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 7.450580596923829e-10, "cur_lr": 0.0005000000000000001, "total_loss": 740.8109893798828, "policy_loss": -0.0028965018689632418, "vf_loss": 740.8211029052734, "vf_explained_var": 0.049289411306381224, "kl": 0.0035801646543177413, "entropy": 0.7222079992294311, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 71000, "num_agent_steps_sampled": 142000, "num_steps_trained": 71000, "num_agent_steps_trained": 142000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 5583, "training_iteration": 71, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-05", "timestamp": 1749778565, "time_this_iter_s": 0.31973814964294434, "time_total_s": 26.51436495780945, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c95e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 26.51436495780945, "timesteps_since_restore": 0, "iterations_since_restore": 71, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 21.754, "episode_len_mean": 22.02, "episode_media": {}, "episodes_this_iter": 44, "policy_reward_min": {"shared_policy": -12.3}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 10.877}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, 89.4, 85.6, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 88.0, -4.999999999999998, 88.2, -4.999999999999998, 87.2, 87.4, 88.4, 86.2, -4.999999999999998, -4.999999999999998, 89.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, 85.4, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.0, 88.4, 86.39999999999999, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, 87.2, 87.0, -4.999999999999998, 87.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998], "episode_lengths": [25, 25, 25, 25, 25, 18, 25, 25, 25, 25, 25, 25, 25, 25, 25, 10, 25, 25, 25, 22, 25, 25, 4, 23, 25, 25, 4, 25, 11, 25, 10, 25, 15, 14, 9, 20, 25, 25, 6, 25, 25, 25, 10, 25, 25, 25, 24, 25, 25, 25, 25, 25, 21, 25, 25, 25, 25, 14, 24, 18, 25, 25, 25, 6, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 16, 9, 19, 25, 25, 25, 25, 22, 25, 25, 25, 17, 25, 25, 15, 16, 25, 16, 25, 25, 25, 25, 25, 14, 25, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -11.4, 98.6, 98.7, -11.3, 99.2, -10.8, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, 97.7, -12.3, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, 99.2, -10.8, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4033550801553237, "mean_inference_ms": 1.6412895549287612, "mean_action_processing_ms": 0.08921923982319922, "mean_env_wait_ms": 0.0867363596327014, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 72000, "timesteps_this_iter": 0, "agent_timesteps_total": 144000, "timers": {"sample_time_ms": 381.331, "sample_throughput": 2622.394, "load_time_ms": 1.242, "load_throughput": 804832.483, "learn_time_ms": 96.752, "learn_throughput": 10335.701, "update_time_ms": 2.984}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 3.7252902984619143e-10, "cur_lr": 0.0005000000000000001, "total_loss": 766.6880432128906, "policy_loss": -0.0031600459304172547, "vf_loss": 766.6984619140625, "vf_explained_var": 0.0620574414730072, "kl": 0.003609117749047666, "entropy": 0.7255894899368286, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 72000, "num_agent_steps_sampled": 144000, "num_steps_trained": 72000, "num_agent_steps_trained": 144000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 5627, "training_iteration": 72, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-05", "timestamp": 1749778565, "time_this_iter_s": 0.35037827491760254, "time_total_s": 26.86474323272705, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018212d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 26.86474323272705, "timesteps_since_restore": 0, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 55.9, "ram_util_percent": 90.5}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 23.7, "episode_len_mean": 21.31, "episode_media": {}, "episodes_this_iter": 49, "policy_reward_min": {"shared_policy": -12.3}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 11.85}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, 85.4, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.0, 88.4, 86.39999999999999, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, 87.2, 87.0, -4.999999999999998, 87.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 88.4, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 86.39999999999999, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 89.4, 88.6, 88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, 87.2, 88.6, -4.999999999999998, -4.999999999999998, 88.0, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998], "episode_lengths": [25, 25, 25, 21, 25, 25, 25, 25, 14, 24, 18, 25, 25, 25, 6, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 16, 9, 19, 25, 25, 25, 25, 22, 25, 25, 25, 17, 25, 25, 15, 16, 25, 16, 25, 25, 25, 25, 25, 14, 25, 25, 25, 25, 17, 9, 25, 13, 25, 25, 4, 25, 19, 4, 25, 25, 25, 25, 4, 25, 25, 4, 8, 7, 25, 25, 25, 25, 25, 4, 25, 25, 25, 25, 18, 25, 25, 15, 8, 25, 25, 11, 21, 25, 25, 25, 13, 25, 25, 25, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, 97.7, -12.3, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, 99.2, -10.8, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.4, -11.6, 99.2, -10.8, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 98.2, -11.8, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.7, 99.3, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.40208774835762406, "mean_inference_ms": 1.6393448079847022, "mean_action_processing_ms": 0.08906349624418232, "mean_env_wait_ms": 0.08668990760820092, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 73000, "timesteps_this_iter": 0, "agent_timesteps_total": 146000, "timers": {"sample_time_ms": 380.978, "sample_throughput": 2624.824, "load_time_ms": 1.311, "load_throughput": 763058.562, "learn_time_ms": 96.255, "learn_throughput": 10389.082, "update_time_ms": 2.964}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.8626451492309571e-10, "cur_lr": 0.0005000000000000001, "total_loss": 643.9338439941406, "policy_loss": -0.0026931166648864746, "vf_loss": 643.9436157226562, "vf_explained_var": 0.04412016272544861, "kl": 0.006740548661175438, "entropy": 0.7082757532596589, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 73000, "num_agent_steps_sampled": 146000, "num_steps_trained": 73000, "num_agent_steps_trained": 146000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 5676, "training_iteration": 73, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-05", "timestamp": 1749778565, "time_this_iter_s": 0.3371312618255615, "time_total_s": 27.201874494552612, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018301d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 27.201874494552612, "timesteps_since_restore": 0, "iterations_since_restore": 73, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 29.294, "episode_len_mean": 20.4, "episode_media": {}, "episodes_this_iter": 49, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 14.647}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 88.4, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 86.39999999999999, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 89.4, 88.6, 88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, 87.2, 88.6, -4.999999999999998, -4.999999999999998, 88.0, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.6, 87.4, -4.999999999999998, 87.6, 88.0, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, 87.2, 89.4, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, 89.4, 89.4, -4.999999999999998, 85.6, 86.2, 86.39999999999999, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, 87.0, 87.6, -4.999999999999998], "episode_lengths": [25, 25, 25, 25, 17, 9, 25, 13, 25, 25, 4, 25, 19, 4, 25, 25, 25, 25, 4, 25, 25, 4, 8, 7, 25, 25, 25, 25, 25, 4, 25, 25, 25, 25, 18, 25, 25, 15, 8, 25, 25, 11, 21, 25, 25, 25, 13, 25, 25, 25, 25, 25, 8, 14, 25, 13, 11, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 7, 25, 25, 25, 20, 15, 4, 25, 25, 22, 25, 25, 4, 4, 25, 23, 20, 19, 25, 25, 23, 25, 4, 25, 25, 25, 25, 25, 21, 16, 13, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.4, -11.6, 99.2, -10.8, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 98.2, -11.8, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.7, 99.3, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -11.0, 99.0, 97.6, -12.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.1, -11.9, 98.6, -11.4, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, -11.9, 98.1, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -11.5, 98.5, -11.2, 98.8, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4005662330288643, "mean_inference_ms": 1.6366777107260424, "mean_action_processing_ms": 0.08892108614678484, "mean_env_wait_ms": 0.08654096042094378, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 74000, "timesteps_this_iter": 0, "agent_timesteps_total": 148000, "timers": {"sample_time_ms": 380.623, "sample_throughput": 2627.271, "load_time_ms": 1.34, "load_throughput": 746450.258, "learn_time_ms": 96.6, "learn_throughput": 10351.979, "update_time_ms": 2.983}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.8626451492309571e-10, "cur_lr": 0.0005000000000000001, "total_loss": 1051.69150390625, "policy_loss": -0.0025820232927799224, "vf_loss": 1051.701190185547, "vf_explained_var": 0.04936556220054626, "kl": 0.004315159318680273, "entropy": 0.7085689067840576, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 74000, "num_agent_steps_sampled": 148000, "num_steps_trained": 74000, "num_agent_steps_trained": 148000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 5725, "training_iteration": 74, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-06", "timestamp": 1749778566, "time_this_iter_s": 0.3517873287200928, "time_total_s": 27.553661823272705, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c95e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 27.553661823272705, "timesteps_since_restore": 0, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 51.0, "ram_util_percent": 90.5}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 28.333999999999996, "episode_len_mean": 20.69, "episode_media": {}, "episodes_this_iter": 47, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 14.167}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.6, 87.4, -4.999999999999998, 87.6, 88.0, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, 87.2, 89.4, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, 89.4, 89.4, -4.999999999999998, 85.6, 86.2, 86.39999999999999, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, 87.0, 87.6, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, 89.4, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 86.2, -4.999999999999998, 89.4, 86.6, -4.999999999999998, 88.2, 89.2, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.39999999999999, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998], "episode_lengths": [25, 25, 25, 25, 25, 8, 14, 25, 13, 11, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 7, 25, 25, 25, 20, 15, 4, 25, 25, 22, 25, 25, 4, 4, 25, 23, 20, 19, 25, 25, 23, 25, 4, 25, 25, 25, 25, 25, 21, 16, 13, 25, 4, 25, 25, 25, 25, 25, 25, 25, 22, 25, 4, 25, 15, 25, 25, 25, 4, 20, 25, 4, 18, 25, 10, 5, 13, 25, 25, 25, 25, 25, 24, 4, 25, 25, 25, 4, 25, 25, 25, 19, 13, 25, 25, 25, 25, 25, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -11.0, 99.0, 97.6, -12.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.1, -11.9, 98.6, -11.4, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, -11.9, 98.1, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -11.5, 98.5, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.1, -11.9, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -10.4, 99.6, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3995730247765606, "mean_inference_ms": 1.636137113313323, "mean_action_processing_ms": 0.08896951647911414, "mean_env_wait_ms": 0.08647547110182527, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 75000, "timesteps_this_iter": 0, "agent_timesteps_total": 150000, "timers": {"sample_time_ms": 379.6, "sample_throughput": 2634.354, "load_time_ms": 1.326, "load_throughput": 753964.408, "learn_time_ms": 95.167, "learn_throughput": 10507.845, "update_time_ms": 2.898}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 9.313225746154786e-11, "cur_lr": 0.0005000000000000001, "total_loss": 663.5914794921875, "policy_loss": -0.0023334525525569917, "vf_loss": 663.6005004882812, "vf_explained_var": 0.05350412130355835, "kl": 0.005244091884713242, "entropy": 0.6710674524307251, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 75000, "num_agent_steps_sampled": 150000, "num_steps_trained": 75000, "num_agent_steps_trained": 150000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 5772, "training_iteration": 75, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-06", "timestamp": 1749778566, "time_this_iter_s": 0.32781314849853516, "time_total_s": 27.88147497177124, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c9d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 27.88147497177124, "timesteps_since_restore": 0, "iterations_since_restore": 75, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 25.55, "episode_len_mean": 21.08, "episode_media": {}, "episodes_this_iter": 48, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 12.775}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 86.0, 87.0, 87.6, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, 89.4, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 86.2, -4.999999999999998, 89.4, 86.6, -4.999999999999998, 88.2, 89.2, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.39999999999999, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, 86.6, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, 85.2, 85.2, 89.0, -4.999999999999998, 89.4, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998], "episode_lengths": [25, 21, 16, 13, 25, 4, 25, 25, 25, 25, 25, 25, 25, 22, 25, 4, 25, 15, 25, 25, 25, 4, 20, 25, 4, 18, 25, 10, 5, 13, 25, 25, 25, 25, 25, 24, 4, 25, 25, 25, 4, 25, 25, 25, 19, 13, 25, 25, 25, 25, 25, 25, 25, 25, 25, 20, 25, 25, 25, 25, 25, 25, 25, 14, 18, 25, 18, 25, 25, 25, 25, 6, 25, 4, 25, 21, 25, 25, 25, 4, 25, 25, 4, 25, 25, 25, 25, 25, 25, 25, 25, 24, 25, 25, 4, 25, 13, 25, 25, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -12.0, 98.0, -11.5, 98.5, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.1, -11.9, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -10.4, 99.6, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.1, -11.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -12.4, 97.6, 99.5, -10.5, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3988694928977116, "mean_inference_ms": 1.6360369208891046, "mean_action_processing_ms": 0.08898500424841892, "mean_env_wait_ms": 0.08648859947054369, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 76000, "timesteps_this_iter": 0, "agent_timesteps_total": 152000, "timers": {"sample_time_ms": 376.521, "sample_throughput": 2655.895, "load_time_ms": 1.402, "load_throughput": 713268.485, "learn_time_ms": 94.383, "learn_throughput": 10595.083, "update_time_ms": 2.898}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 9.313225746154786e-11, "cur_lr": 0.0005000000000000001, "total_loss": 704.226840209961, "policy_loss": -0.0014109522104263305, "vf_loss": 704.2349517822265, "vf_explained_var": -0.009453356266021729, "kl": 0.0034682786663512654, "entropy": 0.6695254564285278, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 76000, "num_agent_steps_sampled": 152000, "num_steps_trained": 76000, "num_agent_steps_trained": 152000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 5820, "training_iteration": 76, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-06", "timestamp": 1749778566, "time_this_iter_s": 0.34490036964416504, "time_total_s": 28.226375341415405, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018301dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 28.226375341415405, "timesteps_since_restore": 0, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 51.7, "ram_util_percent": 90.5}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 26.42, "episode_len_mean": 21.24, "episode_media": {}, "episodes_this_iter": 49, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 13.21}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, 86.6, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, 85.2, 85.2, 89.0, -4.999999999999998, 89.4, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, 87.4, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 88.2, -4.999999999999998, 85.4, -4.999999999999998, 86.39999999999999, -4.999999999999998, 88.6, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, 89.4, -4.999999999999998, 85.6, -4.999999999999998, 85.8, -4.999999999999998, 87.0, 87.0, -4.999999999999998, 89.4, 86.39999999999999, -4.999999999999998, -4.999999999999998, 87.8, -4.999999999999998, -4.999999999999998], "episode_lengths": [25, 25, 25, 25, 25, 25, 20, 25, 25, 25, 25, 25, 25, 25, 14, 18, 25, 18, 25, 25, 25, 25, 6, 25, 4, 25, 21, 25, 25, 25, 4, 25, 25, 4, 25, 25, 25, 25, 25, 25, 25, 25, 24, 25, 25, 4, 25, 13, 25, 25, 25, 11, 25, 25, 25, 9, 14, 25, 25, 4, 25, 10, 25, 24, 25, 19, 25, 8, 25, 17, 25, 25, 25, 25, 25, 21, 11, 25, 25, 25, 25, 25, 25, 10, 4, 25, 23, 25, 22, 25, 16, 16, 25, 4, 19, 25, 25, 12, 25, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.1, -11.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -12.4, 97.6, 99.5, -10.5, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.8, 99.2, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -11.5, 98.5, 98.5, -11.5, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.39801145223038653, "mean_inference_ms": 1.633731469107247, "mean_action_processing_ms": 0.08873670922023263, "mean_env_wait_ms": 0.08632438111527536, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 77000, "timesteps_this_iter": 0, "agent_timesteps_total": 154000, "timers": {"sample_time_ms": 375.943, "sample_throughput": 2659.978, "load_time_ms": 1.39, "load_throughput": 719397.63, "learn_time_ms": 93.226, "learn_throughput": 10726.588, "update_time_ms": 2.775}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 4.656612873077393e-11, "cur_lr": 0.0005000000000000001, "total_loss": 919.2504028320312, "policy_loss": -0.0036100741475820542, "vf_loss": 919.2606872558594, "vf_explained_var": 0.04185593128204346, "kl": 0.005310028055854144, "entropy": 0.6712103843688965, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 77000, "num_agent_steps_sampled": 154000, "num_steps_trained": 77000, "num_agent_steps_trained": 154000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 5869, "training_iteration": 77, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-07", "timestamp": 1749778567, "time_this_iter_s": 0.3413050174713135, "time_total_s": 28.56768035888672, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c95e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 28.56768035888672, "timesteps_since_restore": 0, "iterations_since_restore": 77, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 26.416, "episode_len_mean": 21.26, "episode_media": {}, "episodes_this_iter": 48, "policy_reward_min": {"shared_policy": -12.3}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 13.207999999999997}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, 87.4, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 88.2, -4.999999999999998, 85.4, -4.999999999999998, 86.39999999999999, -4.999999999999998, 88.6, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, 89.4, -4.999999999999998, 85.6, -4.999999999999998, 85.8, -4.999999999999998, 87.0, 87.0, -4.999999999999998, 89.4, 86.39999999999999, -4.999999999999998, -4.999999999999998, 87.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, 88.8, 86.6, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.8, -4.999999999999998, 87.8, -4.999999999999998, -4.999999999999998, -4.999999999999998], "episode_lengths": [25, 25, 25, 11, 25, 25, 25, 9, 14, 25, 25, 4, 25, 10, 25, 24, 25, 19, 25, 8, 25, 17, 25, 25, 25, 25, 25, 21, 11, 25, 25, 25, 25, 25, 25, 10, 4, 25, 23, 25, 22, 25, 16, 16, 25, 4, 19, 25, 25, 12, 25, 25, 25, 25, 24, 7, 18, 4, 25, 25, 25, 25, 25, 4, 25, 25, 25, 20, 25, 17, 25, 25, 23, 25, 25, 15, 25, 25, 25, 24, 25, 25, 25, 25, 25, 18, 25, 25, 25, 25, 4, 25, 25, 25, 12, 25, 12, 25, 25, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.8, 99.2, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -11.5, 98.5, 98.5, -11.5, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -10.6, 99.4, -11.700000000000001, 98.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.1, -11.9, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3970035086301301, "mean_inference_ms": 1.632120353888366, "mean_action_processing_ms": 0.0886464605452651, "mean_env_wait_ms": 0.0862991804353942, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 78000, "timesteps_this_iter": 0, "agent_timesteps_total": 156000, "timers": {"sample_time_ms": 374.812, "sample_throughput": 2668.001, "load_time_ms": 1.483, "load_throughput": 674466.368, "learn_time_ms": 94.14, "learn_throughput": 10622.49, "update_time_ms": 2.708}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 4.656612873077393e-11, "cur_lr": 0.0005000000000000001, "total_loss": 679.28369140625, "policy_loss": -0.003770393133163452, "vf_loss": 679.2944580078125, "vf_explained_var": 0.03651158213615417, "kl": 0.010938477148004644, "entropy": 0.7016337096691132, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 78000, "num_agent_steps_sampled": 156000, "num_steps_trained": 78000, "num_agent_steps_trained": 156000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 5917, "training_iteration": 78, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-07", "timestamp": 1749778567, "time_this_iter_s": 0.3537001609802246, "time_total_s": 28.921380519866943, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c9d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 28.921380519866943, "timesteps_since_restore": 0, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 50.0, "ram_util_percent": 90.5}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 39.452, "episode_len_mean": 19.22, "episode_media": {}, "episodes_this_iter": 57, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 19.726}, "custom_metrics": {}, "hist_stats": {"episode_reward": [89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.8, -4.999999999999998, 87.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, 85.2, 88.4, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, 85.2, 86.8, -4.999999999999998, -4.999999999999998, 87.8, 89.4, -4.999999999999998, 87.4, 89.0, -4.999999999999998, -4.999999999999998, 85.8, 87.8, 85.8, 88.6, -4.999999999999998, 86.6, 86.0, -4.999999999999998, 87.4, 89.4, 87.6, 88.6, 86.8, 88.8, 87.4, 88.2, -4.999999999999998, -4.999999999999998, 87.8, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, 88.2, 88.0, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, 86.2, 87.6, 89.4, -4.999999999999998, 88.0, 88.6, 89.4, 87.2, -4.999999999999998], "episode_lengths": [4, 25, 25, 25, 25, 25, 4, 25, 25, 25, 20, 25, 17, 25, 25, 23, 25, 25, 15, 25, 25, 25, 24, 25, 25, 25, 25, 25, 18, 25, 25, 25, 25, 4, 25, 25, 25, 12, 25, 12, 25, 25, 25, 10, 25, 9, 25, 17, 25, 25, 25, 17, 25, 25, 12, 4, 25, 14, 6, 25, 25, 22, 12, 22, 8, 25, 18, 21, 25, 14, 4, 13, 8, 17, 7, 14, 10, 25, 25, 12, 25, 25, 10, 25, 10, 11, 8, 25, 25, 25, 14, 20, 13, 4, 25, 11, 8, 4, 15, 25], "policy_shared_policy_reward": [99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.1, -11.9, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -12.4, 97.6, -10.8, 99.2, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.4, 97.6, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.1, 98.9, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, 98.9, -11.1, -12.100000000000001, 97.9, 99.3, -10.7, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, 98.7, -11.3, 99.7, -10.3, 98.8, -11.2, 99.3, -10.7, 98.4, -11.6, -10.6, 99.4, 98.7, -11.3, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 99.0, -11.0, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -11.9, 98.1, 98.8, -11.2, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -10.7, 99.3, 99.7, -10.3, 98.6, -11.4, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3967413191431928, "mean_inference_ms": 1.6353808975009576, "mean_action_processing_ms": 0.08886265320009193, "mean_env_wait_ms": 0.08647255508214917, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 79000, "timesteps_this_iter": 0, "agent_timesteps_total": 158000, "timers": {"sample_time_ms": 377.643, "sample_throughput": 2648.006, "load_time_ms": 1.592, "load_throughput": 628162.526, "learn_time_ms": 94.824, "learn_throughput": 10545.903, "update_time_ms": 2.552}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 4.656612873077393e-11, "cur_lr": 0.0005000000000000001, "total_loss": 1623.1982788085938, "policy_loss": -0.0037383386865258218, "vf_loss": 1623.20927734375, "vf_explained_var": 0.04891364574432373, "kl": 0.00510293041439569, "entropy": 0.7248301863670349, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 79000, "num_agent_steps_sampled": 158000, "num_steps_trained": 79000, "num_agent_steps_trained": 158000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 5974, "training_iteration": 79, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-08", "timestamp": 1749778568, "time_this_iter_s": 0.36307454109191895, "time_total_s": 29.284455060958862, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018319280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 29.284455060958862, "timesteps_since_restore": 0, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 56.9, "ram_util_percent": 90.5}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 53.364000000000004, "episode_len_mean": 17.31, "episode_media": {}, "episodes_this_iter": 56, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 26.682}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 87.4, 89.0, -4.999999999999998, -4.999999999999998, 85.8, 87.8, 85.8, 88.6, -4.999999999999998, 86.6, 86.0, -4.999999999999998, 87.4, 89.4, 87.6, 88.6, 86.8, 88.8, 87.4, 88.2, -4.999999999999998, -4.999999999999998, 87.8, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, 88.2, 88.0, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, 86.2, 87.6, 89.4, -4.999999999999998, 88.0, 88.6, 89.4, 87.2, -4.999999999999998, -4.999999999999998, 85.2, 89.0, 88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 85.6, 88.0, 86.6, 87.4, 87.4, 87.4, -4.999999999999998, 85.6, 88.6, 85.8, 87.6, -4.999999999999998, -4.999999999999998, 86.4, 87.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, 86.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.8, 89.4, -4.999999999999998, -4.999999999999998, 88.6, 87.0, 88.2, -4.999999999999998, -4.999999999999998, 85.2, 88.6, 89.4, 89.4, 88.4, -4.999999999999998, 86.0, 88.2, 89.4, 86.6, -4.999999999999998, 87.0, 85.6], "episode_lengths": [25, 14, 6, 25, 25, 22, 12, 22, 8, 25, 18, 21, 25, 14, 4, 13, 8, 17, 7, 14, 10, 25, 25, 12, 25, 25, 10, 25, 10, 11, 8, 25, 25, 25, 14, 20, 13, 4, 25, 11, 8, 4, 15, 25, 25, 25, 6, 7, 25, 25, 25, 4, 25, 25, 23, 11, 18, 14, 14, 14, 25, 23, 8, 22, 13, 25, 25, 19, 12, 25, 25, 25, 11, 20, 25, 25, 25, 25, 12, 4, 25, 25, 8, 16, 10, 25, 25, 25, 8, 4, 4, 9, 25, 21, 10, 4, 18, 25, 16, 23], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, 98.7, -11.3, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, 98.9, -11.1, -12.100000000000001, 97.9, 99.3, -10.7, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, 98.7, -11.3, 99.7, -10.3, 98.8, -11.2, 99.3, -10.7, 98.4, -11.6, -10.6, 99.4, 98.7, -11.3, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 99.0, -11.0, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -11.9, 98.1, 98.8, -11.2, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -10.7, 99.3, 99.7, -10.3, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -10.5, 99.5, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, 99.0, -11.0, -11.700000000000001, 98.3, -11.3, 98.7, 98.7, -11.3, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -10.7, 99.3, 97.9, -12.100000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, 98.1, -11.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -11.5, 98.5, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.6, -12.4, 99.3, -10.7, 99.7, -10.3, 99.7, -10.3, -10.8, 99.2, -2.500000000000001, -2.500000000000001, 98.0, -12.0, 99.1, -10.9, 99.7, -10.3, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, 97.8, -12.200000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.39619488585235, "mean_inference_ms": 1.634055984499505, "mean_action_processing_ms": 0.08893994092874849, "mean_env_wait_ms": 0.08646489088426136, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 80000, "timesteps_this_iter": 0, "agent_timesteps_total": 160000, "timers": {"sample_time_ms": 379.305, "sample_throughput": 2636.4, "load_time_ms": 1.596, "load_throughput": 626473.69, "learn_time_ms": 96.804, "learn_throughput": 10330.121, "update_time_ms": 2.608}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 4.656612873077393e-11, "cur_lr": 0.0005000000000000001, "total_loss": 1423.706396484375, "policy_loss": -0.002702132239937782, "vf_loss": 1423.71630859375, "vf_explained_var": 0.06661351919174194, "kl": 0.0036253770449968135, "entropy": 0.7181451976299286, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 80000, "num_agent_steps_sampled": 160000, "num_steps_trained": 80000, "num_agent_steps_trained": 160000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 6030, "training_iteration": 80, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-08", "timestamp": 1749778568, "time_this_iter_s": 0.3569047451019287, "time_total_s": 29.64135980606079, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c95e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 29.64135980606079, "timesteps_since_restore": 0, "iterations_since_restore": 80, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 53.36599999999999, "episode_len_mean": 17.3, "episode_media": {}, "episodes_this_iter": 58, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 26.683000000000003}, "custom_metrics": {}, "hist_stats": {"episode_reward": [87.4, 87.4, -4.999999999999998, 85.6, 88.6, 85.8, 87.6, -4.999999999999998, -4.999999999999998, 86.4, 87.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, 86.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.8, 89.4, -4.999999999999998, -4.999999999999998, 88.6, 87.0, 88.2, -4.999999999999998, -4.999999999999998, 85.2, 88.6, 89.4, 89.4, 88.4, -4.999999999999998, 86.0, 88.2, 89.4, 86.6, -4.999999999999998, 87.0, 85.6, 87.6, -4.999999999999998, 88.0, -4.999999999999998, 88.2, 86.8, 88.4, 87.0, 88.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, 87.4, 89.4, 86.8, -4.999999999999998, -4.999999999999998, 86.4, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 85.4, 88.6, -4.999999999999998, 87.0, 87.2, -4.999999999999998, 89.4, 86.6, 89.4, 86.2, -4.999999999999998, 86.6, 87.8, 89.4, 87.0, -4.999999999999998, 87.4, 89.0, 88.2, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 86.0, 88.6, 87.2, 88.4, -4.999999999999998, 87.8, 89.4, 85.6], "episode_lengths": [14, 14, 25, 23, 8, 22, 13, 25, 25, 19, 12, 25, 25, 25, 11, 20, 25, 25, 25, 25, 12, 4, 25, 25, 8, 16, 10, 25, 25, 25, 8, 4, 4, 9, 25, 21, 10, 4, 18, 25, 16, 23, 13, 25, 11, 25, 10, 17, 9, 16, 10, 25, 25, 25, 13, 14, 4, 17, 25, 25, 19, 25, 25, 15, 25, 25, 25, 4, 25, 24, 8, 25, 16, 15, 25, 4, 18, 4, 20, 25, 18, 12, 4, 16, 25, 14, 6, 10, 25, 25, 4, 25, 21, 8, 15, 9, 25, 12, 4, 23], "policy_shared_policy_reward": [98.7, -11.3, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -10.7, 99.3, 97.9, -12.100000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, 98.1, -11.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -11.5, 98.5, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.6, -12.4, 99.3, -10.7, 99.7, -10.3, 99.7, -10.3, -10.8, 99.2, -2.500000000000001, -2.500000000000001, 98.0, -12.0, 99.1, -10.9, 99.7, -10.3, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, 97.8, -12.200000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -11.6, 98.4, 99.2, -10.8, -11.5, 98.5, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -11.3, 98.7, 99.7, -10.3, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -10.7, 99.3, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -11.4, 98.6, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.3, -11.700000000000001, 99.7, -10.3, 98.1, -11.9, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -11.1, 98.9, 99.7, -10.3, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -10.5, 99.5, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -10.7, 99.3, -11.4, 98.6, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -11.1, 98.9, 99.7, -10.3, 97.8, -12.200000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3954235101355023, "mean_inference_ms": 1.632128457514664, "mean_action_processing_ms": 0.08884985866452215, "mean_env_wait_ms": 0.08640689886447271, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 81000, "timesteps_this_iter": 0, "agent_timesteps_total": 162000, "timers": {"sample_time_ms": 382.118, "sample_throughput": 2616.993, "load_time_ms": 1.6, "load_throughput": 624896.305, "learn_time_ms": 98.298, "learn_throughput": 10173.139, "update_time_ms": 2.709}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 2.3283064365386964e-11, "cur_lr": 0.0005000000000000001, "total_loss": 1459.569189453125, "policy_loss": -0.003182988613843918, "vf_loss": 1459.5792846679688, "vf_explained_var": 0.06864538788795471, "kl": 0.006798194537408708, "entropy": 0.6875502407550812, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 81000, "num_agent_steps_sampled": 162000, "num_steps_trained": 81000, "num_agent_steps_trained": 162000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 6088, "training_iteration": 81, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-08", "timestamp": 1749778568, "time_this_iter_s": 0.3465080261230469, "time_total_s": 29.987867832183838, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018229d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 29.987867832183838, "timesteps_since_restore": 0, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 57.9, "ram_util_percent": 90.4}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 49.638000000000005, "episode_len_mean": 17.9, "episode_media": {}, "episodes_this_iter": 53, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 24.818999999999996}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 87.6, 87.4, 89.4, 86.8, -4.999999999999998, -4.999999999999998, 86.4, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 85.4, 88.6, -4.999999999999998, 87.0, 87.2, -4.999999999999998, 89.4, 86.6, 89.4, 86.2, -4.999999999999998, 86.6, 87.8, 89.4, 87.0, -4.999999999999998, 87.4, 89.0, 88.2, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 86.0, 88.6, 87.2, 88.4, -4.999999999999998, 87.8, 89.4, 85.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.8, -4.999999999999998, -4.999999999999998, 89.4, 85.6, 85.4, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 86.0, 87.6, 88.2, -4.999999999999998, -4.999999999999998, 88.2, 88.4, 88.4, 89.4, -4.999999999999998, 86.0, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, 89.4, 85.4, -4.999999999999998, 85.2, 86.4, 89.4, -4.999999999999998, -4.999999999999998, 86.0, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, 86.4, -4.999999999999998, 87.6, -4.999999999999998, 87.8, 87.8, -4.999999999999998, 89.4, 87.6], "episode_lengths": [25, 13, 14, 4, 17, 25, 25, 19, 25, 25, 15, 25, 25, 25, 4, 25, 24, 8, 25, 16, 15, 25, 4, 18, 4, 20, 25, 18, 12, 4, 16, 25, 14, 6, 10, 25, 25, 4, 25, 21, 8, 15, 9, 25, 12, 4, 23, 25, 25, 25, 12, 25, 25, 4, 23, 24, 25, 4, 25, 25, 21, 13, 10, 25, 25, 10, 9, 9, 4, 25, 21, 4, 25, 25, 25, 25, 24, 4, 24, 25, 25, 19, 4, 25, 25, 21, 18, 25, 25, 25, 14, 19, 25, 13, 25, 12, 12, 25, 4, 13], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, 98.8, -11.2, -11.3, 98.7, 99.7, -10.3, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -10.7, 99.3, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -11.4, 98.6, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.3, -11.700000000000001, 99.7, -10.3, 98.1, -11.9, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -11.1, 98.9, 99.7, -10.3, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -10.5, 99.5, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -10.7, 99.3, -11.4, 98.6, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -11.1, 98.9, 99.7, -10.3, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 97.8, -12.200000000000001, 97.7, -12.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, 98.8, -11.2, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, 99.2, -10.8, -10.8, 99.2, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.0, -12.0, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, 99.7, -10.3, -12.3, 97.7, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -11.8, 98.2, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -11.8, 98.2, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 98.9, -11.1, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.8, -11.2]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.39501970508960227, "mean_inference_ms": 1.6325119652543645, "mean_action_processing_ms": 0.08889075397620327, "mean_env_wait_ms": 0.08648793470011938, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 82000, "timesteps_this_iter": 0, "agent_timesteps_total": 164000, "timers": {"sample_time_ms": 382.85, "sample_throughput": 2611.99, "load_time_ms": 1.544, "load_throughput": 647728.943, "learn_time_ms": 97.858, "learn_throughput": 10218.851, "update_time_ms": 2.646}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 2.3283064365386964e-11, "cur_lr": 0.0005000000000000001, "total_loss": 1322.912890625, "policy_loss": -0.0023194290697574615, "vf_loss": 1322.9221923828125, "vf_explained_var": 0.04176698923110962, "kl": 0.003261383073016244, "entropy": 0.6956074416637421, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 82000, "num_agent_steps_sampled": 164000, "num_steps_trained": 82000, "num_agent_steps_trained": 164000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 6141, "training_iteration": 82, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-09", "timestamp": 1749778569, "time_this_iter_s": 0.338026762008667, "time_total_s": 30.325894594192505, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018229f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 30.325894594192505, "timesteps_since_restore": 0, "iterations_since_restore": 82, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 44.022, "episode_len_mean": 18.92, "episode_media": {}, "episodes_this_iter": 50, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 22.011}, "custom_metrics": {}, "hist_stats": {"episode_reward": [87.8, -4.999999999999998, -4.999999999999998, 89.4, 85.6, 85.4, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 86.0, 87.6, 88.2, -4.999999999999998, -4.999999999999998, 88.2, 88.4, 88.4, 89.4, -4.999999999999998, 86.0, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, 89.4, 85.4, -4.999999999999998, 85.2, 86.4, 89.4, -4.999999999999998, -4.999999999999998, 86.0, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, 86.4, -4.999999999999998, 87.6, -4.999999999999998, 87.8, 87.8, -4.999999999999998, 89.4, 87.6, -4.999999999999998, 89.4, 88.2, -4.999999999999998, 87.4, -4.999999999999998, 85.8, 85.2, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, 86.8, 88.2, 86.0, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.8, 86.8, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 86.8, 88.0, 89.4, -4.999999999999998, 88.2, -4.999999999999998, -4.999999999999998, 87.8, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, 89.4, 87.0, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998], "episode_lengths": [12, 25, 25, 4, 23, 24, 25, 4, 25, 25, 21, 13, 10, 25, 25, 10, 9, 9, 4, 25, 21, 4, 25, 25, 25, 25, 24, 4, 24, 25, 25, 19, 4, 25, 25, 21, 18, 25, 25, 25, 14, 19, 25, 13, 25, 12, 12, 25, 4, 13, 25, 4, 10, 25, 14, 25, 22, 25, 25, 25, 24, 25, 25, 25, 20, 17, 10, 21, 25, 25, 15, 25, 25, 25, 12, 17, 4, 25, 25, 25, 4, 17, 11, 4, 25, 10, 25, 25, 12, 25, 15, 25, 25, 4, 16, 25, 15, 25, 25, 25], "policy_shared_policy_reward": [98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 97.8, -12.200000000000001, 97.7, -12.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, 98.8, -11.2, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, 99.2, -10.8, -10.8, 99.2, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.0, -12.0, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, 99.7, -10.3, -12.3, 97.7, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -11.8, 98.2, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -11.8, 98.2, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 98.9, -11.1, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.8, -11.2, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, 97.6, -12.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.1, -11.9, 98.4, -11.6, 99.1, -10.9, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 98.4, -11.6, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.4, -11.6, 99.0, -11.0, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.5, 98.5, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3944388388526708, "mean_inference_ms": 1.630282678743265, "mean_action_processing_ms": 0.08869154083468392, "mean_env_wait_ms": 0.08630458883984941, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 83000, "timesteps_this_iter": 0, "agent_timesteps_total": 166000, "timers": {"sample_time_ms": 382.826, "sample_throughput": 2612.154, "load_time_ms": 1.549, "load_throughput": 645545.688, "learn_time_ms": 98.023, "learn_throughput": 10201.729, "update_time_ms": 2.676}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.1641532182693482e-11, "cur_lr": 0.0005000000000000001, "total_loss": 959.0732727050781, "policy_loss": -0.002297575683041941, "vf_loss": 959.0822387695313, "vf_explained_var": 0.09295386672019959, "kl": 0.0045165287267729505, "entropy": 0.6667347967624664, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 83000, "num_agent_steps_sampled": 166000, "num_steps_trained": 83000, "num_agent_steps_trained": 166000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 6191, "training_iteration": 83, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-09", "timestamp": 1749778569, "time_this_iter_s": 0.3564627170562744, "time_total_s": 30.68235731124878, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c9d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 30.68235731124878, "timesteps_since_restore": 0, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 55.2, "ram_util_percent": 90.3}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 45.82200000000001, "episode_len_mean": 18.94, "episode_media": {}, "episodes_this_iter": 57, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 22.910999999999998}, "custom_metrics": {}, "hist_stats": {"episode_reward": [85.2, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, 86.8, 88.2, 86.0, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.8, 86.8, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 86.8, 88.0, 89.4, -4.999999999999998, 88.2, -4.999999999999998, -4.999999999999998, 87.8, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, 89.4, 87.0, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, 89.4, 88.0, -4.999999999999998, 88.8, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, 88.0, 85.4, 87.6, 87.6, -4.999999999999998, -4.999999999999998, 87.8, 86.6, 85.2, -4.999999999999998, -4.999999999999998, 87.4, 87.8, 86.8, -4.999999999999998, 86.8, 86.0, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, 89.4, 86.8, 85.8, -4.999999999999998, 87.4, 89.4, 88.2, 87.4, -4.999999999999998, 87.8, -4.999999999999998, 85.4, 86.0, 89.0, 87.4, 87.8, 87.6, -4.999999999999998, 86.8], "episode_lengths": [25, 25, 25, 24, 25, 25, 25, 20, 17, 10, 21, 25, 25, 15, 25, 25, 25, 12, 17, 4, 25, 25, 25, 4, 17, 11, 4, 25, 10, 25, 25, 12, 25, 15, 25, 25, 4, 16, 25, 15, 25, 25, 25, 25, 10, 4, 11, 25, 7, 25, 22, 25, 25, 17, 25, 25, 25, 25, 7, 25, 11, 24, 13, 13, 25, 25, 12, 18, 25, 25, 25, 14, 12, 17, 25, 17, 21, 25, 17, 25, 25, 4, 17, 22, 25, 14, 4, 10, 14, 25, 12, 25, 24, 21, 6, 14, 12, 13, 25, 17], "policy_shared_policy_reward": [97.6, -12.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.1, -11.9, 98.4, -11.6, 99.1, -10.9, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 98.4, -11.6, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.4, -11.6, 99.0, -11.0, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.5, 98.5, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, 99.7, -10.3, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -11.0, 99.0, 97.7, -12.3, 98.8, -11.2, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 98.3, -11.700000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, 98.9, -11.1, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -12.0, 98.0, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.4, -11.6, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, 99.7, -10.3, -10.9, 99.1, -11.3, 98.7, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -2.500000000000001, -2.500000000000001, 97.7, -12.3, 98.0, -12.0, -10.5, 99.5, 98.7, -11.3, 98.9, -11.1, -11.2, 98.8, -2.500000000000001, -2.500000000000001, 98.4, -11.6]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3935923939160642, "mean_inference_ms": 1.6289851089724647, "mean_action_processing_ms": 0.08859495580723423, "mean_env_wait_ms": 0.08618372679117145, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 84000, "timesteps_this_iter": 0, "agent_timesteps_total": 168000, "timers": {"sample_time_ms": 382.795, "sample_throughput": 2612.368, "load_time_ms": 1.449, "load_throughput": 689898.02, "learn_time_ms": 97.894, "learn_throughput": 10215.136, "update_time_ms": 2.629}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 5.820766091346741e-12, "cur_lr": 0.0005000000000000001, "total_loss": 1477.4178466796875, "policy_loss": -0.003916037082672119, "vf_loss": 1477.4286865234376, "vf_explained_var": 0.06257209181785583, "kl": 0.004802736759400972, "entropy": 0.6930175185203552, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 84000, "num_agent_steps_sampled": 168000, "num_steps_trained": 84000, "num_agent_steps_trained": 168000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 6248, "training_iteration": 84, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-10", "timestamp": 1749778570, "time_this_iter_s": 0.3451693058013916, "time_total_s": 31.02752661705017, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 31.02752661705017, "timesteps_since_restore": 0, "iterations_since_restore": 84, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 54.042, "episode_len_mean": 18.43, "episode_media": {}, "episodes_this_iter": 53, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 27.021}, "custom_metrics": {}, "hist_stats": {"episode_reward": [86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, 88.0, 85.4, 87.6, 87.6, -4.999999999999998, -4.999999999999998, 87.8, 86.6, 85.2, -4.999999999999998, -4.999999999999998, 87.4, 87.8, 86.8, -4.999999999999998, 86.8, 86.0, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, 89.4, 86.8, 85.8, -4.999999999999998, 87.4, 89.4, 88.2, 87.4, -4.999999999999998, 87.8, -4.999999999999998, 85.4, 86.0, 89.0, 87.4, 87.8, 87.6, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, 88.8, 89.4, 87.0, -4.999999999999998, 85.8, -4.999999999999998, 86.39999999999999, 85.6, -4.999999999999998, 86.8, -4.999999999999998, 85.6, 89.4, -4.999999999999998, 87.4, 85.8, -4.999999999999998, 85.6, -4.999999999999998, 88.0, 86.8, 87.6, -4.999999999999998, 86.8, 86.39999999999999, 85.8, 87.2, -4.999999999999998, -4.999999999999998, 88.0, 89.4, 88.0, -4.999999999999998, 87.0, 88.6, 88.2, 88.6, 88.6, -4.999999999999998, -4.999999999999998, 85.2, 85.8, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, 87.2, 86.6], "episode_lengths": [17, 25, 25, 25, 25, 7, 25, 11, 24, 13, 13, 25, 25, 12, 18, 25, 25, 25, 14, 12, 17, 25, 17, 21, 25, 17, 25, 25, 4, 17, 22, 25, 14, 4, 10, 14, 25, 12, 25, 24, 21, 6, 14, 12, 13, 25, 17, 25, 25, 25, 13, 7, 4, 16, 25, 22, 25, 19, 23, 25, 17, 25, 23, 4, 25, 14, 22, 25, 23, 25, 11, 17, 13, 25, 17, 19, 22, 15, 25, 25, 11, 4, 11, 25, 16, 8, 10, 8, 8, 25, 25, 25, 22, 11, 25, 25, 25, 13, 15, 18], "policy_shared_policy_reward": [-11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -11.0, 99.0, 97.7, -12.3, 98.8, -11.2, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 98.3, -11.700000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, 98.9, -11.1, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -12.0, 98.0, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.4, -11.6, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, 99.7, -10.3, -10.9, 99.1, -11.3, 98.7, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -2.500000000000001, -2.500000000000001, 97.7, -12.3, 98.0, -12.0, -10.5, 99.5, 98.7, -11.3, 98.9, -11.1, -11.2, 98.8, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -10.6, 99.4, 99.7, -10.3, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, 98.2, -11.8, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -11.6, 98.4, -11.2, 98.8, -2.500000000000001, -2.500000000000001, 98.4, -11.6, 98.2, -11.8, 97.9, -12.100000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, 99.7, -10.3, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -10.7, 99.3, 99.1, -10.9, -10.7, 99.3, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.4, 97.6, 97.9, -12.100000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.8, -11.2, 98.6, -11.4, 98.3, -11.700000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3929232863800921, "mean_inference_ms": 1.6282315306765005, "mean_action_processing_ms": 0.08863578536621562, "mean_env_wait_ms": 0.08616036135523071, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 85000, "timesteps_this_iter": 0, "agent_timesteps_total": 170000, "timers": {"sample_time_ms": 382.872, "sample_throughput": 2611.842, "load_time_ms": 1.476, "load_throughput": 677385.617, "learn_time_ms": 98.926, "learn_throughput": 10108.581, "update_time_ms": 2.673}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 2.9103830456733705e-12, "cur_lr": 0.0005000000000000001, "total_loss": 1561.2462036132813, "policy_loss": -0.001353578455746174, "vf_loss": 1561.2541870117188, "vf_explained_var": 0.052570611238479614, "kl": 0.004634111558543386, "entropy": 0.6653545260429382, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 85000, "num_agent_steps_sampled": 170000, "num_steps_trained": 85000, "num_agent_steps_trained": 170000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 6301, "training_iteration": 85, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-10", "timestamp": 1749778570, "time_this_iter_s": 0.33550453186035156, "time_total_s": 31.363031148910522, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018229820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 31.363031148910522, "timesteps_since_restore": 0, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 48.8, "ram_util_percent": 90.3}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 53.05799999999999, "episode_len_mean": 18.84, "episode_media": {}, "episodes_this_iter": 53, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 26.529}, "custom_metrics": {}, "hist_stats": {"episode_reward": [87.0, -4.999999999999998, 85.8, -4.999999999999998, 86.39999999999999, 85.6, -4.999999999999998, 86.8, -4.999999999999998, 85.6, 89.4, -4.999999999999998, 87.4, 85.8, -4.999999999999998, 85.6, -4.999999999999998, 88.0, 86.8, 87.6, -4.999999999999998, 86.8, 86.39999999999999, 85.8, 87.2, -4.999999999999998, -4.999999999999998, 88.0, 89.4, 88.0, -4.999999999999998, 87.0, 88.6, 88.2, 88.6, 88.6, -4.999999999999998, -4.999999999999998, 85.2, 85.8, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, 87.2, 86.6, -4.999999999999998, 88.2, 87.0, 87.4, 86.2, 86.39999999999999, 85.4, 88.4, 89.4, 85.2, 85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, 86.4, -4.999999999999998, 87.4, 86.39999999999999, 85.4, 87.0, -4.999999999999998, 85.6, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 89.0, 87.0, -4.999999999999998, 88.2, 87.2, 87.2, 86.8, -4.999999999999998, 88.8, -4.999999999999998, 87.8, 86.2, 86.8, 87.4], "episode_lengths": [16, 25, 22, 25, 19, 23, 25, 17, 25, 23, 4, 25, 14, 22, 25, 23, 25, 11, 17, 13, 25, 17, 19, 22, 15, 25, 25, 11, 4, 11, 25, 16, 8, 10, 8, 8, 25, 25, 25, 22, 11, 25, 25, 25, 13, 15, 18, 25, 10, 16, 14, 20, 19, 24, 9, 4, 25, 22, 25, 25, 25, 4, 25, 25, 22, 25, 19, 25, 14, 19, 24, 16, 25, 23, 21, 25, 25, 25, 25, 25, 4, 25, 25, 25, 4, 25, 6, 16, 25, 10, 15, 15, 17, 25, 7, 25, 12, 20, 17, 14], "policy_shared_policy_reward": [98.5, -11.5, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, 98.2, -11.8, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -11.6, 98.4, -11.2, 98.8, -2.500000000000001, -2.500000000000001, 98.4, -11.6, 98.2, -11.8, 97.9, -12.100000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, 99.7, -10.3, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -10.7, 99.3, 99.1, -10.9, -10.7, 99.3, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.4, 97.6, 97.9, -12.100000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.8, -11.2, 98.6, -11.4, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, 98.5, -11.5, 98.7, -11.3, 98.1, -11.9, 98.2, -11.8, 97.7, -12.3, 99.2, -10.8, 99.7, -10.3, 97.6, -12.4, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, 98.7, -11.3, 98.2, -11.8, 97.7, -12.3, 98.5, -11.5, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -11.5, 98.5, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 98.6, -11.4, 98.6, -11.4, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -11.9, 98.1, 98.4, -11.6, 98.7, -11.3]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.39226846223035794, "mean_inference_ms": 1.627002540793424, "mean_action_processing_ms": 0.08852495316169313, "mean_env_wait_ms": 0.08601000838608497, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 86000, "timesteps_this_iter": 0, "agent_timesteps_total": 172000, "timers": {"sample_time_ms": 384.534, "sample_throughput": 2600.552, "load_time_ms": 1.488, "load_throughput": 672196.42, "learn_time_ms": 97.11, "learn_throughput": 10297.615, "update_time_ms": 2.657}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.4551915228366853e-12, "cur_lr": 0.0005000000000000001, "total_loss": 1561.6290161132813, "policy_loss": -0.0014553792774677277, "vf_loss": 1561.6364135742188, "vf_explained_var": 0.037300610542297365, "kl": 0.0029775544404380128, "entropy": 0.59738729596138, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 86000, "num_agent_steps_sampled": 172000, "num_steps_trained": 86000, "num_agent_steps_trained": 172000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 6354, "training_iteration": 86, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-10", "timestamp": 1749778570, "time_this_iter_s": 0.32732200622558594, "time_total_s": 31.69035315513611, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182290d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 31.69035315513611, "timesteps_since_restore": 0, "iterations_since_restore": 86, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 46.61, "episode_len_mean": 19.51, "episode_media": {}, "episodes_this_iter": 52, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 23.305}, "custom_metrics": {}, "hist_stats": {"episode_reward": [86.39999999999999, 85.4, 88.4, 89.4, 85.2, 85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, 86.4, -4.999999999999998, 87.4, 86.39999999999999, 85.4, 87.0, -4.999999999999998, 85.6, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 89.0, 87.0, -4.999999999999998, 88.2, 87.2, 87.2, 86.8, -4.999999999999998, 88.8, -4.999999999999998, 87.8, 86.2, 86.8, 87.4, -4.999999999999998, 88.2, -4.999999999999998, 89.4, -4.999999999999998, 88.0, 86.2, 87.4, -4.999999999999998, 87.0, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, 88.0, 85.2, -4.999999999999998, 86.39999999999999, -4.999999999999998, 88.8, -4.999999999999998, 86.4, -4.999999999999998, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, 86.0, 85.8, 85.2, -4.999999999999998, 86.4, -4.999999999999998, -4.999999999999998, 88.4, 86.39999999999999, -4.999999999999998, 87.6, 88.2, -4.999999999999998, 88.2, -4.999999999999998, 85.6, 88.2, -4.999999999999998, -4.999999999999998, 85.6, 85.4, 87.4, -4.999999999999998], "episode_lengths": [19, 24, 9, 4, 25, 22, 25, 25, 25, 4, 25, 25, 22, 25, 19, 25, 14, 19, 24, 16, 25, 23, 21, 25, 25, 25, 25, 25, 4, 25, 25, 25, 4, 25, 6, 16, 25, 10, 15, 15, 17, 25, 7, 25, 12, 20, 17, 14, 25, 10, 25, 4, 25, 11, 20, 14, 25, 16, 25, 25, 10, 25, 11, 25, 25, 19, 25, 7, 25, 19, 25, 25, 8, 25, 25, 25, 13, 21, 22, 25, 25, 19, 25, 25, 9, 19, 25, 13, 10, 25, 10, 25, 23, 10, 25, 25, 23, 24, 14, 25], "policy_shared_policy_reward": [98.2, -11.8, 97.7, -12.3, 99.2, -10.8, 99.7, -10.3, 97.6, -12.4, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, 98.7, -11.3, 98.2, -11.8, 97.7, -12.3, 98.5, -11.5, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -11.5, 98.5, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 98.6, -11.4, 98.6, -11.4, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -11.9, 98.1, 98.4, -11.6, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.0, -11.0, 98.1, -11.9, 98.7, -11.3, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -12.4, 97.6, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.8, -11.2, 98.0, -12.0, 97.9, -12.100000000000001, 97.6, -12.4, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, 98.2, -11.8, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, 97.7, -12.3, 98.7, -11.3, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3915365790051712, "mean_inference_ms": 1.6259586511524011, "mean_action_processing_ms": 0.08844884431623616, "mean_env_wait_ms": 0.0859966599619752, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 87000, "timesteps_this_iter": 0, "agent_timesteps_total": 174000, "timers": {"sample_time_ms": 381.862, "sample_throughput": 2618.747, "load_time_ms": 1.431, "load_throughput": 698922.531, "learn_time_ms": 96.982, "learn_throughput": 10311.227, "update_time_ms": 2.657}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 7.275957614183426e-13, "cur_lr": 0.0005000000000000001, "total_loss": 1396.4625732421875, "policy_loss": -0.002281823754310608, "vf_loss": 1396.4708984375, "vf_explained_var": 0.041996777057647705, "kl": 0.005994465072359278, "entropy": 0.6065857768058777, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 87000, "num_agent_steps_sampled": 174000, "num_steps_trained": 87000, "num_agent_steps_trained": 174000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 6406, "training_iteration": 87, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-11", "timestamp": 1749778571, "time_this_iter_s": 0.3320586681365967, "time_total_s": 32.022411823272705, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018229700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 32.022411823272705, "timesteps_since_restore": 0, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 53.4, "ram_util_percent": 90.3}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 58.666, "episode_len_mean": 17.86, "episode_media": {}, "episodes_this_iter": 60, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 29.333000000000002}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.2, -4.999999999999998, 88.0, 85.2, -4.999999999999998, 86.39999999999999, -4.999999999999998, 88.8, -4.999999999999998, 86.4, -4.999999999999998, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, 86.0, 85.8, 85.2, -4.999999999999998, 86.4, -4.999999999999998, -4.999999999999998, 88.4, 86.39999999999999, -4.999999999999998, 87.6, 88.2, -4.999999999999998, 88.2, -4.999999999999998, 85.6, 88.2, -4.999999999999998, -4.999999999999998, 85.6, 85.4, 87.4, -4.999999999999998, 86.0, 86.39999999999999, 87.4, 88.6, 85.8, -4.999999999999998, 86.8, 89.4, 87.8, 89.4, 87.2, -4.999999999999998, 87.4, 86.39999999999999, -4.999999999999998, 86.0, -4.999999999999998, 87.2, -4.999999999999998, 88.2, 85.4, 89.4, 86.0, 86.6, 88.0, -4.999999999999998, 88.0, 87.6, 89.4, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, 88.6, 88.0, 89.4, 87.6, 86.39999999999999, 89.4, 88.6, 89.0, 88.6, 86.2, -4.999999999999998, 85.8, 85.2, 88.0, 86.2, 86.0, 89.4, -4.999999999999998, 85.6, 86.2, 86.8, -4.999999999999998, 87.4, -4.999999999999998, 89.4, 86.0, 86.2], "episode_lengths": [10, 25, 11, 25, 25, 19, 25, 7, 25, 19, 25, 25, 8, 25, 25, 25, 13, 21, 22, 25, 25, 19, 25, 25, 9, 19, 25, 13, 10, 25, 10, 25, 23, 10, 25, 25, 23, 24, 14, 25, 21, 19, 14, 8, 22, 25, 17, 4, 12, 4, 15, 25, 14, 19, 25, 21, 25, 15, 25, 10, 24, 4, 21, 18, 11, 25, 11, 13, 4, 25, 13, 25, 25, 8, 11, 4, 13, 19, 4, 8, 6, 8, 20, 25, 22, 25, 11, 20, 21, 4, 25, 23, 20, 17, 25, 14, 25, 4, 21, 20], "policy_shared_policy_reward": [99.1, -10.9, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -12.4, 97.6, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.8, -11.2, 98.0, -12.0, 97.9, -12.100000000000001, 97.6, -12.4, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, 98.2, -11.8, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, 97.7, -12.3, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -12.0, 98.0, 98.2, -11.8, 98.7, -11.3, -10.7, 99.3, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, 98.4, -11.6, 99.7, -10.3, 98.9, -11.1, 99.7, -10.3, 98.6, -11.4, -2.500000000000001, -2.500000000000001, 98.7, -11.3, 98.2, -11.8, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 97.7, -12.3, -10.3, 99.7, 98.0, -12.0, 98.3, -11.700000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 99.0, -11.0, 98.8, -11.2, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 99.0, -11.0, 99.7, -10.3, 98.8, -11.2, 98.2, -11.8, 99.7, -10.3, 99.3, -10.7, 99.5, -10.5, -10.7, 99.3, -11.9, 98.1, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, 97.6, -12.4, 99.0, -11.0, 98.1, -11.9, 98.0, -12.0, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, 98.1, -11.9, 98.4, -11.6, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -12.0, 98.0, 98.1, -11.9]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.39159990740540335, "mean_inference_ms": 1.6273280692053715, "mean_action_processing_ms": 0.08859466498653201, "mean_env_wait_ms": 0.08607150069921043, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 88000, "timesteps_this_iter": 0, "agent_timesteps_total": 176000, "timers": {"sample_time_ms": 380.754, "sample_throughput": 2626.368, "load_time_ms": 1.317, "load_throughput": 759342.458, "learn_time_ms": 97.997, "learn_throughput": 10204.347, "update_time_ms": 2.684}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 7.275957614183426e-13, "cur_lr": 0.0005000000000000001, "total_loss": 1937.2941772460938, "policy_loss": -0.003853044845163822, "vf_loss": 1937.3039306640626, "vf_explained_var": 0.04609180688858032, "kl": 0.004795196198645079, "entropy": 0.5908188164234162, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 88000, "num_agent_steps_sampled": 176000, "num_steps_trained": 88000, "num_agent_steps_trained": 176000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 6466, "training_iteration": 88, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-11", "timestamp": 1749778571, "time_this_iter_s": 0.35793566703796387, "time_total_s": 32.38034749031067, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182f4550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 32.38034749031067, "timesteps_since_restore": 0, "iterations_since_restore": 88, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 68.07400000000001, "episode_len_mean": 15.92, "episode_media": {}, "episodes_this_iter": 64, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 34.037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.0, -4.999999999999998, 88.0, 87.6, 89.4, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, 88.6, 88.0, 89.4, 87.6, 86.39999999999999, 89.4, 88.6, 89.0, 88.6, 86.2, -4.999999999999998, 85.8, 85.2, 88.0, 86.2, 86.0, 89.4, -4.999999999999998, 85.6, 86.2, 86.8, -4.999999999999998, 87.4, -4.999999999999998, 89.4, 86.0, 86.2, -4.999999999999998, 88.0, 87.6, 87.6, 88.0, 87.8, 87.0, 86.8, 87.8, -4.999999999999998, 88.2, 87.0, 89.4, 86.8, 87.0, -4.999999999999998, 86.39999999999999, 88.0, 88.2, 88.0, -4.999999999999998, 85.4, -4.999999999999998, 85.4, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 86.39999999999999, 86.6, 85.6, 89.4, 87.6, 89.4, 87.0, 87.8, 89.2, 86.4, 88.2, 85.2, -4.999999999999998, -4.999999999999998, 88.6, 87.2, 88.6, 89.4, 86.8, 85.6, 89.4, -4.999999999999998, 85.8, -4.999999999999998, 89.4, 88.0, 89.0, 86.8, -4.999999999999998, 85.6, 86.39999999999999, 86.39999999999999, 87.4, 88.4, 85.8, 88.6], "episode_lengths": [11, 25, 11, 13, 4, 25, 13, 25, 25, 8, 11, 4, 13, 19, 4, 8, 6, 8, 20, 25, 22, 25, 11, 20, 21, 4, 25, 23, 20, 17, 25, 14, 25, 4, 21, 20, 25, 11, 13, 13, 11, 12, 16, 17, 12, 25, 10, 16, 4, 17, 16, 25, 19, 11, 10, 11, 25, 24, 25, 24, 25, 25, 4, 25, 19, 18, 23, 4, 13, 4, 16, 12, 5, 19, 10, 25, 25, 25, 8, 15, 8, 4, 17, 23, 4, 25, 22, 25, 4, 11, 6, 17, 25, 23, 19, 19, 14, 9, 22, 8], "policy_shared_policy_reward": [99.0, -11.0, -2.500000000000001, -2.500000000000001, 99.0, -11.0, 98.8, -11.2, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 99.0, -11.0, 99.7, -10.3, 98.8, -11.2, 98.2, -11.8, 99.7, -10.3, 99.3, -10.7, 99.5, -10.5, -10.7, 99.3, -11.9, 98.1, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, 97.6, -12.4, 99.0, -11.0, 98.1, -11.9, 98.0, -12.0, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, 98.1, -11.9, 98.4, -11.6, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -12.0, 98.0, 98.1, -11.9, -2.500000000000001, -2.500000000000001, 99.0, -11.0, 98.8, -11.2, 98.8, -11.2, 99.0, -11.0, -11.1, 98.9, 98.5, -11.5, 98.4, -11.6, 98.9, -11.1, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 98.5, -11.5, 99.7, -10.3, 98.4, -11.6, 98.5, -11.5, -2.500000000000001, -2.500000000000001, 98.2, -11.8, 99.0, -11.0, 99.1, -10.9, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.2, -11.8, 98.3, -11.700000000000001, 97.8, -12.200000000000001, 99.7, -10.3, 98.8, -11.2, 99.7, -10.3, 98.5, -11.5, -11.1, 98.9, 99.6, -10.4, -11.8, 98.2, 99.1, -10.9, 97.6, -12.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 98.6, -11.4, 99.3, -10.7, 99.7, -10.3, 98.4, -11.6, 97.8, -12.200000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.0, -11.0, -10.5, 99.5, 98.4, -11.6, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, 98.2, -11.8, 98.2, -11.8, -11.3, 98.7, 99.2, -10.8, 97.9, -12.100000000000001, -10.7, 99.3]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.39091638091333647, "mean_inference_ms": 1.6253152721157724, "mean_action_processing_ms": 0.08843862770633112, "mean_env_wait_ms": 0.08575012028303952, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 89000, "timesteps_this_iter": 0, "agent_timesteps_total": 178000, "timers": {"sample_time_ms": 380.5, "sample_throughput": 2628.119, "load_time_ms": 1.19, "load_throughput": 839986.382, "learn_time_ms": 97.938, "learn_throughput": 10210.585, "update_time_ms": 2.663}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 3.637978807091713e-13, "cur_lr": 0.0005000000000000001, "total_loss": 2068.50400390625, "policy_loss": -0.003543698787689209, "vf_loss": 2068.5134399414064, "vf_explained_var": 0.014408034086227418, "kl": 0.004322934734790551, "entropy": 0.5824430584907532, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 89000, "num_agent_steps_sampled": 178000, "num_steps_trained": 89000, "num_agent_steps_trained": 178000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 6530, "training_iteration": 89, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-11", "timestamp": 1749778571, "time_this_iter_s": 0.3446528911590576, "time_total_s": 32.72500038146973, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018319700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 32.72500038146973, "timesteps_since_restore": 0, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 59.4, "ram_util_percent": 90.4}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 66.108, "episode_len_mean": 16.73, "episode_media": {}, "episodes_this_iter": 58, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 33.054}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 85.4, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 86.39999999999999, 86.6, 85.6, 89.4, 87.6, 89.4, 87.0, 87.8, 89.2, 86.4, 88.2, 85.2, -4.999999999999998, -4.999999999999998, 88.6, 87.2, 88.6, 89.4, 86.8, 85.6, 89.4, -4.999999999999998, 85.8, -4.999999999999998, 89.4, 88.0, 89.0, 86.8, -4.999999999999998, 85.6, 86.39999999999999, 86.39999999999999, 87.4, 88.4, 85.8, 88.6, 89.4, -4.999999999999998, 85.4, 86.2, 86.8, 85.4, 86.39999999999999, 85.6, 86.8, 88.0, 86.6, 86.8, 87.4, 87.6, 87.0, 88.2, 86.4, 85.6, -4.999999999999998, -4.999999999999998, 86.39999999999999, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, 87.2, 88.2, -4.999999999999998, 89.0, 85.2, 86.2, 86.6, 88.4, 87.6, 87.2, 89.2, 89.4, 88.6, -4.999999999999998, 86.0, 89.2, 86.0, 88.6, 86.2, 88.2, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, 87.0, -4.999999999999998, 88.2, 85.2, 87.8, 88.6, -4.999999999999998, -4.999999999999998, 89.4], "episode_lengths": [25, 24, 25, 25, 4, 25, 19, 18, 23, 4, 13, 4, 16, 12, 5, 19, 10, 25, 25, 25, 8, 15, 8, 4, 17, 23, 4, 25, 22, 25, 4, 11, 6, 17, 25, 23, 19, 19, 14, 9, 22, 8, 4, 25, 24, 20, 17, 24, 19, 23, 17, 11, 18, 17, 14, 13, 16, 10, 19, 23, 25, 25, 19, 25, 25, 20, 25, 15, 10, 25, 6, 25, 20, 18, 9, 13, 15, 5, 4, 8, 25, 21, 5, 21, 8, 20, 10, 25, 13, 25, 25, 16, 25, 10, 25, 12, 8, 25, 25, 4], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, 97.7, -12.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.2, -11.8, 98.3, -11.700000000000001, 97.8, -12.200000000000001, 99.7, -10.3, 98.8, -11.2, 99.7, -10.3, 98.5, -11.5, -11.1, 98.9, 99.6, -10.4, -11.8, 98.2, 99.1, -10.9, 97.6, -12.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 98.6, -11.4, 99.3, -10.7, 99.7, -10.3, 98.4, -11.6, 97.8, -12.200000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.0, -11.0, -10.5, 99.5, 98.4, -11.6, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, 98.2, -11.8, 98.2, -11.8, -11.3, 98.7, 99.2, -10.8, 97.9, -12.100000000000001, -10.7, 99.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -11.9, 98.1, 98.4, -11.6, 97.7, -12.3, 98.2, -11.8, 97.8, -12.200000000000001, -11.6, 98.4, 99.0, -11.0, 98.3, -11.700000000000001, 98.4, -11.6, 98.7, -11.3, 98.8, -11.2, 98.5, -11.5, 99.1, -10.9, -11.8, 98.2, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -11.4, 98.6, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -12.4, 97.6, 98.1, -11.9, 98.3, -11.700000000000001, 99.2, -10.8, 98.8, -11.2, 98.6, -11.4, -10.4, 99.6, 99.7, -10.3, 99.3, -10.7, -2.500000000000001, -2.500000000000001, 98.0, -12.0, 99.6, -10.4, 98.0, -12.0, -10.7, 99.3, 98.1, -11.9, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 97.6, -12.4, 98.9, -11.1, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3909374968332566, "mean_inference_ms": 1.6268235069802486, "mean_action_processing_ms": 0.08864466647476775, "mean_env_wait_ms": 0.08602276736147502, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 90000, "timesteps_this_iter": 0, "agent_timesteps_total": 180000, "timers": {"sample_time_ms": 378.976, "sample_throughput": 2638.687, "load_time_ms": 1.098, "load_throughput": 910637.226, "learn_time_ms": 97.621, "learn_throughput": 10243.724, "update_time_ms": 2.686}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.8189894035458566e-13, "cur_lr": 0.0005000000000000001, "total_loss": 1857.6766845703125, "policy_loss": -0.004011677391827106, "vf_loss": 1857.68623046875, "vf_explained_var": 0.03978418111801148, "kl": 0.004804566200469584, "entropy": 0.5549059689044953, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 90000, "num_agent_steps_sampled": 180000, "num_steps_trained": 90000, "num_agent_steps_trained": 180000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 6588, "training_iteration": 90, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-12", "timestamp": 1749778572, "time_this_iter_s": 0.3499257564544678, "time_total_s": 33.074926137924194, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb01b0b3b80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 33.074926137924194, "timesteps_since_restore": 0, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 64.6, "ram_util_percent": 90.4}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 63.39000000000001, "episode_len_mean": 16.79, "episode_media": {}, "episodes_this_iter": 60, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 31.695}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, 86.39999999999999, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, 87.2, 88.2, -4.999999999999998, 89.0, 85.2, 86.2, 86.6, 88.4, 87.6, 87.2, 89.2, 89.4, 88.6, -4.999999999999998, 86.0, 89.2, 86.0, 88.6, 86.2, 88.2, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, 87.0, -4.999999999999998, 88.2, 85.2, 87.8, 88.6, -4.999999999999998, -4.999999999999998, 89.4, 87.0, 85.4, 87.4, 86.2, 88.6, 89.4, 86.0, 85.4, -4.999999999999998, 86.2, 89.4, -4.999999999999998, 89.4, 88.2, -4.999999999999998, -4.999999999999998, 89.4, 86.0, 86.8, 87.4, 89.2, 89.4, 89.4, 88.8, 86.0, 88.2, 88.2, 86.2, 88.8, 85.6, 88.8, 86.0, -4.999999999999998, 87.4, 88.4, -4.999999999999998, 87.2, -4.999999999999998, 86.6, 86.2, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, 87.0, 86.8, 85.2, -4.999999999999998, 86.0, 86.6, 89.4, -4.999999999999998, 88.0, 85.4, 85.8, 87.6, 87.8, -4.999999999999998, 87.8, 86.8], "episode_lengths": [25, 25, 19, 25, 25, 20, 25, 15, 10, 25, 6, 25, 20, 18, 9, 13, 15, 5, 4, 8, 25, 21, 5, 21, 8, 20, 10, 25, 13, 25, 25, 16, 25, 10, 25, 12, 8, 25, 25, 4, 16, 24, 14, 20, 8, 4, 21, 24, 25, 20, 4, 25, 4, 10, 25, 25, 4, 21, 17, 14, 5, 4, 4, 7, 21, 10, 10, 20, 7, 23, 7, 21, 25, 14, 9, 25, 15, 25, 18, 20, 25, 17, 25, 25, 16, 17, 25, 25, 21, 18, 4, 25, 11, 24, 22, 13, 12, 25, 12, 17], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -11.4, 98.6, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -12.4, 97.6, 98.1, -11.9, 98.3, -11.700000000000001, 99.2, -10.8, 98.8, -11.2, 98.6, -11.4, -10.4, 99.6, 99.7, -10.3, 99.3, -10.7, -2.500000000000001, -2.500000000000001, 98.0, -12.0, 99.6, -10.4, 98.0, -12.0, -10.7, 99.3, 98.1, -11.9, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 97.6, -12.4, 98.9, -11.1, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.5, -11.5, 97.7, -12.3, 98.7, -11.3, 98.1, -11.9, -10.7, 99.3, 99.7, -10.3, 98.0, -12.0, -12.3, 97.7, -2.500000000000001, -2.500000000000001, 98.1, -11.9, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -12.0, 98.0, 98.4, -11.6, -11.3, 98.7, -10.4, 99.6, 99.7, -10.3, 99.7, -10.3, -10.6, 99.4, 98.0, -12.0, 99.1, -10.9, 99.1, -10.9, 98.1, -11.9, -10.6, 99.4, -12.200000000000001, 97.8, 99.4, -10.6, -12.0, 98.0, -2.500000000000001, -2.500000000000001, 98.7, -11.3, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, 98.1, -11.9, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.5, -11.5, 98.4, -11.6, -12.4, 97.6, -2.500000000000001, -2.500000000000001, 98.0, -12.0, 98.3, -11.700000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.0, -11.0, 97.7, -12.3, -12.100000000000001, 97.9, 98.8, -11.2, 98.9, -11.1, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 98.4, -11.6]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3904614733937876, "mean_inference_ms": 1.625373201152214, "mean_action_processing_ms": 0.08861956285434378, "mean_env_wait_ms": 0.08612149770360161, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 91000, "timesteps_this_iter": 0, "agent_timesteps_total": 182000, "timers": {"sample_time_ms": 380.946, "sample_throughput": 2625.046, "load_time_ms": 1.197, "load_throughput": 835086.21, "learn_time_ms": 97.93, "learn_throughput": 10211.368, "update_time_ms": 2.656}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 9.094947017729283e-14, "cur_lr": 0.0005000000000000001, "total_loss": 1933.3226806640625, "policy_loss": -0.005022770911455155, "vf_loss": 1933.3331909179688, "vf_explained_var": 0.01561306118965149, "kl": 0.0069519916712884825, "entropy": 0.5449691414833069, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 91000, "num_agent_steps_sampled": 182000, "num_steps_trained": 91000, "num_agent_steps_trained": 182000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 6648, "training_iteration": 91, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-12", "timestamp": 1749778572, "time_this_iter_s": 0.36986255645751953, "time_total_s": 33.444788694381714, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018229a60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 33.444788694381714, "timesteps_since_restore": 0, "iterations_since_restore": 91, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 56.992, "episode_len_mean": 17.21, "episode_media": {}, "episodes_this_iter": 55, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 28.496}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 89.4, 86.0, 86.8, 87.4, 89.2, 89.4, 89.4, 88.8, 86.0, 88.2, 88.2, 86.2, 88.8, 85.6, 88.8, 86.0, -4.999999999999998, 87.4, 88.4, -4.999999999999998, 87.2, -4.999999999999998, 86.6, 86.2, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, 87.0, 86.8, 85.2, -4.999999999999998, 86.0, 86.6, 89.4, -4.999999999999998, 88.0, 85.4, 85.8, 87.6, 87.8, -4.999999999999998, 87.8, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, 87.2, 87.0, 89.4, 89.4, 86.2, 88.0, -4.999999999999998, 86.6, 85.8, 87.0, 87.4, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.6, 89.4, -4.999999999999998, 87.2, -4.999999999999998, 86.2, 88.6, -4.999999999999998, -4.999999999999998, 88.2, 89.4, -4.999999999999998, 86.2, 88.0, 89.4, -4.999999999999998, 89.4, 89.4, -4.999999999999998, 86.2, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.6, 89.4, 87.0, -4.999999999999998, 89.4, 88.2], "episode_lengths": [25, 4, 21, 17, 14, 5, 4, 4, 7, 21, 10, 10, 20, 7, 23, 7, 21, 25, 14, 9, 25, 15, 25, 18, 20, 25, 17, 25, 25, 16, 17, 25, 25, 21, 18, 4, 25, 11, 24, 22, 13, 12, 25, 12, 17, 25, 25, 25, 21, 15, 16, 4, 4, 20, 11, 25, 18, 22, 16, 14, 13, 25, 25, 25, 8, 4, 25, 15, 25, 20, 8, 25, 25, 10, 4, 25, 20, 11, 4, 25, 4, 4, 25, 20, 25, 18, 25, 25, 25, 25, 15, 25, 25, 25, 23, 4, 16, 25, 4, 10], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, 99.7, -10.3, -12.0, 98.0, 98.4, -11.6, -11.3, 98.7, -10.4, 99.6, 99.7, -10.3, 99.7, -10.3, -10.6, 99.4, 98.0, -12.0, 99.1, -10.9, 99.1, -10.9, 98.1, -11.9, -10.6, 99.4, -12.200000000000001, 97.8, 99.4, -10.6, -12.0, 98.0, -2.500000000000001, -2.500000000000001, 98.7, -11.3, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, 98.1, -11.9, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.5, -11.5, 98.4, -11.6, -12.4, 97.6, -2.500000000000001, -2.500000000000001, 98.0, -12.0, 98.3, -11.700000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.0, -11.0, 97.7, -12.3, -12.100000000000001, 97.9, 98.8, -11.2, 98.9, -11.1, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, 98.6, -11.4, 98.5, -11.5, 99.7, -10.3, 99.7, -10.3, 98.1, -11.9, -11.0, 99.0, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, 97.9, -12.100000000000001, 98.5, -11.5, 98.7, -11.3, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.1, -11.9, 99.0, -11.0, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.1, -11.9, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, 99.7, -10.3, 98.5, -11.5, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.1, -10.9]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.39016208210118536, "mean_inference_ms": 1.6265295121853611, "mean_action_processing_ms": 0.0886563256206745, "mean_env_wait_ms": 0.08625958177408503, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 92000, "timesteps_this_iter": 0, "agent_timesteps_total": 184000, "timers": {"sample_time_ms": 382.825, "sample_throughput": 2612.156, "load_time_ms": 1.265, "load_throughput": 790468.329, "learn_time_ms": 98.256, "learn_throughput": 10177.509, "update_time_ms": 2.993}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 9.094947017729283e-14, "cur_lr": 0.0005000000000000001, "total_loss": 1360.5938354492187, "policy_loss": -0.0011995479464530945, "vf_loss": 1360.6004516601563, "vf_explained_var": 0.027267110347747803, "kl": 0.0028238848474668953, "entropy": 0.5410079956054688, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 92000, "num_agent_steps_sampled": 184000, "num_steps_trained": 92000, "num_agent_steps_trained": 184000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 6703, "training_iteration": 92, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-13", "timestamp": 1749778573, "time_this_iter_s": 0.35897397994995117, "time_total_s": 33.803762674331665, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 33.803762674331665, "timesteps_since_restore": 0, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 67.0, "ram_util_percent": 90.2}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 56.19, "episode_len_mean": 16.71, "episode_media": {}, "episodes_this_iter": 63, "policy_reward_min": {"shared_policy": -12.3}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 28.095}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 88.6, 89.4, -4.999999999999998, 87.2, -4.999999999999998, 86.2, 88.6, -4.999999999999998, -4.999999999999998, 88.2, 89.4, -4.999999999999998, 86.2, 88.0, 89.4, -4.999999999999998, 89.4, 89.4, -4.999999999999998, 86.2, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.6, 89.4, 87.0, -4.999999999999998, 89.4, 88.2, 85.8, 88.4, 86.8, -4.999999999999998, 88.8, 87.8, 88.6, 88.0, 85.6, 86.8, 86.8, 89.4, 87.0, -4.999999999999998, 88.2, 88.0, 89.4, -4.999999999999998, -4.999999999999998, 86.8, 87.6, 89.4, 88.0, 86.8, 89.4, 86.39999999999999, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, -4.999999999999998, 85.8, 88.6, -4.999999999999998, 86.8, 87.6, 87.8, -4.999999999999998, -4.999999999999998, 87.0, 88.6, 87.4, 89.4, -4.999999999999998, 86.2, 87.4, 87.4, 85.6, 86.2, -4.999999999999998, 87.0, 85.4, 87.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.6, 89.4, 87.8, 87.4, -4.999999999999998, 88.2, 88.6], "episode_lengths": [25, 8, 4, 25, 15, 25, 20, 8, 25, 25, 10, 4, 25, 20, 11, 4, 25, 4, 4, 25, 20, 25, 18, 25, 25, 25, 25, 15, 25, 25, 25, 23, 4, 16, 25, 4, 10, 22, 9, 17, 25, 7, 12, 8, 11, 23, 17, 17, 4, 16, 25, 10, 11, 4, 25, 25, 17, 13, 4, 11, 17, 4, 19, 25, 25, 25, 13, 25, 22, 8, 25, 17, 13, 12, 25, 25, 16, 8, 14, 4, 25, 20, 14, 14, 23, 20, 25, 16, 24, 12, 25, 25, 25, 8, 4, 12, 14, 25, 10, 8], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, 99.3, -10.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.1, -11.9, 99.0, -11.0, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.1, -11.9, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, 99.7, -10.3, 98.5, -11.5, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.1, -10.9, 97.9, -12.100000000000001, 99.2, -10.8, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -11.1, 98.9, 99.3, -10.7, 99.0, -11.0, 97.8, -12.200000000000001, 98.4, -11.6, -11.6, 98.4, 99.7, -10.3, 98.5, -11.5, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 99.0, -11.0, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.4, -11.6, 98.8, -11.2, 99.7, -10.3, 99.0, -11.0, 98.4, -11.6, 99.7, -10.3, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, 98.4, -11.6, 98.8, -11.2, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, 99.3, -10.7, 98.7, -11.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.9, 98.1, 98.7, -11.3, 98.7, -11.3, 97.8, -12.200000000000001, 98.1, -11.9, -2.500000000000001, -2.500000000000001, 98.5, -11.5, 97.7, -12.3, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 99.7, -10.3, 98.9, -11.1, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -10.7, 99.3]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3898509966778252, "mean_inference_ms": 1.6257399991234598, "mean_action_processing_ms": 0.08856712335651014, "mean_env_wait_ms": 0.08606814363708935, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 93000, "timesteps_this_iter": 0, "agent_timesteps_total": 186000, "timers": {"sample_time_ms": 385.103, "sample_throughput": 2596.706, "load_time_ms": 1.179, "load_throughput": 848379.619, "learn_time_ms": 98.326, "learn_throughput": 10170.285, "update_time_ms": 2.928}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 4.5474735088646414e-14, "cur_lr": 0.0005000000000000001, "total_loss": 1813.116796875, "policy_loss": -0.0017521077767014503, "vf_loss": 1813.1238159179688, "vf_explained_var": 0.019656062126159668, "kl": 0.002188135626377452, "entropy": 0.5289771735668183, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 93000, "num_agent_steps_sampled": 186000, "num_steps_trained": 93000, "num_agent_steps_trained": 186000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 6766, "training_iteration": 93, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-13", "timestamp": 1749778573, "time_this_iter_s": 0.36864376068115234, "time_total_s": 34.17240643501282, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c9d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 34.17240643501282, "timesteps_since_restore": 0, "iterations_since_restore": 93, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 58.798, "episode_len_mean": 17.2, "episode_media": {}, "episodes_this_iter": 60, "policy_reward_min": {"shared_policy": -12.3}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 29.398999999999997}, "custom_metrics": {}, "hist_stats": {"episode_reward": [86.8, 89.4, 86.39999999999999, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, -4.999999999999998, 85.8, 88.6, -4.999999999999998, 86.8, 87.6, 87.8, -4.999999999999998, -4.999999999999998, 87.0, 88.6, 87.4, 89.4, -4.999999999999998, 86.2, 87.4, 87.4, 85.6, 86.2, -4.999999999999998, 87.0, 85.4, 87.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.6, 89.4, 87.8, 87.4, -4.999999999999998, 88.2, 88.6, 86.8, 85.6, 86.6, 86.39999999999999, 86.39999999999999, 88.0, -4.999999999999998, 88.2, 88.8, -4.999999999999998, 89.4, -4.999999999999998, 86.6, 89.2, 86.4, -4.999999999999998, 87.6, 88.4, 88.0, -4.999999999999998, 88.2, -4.999999999999998, 88.6, -4.999999999999998, 87.6, 87.6, 87.4, 87.0, -4.999999999999998, 87.8, 88.4, 88.2, 85.6, 88.6, -4.999999999999998, 85.8, 86.39999999999999, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, 88.6, 87.2, 86.6, 85.4, 87.0, 88.8, -4.999999999999998, 85.4, -4.999999999999998, 88.0, -4.999999999999998, 86.6, 87.6, 88.0, 88.0, -4.999999999999998, -4.999999999999998], "episode_lengths": [17, 4, 19, 25, 25, 25, 13, 25, 22, 8, 25, 17, 13, 12, 25, 25, 16, 8, 14, 4, 25, 20, 14, 14, 23, 20, 25, 16, 24, 12, 25, 25, 25, 8, 4, 12, 14, 25, 10, 8, 17, 23, 18, 19, 19, 11, 25, 10, 7, 25, 4, 25, 18, 5, 19, 25, 13, 9, 11, 25, 10, 25, 8, 25, 13, 13, 14, 16, 25, 12, 9, 10, 23, 8, 25, 22, 19, 8, 25, 25, 25, 25, 15, 8, 15, 18, 24, 16, 7, 25, 24, 25, 11, 25, 18, 13, 11, 11, 25, 25], "policy_shared_policy_reward": [98.4, -11.6, 99.7, -10.3, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, 98.4, -11.6, 98.8, -11.2, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, 99.3, -10.7, 98.7, -11.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.9, 98.1, 98.7, -11.3, 98.7, -11.3, 97.8, -12.200000000000001, 98.1, -11.9, -2.500000000000001, -2.500000000000001, 98.5, -11.5, 97.7, -12.3, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 99.7, -10.3, 98.9, -11.1, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -10.7, 99.3, 98.4, -11.6, 97.8, -12.200000000000001, -11.700000000000001, 98.3, 98.2, -11.8, 98.2, -11.8, -11.0, 99.0, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -10.4, 99.6, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -11.2, 98.8, 99.2, -10.8, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -11.2, 98.8, 98.7, -11.3, 98.5, -11.5, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -10.8, 99.2, 99.1, -10.9, -12.200000000000001, 97.8, 99.3, -10.7, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, 98.2, -11.8, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, 99.3, -10.7, -11.4, 98.6, -11.700000000000001, 98.3, 97.7, -12.3, 98.5, -11.5, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, 98.8, -11.2, -11.0, 99.0, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.38973353173356357, "mean_inference_ms": 1.6262440332588972, "mean_action_processing_ms": 0.08863270508765794, "mean_env_wait_ms": 0.08599279177958824, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 94000, "timesteps_this_iter": 0, "agent_timesteps_total": 188000, "timers": {"sample_time_ms": 385.238, "sample_throughput": 2595.799, "load_time_ms": 1.205, "load_throughput": 830012.863, "learn_time_ms": 98.495, "learn_throughput": 10152.843, "update_time_ms": 2.938}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 2.2737367544323207e-14, "cur_lr": 0.0005000000000000001, "total_loss": 1680.59599609375, "policy_loss": -0.0029932796955108643, "vf_loss": 1680.6043090820312, "vf_explained_var": 0.05203213691711426, "kl": 0.002199967703967598, "entropy": 0.5328839302062989, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 94000, "num_agent_steps_sampled": 188000, "num_steps_trained": 94000, "num_agent_steps_trained": 188000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 6826, "training_iteration": 94, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-13", "timestamp": 1749778573, "time_this_iter_s": 0.346893310546875, "time_total_s": 34.51929974555969, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c9550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 34.51929974555969, "timesteps_since_restore": 0, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 61.5, "ram_util_percent": 90.0}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 55.06400000000001, "episode_len_mean": 17.83, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"shared_policy": -12.3}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 27.531999999999996}, "custom_metrics": {}, "hist_stats": {"episode_reward": [86.4, -4.999999999999998, 87.6, 88.4, 88.0, -4.999999999999998, 88.2, -4.999999999999998, 88.6, -4.999999999999998, 87.6, 87.6, 87.4, 87.0, -4.999999999999998, 87.8, 88.4, 88.2, 85.6, 88.6, -4.999999999999998, 85.8, 86.39999999999999, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, 88.6, 87.2, 86.6, 85.4, 87.0, 88.8, -4.999999999999998, 85.4, -4.999999999999998, 88.0, -4.999999999999998, 86.6, 87.6, 88.0, 88.0, -4.999999999999998, -4.999999999999998, 89.4, 89.4, 86.2, 88.6, 88.8, 88.2, -4.999999999999998, -4.999999999999998, 85.4, 85.4, 85.6, -4.999999999999998, -4.999999999999998, 86.39999999999999, 89.4, 87.8, 87.2, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, 85.4, 85.6, 87.2, -4.999999999999998, 87.0, 88.2, 86.0, -4.999999999999998, -4.999999999999998, 87.4, 86.2, -4.999999999999998, 86.8, -4.999999999999998, 86.0, 89.4, -4.999999999999998, 89.4, -4.999999999999998, 88.6, -4.999999999999998, 89.4, 87.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 88.0, 87.6, 86.0, 88.2], "episode_lengths": [19, 25, 13, 9, 11, 25, 10, 25, 8, 25, 13, 13, 14, 16, 25, 12, 9, 10, 23, 8, 25, 22, 19, 8, 25, 25, 25, 25, 15, 8, 15, 18, 24, 16, 7, 25, 24, 25, 11, 25, 18, 13, 11, 11, 25, 25, 4, 4, 20, 8, 7, 10, 25, 25, 24, 24, 23, 25, 25, 19, 4, 12, 15, 25, 25, 21, 25, 25, 24, 23, 15, 25, 16, 10, 21, 25, 25, 14, 20, 25, 17, 25, 21, 4, 25, 4, 25, 8, 25, 4, 12, 25, 25, 25, 25, 17, 11, 13, 21, 10], "policy_shared_policy_reward": [-11.8, 98.2, -2.500000000000001, -2.500000000000001, -11.2, 98.8, 99.2, -10.8, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -11.2, 98.8, 98.7, -11.3, 98.5, -11.5, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -10.8, 99.2, 99.1, -10.9, -12.200000000000001, 97.8, 99.3, -10.7, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, 98.2, -11.8, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, 99.3, -10.7, -11.4, 98.6, -11.700000000000001, 98.3, 97.7, -12.3, 98.5, -11.5, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, 98.8, -11.2, -11.0, 99.0, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, -11.9, 98.1, 99.3, -10.7, -10.6, 99.4, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -12.3, 97.7, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -10.3, 99.7, 98.9, -11.1, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, 97.8, -12.200000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -10.9, 99.1, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, 98.1, -11.9, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, 98.0, -12.0, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.4, -11.6, 99.0, -11.0, -11.2, 98.8, 98.0, -12.0, 99.1, -10.9]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.38862096900988724, "mean_inference_ms": 1.6252353825668755, "mean_action_processing_ms": 0.08860359771123635, "mean_env_wait_ms": 0.08605724710714831, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 95000, "timesteps_this_iter": 0, "agent_timesteps_total": 190000, "timers": {"sample_time_ms": 385.556, "sample_throughput": 2593.66, "load_time_ms": 1.257, "load_throughput": 795671.738, "learn_time_ms": 98.585, "learn_throughput": 10143.54, "update_time_ms": 2.975}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.1368683772161604e-14, "cur_lr": 0.0005000000000000001, "total_loss": 1538.3953369140625, "policy_loss": -0.0034499522298574448, "vf_loss": 1538.40380859375, "vf_explained_var": 0.032896417379379275, "kl": 0.004205847857288303, "entropy": 0.5036658704280853, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 95000, "num_agent_steps_sampled": 190000, "num_steps_trained": 95000, "num_agent_steps_trained": 190000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 6880, "training_iteration": 95, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-14", "timestamp": 1749778574, "time_this_iter_s": 0.3483307361602783, "time_total_s": 34.86763048171997, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182290d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 34.86763048171997, "timesteps_since_restore": 0, "iterations_since_restore": 95, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 47.568000000000005, "episode_len_mean": 19.23, "episode_media": {}, "episodes_this_iter": 48, "policy_reward_min": {"shared_policy": -12.3}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 23.784000000000002}, "custom_metrics": {}, "hist_stats": {"episode_reward": [86.2, 88.6, 88.8, 88.2, -4.999999999999998, -4.999999999999998, 85.4, 85.4, 85.6, -4.999999999999998, -4.999999999999998, 86.39999999999999, 89.4, 87.8, 87.2, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, 85.4, 85.6, 87.2, -4.999999999999998, 87.0, 88.2, 86.0, -4.999999999999998, -4.999999999999998, 87.4, 86.2, -4.999999999999998, 86.8, -4.999999999999998, 86.0, 89.4, -4.999999999999998, 89.4, -4.999999999999998, 88.6, -4.999999999999998, 89.4, 87.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 88.0, 87.6, 86.0, 88.2, 86.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.8, 86.0, -4.999999999999998, 87.6, -4.999999999999998, 87.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.0, 87.2, 86.6, 87.6, 87.4, 87.8, 88.0, 85.6, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, 86.0, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, 88.0, 85.4, -4.999999999999998, 88.6, 86.8, 88.0, 85.8, 88.2], "episode_lengths": [20, 8, 7, 10, 25, 25, 24, 24, 23, 25, 25, 19, 4, 12, 15, 25, 25, 21, 25, 25, 24, 23, 15, 25, 16, 10, 21, 25, 25, 14, 20, 25, 17, 25, 21, 4, 25, 4, 25, 8, 25, 4, 12, 25, 25, 25, 25, 17, 11, 13, 21, 10, 20, 25, 25, 25, 12, 21, 25, 13, 25, 16, 25, 25, 25, 25, 25, 25, 25, 6, 15, 18, 13, 14, 12, 11, 23, 25, 14, 25, 25, 21, 15, 25, 25, 25, 14, 25, 25, 25, 25, 15, 11, 24, 25, 8, 17, 11, 22, 10], "policy_shared_policy_reward": [-11.9, 98.1, 99.3, -10.7, -10.6, 99.4, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -12.3, 97.7, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -10.3, 99.7, 98.9, -11.1, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, 97.8, -12.200000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -10.9, 99.1, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, 98.1, -11.9, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, 98.0, -12.0, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.4, -11.6, 99.0, -11.0, -11.2, 98.8, 98.0, -12.0, 99.1, -10.9, 98.1, -11.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -12.0, 98.0, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -11.4, 98.6, 98.3, -11.700000000000001, -11.2, 98.8, -11.3, 98.7, 98.9, -11.1, 99.0, -11.0, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, 99.0, -11.0, -12.3, 97.7, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -11.6, 98.4, -11.0, 99.0, 97.9, -12.100000000000001, -10.9, 99.1]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.38818373484647056, "mean_inference_ms": 1.6232369539755342, "mean_action_processing_ms": 0.08838826782921774, "mean_env_wait_ms": 0.08587480823412784, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 96000, "timesteps_this_iter": 0, "agent_timesteps_total": 192000, "timers": {"sample_time_ms": 386.648, "sample_throughput": 2586.331, "load_time_ms": 1.237, "load_throughput": 808104.348, "learn_time_ms": 100.6, "learn_throughput": 9940.405, "update_time_ms": 3.025}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 5.684341886080802e-15, "cur_lr": 0.0005000000000000001, "total_loss": 1228.61259765625, "policy_loss": -0.0028944388031959534, "vf_loss": 1228.6208374023438, "vf_explained_var": 0.02123779058456421, "kl": 0.006442303993852328, "entropy": 0.5346647500991821, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 96000, "num_agent_steps_sampled": 192000, "num_steps_trained": 96000, "num_agent_steps_trained": 192000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 6928, "training_iteration": 96, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-14", "timestamp": 1749778574, "time_this_iter_s": 0.356187105178833, "time_total_s": 35.223817586898804, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5ee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 35.223817586898804, "timesteps_since_restore": 0, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 59.0, "ram_util_percent": 90.0}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 44.705999999999996, "episode_len_mean": 20.01, "episode_media": {}, "episodes_this_iter": 52, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 22.353}, "custom_metrics": {}, "hist_stats": {"episode_reward": [86.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.8, 86.0, -4.999999999999998, 87.6, -4.999999999999998, 87.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.0, 87.2, 86.6, 87.6, 87.4, 87.8, 88.0, 85.6, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, 86.0, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, 88.0, 85.4, -4.999999999999998, 88.6, 86.8, 88.0, 85.8, 88.2, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.0, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, 86.39999999999999, -4.999999999999998, 85.8, 87.2, 86.8, 86.2, 85.2, -4.999999999999998, 89.4, 88.6, 87.8, 85.6, 86.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.6, 87.0, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, 86.6, 86.8, -4.999999999999998, 86.8, 87.0, -4.999999999999998, 87.8, 87.6, 85.6, 85.4, -4.999999999999998, 86.8, 88.6, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 87.0], "episode_lengths": [20, 25, 25, 25, 12, 21, 25, 13, 25, 16, 25, 25, 25, 25, 25, 25, 25, 6, 15, 18, 13, 14, 12, 11, 23, 25, 14, 25, 25, 21, 15, 25, 25, 25, 14, 25, 25, 25, 25, 15, 11, 24, 25, 8, 17, 11, 22, 10, 25, 17, 25, 25, 25, 16, 25, 25, 17, 25, 19, 25, 22, 15, 17, 20, 25, 25, 4, 8, 12, 23, 20, 25, 25, 25, 25, 25, 18, 16, 25, 21, 25, 25, 18, 17, 25, 17, 16, 25, 12, 13, 23, 24, 25, 17, 8, 25, 25, 4, 25, 16], "policy_shared_policy_reward": [98.1, -11.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -12.0, 98.0, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -11.4, 98.6, 98.3, -11.700000000000001, -11.2, 98.8, -11.3, 98.7, 98.9, -11.1, 99.0, -11.0, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, 99.0, -11.0, -12.3, 97.7, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -11.6, 98.4, -11.0, 99.0, 97.9, -12.100000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, 98.6, -11.4, 98.4, -11.6, -11.9, 98.1, 97.6, -12.4, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -10.7, 99.3, -11.1, 98.9, 97.8, -12.200000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -11.5, 98.5, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -11.2, 98.8, -12.200000000000001, 97.8, 97.7, -12.3, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.5, -11.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.38796618351441453, "mean_inference_ms": 1.6239898848265912, "mean_action_processing_ms": 0.08844095048376702, "mean_env_wait_ms": 0.08596372348845632, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 97000, "timesteps_this_iter": 0, "agent_timesteps_total": 194000, "timers": {"sample_time_ms": 388.951, "sample_throughput": 2571.02, "load_time_ms": 1.195, "load_throughput": 836752.184, "learn_time_ms": 101.542, "learn_throughput": 9848.128, "update_time_ms": 3.053}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 5.684341886080802e-15, "cur_lr": 0.0005000000000000001, "total_loss": 1450.708447265625, "policy_loss": -0.002095599526364822, "vf_loss": 1450.7158447265624, "vf_explained_var": 0.03360899090766907, "kl": 0.005350255404856341, "entropy": 0.5179012775421142, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 97000, "num_agent_steps_sampled": 194000, "num_steps_trained": 97000, "num_agent_steps_trained": 194000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 6980, "training_iteration": 97, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-15", "timestamp": 1749778575, "time_this_iter_s": 0.354339599609375, "time_total_s": 35.57815718650818, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c9550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 35.57815718650818, "timesteps_since_restore": 0, "iterations_since_restore": 97, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 50.211999999999996, "episode_len_mean": 19.54, "episode_media": {}, "episodes_this_iter": 53, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 25.105999999999998}, "custom_metrics": {}, "hist_stats": {"episode_reward": [87.0, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, 86.39999999999999, -4.999999999999998, 85.8, 87.2, 86.8, 86.2, 85.2, -4.999999999999998, 89.4, 88.6, 87.8, 85.6, 86.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.6, 87.0, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, 86.6, 86.8, -4.999999999999998, 86.8, 87.0, -4.999999999999998, 87.8, 87.6, 85.6, 85.4, -4.999999999999998, 86.8, 88.6, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 87.0, 87.2, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, 87.0, -4.999999999999998, 89.4, 86.6, 85.8, 88.6, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, 85.2, -4.999999999999998, 87.8, 85.2, -4.999999999999998, 85.8, 87.0, 86.39999999999999, 85.6, 85.8, -4.999999999999998, 88.4, -4.999999999999998, 86.8, 87.4, -4.999999999999998, 87.0, 88.8, -4.999999999999998, 87.6, -4.999999999999998, 86.0, 86.2, -4.999999999999998, 89.4, -4.999999999999998, 88.2, 85.8, 85.4, 89.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2], "episode_lengths": [16, 25, 25, 17, 25, 19, 25, 22, 15, 17, 20, 25, 25, 4, 8, 12, 23, 20, 25, 25, 25, 25, 25, 18, 16, 25, 21, 25, 25, 18, 17, 25, 17, 16, 25, 12, 13, 23, 24, 25, 17, 8, 25, 25, 4, 25, 16, 15, 17, 25, 25, 25, 10, 25, 16, 25, 4, 18, 22, 8, 25, 18, 25, 25, 11, 25, 25, 25, 12, 25, 25, 22, 16, 19, 23, 22, 25, 9, 25, 17, 14, 25, 16, 7, 25, 13, 25, 21, 20, 25, 4, 25, 10, 22, 24, 6, 25, 25, 25, 10], "policy_shared_policy_reward": [98.5, -11.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, 98.6, -11.4, 98.4, -11.6, -11.9, 98.1, 97.6, -12.4, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -10.7, 99.3, -11.1, 98.9, 97.8, -12.200000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -11.5, 98.5, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -11.2, 98.8, -12.200000000000001, 97.8, 97.7, -12.3, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.5, -11.5, 98.6, -11.4, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.3, -11.700000000000001, 97.9, -12.100000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 97.6, -12.4, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -11.5, 98.5, 98.2, -11.8, 97.8, -12.200000000000001, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -12.0, 98.0, 98.1, -11.9, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -12.100000000000001, 97.9, 97.7, -12.3, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.38791665604378517, "mean_inference_ms": 1.6251263075427855, "mean_action_processing_ms": 0.08844318916698693, "mean_env_wait_ms": 0.08601668746572713, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 98000, "timesteps_this_iter": 0, "agent_timesteps_total": 196000, "timers": {"sample_time_ms": 389.812, "sample_throughput": 2565.339, "load_time_ms": 1.174, "load_throughput": 851739.095, "learn_time_ms": 100.266, "learn_throughput": 9973.482, "update_time_ms": 3.072}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 5.684341886080802e-15, "cur_lr": 0.0005000000000000001, "total_loss": 1587.679638671875, "policy_loss": -0.0006474442780017853, "vf_loss": 1587.6853881835937, "vf_explained_var": 0.027648794651031493, "kl": 0.0013189034002468957, "entropy": 0.5100801885128021, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 98000, "num_agent_steps_sampled": 196000, "num_steps_trained": 98000, "num_agent_steps_trained": 196000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 7033, "training_iteration": 98, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-15", "timestamp": 1749778575, "time_this_iter_s": 0.3379220962524414, "time_total_s": 35.91607928276062, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 35.91607928276062, "timesteps_since_restore": 0, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 54.8, "ram_util_percent": 90.0}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 58.587999999999994, "episode_len_mean": 18.25, "episode_media": {}, "episodes_this_iter": 55, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 29.293999999999997}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 89.4, 86.6, 85.8, 88.6, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, 85.2, -4.999999999999998, 87.8, 85.2, -4.999999999999998, 85.8, 87.0, 86.39999999999999, 85.6, 85.8, -4.999999999999998, 88.4, -4.999999999999998, 86.8, 87.4, -4.999999999999998, 87.0, 88.8, -4.999999999999998, 87.6, -4.999999999999998, 86.0, 86.2, -4.999999999999998, 89.4, -4.999999999999998, 88.2, 85.8, 85.4, 89.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, 87.2, -4.999999999999998, 86.2, 88.6, 89.4, 87.2, 86.6, 88.4, 86.8, -4.999999999999998, 85.2, 85.8, -4.999999999999998, -4.999999999999998, 86.2, 86.8, 87.2, 88.2, 86.8, 87.0, 87.0, 88.2, 85.4, -4.999999999999998, 85.4, 88.4, 86.0, 87.4, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, 87.4, 88.8, 88.2, 89.4, 86.0, 88.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.6, 87.6, 87.0, 85.8, 86.2, 86.6, -4.999999999999998, 88.0, -4.999999999999998, 88.2, 87.8, 89.4, -4.999999999999998, 88.2], "episode_lengths": [25, 4, 18, 22, 8, 25, 18, 25, 25, 11, 25, 25, 25, 12, 25, 25, 22, 16, 19, 23, 22, 25, 9, 25, 17, 14, 25, 16, 7, 25, 13, 25, 21, 20, 25, 4, 25, 10, 22, 24, 6, 25, 25, 25, 10, 15, 25, 20, 8, 4, 15, 18, 9, 17, 25, 25, 22, 25, 25, 20, 17, 15, 10, 17, 16, 16, 10, 24, 25, 24, 9, 21, 14, 25, 21, 25, 25, 14, 7, 10, 4, 21, 10, 25, 25, 25, 23, 13, 16, 22, 20, 18, 25, 11, 25, 10, 12, 4, 25, 10], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.3, -11.700000000000001, 97.9, -12.100000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 97.6, -12.4, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -11.5, 98.5, 98.2, -11.8, 97.8, -12.200000000000001, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -12.0, 98.0, 98.1, -11.9, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -12.100000000000001, 97.9, 97.7, -12.3, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -11.4, 98.6, -2.500000000000001, -2.500000000000001, 98.1, -11.9, -10.7, 99.3, 99.7, -10.3, 98.6, -11.4, -11.700000000000001, 98.3, 99.2, -10.8, 98.4, -11.6, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.1, -11.9, 98.4, -11.6, 98.6, -11.4, 99.1, -10.9, -11.6, 98.4, 98.5, -11.5, 98.5, -11.5, 99.1, -10.9, -12.3, 97.7, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -10.8, 99.2, 98.0, -12.0, -11.3, 98.7, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -10.6, 99.4, 99.1, -10.9, -10.3, 99.7, -12.0, 98.0, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, 98.8, -11.2, 98.5, -11.5, 97.9, -12.100000000000001, 98.1, -11.9, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -11.1, 98.9, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.9, 99.1]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3873912148916173, "mean_inference_ms": 1.623841628476145, "mean_action_processing_ms": 0.08842114694529771, "mean_env_wait_ms": 0.08599698229358539, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 99000, "timesteps_this_iter": 0, "agent_timesteps_total": 198000, "timers": {"sample_time_ms": 388.758, "sample_throughput": 2572.295, "load_time_ms": 1.194, "load_throughput": 837470.599, "learn_time_ms": 100.045, "learn_throughput": 9995.515, "update_time_ms": 3.037}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 2.842170943040401e-15, "cur_lr": 0.0005000000000000001, "total_loss": 1885.04501953125, "policy_loss": -0.005394194088876247, "vf_loss": 1885.055810546875, "vf_explained_var": 0.025906836986541747, "kl": 0.006191320500218822, "entropy": 0.5401610314846039, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 99000, "num_agent_steps_sampled": 198000, "num_steps_trained": 99000, "num_agent_steps_trained": 198000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 7088, "training_iteration": 99, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-15", "timestamp": 1749778575, "time_this_iter_s": 0.3405575752258301, "time_total_s": 36.25663685798645, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018301ca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 36.25663685798645, "timesteps_since_restore": 0, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 56.4, "ram_util_percent": 90.0}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 55.90200000000001, "episode_len_mean": 18.15, "episode_media": {}, "episodes_this_iter": 55, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 27.951}, "custom_metrics": {}, "hist_stats": {"episode_reward": [85.2, 85.8, -4.999999999999998, -4.999999999999998, 86.2, 86.8, 87.2, 88.2, 86.8, 87.0, 87.0, 88.2, 85.4, -4.999999999999998, 85.4, 88.4, 86.0, 87.4, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, 87.4, 88.8, 88.2, 89.4, 86.0, 88.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.6, 87.6, 87.0, 85.8, 86.2, 86.6, -4.999999999999998, 88.0, -4.999999999999998, 88.2, 87.8, 89.4, -4.999999999999998, 88.2, 85.4, 88.2, 89.0, 87.6, 87.8, 89.4, 85.8, -4.999999999999998, 86.0, -4.999999999999998, 86.2, -4.999999999999998, 87.0, 87.2, 87.6, 86.6, 88.6, 87.6, 89.2, 88.2, 86.6, -4.999999999999998, 88.2, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, 86.6, 87.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, 89.2, -4.999999999999998, -4.999999999999998, 87.0, 88.2, -4.999999999999998, 87.8, 87.4, -4.999999999999998, -4.999999999999998, 86.6, -4.999999999999998, 87.6, -4.999999999999998, 85.8, 86.8, -4.999999999999998], "episode_lengths": [25, 22, 25, 25, 20, 17, 15, 10, 17, 16, 16, 10, 24, 25, 24, 9, 21, 14, 25, 21, 25, 25, 14, 7, 10, 4, 21, 10, 25, 25, 25, 23, 13, 16, 22, 20, 18, 25, 11, 25, 10, 12, 4, 25, 10, 24, 10, 6, 13, 12, 4, 22, 25, 21, 25, 20, 25, 16, 15, 13, 18, 8, 13, 5, 10, 18, 25, 10, 15, 25, 25, 25, 25, 15, 25, 18, 16, 25, 25, 25, 25, 25, 10, 5, 25, 25, 16, 10, 25, 12, 14, 25, 25, 18, 25, 13, 25, 22, 17, 25], "policy_shared_policy_reward": [97.6, -12.4, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.1, -11.9, 98.4, -11.6, 98.6, -11.4, 99.1, -10.9, -11.6, 98.4, 98.5, -11.5, 98.5, -11.5, 99.1, -10.9, -12.3, 97.7, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -10.8, 99.2, 98.0, -12.0, -11.3, 98.7, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -10.6, 99.4, 99.1, -10.9, -10.3, 99.7, -12.0, 98.0, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, 98.8, -11.2, 98.5, -11.5, 97.9, -12.100000000000001, 98.1, -11.9, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -11.1, 98.9, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -12.3, 97.7, -10.9, 99.1, -10.5, 99.5, 98.8, -11.2, 98.9, -11.1, 99.7, -10.3, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, 98.1, -11.9, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -11.4, 98.6, -11.2, 98.8, 98.3, -11.700000000000001, -10.7, 99.3, -11.2, 98.8, -10.4, 99.6, 99.1, -10.9, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -10.9, 99.1, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, 98.4, -11.6, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3862299238920254, "mean_inference_ms": 1.6215191771935287, "mean_action_processing_ms": 0.08831266408506404, "mean_env_wait_ms": 0.08593145065463187, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 100000, "timesteps_this_iter": 0, "agent_timesteps_total": 200000, "timers": {"sample_time_ms": 389.024, "sample_throughput": 2570.537, "load_time_ms": 1.19, "load_throughput": 840120.981, "learn_time_ms": 99.579, "learn_throughput": 10042.321, "update_time_ms": 3.102}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 2.842170943040401e-15, "cur_lr": 0.0005000000000000001, "total_loss": 1448.8929443359375, "policy_loss": -0.005096916854381561, "vf_loss": 1448.9033447265624, "vf_explained_var": 0.03934265971183777, "kl": 0.007842460532278394, "entropy": 0.5321416556835175, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 100000, "num_agent_steps_sampled": 200000, "num_steps_trained": 100000, "num_agent_steps_trained": 200000, "num_steps_trained_this_iter": 0}, "evaluation": {"episode_reward_max": 89.2, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 50.540000000000006, "episode_len_mean": 17.9, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"shared_policy": -12.200000000000001}, "policy_reward_max": {"shared_policy": 99.6}, "policy_reward_mean": {"shared_policy": 25.27}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 86.6, 88.0, -4.999999999999998, 85.6, -4.999999999999998, 87.4, 88.6, -4.999999999999998, 89.2], "episode_lengths": [25, 18, 11, 25, 23, 25, 14, 8, 25, 5], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -10.4, 99.6]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18631666898727417, "mean_inference_ms": 1.2876844654480615, "mean_action_processing_ms": 0.04470224181811015, "mean_env_wait_ms": 0.04067209859689076, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "done": false, "episodes_total": 7143, "training_iteration": 100, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-16", "timestamp": 1749778576, "time_this_iter_s": 0.6297845840454102, "time_total_s": 36.88642144203186, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182f4940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 36.88642144203186, "timesteps_since_restore": 0, "iterations_since_restore": 100, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 52.065999999999995, "episode_len_mean": 19.29, "episode_media": {}, "episodes_this_iter": 50, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 26.033}, "custom_metrics": {}, "hist_stats": {"episode_reward": [89.4, 85.8, -4.999999999999998, 86.0, -4.999999999999998, 86.2, -4.999999999999998, 87.0, 87.2, 87.6, 86.6, 88.6, 87.6, 89.2, 88.2, 86.6, -4.999999999999998, 88.2, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, 86.6, 87.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, 89.2, -4.999999999999998, -4.999999999999998, 87.0, 88.2, -4.999999999999998, 87.8, 87.4, -4.999999999999998, -4.999999999999998, 86.6, -4.999999999999998, 87.6, -4.999999999999998, 85.8, 86.8, -4.999999999999998, 85.2, 88.6, 86.39999999999999, 86.2, 85.8, -4.999999999999998, 89.4, 87.8, -4.999999999999998, -4.999999999999998, 87.2, 86.8, -4.999999999999998, 86.0, 87.2, 87.6, 85.2, -4.999999999999998, 86.8, 87.4, -4.999999999999998, 85.2, 85.6, -4.999999999999998, -4.999999999999998, 88.6, 86.2, 86.2, 86.2, 85.2, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, 87.8, 86.6, 85.4, -4.999999999999998, 88.6, 87.2, 87.4, -4.999999999999998, 87.0, -4.999999999999998, -4.999999999999998, 87.0, 85.2, 88.0, -4.999999999999998], "episode_lengths": [4, 22, 25, 21, 25, 20, 25, 16, 15, 13, 18, 8, 13, 5, 10, 18, 25, 10, 15, 25, 25, 25, 25, 15, 25, 18, 16, 25, 25, 25, 25, 25, 10, 5, 25, 25, 16, 10, 25, 12, 14, 25, 25, 18, 25, 13, 25, 22, 17, 25, 25, 8, 19, 20, 22, 25, 4, 12, 25, 25, 15, 17, 25, 21, 15, 13, 25, 25, 17, 14, 25, 25, 23, 25, 25, 8, 20, 20, 20, 25, 17, 25, 25, 25, 21, 12, 18, 24, 25, 8, 15, 14, 25, 16, 25, 25, 16, 25, 11, 25], "policy_shared_policy_reward": [99.7, -10.3, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, 98.1, -11.9, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -11.4, 98.6, -11.2, 98.8, 98.3, -11.700000000000001, -10.7, 99.3, -11.2, 98.8, -10.4, 99.6, 99.1, -10.9, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -10.9, 99.1, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -10.7, 99.3, 98.2, -11.8, -11.9, 98.1, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -12.0, 98.0, 98.6, -11.4, 98.8, -11.2, -12.4, 97.6, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -11.3, 98.7, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 98.1, -11.9, 98.1, -11.9, 98.1, -11.9, -12.4, 97.6, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -11.1, 98.9, -11.700000000000001, 98.3, 97.7, -12.3, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -11.4, 98.6, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.5, -11.5, 97.6, -12.4, 99.0, -11.0, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.38582141927580405, "mean_inference_ms": 1.6208704367925872, "mean_action_processing_ms": 0.08816484782309761, "mean_env_wait_ms": 0.08579386035406504, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 101000, "timesteps_this_iter": 0, "agent_timesteps_total": 202000, "timers": {"sample_time_ms": 417.642, "sample_throughput": 2394.398, "load_time_ms": 1.11, "load_throughput": 900625.711, "learn_time_ms": 99.628, "learn_throughput": 10037.332, "update_time_ms": 3.08}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 2.842170943040401e-15, "cur_lr": 0.0005000000000000001, "total_loss": 1687.3590087890625, "policy_loss": -0.0030364177189767362, "vf_loss": 1687.3672729492187, "vf_explained_var": 0.020379161834716795, "kl": 0.004490100272047393, "entropy": 0.5255402326583862, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 101000, "num_agent_steps_sampled": 202000, "num_steps_trained": 101000, "num_agent_steps_trained": 202000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 7193, "training_iteration": 101, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-16", "timestamp": 1749778576, "time_this_iter_s": 0.3425788879394531, "time_total_s": 37.22900032997131, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 37.22900032997131, "timesteps_since_restore": 0, "iterations_since_restore": 101, "perf": {"cpu_util_percent": 33.8, "ram_util_percent": 90.0}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 51.21, "episode_len_mean": 19.06, "episode_media": {}, "episodes_this_iter": 55, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 25.605}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 89.4, 87.8, -4.999999999999998, -4.999999999999998, 87.2, 86.8, -4.999999999999998, 86.0, 87.2, 87.6, 85.2, -4.999999999999998, 86.8, 87.4, -4.999999999999998, 85.2, 85.6, -4.999999999999998, -4.999999999999998, 88.6, 86.2, 86.2, 86.2, 85.2, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, 87.8, 86.6, 85.4, -4.999999999999998, 88.6, 87.2, 87.4, -4.999999999999998, 87.0, -4.999999999999998, -4.999999999999998, 87.0, 85.2, 88.0, -4.999999999999998, 86.8, -4.999999999999998, 88.4, -4.999999999999998, 87.0, -4.999999999999998, 88.6, -4.999999999999998, 86.6, 89.4, -4.999999999999998, 86.39999999999999, 89.4, 89.0, 86.8, 86.8, -4.999999999999998, 85.4, -4.999999999999998, 85.2, 89.4, -4.999999999999998, -4.999999999999998, 88.6, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, -4.999999999999998, 87.2, 88.0, -4.999999999999998, 87.2, 86.6, 88.8, -4.999999999999998, -4.999999999999998, 89.0, 86.0, 87.2, 85.6, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, 88.0, 86.2, 85.6, 88.6, -4.999999999999998, -4.999999999999998], "episode_lengths": [25, 4, 12, 25, 25, 15, 17, 25, 21, 15, 13, 25, 25, 17, 14, 25, 25, 23, 25, 25, 8, 20, 20, 20, 25, 17, 25, 25, 25, 21, 12, 18, 24, 25, 8, 15, 14, 25, 16, 25, 25, 16, 25, 11, 25, 17, 25, 9, 25, 16, 25, 8, 25, 18, 4, 25, 19, 4, 6, 17, 17, 25, 24, 25, 25, 4, 25, 25, 8, 4, 25, 25, 25, 10, 25, 25, 15, 11, 25, 15, 18, 7, 25, 25, 6, 21, 15, 23, 17, 25, 25, 25, 25, 20, 11, 20, 23, 8, 25, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -12.0, 98.0, 98.6, -11.4, 98.8, -11.2, -12.4, 97.6, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -11.3, 98.7, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 98.1, -11.9, 98.1, -11.9, 98.1, -11.9, -12.4, 97.6, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -11.1, 98.9, -11.700000000000001, 98.3, 97.7, -12.3, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -11.4, 98.6, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.5, -11.5, 97.6, -12.4, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 98.2, -11.8, 99.7, -10.3, -10.5, 99.5, 98.4, -11.6, 98.4, -11.6, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -2.500000000000001, -2.500000000000001, -12.4, 97.6, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -11.700000000000001, 98.3, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -12.0, 98.0, 98.6, -11.4, -12.200000000000001, 97.8, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.1, -11.9, -11.0, 99.0, 98.1, -11.9, 97.8, -12.200000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3859152487248061, "mean_inference_ms": 1.6224104256641185, "mean_action_processing_ms": 0.0882755906711371, "mean_env_wait_ms": 0.08583037539170131, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 102000, "timesteps_this_iter": 0, "agent_timesteps_total": 204000, "timers": {"sample_time_ms": 417.596, "sample_throughput": 2394.657, "load_time_ms": 1.095, "load_throughput": 913075.583, "learn_time_ms": 99.412, "learn_throughput": 10059.163, "update_time_ms": 2.778}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.4210854715202005e-15, "cur_lr": 0.0005000000000000001, "total_loss": 1393.3316772460937, "policy_loss": -0.0055249262601137165, "vf_loss": 1393.3424926757812, "vf_explained_var": 0.034340792894363405, "kl": 0.006542694027654683, "entropy": 0.5268666326999665, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 102000, "num_agent_steps_sampled": 204000, "num_steps_trained": 102000, "num_agent_steps_trained": 204000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 7248, "training_iteration": 102, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-17", "timestamp": 1749778577, "time_this_iter_s": 0.3543682098388672, "time_total_s": 37.58336853981018, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018319e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 37.58336853981018, "timesteps_since_restore": 0, "iterations_since_restore": 102, "perf": {"cpu_util_percent": 58.1, "ram_util_percent": 90.1}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 47.63399999999999, "episode_len_mean": 18.9, "episode_media": {}, "episodes_this_iter": 52, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 23.816999999999997}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 86.6, 89.4, -4.999999999999998, 86.39999999999999, 89.4, 89.0, 86.8, 86.8, -4.999999999999998, 85.4, -4.999999999999998, 85.2, 89.4, -4.999999999999998, -4.999999999999998, 88.6, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, -4.999999999999998, 87.2, 88.0, -4.999999999999998, 87.2, 86.6, 88.8, -4.999999999999998, -4.999999999999998, 89.0, 86.0, 87.2, 85.6, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, 88.0, 86.2, 85.6, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.0, -4.999999999999998, 88.2, 87.2, 87.6, 89.4, -4.999999999999998, -4.999999999999998, 89.0, 89.4, 87.4, -4.999999999999998, 85.6, -4.999999999999998, 86.8, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, 88.2, 86.6, -4.999999999999998, 85.4, 88.0, -4.999999999999998, 87.2, 87.0, 87.8, -4.999999999999998, 86.6, 88.4, -4.999999999999998, 85.6, -4.999999999999998, 87.2, -4.999999999999998, 85.2, 85.8, -4.999999999999998, 87.0, -4.999999999999998, 85.6, -4.999999999999998, -4.999999999999998, 88.8, 88.2, -4.999999999999998, -4.999999999999998], "episode_lengths": [25, 18, 4, 25, 19, 4, 6, 17, 17, 25, 24, 25, 25, 4, 25, 25, 8, 4, 25, 25, 25, 10, 25, 25, 15, 11, 25, 15, 18, 7, 25, 25, 6, 21, 15, 23, 17, 25, 25, 25, 25, 20, 11, 20, 23, 8, 25, 25, 25, 25, 16, 25, 10, 15, 13, 4, 25, 25, 6, 4, 14, 25, 23, 25, 17, 25, 14, 25, 25, 25, 15, 10, 18, 25, 24, 11, 25, 15, 16, 12, 25, 18, 9, 25, 23, 25, 15, 25, 25, 22, 25, 16, 25, 23, 25, 25, 7, 10, 25, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 98.2, -11.8, 99.7, -10.3, -10.5, 99.5, 98.4, -11.6, 98.4, -11.6, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -2.500000000000001, -2.500000000000001, -12.4, 97.6, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -11.700000000000001, 98.3, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -12.0, 98.0, 98.6, -11.4, -12.200000000000001, 97.8, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.1, -11.9, -11.0, 99.0, 98.1, -11.9, 97.8, -12.200000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -11.4, 98.6, 98.8, -11.2, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -10.3, 99.7, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.6, -11.4, 99.1, -10.9, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 98.6, -11.4, 98.5, -11.5, 98.9, -11.1, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.38550242373585886, "mean_inference_ms": 1.6220698644338376, "mean_action_processing_ms": 0.08829022855409381, "mean_env_wait_ms": 0.08577401308965406, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 103000, "timesteps_this_iter": 0, "agent_timesteps_total": 206000, "timers": {"sample_time_ms": 414.396, "sample_throughput": 2413.151, "load_time_ms": 1.094, "load_throughput": 914110.365, "learn_time_ms": 99.091, "learn_throughput": 10091.782, "update_time_ms": 2.946}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.4210854715202005e-15, "cur_lr": 0.0005000000000000001, "total_loss": 1393.9977172851563, "policy_loss": -0.0034686625935137273, "vf_loss": 1394.0062133789063, "vf_explained_var": 0.03946815133094787, "kl": 0.006309814273617853, "entropy": 0.49944052994251253, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 103000, "num_agent_steps_sampled": 206000, "num_steps_trained": 103000, "num_agent_steps_trained": 206000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 7300, "training_iteration": 103, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-17", "timestamp": 1749778577, "time_this_iter_s": 0.3406643867492676, "time_total_s": 37.92403292655945, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0183191f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 37.92403292655945, "timesteps_since_restore": 0, "iterations_since_restore": 103, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 48.52399999999999, "episode_len_mean": 18.96, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 24.261999999999997}, "custom_metrics": {}, "hist_stats": {"episode_reward": [87.6, 89.4, -4.999999999999998, -4.999999999999998, 89.0, 89.4, 87.4, -4.999999999999998, 85.6, -4.999999999999998, 86.8, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, 88.2, 86.6, -4.999999999999998, 85.4, 88.0, -4.999999999999998, 87.2, 87.0, 87.8, -4.999999999999998, 86.6, 88.4, -4.999999999999998, 85.6, -4.999999999999998, 87.2, -4.999999999999998, 85.2, 85.8, -4.999999999999998, 87.0, -4.999999999999998, 85.6, -4.999999999999998, -4.999999999999998, 88.8, 88.2, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, 87.4, -4.999999999999998, 87.6, 85.4, 86.2, 86.0, 86.2, -4.999999999999998, -4.999999999999998, 86.39999999999999, -4.999999999999998, 89.0, 85.2, -4.999999999999998, -4.999999999999998, 86.39999999999999, -4.999999999999998, 85.6, 88.0, 89.4, 87.0, 89.4, 86.8, -4.999999999999998, 88.2, 87.2, -4.999999999999998, 85.8, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, 88.2, -4.999999999999998, 88.4, 88.0, 85.6, 86.4, -4.999999999999998, 88.6, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, 88.4, 87.8, -4.999999999999998], "episode_lengths": [13, 4, 25, 25, 6, 4, 14, 25, 23, 25, 17, 25, 14, 25, 25, 25, 15, 10, 18, 25, 24, 11, 25, 15, 16, 12, 25, 18, 9, 25, 23, 25, 15, 25, 25, 22, 25, 16, 25, 23, 25, 25, 7, 10, 25, 25, 21, 25, 14, 25, 13, 24, 20, 21, 20, 25, 25, 19, 25, 6, 25, 25, 25, 19, 25, 23, 11, 4, 16, 4, 17, 25, 10, 15, 25, 22, 9, 25, 25, 25, 25, 10, 25, 10, 25, 9, 11, 23, 19, 25, 8, 25, 9, 25, 25, 25, 9, 9, 12, 25], "policy_shared_policy_reward": [98.8, -11.2, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -10.3, 99.7, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.6, -11.4, 99.1, -10.9, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 98.6, -11.4, 98.5, -11.5, 98.9, -11.1, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -11.2, 98.8, 97.7, -12.3, 98.1, -11.9, 98.0, -12.0, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, 99.0, -11.0, 99.7, -10.3, 98.5, -11.5, -10.3, 99.7, -11.6, 98.4, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 98.6, -11.4, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 99.2, -10.8, 99.0, -11.0, 97.8, -12.200000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -10.8, 99.2, 98.9, -11.1, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3850125221728283, "mean_inference_ms": 1.621386223523206, "mean_action_processing_ms": 0.08830675793774023, "mean_env_wait_ms": 0.08569677481964601, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 104000, "timesteps_this_iter": 0, "agent_timesteps_total": 208000, "timers": {"sample_time_ms": 414.533, "sample_throughput": 2412.353, "load_time_ms": 1.09, "load_throughput": 917610.099, "learn_time_ms": 99.12, "learn_throughput": 10088.772, "update_time_ms": 2.966}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.4210854715202005e-15, "cur_lr": 0.0005000000000000001, "total_loss": 1435.6079467773438, "policy_loss": -0.0035178791731595993, "vf_loss": 1435.6161499023438, "vf_explained_var": 0.042344164848327634, "kl": 0.00423087567331778, "entropy": 0.47357398867607114, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 104000, "num_agent_steps_sampled": 208000, "num_steps_trained": 104000, "num_agent_steps_trained": 208000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 7354, "training_iteration": 104, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-18", "timestamp": 1749778578, "time_this_iter_s": 0.3542287349700928, "time_total_s": 38.27826166152954, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f54c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 38.27826166152954, "timesteps_since_restore": 0, "iterations_since_restore": 104, "perf": {"cpu_util_percent": 58.3, "ram_util_percent": 90.1}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 55.03199999999999, "episode_len_mean": 17.99, "episode_media": {}, "episodes_this_iter": 55, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 27.516}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, 86.39999999999999, -4.999999999999998, 89.0, 85.2, -4.999999999999998, -4.999999999999998, 86.39999999999999, -4.999999999999998, 85.6, 88.0, 89.4, 87.0, 89.4, 86.8, -4.999999999999998, 88.2, 87.2, -4.999999999999998, 85.8, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, 88.2, -4.999999999999998, 88.4, 88.0, 85.6, 86.4, -4.999999999999998, 88.6, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, 88.4, 87.8, -4.999999999999998, -4.999999999999998, 87.6, 87.8, 86.6, 88.6, 86.2, 85.6, 86.6, 87.6, 86.2, 88.2, 86.4, 87.0, -4.999999999999998, -4.999999999999998, 86.39999999999999, 89.4, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 87.2, -4.999999999999998, 88.6, 85.8, 87.8, 88.2, 89.4, 86.2, -4.999999999999998, 88.6, 87.2, -4.999999999999998, 85.8, 87.0, 86.8, 86.8, -4.999999999999998, 87.0, 88.4, 86.0, -4.999999999999998, 87.4, 86.6, 88.2, 85.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, 85.2, 89.4, 87.2, -4.999999999999998], "episode_lengths": [25, 25, 19, 25, 6, 25, 25, 25, 19, 25, 23, 11, 4, 16, 4, 17, 25, 10, 15, 25, 22, 9, 25, 25, 25, 25, 10, 25, 10, 25, 9, 11, 23, 19, 25, 8, 25, 9, 25, 25, 25, 9, 9, 12, 25, 25, 13, 12, 18, 8, 20, 23, 18, 13, 20, 10, 19, 16, 25, 25, 19, 4, 25, 25, 25, 25, 4, 15, 25, 8, 22, 12, 10, 4, 20, 25, 8, 15, 25, 22, 16, 17, 17, 25, 16, 9, 21, 25, 14, 18, 10, 24, 25, 25, 25, 11, 25, 4, 15, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, 99.0, -11.0, 99.7, -10.3, 98.5, -11.5, -10.3, 99.7, -11.6, 98.4, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 98.6, -11.4, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 99.2, -10.8, 99.0, -11.0, 97.8, -12.200000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -10.8, 99.2, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -11.1, 98.9, 98.3, -11.700000000000001, -10.7, 99.3, -11.9, 98.1, -12.200000000000001, 97.8, -11.700000000000001, 98.3, 98.8, -11.2, 98.1, -11.9, -10.9, 99.1, -11.8, 98.2, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -10.3, 99.7, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -10.7, 99.3, 97.9, -12.100000000000001, -11.1, 98.9, 99.1, -10.9, 99.7, -10.3, 98.1, -11.9, -2.500000000000001, -2.500000000000001, -10.7, 99.3, 98.6, -11.4, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, 98.5, -11.5, -11.6, 98.4, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -10.8, 99.2, 98.0, -12.0, -2.500000000000001, -2.500000000000001, 98.7, -11.3, 98.3, -11.700000000000001, 99.1, -10.9, 97.7, -12.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -12.4, 97.6, -10.3, 99.7, 98.6, -11.4, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.38427123158848664, "mean_inference_ms": 1.6201310644839664, "mean_action_processing_ms": 0.0883374220855887, "mean_env_wait_ms": 0.08567104076887205, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 105000, "timesteps_this_iter": 0, "agent_timesteps_total": 210000, "timers": {"sample_time_ms": 415.5, "sample_throughput": 2406.737, "load_time_ms": 1.102, "load_throughput": 907759.766, "learn_time_ms": 98.328, "learn_throughput": 10169.994, "update_time_ms": 2.987}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 7.105427357601002e-16, "cur_lr": 0.0005000000000000001, "total_loss": 1789.0587280273437, "policy_loss": -0.0036474790424108504, "vf_loss": 1789.0669311523438, "vf_explained_var": 0.025893276929855345, "kl": 0.005857310912700342, "entropy": 0.4544209033250809, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 105000, "num_agent_steps_sampled": 210000, "num_steps_trained": 105000, "num_agent_steps_trained": 210000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 7409, "training_iteration": 105, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-18", "timestamp": 1749778578, "time_this_iter_s": 0.34783077239990234, "time_total_s": 38.62609243392944, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018319e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 38.62609243392944, "timesteps_since_restore": 0, "iterations_since_restore": 105, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 49.56399999999999, "episode_len_mean": 18.27, "episode_media": {}, "episodes_this_iter": 55, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 24.781999999999996}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.2, 86.4, 87.0, -4.999999999999998, -4.999999999999998, 86.39999999999999, 89.4, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 87.2, -4.999999999999998, 88.6, 85.8, 87.8, 88.2, 89.4, 86.2, -4.999999999999998, 88.6, 87.2, -4.999999999999998, 85.8, 87.0, 86.8, 86.8, -4.999999999999998, 87.0, 88.4, 86.0, -4.999999999999998, 87.4, 86.6, 88.2, 85.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, 85.2, 89.4, 87.2, -4.999999999999998, 85.6, 88.4, 86.8, -4.999999999999998, 88.2, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, 88.0, 86.8, -4.999999999999998, 87.4, -4.999999999999998, 88.6, 88.2, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, 87.6, -4.999999999999998, 89.4, 87.4, 88.2, -4.999999999999998, 87.0, 88.4, -4.999999999999998, 88.8, -4.999999999999998, 87.2, 86.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.2, 88.6, 87.4, -4.999999999999998, -4.999999999999998, 88.0, 87.4, -4.999999999999998, 86.39999999999999, 88.4, -4.999999999999998], "episode_lengths": [10, 19, 16, 25, 25, 19, 4, 25, 25, 25, 25, 4, 15, 25, 8, 22, 12, 10, 4, 20, 25, 8, 15, 25, 22, 16, 17, 17, 25, 16, 9, 21, 25, 14, 18, 10, 24, 25, 25, 25, 11, 25, 4, 15, 25, 23, 9, 17, 25, 10, 25, 25, 22, 25, 11, 17, 25, 14, 25, 8, 10, 25, 25, 9, 25, 25, 13, 25, 4, 14, 10, 25, 16, 9, 25, 7, 25, 15, 19, 25, 25, 25, 25, 25, 15, 25, 25, 25, 25, 5, 8, 14, 25, 25, 11, 14, 25, 19, 9, 25], "policy_shared_policy_reward": [-10.9, 99.1, -11.8, 98.2, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -10.3, 99.7, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -10.7, 99.3, 97.9, -12.100000000000001, -11.1, 98.9, 99.1, -10.9, 99.7, -10.3, 98.1, -11.9, -2.500000000000001, -2.500000000000001, -10.7, 99.3, 98.6, -11.4, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, 98.5, -11.5, -11.6, 98.4, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -10.8, 99.2, 98.0, -12.0, -2.500000000000001, -2.500000000000001, 98.7, -11.3, 98.3, -11.700000000000001, 99.1, -10.9, 97.7, -12.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -12.4, 97.6, -10.3, 99.7, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -10.8, 99.2, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.7, -11.3, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -10.8, 99.2, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -10.7, 99.3, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -11.3, 98.7, -2.500000000000001, -2.500000000000001, 98.2, -11.8, 99.2, -10.8, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.38391539554212806, "mean_inference_ms": 1.6195988440539497, "mean_action_processing_ms": 0.0882566074621859, "mean_env_wait_ms": 0.08567628860203261, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 106000, "timesteps_this_iter": 0, "agent_timesteps_total": 212000, "timers": {"sample_time_ms": 415.557, "sample_throughput": 2406.406, "load_time_ms": 1.033, "load_throughput": 967812.082, "learn_time_ms": 96.569, "learn_throughput": 10355.248, "update_time_ms": 2.913}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 7.105427357601002e-16, "cur_lr": 0.0005000000000000001, "total_loss": 1229.3738525390625, "policy_loss": -0.004593507945537567, "vf_loss": 1229.3829956054688, "vf_explained_var": 0.02305415868759155, "kl": 0.006721219439137105, "entropy": 0.45409814119338987, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 106000, "num_agent_steps_sampled": 212000, "num_steps_trained": 106000, "num_agent_steps_trained": 212000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 7464, "training_iteration": 106, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-18", "timestamp": 1749778578, "time_this_iter_s": 0.34293079376220703, "time_total_s": 38.96902322769165, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0183191f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 38.96902322769165, "timesteps_since_restore": 0, "iterations_since_restore": 106, "perf": {"cpu_util_percent": 50.8, "ram_util_percent": 90.1}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 46.00200000000001, "episode_len_mean": 18.04, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"shared_policy": -12.3}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 23.000999999999998}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.0, 86.8, -4.999999999999998, 87.4, -4.999999999999998, 88.6, 88.2, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, 87.6, -4.999999999999998, 89.4, 87.4, 88.2, -4.999999999999998, 87.0, 88.4, -4.999999999999998, 88.8, -4.999999999999998, 87.2, 86.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.2, 88.6, 87.4, -4.999999999999998, -4.999999999999998, 88.0, 87.4, -4.999999999999998, 86.39999999999999, 88.4, -4.999999999999998, -4.999999999999998, 88.6, -4.999999999999998, 86.39999999999999, 86.6, 88.2, 86.39999999999999, 87.2, -4.999999999999998, 86.2, 87.4, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, 88.6, -4.999999999999998, 87.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, 88.6, -4.999999999999998, 88.2, -4.999999999999998, 88.6, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.8, 88.2, -4.999999999999998, 89.4, 87.6, -4.999999999999998, 87.6, 85.4, -4.999999999999998, 88.2, 87.2, 86.8, 89.4, 86.39999999999999, -4.999999999999998, 88.2, -4.999999999999998, 87.4, 89.2, -4.999999999999998, 87.8, -4.999999999999998, 88.8], "episode_lengths": [11, 17, 25, 14, 25, 8, 10, 25, 25, 9, 25, 25, 13, 25, 4, 14, 10, 25, 16, 9, 25, 7, 25, 15, 19, 25, 25, 25, 25, 25, 15, 25, 25, 25, 25, 5, 8, 14, 25, 25, 11, 14, 25, 19, 9, 25, 25, 8, 25, 19, 18, 10, 19, 15, 25, 20, 14, 25, 22, 25, 25, 8, 25, 12, 25, 25, 25, 20, 8, 25, 10, 25, 8, 8, 25, 25, 25, 12, 10, 25, 4, 13, 25, 13, 24, 25, 10, 15, 17, 4, 19, 25, 10, 25, 14, 5, 25, 12, 25, 7], "policy_shared_policy_reward": [-11.0, 99.0, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.7, -11.3, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -10.8, 99.2, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -10.7, 99.3, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -11.3, 98.7, -2.500000000000001, -2.500000000000001, 98.2, -11.8, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, 98.2, -11.8, 98.3, -11.700000000000001, 99.1, -10.9, 98.2, -11.8, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -10.7, 99.3, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -10.9, 99.1, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -12.3, 97.7, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 98.6, -11.4, 98.4, -11.6, -10.3, 99.7, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -10.6, 99.4]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.38339111737968884, "mean_inference_ms": 1.6181307800450082, "mean_action_processing_ms": 0.0881017604093174, "mean_env_wait_ms": 0.08567800119353695, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 107000, "timesteps_this_iter": 0, "agent_timesteps_total": 214000, "timers": {"sample_time_ms": 413.186, "sample_throughput": 2420.215, "load_time_ms": 1.034, "load_throughput": 967499.539, "learn_time_ms": 96.076, "learn_throughput": 10408.387, "update_time_ms": 2.832}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 7.105427357601002e-16, "cur_lr": 0.0005000000000000001, "total_loss": 1385.0407470703126, "policy_loss": -0.002686129898938816, "vf_loss": 1385.0476806640625, "vf_explained_var": 0.04243165850639343, "kl": 0.004234766069785123, "entropy": 0.42347995936870575, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 107000, "num_agent_steps_sampled": 214000, "num_steps_trained": 107000, "num_agent_steps_trained": 214000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 7518, "training_iteration": 107, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-19", "timestamp": 1749778579, "time_this_iter_s": 0.3299541473388672, "time_total_s": 39.29897737503052, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb01b0b38b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 39.29897737503052, "timesteps_since_restore": 0, "iterations_since_restore": 107, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 46.903999999999996, "episode_len_mean": 18.04, "episode_media": {}, "episodes_this_iter": 58, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 23.451999999999998}, "custom_metrics": {}, "hist_stats": {"episode_reward": [85.8, -4.999999999999998, -4.999999999999998, 88.6, -4.999999999999998, 87.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, 88.6, -4.999999999999998, 88.2, -4.999999999999998, 88.6, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.8, 88.2, -4.999999999999998, 89.4, 87.6, -4.999999999999998, 87.6, 85.4, -4.999999999999998, 88.2, 87.2, 86.8, 89.4, 86.39999999999999, -4.999999999999998, 88.2, -4.999999999999998, 87.4, 89.2, -4.999999999999998, 87.8, -4.999999999999998, 88.8, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, 89.0, 87.0, 85.6, -4.999999999999998, -4.999999999999998, 86.2, 85.4, 88.2, 88.6, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, 89.4, 88.6, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, -4.999999999999998, 85.6, 89.4, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, 89.0, 88.6, -4.999999999999998, -4.999999999999998, 86.4, 87.2, -4.999999999999998, 89.2, 88.4, -4.999999999999998, 88.4, -4.999999999999998, 85.6, -4.999999999999998, 86.2, 88.6, 87.6, -4.999999999999998, -4.999999999999998, 88.6, 85.4, 85.2, -4.999999999999998, 88.6, 88.2], "episode_lengths": [22, 25, 25, 8, 25, 12, 25, 25, 25, 20, 8, 25, 10, 25, 8, 8, 25, 25, 25, 12, 10, 25, 4, 13, 25, 13, 24, 25, 10, 15, 17, 4, 19, 25, 10, 25, 14, 5, 25, 12, 25, 7, 25, 18, 25, 25, 6, 16, 23, 25, 25, 20, 24, 10, 8, 25, 25, 7, 25, 4, 8, 25, 8, 25, 25, 25, 13, 25, 23, 4, 25, 25, 17, 25, 25, 6, 8, 25, 25, 19, 15, 25, 5, 9, 25, 9, 25, 23, 25, 20, 8, 13, 25, 25, 8, 24, 25, 25, 8, 10], "policy_shared_policy_reward": [-12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -10.7, 99.3, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -10.9, 99.1, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -12.3, 97.7, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 98.6, -11.4, 98.4, -11.6, -10.3, 99.7, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.5, 99.5, 98.5, -11.5, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, 97.7, -12.3, 99.1, -10.9, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -10.7, 99.3, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 97.7, -12.3, -12.4, 97.6, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -10.9, 99.1]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3831961410776432, "mean_inference_ms": 1.6185991752964126, "mean_action_processing_ms": 0.08820137074885931, "mean_env_wait_ms": 0.08575882743374454, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 108000, "timesteps_this_iter": 0, "agent_timesteps_total": 216000, "timers": {"sample_time_ms": 413.184, "sample_throughput": 2420.231, "load_time_ms": 1.102, "load_throughput": 907072.664, "learn_time_ms": 94.888, "learn_throughput": 10538.754, "update_time_ms": 2.77}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 3.552713678800501e-16, "cur_lr": 0.0005000000000000001, "total_loss": 1414.21552734375, "policy_loss": -0.0036886414512991906, "vf_loss": 1414.2231689453124, "vf_explained_var": 0.029279905557632446, "kl": 0.004591071873340446, "entropy": 0.3943060666322708, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 108000, "num_agent_steps_sampled": 216000, "num_steps_trained": 108000, "num_agent_steps_trained": 216000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 7576, "training_iteration": 108, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-19", "timestamp": 1749778579, "time_this_iter_s": 0.3441462516784668, "time_total_s": 39.643123626708984, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 39.643123626708984, "timesteps_since_restore": 0, "iterations_since_restore": 108, "perf": {"cpu_util_percent": 51.7, "ram_util_percent": 90.1}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 48.876000000000005, "episode_len_mean": 17.2, "episode_media": {}, "episodes_this_iter": 59, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 24.438000000000002}, "custom_metrics": {}, "hist_stats": {"episode_reward": [89.4, 88.6, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, -4.999999999999998, 85.6, 89.4, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, 89.0, 88.6, -4.999999999999998, -4.999999999999998, 86.4, 87.2, -4.999999999999998, 89.2, 88.4, -4.999999999999998, 88.4, -4.999999999999998, 85.6, -4.999999999999998, 86.2, 88.6, 87.6, -4.999999999999998, -4.999999999999998, 88.6, 85.4, 85.2, -4.999999999999998, 88.6, 88.2, -4.999999999999998, 88.6, 88.2, -4.999999999999998, 88.2, -4.999999999999998, 86.8, 88.0, 89.4, 88.2, -4.999999999999998, 88.0, 89.4, -4.999999999999998, 86.2, 88.0, -4.999999999999998, 87.6, 88.8, -4.999999999999998, -4.999999999999998, 87.8, -4.999999999999998, 88.2, 86.4, -4.999999999999998, 88.2, 86.0, 89.4, 87.4, -4.999999999999998, 88.2, 89.0, 87.8, 86.0, -4.999999999999998, -4.999999999999998, 89.0, 87.2, 86.0, -4.999999999999998, 89.0, -4.999999999999998, 86.2, 89.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, 88.6, 89.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.6], "episode_lengths": [4, 8, 25, 8, 25, 25, 25, 13, 25, 23, 4, 25, 25, 17, 25, 25, 6, 8, 25, 25, 19, 15, 25, 5, 9, 25, 9, 25, 23, 25, 20, 8, 13, 25, 25, 8, 24, 25, 25, 8, 10, 25, 8, 10, 25, 10, 25, 17, 11, 4, 10, 25, 11, 4, 25, 20, 11, 25, 13, 7, 25, 25, 12, 25, 10, 19, 25, 10, 21, 4, 14, 25, 10, 6, 12, 21, 25, 25, 6, 15, 21, 25, 6, 25, 20, 6, 25, 25, 25, 10, 8, 4, 4, 25, 25, 25, 25, 25, 25, 8], "policy_shared_policy_reward": [-10.3, 99.7, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -10.7, 99.3, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 97.7, -12.3, -12.4, 97.6, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -11.0, 99.0, -10.3, 99.7, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -11.2, 98.8, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -12.0, 98.0, -10.3, 99.7, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -10.9, 99.1, 99.5, -10.5, -11.1, 98.9, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -11.4, 98.6, -12.0, 98.0, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -10.7, 99.3, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3830919103196223, "mean_inference_ms": 1.6176871439368141, "mean_action_processing_ms": 0.08820284066898428, "mean_env_wait_ms": 0.08562131852826266, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 109000, "timesteps_this_iter": 0, "agent_timesteps_total": 218000, "timers": {"sample_time_ms": 410.742, "sample_throughput": 2434.621, "load_time_ms": 1.126, "load_throughput": 887946.481, "learn_time_ms": 93.974, "learn_throughput": 10641.201, "update_time_ms": 2.824}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.7763568394002506e-16, "cur_lr": 0.0005000000000000001, "total_loss": 1363.209619140625, "policy_loss": -0.0015546556562185288, "vf_loss": 1363.2153442382812, "vf_explained_var": 0.03725617527961731, "kl": 0.0029660139488589367, "entropy": 0.42027453482151034, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 109000, "num_agent_steps_sampled": 218000, "num_steps_trained": 109000, "num_agent_steps_trained": 218000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 7635, "training_iteration": 109, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-19", "timestamp": 1749778579, "time_this_iter_s": 0.3290114402770996, "time_total_s": 39.972135066986084, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018224f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 39.972135066986084, "timesteps_since_restore": 0, "iterations_since_restore": 109, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 55.38400000000001, "episode_len_mean": 16.23, "episode_media": {}, "episodes_this_iter": 60, "policy_reward_min": {"shared_policy": -12.100000000000001}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 27.691999999999997}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, 87.8, -4.999999999999998, 88.2, 86.4, -4.999999999999998, 88.2, 86.0, 89.4, 87.4, -4.999999999999998, 88.2, 89.0, 87.8, 86.0, -4.999999999999998, -4.999999999999998, 89.0, 87.2, 86.0, -4.999999999999998, 89.0, -4.999999999999998, 86.2, 89.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, 88.6, 89.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.6, 87.2, 89.0, -4.999999999999998, 86.6, 86.39999999999999, 87.4, -4.999999999999998, 88.6, 88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, 86.39999999999999, 88.6, 87.2, 89.4, 86.8, 86.2, -4.999999999999998, -4.999999999999998, 88.6, -4.999999999999998, 88.0, 88.2, -4.999999999999998, -4.999999999999998, 87.0, 88.2, 87.2, 85.8, 87.2, 88.6, 88.0, 87.8, 88.6, 86.6, -4.999999999999998, -4.999999999999998, 89.4, 89.0, 89.4, -4.999999999999998, 86.6, 88.6, 89.4, 88.2, 88.2, 88.6, 88.6, -4.999999999999998, -4.999999999999998, 86.39999999999999, 87.2, 88.2, -4.999999999999998, 88.8, -4.999999999999998, 88.2, 87.0], "episode_lengths": [25, 25, 12, 25, 10, 19, 25, 10, 21, 4, 14, 25, 10, 6, 12, 21, 25, 25, 6, 15, 21, 25, 6, 25, 20, 6, 25, 25, 25, 10, 8, 4, 4, 25, 25, 25, 25, 25, 25, 8, 15, 6, 25, 18, 19, 14, 25, 8, 7, 25, 25, 25, 10, 19, 8, 15, 4, 17, 20, 25, 25, 8, 25, 11, 10, 25, 25, 16, 10, 15, 22, 15, 8, 11, 12, 8, 18, 25, 25, 4, 6, 4, 25, 18, 8, 4, 10, 10, 8, 8, 25, 25, 19, 15, 10, 25, 7, 25, 10, 16], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -12.0, 98.0, -10.3, 99.7, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -10.9, 99.1, 99.5, -10.5, -11.1, 98.9, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -11.4, 98.6, -12.0, 98.0, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -10.7, 99.3, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -11.4, 98.6, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, 98.2, -11.8, 98.7, -11.3, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 98.2, -11.8, 99.3, -10.7, 98.6, -11.4, -10.3, 99.7, -11.6, 98.4, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -10.9, 99.1, 98.6, -11.4, -12.100000000000001, 97.9, -11.4, 98.6, -10.7, 99.3, -11.0, 99.0, 98.9, -11.1, -10.7, 99.3, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.5, -10.5, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, 99.3, -10.7, 99.7, -10.3, -10.9, 99.1, 99.1, -10.9, 99.3, -10.7, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -11.4, 98.6, -10.9, 99.1, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -11.5, 98.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3826019161613391, "mean_inference_ms": 1.6165950491259686, "mean_action_processing_ms": 0.08810896488691122, "mean_env_wait_ms": 0.08550393987808988, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 110000, "timesteps_this_iter": 0, "agent_timesteps_total": 220000, "timers": {"sample_time_ms": 408.787, "sample_throughput": 2446.263, "load_time_ms": 1.122, "load_throughput": 891437.802, "learn_time_ms": 94.359, "learn_throughput": 10597.848, "update_time_ms": 2.636}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 8.881784197001253e-17, "cur_lr": 0.0005000000000000001, "total_loss": 1650.5324462890626, "policy_loss": -0.0038047850131988524, "vf_loss": 1650.5402221679688, "vf_explained_var": 0.04104511141777038, "kl": 0.004709154927545001, "entropy": 0.39809557795524597, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 110000, "num_agent_steps_sampled": 220000, "num_steps_trained": 110000, "num_agent_steps_trained": 220000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 7695, "training_iteration": 110, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-20", "timestamp": 1749778580, "time_this_iter_s": 0.3393735885620117, "time_total_s": 40.311508655548096, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c99d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 40.311508655548096, "timesteps_since_restore": 0, "iterations_since_restore": 110, "perf": {"cpu_util_percent": 55.8, "ram_util_percent": 90.1}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 60.952000000000005, "episode_len_mean": 15.45, "episode_media": {}, "episodes_this_iter": 65, "policy_reward_min": {"shared_policy": -12.100000000000001}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 30.476}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, 87.0, 88.2, 87.2, 85.8, 87.2, 88.6, 88.0, 87.8, 88.6, 86.6, -4.999999999999998, -4.999999999999998, 89.4, 89.0, 89.4, -4.999999999999998, 86.6, 88.6, 89.4, 88.2, 88.2, 88.6, 88.6, -4.999999999999998, -4.999999999999998, 86.39999999999999, 87.2, 88.2, -4.999999999999998, 88.8, -4.999999999999998, 88.2, 87.0, 86.0, 89.0, 88.2, 85.8, 87.2, 88.8, 87.2, 88.4, 88.6, 88.2, -4.999999999999998, 88.6, 87.0, -4.999999999999998, -4.999999999999998, 87.4, 89.4, 87.4, 88.2, -4.999999999999998, 87.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, 87.8, -4.999999999999998, -4.999999999999998, 88.0, 87.8, -4.999999999999998, 86.2, 87.0, 85.8, 88.2, 88.6, 88.2, 86.2, -4.999999999999998, 89.4, 89.4, 89.4, 88.2, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, 87.2, 89.4, 88.4, -4.999999999999998, 88.6, 88.0, 87.8, -4.999999999999998, 88.2, 87.8, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, 88.6, 86.8], "episode_lengths": [25, 25, 16, 10, 15, 22, 15, 8, 11, 12, 8, 18, 25, 25, 4, 6, 4, 25, 18, 8, 4, 10, 10, 8, 8, 25, 25, 19, 15, 10, 25, 7, 25, 10, 16, 21, 6, 10, 22, 15, 7, 15, 9, 8, 10, 25, 8, 16, 25, 25, 14, 4, 14, 10, 25, 14, 4, 25, 25, 25, 13, 12, 25, 25, 11, 12, 25, 20, 16, 22, 10, 8, 10, 20, 25, 4, 4, 4, 10, 25, 18, 25, 25, 15, 4, 9, 25, 8, 11, 12, 25, 10, 12, 25, 25, 21, 25, 25, 8, 17], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -10.9, 99.1, 98.6, -11.4, -12.100000000000001, 97.9, -11.4, 98.6, -10.7, 99.3, -11.0, 99.0, 98.9, -11.1, -10.7, 99.3, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.5, -10.5, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, 99.3, -10.7, 99.7, -10.3, -10.9, 99.1, 99.1, -10.9, 99.3, -10.7, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -11.4, 98.6, -10.9, 99.1, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -11.5, 98.5, 98.0, -12.0, 99.5, -10.5, -10.9, 99.1, -12.100000000000001, 97.9, -11.4, 98.6, 99.4, -10.6, -11.4, 98.6, 99.2, -10.8, -10.7, 99.3, -10.9, 99.1, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -10.3, 99.7, -11.3, 98.7, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -11.9, 98.1, 98.5, -11.5, -12.100000000000001, 97.9, -10.9, 99.1, -10.7, 99.3, 99.1, -10.9, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -10.3, 99.7, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -10.7, 99.3, 99.0, -11.0, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -10.9, 99.1, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -11.6, 98.4]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3821626099878907, "mean_inference_ms": 1.6146987188439952, "mean_action_processing_ms": 0.0878725360240779, "mean_env_wait_ms": 0.08532076104898344, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 111000, "timesteps_this_iter": 0, "agent_timesteps_total": 222000, "timers": {"sample_time_ms": 378.1, "sample_throughput": 2644.803, "load_time_ms": 1.156, "load_throughput": 865018.974, "learn_time_ms": 94.324, "learn_throughput": 10601.7, "update_time_ms": 2.671}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 4.4408920985006264e-17, "cur_lr": 0.0005000000000000001, "total_loss": 1643.7517211914062, "policy_loss": -0.0026076198555529118, "vf_loss": 1643.75859375, "vf_explained_var": 0.03209228515625, "kl": 0.0026619251205096004, "entropy": 0.42005505263805387, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 111000, "num_agent_steps_sampled": 222000, "num_steps_trained": 111000, "num_agent_steps_trained": 222000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 7760, "training_iteration": 111, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-20", "timestamp": 1749778580, "time_this_iter_s": 0.35536909103393555, "time_total_s": 40.66687774658203, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 40.66687774658203, "timesteps_since_restore": 0, "iterations_since_restore": 111, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 57.106000000000016, "episode_len_mean": 16.64, "episode_media": {}, "episodes_this_iter": 62, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 28.553}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, 88.0, 87.8, -4.999999999999998, 86.2, 87.0, 85.8, 88.2, 88.6, 88.2, 86.2, -4.999999999999998, 89.4, 89.4, 89.4, 88.2, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, 87.2, 89.4, 88.4, -4.999999999999998, 88.6, 88.0, 87.8, -4.999999999999998, 88.2, 87.8, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, 88.6, 86.8, -4.999999999999998, 85.2, 87.2, 85.8, 88.2, -4.999999999999998, 87.0, -4.999999999999998, 86.8, 88.6, 85.8, 87.8, -4.999999999999998, 86.8, 86.39999999999999, 87.2, 87.8, -4.999999999999998, 85.4, -4.999999999999998, 89.4, 87.0, -4.999999999999998, 88.4, 88.4, 89.0, 89.0, -4.999999999999998, 89.4, -4.999999999999998, 88.8, -4.999999999999998, 88.6, 88.6, 88.2, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, 86.6, 85.6, -4.999999999999998, 88.0, 86.0, 88.6, 88.8, 88.8, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 87.8, 88.6, -4.999999999999998, 87.4, 86.8, -4.999999999999998, 89.0, 85.6, 87.8, 85.6, -4.999999999999998], "episode_lengths": [25, 25, 11, 12, 25, 20, 16, 22, 10, 8, 10, 20, 25, 4, 4, 4, 10, 25, 18, 25, 25, 15, 4, 9, 25, 8, 11, 12, 25, 10, 12, 25, 25, 21, 25, 25, 8, 17, 25, 25, 15, 22, 10, 25, 16, 25, 17, 8, 22, 12, 25, 17, 19, 15, 12, 25, 24, 25, 4, 16, 25, 9, 9, 6, 6, 25, 4, 25, 7, 25, 8, 8, 10, 25, 8, 25, 25, 18, 23, 25, 11, 21, 8, 7, 7, 25, 25, 4, 25, 12, 8, 25, 14, 17, 25, 6, 23, 12, 23, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -11.9, 98.1, 98.5, -11.5, -12.100000000000001, 97.9, -10.9, 99.1, -10.7, 99.3, 99.1, -10.9, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -10.3, 99.7, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -10.3, 99.7, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -10.7, 99.3, 99.0, -11.0, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -10.9, 99.1, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -12.4, 97.6, 98.6, -11.4, 97.9, -12.100000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -10.7, 99.3, -12.100000000000001, 97.9, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 98.2, -11.8, 98.6, -11.4, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 98.5, -11.5, -2.500000000000001, -2.500000000000001, 99.2, -10.8, 99.2, -10.8, 99.5, -10.5, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 99.3, -10.7, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, 98.0, -12.0, -10.7, 99.3, 99.4, -10.6, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 99.3, -10.7, -2.500000000000001, -2.500000000000001, 98.7, -11.3, 98.4, -11.6, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -12.200000000000001, 97.8, 98.9, -11.1, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3822347543353979, "mean_inference_ms": 1.6156905459979103, "mean_action_processing_ms": 0.08808536227543325, "mean_env_wait_ms": 0.08534543276116587, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 112000, "timesteps_this_iter": 0, "agent_timesteps_total": 224000, "timers": {"sample_time_ms": 377.907, "sample_throughput": 2646.154, "load_time_ms": 1.203, "load_throughput": 830999.544, "learn_time_ms": 92.721, "learn_throughput": 10785.053, "update_time_ms": 2.688}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 2.2204460492503132e-17, "cur_lr": 0.0005000000000000001, "total_loss": 1763.8099975585938, "policy_loss": -0.002107427641749382, "vf_loss": 1763.816259765625, "vf_explained_var": 0.02606843113899231, "kl": 0.0036335510767441905, "entropy": 0.4143211364746094, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 112000, "num_agent_steps_sampled": 224000, "num_steps_trained": 112000, "num_agent_steps_trained": 224000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 7822, "training_iteration": 112, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-21", "timestamp": 1749778581, "time_this_iter_s": 0.3324778079986572, "time_total_s": 40.99935555458069, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018224f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 40.99935555458069, "timesteps_since_restore": 0, "iterations_since_restore": 112, "perf": {"cpu_util_percent": 51.6, "ram_util_percent": 90.2}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 56.096000000000004, "episode_len_mean": 17.18, "episode_media": {}, "episodes_this_iter": 55, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 28.048000000000002}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 85.4, -4.999999999999998, 89.4, 87.0, -4.999999999999998, 88.4, 88.4, 89.0, 89.0, -4.999999999999998, 89.4, -4.999999999999998, 88.8, -4.999999999999998, 88.6, 88.6, 88.2, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, 86.6, 85.6, -4.999999999999998, 88.0, 86.0, 88.6, 88.8, 88.8, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 87.8, 88.6, -4.999999999999998, 87.4, 86.8, -4.999999999999998, 89.0, 85.6, 87.8, 85.6, -4.999999999999998, 85.8, 85.6, 87.8, -4.999999999999998, 86.39999999999999, -4.999999999999998, 87.6, 85.2, 88.0, 87.0, 85.4, -4.999999999999998, 88.2, 87.6, 87.6, -4.999999999999998, -4.999999999999998, 88.8, 86.8, 89.4, 85.6, -4.999999999999998, 89.0, 85.6, 88.2, -4.999999999999998, 88.2, -4.999999999999998, 89.4, 87.2, -4.999999999999998, -4.999999999999998, 86.39999999999999, 89.0, 88.4, 88.2, 89.0, -4.999999999999998, 86.6, 86.0, 86.6, -4.999999999999998, 86.0, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, 88.0, 89.4, -4.999999999999998, 85.6, -4.999999999999998, 85.6, -4.999999999999998, 89.2], "episode_lengths": [25, 24, 25, 4, 16, 25, 9, 9, 6, 6, 25, 4, 25, 7, 25, 8, 8, 10, 25, 8, 25, 25, 18, 23, 25, 11, 21, 8, 7, 7, 25, 25, 4, 25, 12, 8, 25, 14, 17, 25, 6, 23, 12, 23, 25, 22, 23, 12, 25, 19, 25, 13, 25, 11, 16, 24, 25, 10, 13, 13, 25, 25, 7, 17, 4, 23, 25, 6, 23, 10, 25, 10, 25, 4, 15, 25, 25, 19, 6, 9, 10, 6, 25, 18, 21, 18, 25, 21, 25, 21, 25, 25, 11, 4, 25, 23, 25, 23, 25, 5], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 98.5, -11.5, -2.500000000000001, -2.500000000000001, 99.2, -10.8, 99.2, -10.8, 99.5, -10.5, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 99.3, -10.7, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, 98.0, -12.0, -10.7, 99.3, 99.4, -10.6, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 99.3, -10.7, -2.500000000000001, -2.500000000000001, 98.7, -11.3, 98.4, -11.6, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -12.200000000000001, 97.8, 98.9, -11.1, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -12.200000000000001, 97.8, -11.1, 98.9, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -11.2, 98.8, 97.6, -12.4, 99.0, -11.0, -11.5, 98.5, 97.7, -12.3, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -11.2, 98.8, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -11.6, 98.4, -10.3, 99.7, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -10.5, 99.5, 97.8, -12.200000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -10.5, 99.5, -10.8, 99.2, -10.9, 99.1, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, 98.0, -12.0, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -10.4, 99.6]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3819171498016014, "mean_inference_ms": 1.6154868663527255, "mean_action_processing_ms": 0.08820945731252007, "mean_env_wait_ms": 0.08551612292092546, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 113000, "timesteps_this_iter": 0, "agent_timesteps_total": 226000, "timers": {"sample_time_ms": 376.089, "sample_throughput": 2658.942, "load_time_ms": 1.205, "load_throughput": 830193.579, "learn_time_ms": 92.776, "learn_throughput": 10778.704, "update_time_ms": 2.625}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.1102230246251566e-17, "cur_lr": 0.0005000000000000001, "total_loss": 1647.8294799804687, "policy_loss": -0.0007942989468574524, "vf_loss": 1647.834423828125, "vf_explained_var": 0.01641220450401306, "kl": 0.00157247929117994, "entropy": 0.41979733407497405, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 113000, "num_agent_steps_sampled": 226000, "num_steps_trained": 113000, "num_agent_steps_trained": 226000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 7877, "training_iteration": 113, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-21", "timestamp": 1749778581, "time_this_iter_s": 0.3346238136291504, "time_total_s": 41.33397936820984, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 41.33397936820984, "timesteps_since_restore": 0, "iterations_since_restore": 113, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 52.43600000000001, "episode_len_mean": 17.44, "episode_media": {}, "episodes_this_iter": 60, "policy_reward_min": {"shared_policy": -12.3}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 26.218000000000004}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, 88.8, 86.8, 89.4, 85.6, -4.999999999999998, 89.0, 85.6, 88.2, -4.999999999999998, 88.2, -4.999999999999998, 89.4, 87.2, -4.999999999999998, -4.999999999999998, 86.39999999999999, 89.0, 88.4, 88.2, 89.0, -4.999999999999998, 86.6, 86.0, 86.6, -4.999999999999998, 86.0, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, 88.0, 89.4, -4.999999999999998, 85.6, -4.999999999999998, 85.6, -4.999999999999998, 89.2, -4.999999999999998, -4.999999999999998, 88.6, 89.4, -4.999999999999998, -4.999999999999998, 89.0, 85.4, 86.0, 88.8, -4.999999999999998, 86.8, 88.2, 87.8, -4.999999999999998, 89.0, 88.4, 87.0, 88.6, 88.2, -4.999999999999998, 87.4, 86.8, 88.0, 86.2, 85.4, 88.6, 88.6, 89.0, 88.4, 85.6, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, 85.4, 89.4, 88.2, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, 88.2, 88.6, 86.6], "episode_lengths": [25, 25, 7, 17, 4, 23, 25, 6, 23, 10, 25, 10, 25, 4, 15, 25, 25, 19, 6, 9, 10, 6, 25, 18, 21, 18, 25, 21, 25, 21, 25, 25, 11, 4, 25, 23, 25, 23, 25, 5, 25, 25, 8, 4, 25, 25, 6, 24, 21, 7, 25, 17, 10, 12, 25, 6, 9, 16, 8, 10, 25, 14, 17, 11, 20, 24, 8, 8, 6, 9, 23, 25, 25, 4, 25, 17, 25, 25, 13, 25, 25, 8, 25, 25, 25, 24, 25, 24, 4, 10, 25, 25, 15, 25, 25, 7, 25, 10, 8, 18], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -11.6, 98.4, -10.3, 99.7, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -10.5, 99.5, 97.8, -12.200000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -10.5, 99.5, -10.8, 99.2, -10.9, 99.1, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, 98.0, -12.0, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -12.3, 97.7, 98.0, -12.0, -10.6, 99.4, -2.500000000000001, -2.500000000000001, 98.4, -11.6, 99.1, -10.9, 98.9, -11.1, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -10.8, 99.2, -11.5, 98.5, -10.7, 99.3, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -11.6, 98.4, -11.0, 99.0, 98.1, -11.9, -12.3, 97.7, -10.7, 99.3, -10.7, 99.3, -10.5, 99.5, 99.2, -10.8, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -10.3, 99.7, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -10.7, 99.3, 98.3, -11.700000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.38166397313619854, "mean_inference_ms": 1.615724507903322, "mean_action_processing_ms": 0.08816297454127167, "mean_env_wait_ms": 0.08562681772742202, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 114000, "timesteps_this_iter": 0, "agent_timesteps_total": 228000, "timers": {"sample_time_ms": 375.388, "sample_throughput": 2663.91, "load_time_ms": 1.279, "load_throughput": 782140.007, "learn_time_ms": 93.287, "learn_throughput": 10719.641, "update_time_ms": 2.72}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 5.551115123125783e-18, "cur_lr": 0.0005000000000000001, "total_loss": 1568.1958251953124, "policy_loss": -0.004874423146247864, "vf_loss": 1568.204736328125, "vf_explained_var": 0.008168858289718629, "kl": 0.007116179640461584, "entropy": 0.4014791131019592, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 114000, "num_agent_steps_sampled": 228000, "num_steps_trained": 114000, "num_agent_steps_trained": 228000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 7937, "training_iteration": 114, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-21", "timestamp": 1749778581, "time_this_iter_s": 0.354306697845459, "time_total_s": 41.6882860660553, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 41.6882860660553, "timesteps_since_restore": 0, "iterations_since_restore": 114, "perf": {"cpu_util_percent": 57.6, "ram_util_percent": 90.2}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 48.708, "episode_len_mean": 18.04, "episode_media": {}, "episodes_this_iter": 52, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 24.353999999999996}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.2, 87.8, -4.999999999999998, 89.0, 88.4, 87.0, 88.6, 88.2, -4.999999999999998, 87.4, 86.8, 88.0, 86.2, 85.4, 88.6, 88.6, 89.0, 88.4, 85.6, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, 85.4, 89.4, 88.2, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, 88.2, 88.6, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 86.2, 87.6, -4.999999999999998, -4.999999999999998, 85.2, 87.0, 87.6, -4.999999999999998, 87.2, 86.0, -4.999999999999998, -4.999999999999998, 86.0, 85.6, -4.999999999999998, 88.8, 89.4, 88.8, 86.4, -4.999999999999998, 88.6, -4.999999999999998, 87.0, 88.8, 85.8, 88.4, 88.6, -4.999999999999998, 88.4, 87.0, -4.999999999999998, 87.0, 88.4, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998], "episode_lengths": [10, 12, 25, 6, 9, 16, 8, 10, 25, 14, 17, 11, 20, 24, 8, 8, 6, 9, 23, 25, 25, 4, 25, 17, 25, 25, 13, 25, 25, 8, 25, 25, 25, 24, 25, 24, 4, 10, 25, 25, 15, 25, 25, 7, 25, 10, 8, 18, 25, 25, 25, 25, 7, 25, 25, 15, 25, 25, 25, 17, 20, 13, 25, 25, 25, 16, 13, 25, 15, 21, 25, 25, 21, 23, 25, 7, 4, 7, 19, 25, 8, 25, 16, 7, 22, 9, 8, 25, 9, 16, 25, 16, 9, 25, 11, 25, 25, 25, 7, 25], "policy_shared_policy_reward": [99.1, -10.9, 98.9, -11.1, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -10.8, 99.2, -11.5, 98.5, -10.7, 99.3, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -11.6, 98.4, -11.0, 99.0, 98.1, -11.9, -12.3, 97.7, -10.7, 99.3, -10.7, 99.3, -10.5, 99.5, 99.2, -10.8, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -10.3, 99.7, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -10.7, 99.3, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -11.9, 98.1, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -11.5, 98.5, -11.2, 98.8, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -10.3, 99.7, -10.6, 99.4, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, 98.5, -11.5, 99.4, -10.6, 97.9, -12.100000000000001, 99.2, -10.8, 99.3, -10.7, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -11.5, 98.5, 99.2, -10.8, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.38100611325339556, "mean_inference_ms": 1.6146602757523845, "mean_action_processing_ms": 0.08807090354300168, "mean_env_wait_ms": 0.08560794441167864, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 115000, "timesteps_this_iter": 0, "agent_timesteps_total": 230000, "timers": {"sample_time_ms": 376.012, "sample_throughput": 2659.487, "load_time_ms": 1.291, "load_throughput": 774313.986, "learn_time_ms": 94.181, "learn_throughput": 10617.822, "update_time_ms": 2.689}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 5.551115123125783e-18, "cur_lr": 0.0005000000000000001, "total_loss": 1340.6108764648438, "policy_loss": -0.001948384940624237, "vf_loss": 1340.6171264648438, "vf_explained_var": 0.025027787685394286, "kl": 0.002735969658334425, "entropy": 0.4308148562908173, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 115000, "num_agent_steps_sampled": 230000, "num_steps_trained": 115000, "num_agent_steps_trained": 230000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 7989, "training_iteration": 115, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-22", "timestamp": 1749778582, "time_this_iter_s": 0.3599207401275635, "time_total_s": 42.04820680618286, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018224280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 42.04820680618286, "timesteps_since_restore": 0, "iterations_since_restore": 115, "perf": {"cpu_util_percent": 57.2, "ram_util_percent": 90.0}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 54.17799999999999, "episode_len_mean": 17.75, "episode_media": {}, "episodes_this_iter": 57, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 27.089000000000002}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, 86.8, 86.2, 87.6, -4.999999999999998, -4.999999999999998, 85.2, 87.0, 87.6, -4.999999999999998, 87.2, 86.0, -4.999999999999998, -4.999999999999998, 86.0, 85.6, -4.999999999999998, 88.8, 89.4, 88.8, 86.4, -4.999999999999998, 88.6, -4.999999999999998, 87.0, 88.8, 85.8, 88.4, 88.6, -4.999999999999998, 88.4, 87.0, -4.999999999999998, 87.0, 88.4, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, -4.999999999999998, 88.6, 85.8, -4.999999999999998, 87.0, 87.2, 87.2, 87.2, 87.4, 88.0, 88.0, 88.6, -4.999999999999998, 88.6, 85.4, 86.39999999999999, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, 87.8, -4.999999999999998, -4.999999999999998, 87.0, 87.4, 87.8, -4.999999999999998, -4.999999999999998, 85.2, -4.999999999999998, 88.4, 87.4, 86.6, -4.999999999999998, -4.999999999999998, 88.8, 86.2, 86.2, 88.0, 89.0, 88.6, 88.2, 85.2, 88.8, -4.999999999999998, 85.6, 89.4, -4.999999999999998, 85.4, -4.999999999999998, 88.8, -4.999999999999998, 88.6, 89.4, 88.4], "episode_lengths": [25, 25, 17, 20, 13, 25, 25, 25, 16, 13, 25, 15, 21, 25, 25, 21, 23, 25, 7, 4, 7, 19, 25, 8, 25, 16, 7, 22, 9, 8, 25, 9, 16, 25, 16, 9, 25, 11, 25, 25, 25, 7, 25, 25, 8, 22, 25, 16, 15, 15, 15, 14, 11, 11, 8, 25, 8, 24, 19, 25, 25, 25, 17, 25, 25, 12, 25, 25, 16, 14, 12, 25, 25, 25, 25, 9, 14, 18, 25, 25, 7, 20, 20, 11, 6, 8, 10, 25, 7, 25, 23, 4, 25, 24, 25, 7, 25, 8, 4, 9], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -11.9, 98.1, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -11.5, 98.5, -11.2, 98.8, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -10.3, 99.7, -10.6, 99.4, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, 98.5, -11.5, 99.4, -10.6, 97.9, -12.100000000000001, 99.2, -10.8, 99.3, -10.7, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -11.5, 98.5, 99.2, -10.8, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -11.4, 98.6, -11.4, 98.6, 98.6, -11.4, 98.7, -11.3, -11.0, 99.0, -11.0, 99.0, -10.7, 99.3, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -12.3, 97.7, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -11.3, 98.7, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -11.3, 98.7, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -11.9, 98.1, 98.1, -11.9, 99.0, -11.0, -10.5, 99.5, -10.7, 99.3, -10.9, 99.1, 97.6, -12.4, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -10.3, 99.7, -10.8, 99.2]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.38070764250042005, "mean_inference_ms": 1.612886375293492, "mean_action_processing_ms": 0.08791395330012641, "mean_env_wait_ms": 0.08538439154733479, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 116000, "timesteps_this_iter": 0, "agent_timesteps_total": 232000, "timers": {"sample_time_ms": 375.132, "sample_throughput": 2665.73, "load_time_ms": 1.329, "load_throughput": 752692.556, "learn_time_ms": 96.077, "learn_throughput": 10408.27, "update_time_ms": 2.68}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 2.7755575615628915e-18, "cur_lr": 0.0005000000000000001, "total_loss": 1609.4107788085937, "policy_loss": -0.0018167285248637199, "vf_loss": 1609.4172607421874, "vf_explained_var": 0.022078448534011842, "kl": 0.004061469756701186, "entropy": 0.46721460223197936, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 116000, "num_agent_steps_sampled": 232000, "num_steps_trained": 116000, "num_agent_steps_trained": 232000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 8046, "training_iteration": 116, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-22", "timestamp": 1749778582, "time_this_iter_s": 0.3470935821533203, "time_total_s": 42.39530038833618, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018224ee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 42.39530038833618, "timesteps_since_restore": 0, "iterations_since_restore": 116, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 44.06, "episode_len_mean": 18.73, "episode_media": {}, "episodes_this_iter": 50, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 22.03}, "custom_metrics": {}, "hist_stats": {"episode_reward": [87.2, 87.4, 88.0, 88.0, 88.6, -4.999999999999998, 88.6, 85.4, 86.39999999999999, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, 87.8, -4.999999999999998, -4.999999999999998, 87.0, 87.4, 87.8, -4.999999999999998, -4.999999999999998, 85.2, -4.999999999999998, 88.4, 87.4, 86.6, -4.999999999999998, -4.999999999999998, 88.8, 86.2, 86.2, 88.0, 89.0, 88.6, 88.2, 85.2, 88.8, -4.999999999999998, 85.6, 89.4, -4.999999999999998, 85.4, -4.999999999999998, 88.8, -4.999999999999998, 88.6, 89.4, 88.4, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 89.4, 88.8, -4.999999999999998, -4.999999999999998, 88.8, 87.4, 88.4, 86.0, 87.4, 88.8, 88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, 89.0, -4.999999999999998, -4.999999999999998], "episode_lengths": [15, 14, 11, 11, 8, 25, 8, 24, 19, 25, 25, 25, 17, 25, 25, 12, 25, 25, 16, 14, 12, 25, 25, 25, 25, 9, 14, 18, 25, 25, 7, 20, 20, 11, 6, 8, 10, 25, 7, 25, 23, 4, 25, 24, 25, 7, 25, 8, 4, 9, 25, 25, 25, 25, 25, 4, 25, 4, 7, 25, 25, 7, 14, 9, 21, 14, 7, 7, 25, 25, 25, 9, 21, 25, 25, 25, 25, 22, 25, 25, 25, 25, 4, 25, 25, 25, 25, 14, 25, 25, 24, 25, 18, 25, 25, 21, 25, 6, 25, 25], "policy_shared_policy_reward": [98.6, -11.4, 98.7, -11.3, -11.0, 99.0, -11.0, 99.0, -10.7, 99.3, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -12.3, 97.7, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -11.3, 98.7, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -11.3, 98.7, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -11.9, 98.1, 98.1, -11.9, 99.0, -11.0, -10.5, 99.5, -10.7, 99.3, -10.9, 99.1, 97.6, -12.4, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -10.3, 99.7, -10.8, 99.2, 97.6, -12.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 98.7, -11.3, 99.2, -10.8, -12.0, 98.0, 98.7, -11.3, 99.4, -10.6, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.8, 99.2, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3809930878639507, "mean_inference_ms": 1.6147660140423177, "mean_action_processing_ms": 0.08790300162746377, "mean_env_wait_ms": 0.08542376005784061, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 117000, "timesteps_this_iter": 0, "agent_timesteps_total": 234000, "timers": {"sample_time_ms": 377.483, "sample_throughput": 2649.124, "load_time_ms": 1.366, "load_throughput": 732156.336, "learn_time_ms": 97.406, "learn_throughput": 10266.275, "update_time_ms": 2.745}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.3877787807814458e-18, "cur_lr": 0.0005000000000000001, "total_loss": 952.6082580566406, "policy_loss": -0.0020051330327987673, "vf_loss": 952.6148132324219, "vf_explained_var": 0.005316442251205445, "kl": 0.004948287821044994, "entropy": 0.45579043328762053, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 117000, "num_agent_steps_sampled": 234000, "num_steps_trained": 117000, "num_agent_steps_trained": 234000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 8096, "training_iteration": 117, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-22", "timestamp": 1749778582, "time_this_iter_s": 0.3591761589050293, "time_total_s": 42.75447654724121, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018319160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 42.75447654724121, "timesteps_since_restore": 0, "iterations_since_restore": 117, "perf": {"cpu_util_percent": 57.7, "ram_util_percent": 90.0}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 43.22200000000001, "episode_len_mean": 18.41, "episode_media": {}, "episodes_this_iter": 55, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 21.611000000000004}, "custom_metrics": {}, "hist_stats": {"episode_reward": [89.4, -4.999999999999998, 89.4, 88.8, -4.999999999999998, -4.999999999999998, 88.8, 87.4, 88.4, 86.0, 87.4, 88.8, 88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, 89.0, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, 85.2, -4.999999999999998, 87.8, 87.8, -4.999999999999998, 86.2, 88.8, 85.8, 88.8, 87.6, -4.999999999999998, -4.999999999999998, 89.0, -4.999999999999998, 88.4, -4.999999999999998, 88.0, 86.6, 86.6, 88.6, 87.8, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.2, 85.6, 88.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, 87.4, 88.2, 87.4, 86.8, 88.2, 87.2, -4.999999999999998, 89.4, 89.2, 88.2, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998], "episode_lengths": [4, 25, 4, 7, 25, 25, 7, 14, 9, 21, 14, 7, 7, 25, 25, 25, 9, 21, 25, 25, 25, 25, 22, 25, 25, 25, 25, 4, 25, 25, 25, 25, 14, 25, 25, 24, 25, 18, 25, 25, 21, 25, 6, 25, 25, 10, 25, 25, 25, 7, 25, 25, 25, 12, 12, 25, 20, 7, 22, 7, 13, 25, 25, 6, 25, 9, 25, 11, 18, 18, 8, 12, 25, 8, 25, 25, 25, 25, 23, 9, 4, 25, 25, 25, 10, 25, 14, 10, 14, 17, 10, 15, 25, 4, 5, 10, 25, 13, 25, 25], "policy_shared_policy_reward": [-10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 98.7, -11.3, 99.2, -10.8, -12.0, 98.0, 98.7, -11.3, 99.4, -10.6, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.8, 99.2, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -10.6, 99.4, 97.9, -12.100000000000001, 99.4, -10.6, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -11.700000000000001, 98.3, -11.700000000000001, 98.3, -10.7, 99.3, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.4, 97.6, 97.8, -12.200000000000001, 99.2, -10.8, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 98.7, -11.3, 99.1, -10.9, 98.7, -11.3, 98.4, -11.6, -10.9, 99.1, 98.6, -11.4, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -10.4, 99.6, -10.9, 99.1, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.38047350248370093, "mean_inference_ms": 1.614189848913201, "mean_action_processing_ms": 0.08787303190859053, "mean_env_wait_ms": 0.08549064320188177, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 118000, "timesteps_this_iter": 0, "agent_timesteps_total": 236000, "timers": {"sample_time_ms": 378.255, "sample_throughput": 2643.721, "load_time_ms": 1.332, "load_throughput": 750591.267, "learn_time_ms": 99.294, "learn_throughput": 10071.136, "update_time_ms": 2.862}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 6.938893903907229e-19, "cur_lr": 0.0005000000000000001, "total_loss": 1427.765673828125, "policy_loss": -0.0035564765334129334, "vf_loss": 1427.7736694335938, "vf_explained_var": 0.02626640200614929, "kl": 0.003946582746178517, "entropy": 0.44697940945625303, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 118000, "num_agent_steps_sampled": 236000, "num_steps_trained": 118000, "num_agent_steps_trained": 236000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 8151, "training_iteration": 118, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-23", "timestamp": 1749778583, "time_this_iter_s": 0.34964823722839355, "time_total_s": 43.104124784469604, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb01b0b38b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 43.104124784469604, "timesteps_since_restore": 0, "iterations_since_restore": 118, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 54.16400000000001, "episode_len_mean": 17.82, "episode_media": {}, "episodes_this_iter": 55, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 27.081999999999997}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 86.2, 88.8, 85.8, 88.8, 87.6, -4.999999999999998, -4.999999999999998, 89.0, -4.999999999999998, 88.4, -4.999999999999998, 88.0, 86.6, 86.6, 88.6, 87.8, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.2, 85.6, 88.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, 87.4, 88.2, 87.4, 86.8, 88.2, 87.2, -4.999999999999998, 89.4, 89.2, 88.2, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, 87.4, 86.0, 89.4, 87.0, -4.999999999999998, 86.2, -4.999999999999998, 86.6, 87.6, 87.8, 86.39999999999999, 87.4, -4.999999999999998, 85.4, 85.8, 85.4, 87.6, -4.999999999999998, 87.0, 87.8, 89.0, -4.999999999999998, -4.999999999999998, 88.4, 85.8, 88.8, 87.6, 88.2, 86.2, 87.0, 86.6, 85.2, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 87.4, 89.4, 87.4, -4.999999999999998, 87.8, 86.8, 87.6, -4.999999999999998, -4.999999999999998], "episode_lengths": [25, 20, 7, 22, 7, 13, 25, 25, 6, 25, 9, 25, 11, 18, 18, 8, 12, 25, 8, 25, 25, 25, 25, 23, 9, 4, 25, 25, 25, 10, 25, 14, 10, 14, 17, 10, 15, 25, 4, 5, 10, 25, 13, 25, 25, 25, 25, 24, 25, 9, 25, 25, 14, 21, 4, 16, 25, 20, 25, 18, 13, 12, 19, 14, 25, 24, 22, 24, 13, 25, 16, 12, 6, 25, 25, 9, 22, 7, 13, 10, 20, 16, 18, 25, 8, 25, 25, 25, 25, 25, 17, 14, 4, 14, 25, 12, 17, 13, 25, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -11.9, 98.1, -10.6, 99.4, 97.9, -12.100000000000001, 99.4, -10.6, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -11.700000000000001, 98.3, -11.700000000000001, 98.3, -10.7, 99.3, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.4, 97.6, 97.8, -12.200000000000001, 99.2, -10.8, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 98.7, -11.3, 99.1, -10.9, 98.7, -11.3, 98.4, -11.6, -10.9, 99.1, 98.6, -11.4, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -10.4, 99.6, -10.9, 99.1, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, 98.0, -12.0, -10.3, 99.7, -11.5, 98.5, -2.500000000000001, -2.500000000000001, 98.1, -11.9, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, 98.8, -11.2, -11.1, 98.9, 98.2, -11.8, 98.7, -11.3, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -12.100000000000001, 97.9, 97.7, -12.3, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -11.5, 98.5, 98.9, -11.1, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -12.100000000000001, 97.9, 99.4, -10.6, -11.2, 98.8, 99.1, -10.9, 98.1, -11.9, 98.5, -11.5, -11.700000000000001, 98.3, -12.4, 97.6, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 98.7, -11.3, -10.3, 99.7, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -11.6, 98.4, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3798358864625756, "mean_inference_ms": 1.613028456364462, "mean_action_processing_ms": 0.08796441164036622, "mean_env_wait_ms": 0.08551382687067458, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 119000, "timesteps_this_iter": 0, "agent_timesteps_total": 238000, "timers": {"sample_time_ms": 382.545, "sample_throughput": 2614.074, "load_time_ms": 1.385, "load_throughput": 721960.892, "learn_time_ms": 100.992, "learn_throughput": 9901.806, "update_time_ms": 2.858}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 3.4694469519536144e-19, "cur_lr": 0.0005000000000000001, "total_loss": 1610.9538818359374, "policy_loss": -0.00296885960851796, "vf_loss": 1610.9610473632813, "vf_explained_var": 0.021395891904830933, "kl": 0.0027577386143000427, "entropy": 0.42041831016540526, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 119000, "num_agent_steps_sampled": 238000, "num_steps_trained": 119000, "num_agent_steps_trained": 238000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 8206, "training_iteration": 119, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-23", "timestamp": 1749778583, "time_this_iter_s": 0.36043381690979004, "time_total_s": 43.464558601379395, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f50d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 43.464558601379395, "timesteps_since_restore": 0, "iterations_since_restore": 119, "perf": {"cpu_util_percent": 50.9, "ram_util_percent": 90.1}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 61.645999999999994, "episode_len_mean": 16.49, "episode_media": {}, "episodes_this_iter": 65, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 30.822999999999997}, "custom_metrics": {}, "hist_stats": {"episode_reward": [85.4, 85.8, 85.4, 87.6, -4.999999999999998, 87.0, 87.8, 89.0, -4.999999999999998, -4.999999999999998, 88.4, 85.8, 88.8, 87.6, 88.2, 86.2, 87.0, 86.6, 85.2, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 87.4, 89.4, 87.4, -4.999999999999998, 87.8, 86.8, 87.6, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, 87.8, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, 86.0, 87.0, 88.8, -4.999999999999998, -4.999999999999998, 88.6, 86.2, 85.6, -4.999999999999998, 86.6, 88.8, 88.6, 88.0, -4.999999999999998, 85.6, 87.8, 87.0, 86.8, -4.999999999999998, 87.6, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 87.4, -4.999999999999998, 87.2, 88.4, 86.8, -4.999999999999998, 86.6, 88.8, 87.0, 88.2, 88.8, -4.999999999999998, 88.2, 85.6, 88.8, 88.8, 88.8, -4.999999999999998, 88.6, 86.6, -4.999999999999998, 89.4, 86.39999999999999, 88.0, 89.0, 88.4, 85.2, 88.8, 87.4, 88.2, 86.8, 88.8, 89.4], "episode_lengths": [24, 22, 24, 13, 25, 16, 12, 6, 25, 25, 9, 22, 7, 13, 10, 20, 16, 18, 25, 8, 25, 25, 25, 25, 25, 17, 14, 4, 14, 25, 12, 17, 13, 25, 25, 7, 25, 12, 25, 25, 7, 25, 21, 16, 7, 25, 25, 8, 20, 23, 25, 18, 7, 8, 11, 25, 23, 12, 16, 17, 25, 13, 17, 25, 25, 25, 4, 14, 25, 15, 9, 17, 25, 18, 7, 16, 10, 7, 25, 10, 23, 7, 7, 7, 25, 8, 18, 25, 4, 19, 11, 6, 9, 25, 7, 14, 10, 17, 7, 4], "policy_shared_policy_reward": [97.7, -12.3, -12.100000000000001, 97.9, 97.7, -12.3, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -11.5, 98.5, 98.9, -11.1, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -12.100000000000001, 97.9, 99.4, -10.6, -11.2, 98.8, 99.1, -10.9, 98.1, -11.9, 98.5, -11.5, -11.700000000000001, 98.3, -12.4, 97.6, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 98.7, -11.3, -10.3, 99.7, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -11.6, 98.4, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -11.5, 98.5, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, 98.1, -11.9, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, 99.4, -10.6, 99.3, -10.7, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, 98.9, -11.1, 98.5, -11.5, -11.6, 98.4, -2.500000000000001, -2.500000000000001, 98.8, -11.2, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.3, 98.7, -2.500000000000001, -2.500000000000001, 98.6, -11.4, 99.2, -10.8, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, 99.4, -10.6, 98.5, -11.5, -10.9, 99.1, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -10.9, 99.1, 97.8, -12.200000000000001, 99.4, -10.6, 99.4, -10.6, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.2, -11.8, -11.0, 99.0, 99.5, -10.5, 99.2, -10.8, 97.6, -12.4, 99.4, -10.6, 98.7, -11.3, -10.9, 99.1, -11.6, 98.4, 99.4, -10.6, -10.3, 99.7]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.37929764035864677, "mean_inference_ms": 1.6101280030843486, "mean_action_processing_ms": 0.08779496620053512, "mean_env_wait_ms": 0.08520077371011806, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 120000, "timesteps_this_iter": 0, "agent_timesteps_total": 240000, "timers": {"sample_time_ms": 386.15, "sample_throughput": 2589.664, "load_time_ms": 1.508, "load_throughput": 662952.882, "learn_time_ms": 101.377, "learn_throughput": 9864.162, "update_time_ms": 2.924}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.7347234759768072e-19, "cur_lr": 0.0005000000000000001, "total_loss": 1904.5050415039063, "policy_loss": -0.0020745132118463517, "vf_loss": 1904.5109619140626, "vf_explained_var": 0.0033004045486450194, "kl": 0.0029038964278839787, "entropy": 0.3879326432943344, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 120000, "num_agent_steps_sampled": 240000, "num_steps_trained": 120000, "num_agent_steps_trained": 240000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 8271, "training_iteration": 120, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-24", "timestamp": 1749778584, "time_this_iter_s": 0.3639214038848877, "time_total_s": 43.82848000526428, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182f4550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 43.82848000526428, "timesteps_since_restore": 0, "iterations_since_restore": 120, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 60.955999999999996, "episode_len_mean": 15.43, "episode_media": {}, "episodes_this_iter": 63, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 30.478}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 87.4, -4.999999999999998, 87.2, 88.4, 86.8, -4.999999999999998, 86.6, 88.8, 87.0, 88.2, 88.8, -4.999999999999998, 88.2, 85.6, 88.8, 88.8, 88.8, -4.999999999999998, 88.6, 86.6, -4.999999999999998, 89.4, 86.39999999999999, 88.0, 89.0, 88.4, 85.2, 88.8, 87.4, 88.2, 86.8, 88.8, 89.4, 88.8, -4.999999999999998, 88.4, 85.6, -4.999999999999998, 88.2, -4.999999999999998, 88.4, 88.8, 88.8, -4.999999999999998, 87.6, -4.999999999999998, 88.8, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, 85.4, 85.6, 88.8, 87.8, 89.2, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, 88.8, 87.4, -4.999999999999998, 86.0, 88.8, -4.999999999999998, 88.4, 87.0, 87.6, -4.999999999999998, 85.2, 86.0, 88.6, 86.4, 88.8, 88.6, 89.4, 85.2, 88.2, 88.8, 88.8, -4.999999999999998, -4.999999999999998, 87.0, -4.999999999999998, 88.4, 87.2, 88.8, 88.4, -4.999999999999998, 88.6, 89.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8], "episode_lengths": [25, 25, 25, 4, 14, 25, 15, 9, 17, 25, 18, 7, 16, 10, 7, 25, 10, 23, 7, 7, 7, 25, 8, 18, 25, 4, 19, 11, 6, 9, 25, 7, 14, 10, 17, 7, 4, 7, 25, 9, 23, 25, 10, 25, 9, 7, 7, 25, 13, 25, 7, 25, 9, 25, 25, 24, 23, 7, 12, 5, 25, 25, 11, 25, 7, 14, 25, 21, 7, 25, 9, 16, 13, 25, 25, 21, 8, 19, 7, 8, 4, 25, 10, 7, 7, 25, 25, 16, 25, 9, 15, 7, 9, 25, 8, 6, 25, 25, 25, 7], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.3, 98.7, -2.500000000000001, -2.500000000000001, 98.6, -11.4, 99.2, -10.8, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, 99.4, -10.6, 98.5, -11.5, -10.9, 99.1, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -10.9, 99.1, 97.8, -12.200000000000001, 99.4, -10.6, 99.4, -10.6, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.2, -11.8, -11.0, 99.0, 99.5, -10.5, 99.2, -10.8, 97.6, -12.4, 99.4, -10.6, 98.7, -11.3, -10.9, 99.1, -11.6, 98.4, 99.4, -10.6, -10.3, 99.7, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, 99.2, -10.8, 99.4, -10.6, -10.6, 99.4, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -12.200000000000001, 97.8, 99.4, -10.6, -11.1, 98.9, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -12.0, 98.0, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 99.2, -10.8, 98.5, -11.5, 98.8, -11.2, -2.500000000000001, -2.500000000000001, 97.6, -12.4, 98.0, -12.0, 99.3, -10.7, -11.8, 98.2, 99.4, -10.6, -10.7, 99.3, 99.7, -10.3, -12.4, 97.6, -10.9, 99.1, 99.4, -10.6, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -2.500000000000001, -2.500000000000001, 99.2, -10.8, 98.6, -11.4, 99.4, -10.6, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -10.7, 99.3, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.37938501761914883, "mean_inference_ms": 1.609649687140564, "mean_action_processing_ms": 0.0876302779824089, "mean_env_wait_ms": 0.08518846848620398, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 121000, "timesteps_this_iter": 0, "agent_timesteps_total": 242000, "timers": {"sample_time_ms": 387.841, "sample_throughput": 2578.376, "load_time_ms": 1.484, "load_throughput": 674043.647, "learn_time_ms": 101.226, "learn_throughput": 9878.841, "update_time_ms": 2.881}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 8.673617379884036e-20, "cur_lr": 0.0005000000000000001, "total_loss": 1625.4822509765625, "policy_loss": -0.003492081165313721, "vf_loss": 1625.4896728515625, "vf_explained_var": -0.0005522549152374267, "kl": 0.006213218094858064, "entropy": 0.3959482192993164, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 121000, "num_agent_steps_sampled": 242000, "num_steps_trained": 121000, "num_agent_steps_trained": 242000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 8334, "training_iteration": 121, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-24", "timestamp": 1749778584, "time_this_iter_s": 0.3630950450897217, "time_total_s": 44.191575050354004, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c9c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 44.191575050354004, "timesteps_since_restore": 0, "iterations_since_restore": 121, "perf": {"cpu_util_percent": 48.3, "ram_util_percent": 90.1}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 66.404, "episode_len_mean": 15.25, "episode_media": {}, "episodes_this_iter": 63, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 33.202000000000005}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 88.8, 87.4, -4.999999999999998, 86.0, 88.8, -4.999999999999998, 88.4, 87.0, 87.6, -4.999999999999998, 85.2, 86.0, 88.6, 86.4, 88.8, 88.6, 89.4, 85.2, 88.2, 88.8, 88.8, -4.999999999999998, -4.999999999999998, 87.0, -4.999999999999998, 88.4, 87.2, 88.8, 88.4, -4.999999999999998, 88.6, 89.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, 89.0, 86.8, 88.4, 89.4, 89.4, 88.0, -4.999999999999998, 86.39999999999999, 89.4, -4.999999999999998, 87.6, 89.0, 87.8, -4.999999999999998, 87.8, 89.4, 89.4, 86.2, 86.6, 89.4, 87.6, 86.4, 85.4, -4.999999999999998, 88.0, -4.999999999999998, 88.8, -4.999999999999998, 88.2, 86.8, 88.8, 85.8, 87.0, 86.2, -4.999999999999998, 88.8, 88.4, 88.2, 86.2, -4.999999999999998, 87.2, 88.2, 86.6, 86.6, 85.6, 86.0, -4.999999999999998, 88.8, 89.0, 88.8, 88.4, -4.999999999999998, 88.2, -4.999999999999998, 88.0, 88.6, -4.999999999999998, 88.2, 86.2, 85.8, 87.2, 86.0, 87.2], "episode_lengths": [25, 7, 14, 25, 21, 7, 25, 9, 16, 13, 25, 25, 21, 8, 19, 7, 8, 4, 25, 10, 7, 7, 25, 25, 16, 25, 9, 15, 7, 9, 25, 8, 6, 25, 25, 25, 7, 6, 17, 9, 4, 4, 11, 25, 19, 4, 25, 13, 6, 12, 25, 12, 4, 4, 20, 18, 4, 13, 19, 24, 25, 11, 25, 7, 25, 10, 17, 7, 22, 16, 20, 25, 7, 9, 10, 20, 25, 15, 10, 18, 18, 23, 21, 25, 7, 6, 7, 9, 25, 10, 25, 11, 8, 25, 10, 20, 22, 15, 21, 15], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, 99.4, -10.6, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -12.0, 98.0, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 99.2, -10.8, 98.5, -11.5, 98.8, -11.2, -2.500000000000001, -2.500000000000001, 97.6, -12.4, 98.0, -12.0, 99.3, -10.7, -11.8, 98.2, 99.4, -10.6, -10.7, 99.3, 99.7, -10.3, -12.4, 97.6, -10.9, 99.1, 99.4, -10.6, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -2.500000000000001, -2.500000000000001, 99.2, -10.8, 98.6, -11.4, 99.4, -10.6, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -10.7, 99.3, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 99.5, -10.5, 98.4, -11.6, 99.2, -10.8, -10.3, 99.7, -10.3, 99.7, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.2, 98.8, 99.5, -10.5, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -11.1, 98.9, 99.7, -10.3, 99.7, -10.3, 98.1, -11.9, -11.700000000000001, 98.3, 99.7, -10.3, 98.8, -11.2, -11.8, 98.2, -12.3, 97.7, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -10.9, 99.1, 98.4, -11.6, 99.4, -10.6, -12.100000000000001, 97.9, 98.5, -11.5, 98.1, -11.9, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 99.2, -10.8, -10.9, 99.1, 98.1, -11.9, -2.500000000000001, -2.500000000000001, 98.6, -11.4, 99.1, -10.9, 98.3, -11.700000000000001, 98.3, -11.700000000000001, 97.8, -12.200000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 99.5, -10.5, 99.4, -10.6, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -10.7, 99.3, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -11.9, 98.1, 97.9, -12.100000000000001, 98.6, -11.4, -12.0, 98.0, 98.6, -11.4]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3789564966125142, "mean_inference_ms": 1.6084830830759729, "mean_action_processing_ms": 0.08759882316381365, "mean_env_wait_ms": 0.08508677372836186, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 122000, "timesteps_this_iter": 0, "agent_timesteps_total": 244000, "timers": {"sample_time_ms": 387.226, "sample_throughput": 2582.473, "load_time_ms": 1.385, "load_throughput": 721985.747, "learn_time_ms": 103.24, "learn_throughput": 9686.145, "update_time_ms": 2.934}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 8.673617379884036e-20, "cur_lr": 0.0005000000000000001, "total_loss": 1966.2796752929687, "policy_loss": -0.0021214520558714865, "vf_loss": 1966.2856811523438, "vf_explained_var": 0.009838151931762695, "kl": 0.0029528990258205325, "entropy": 0.3956069529056549, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 122000, "num_agent_steps_sampled": 244000, "num_steps_trained": 122000, "num_agent_steps_trained": 244000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 8397, "training_iteration": 122, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-24", "timestamp": 1749778584, "time_this_iter_s": 0.34894847869873047, "time_total_s": 44.540523529052734, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018301d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 44.540523529052734, "timesteps_since_restore": 0, "iterations_since_restore": 122, "perf": {"cpu_util_percent": 54.4, "ram_util_percent": 90.2}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 63.49, "episode_len_mean": 16.29, "episode_media": {}, "episodes_this_iter": 61, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 31.745000000000005}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.0, -4.999999999999998, 88.8, -4.999999999999998, 88.2, 86.8, 88.8, 85.8, 87.0, 86.2, -4.999999999999998, 88.8, 88.4, 88.2, 86.2, -4.999999999999998, 87.2, 88.2, 86.6, 86.6, 85.6, 86.0, -4.999999999999998, 88.8, 89.0, 88.8, 88.4, -4.999999999999998, 88.2, -4.999999999999998, 88.0, 88.6, -4.999999999999998, 88.2, 86.2, 85.8, 87.2, 86.0, 87.2, 88.8, 86.6, -4.999999999999998, -4.999999999999998, 88.6, 87.0, 87.0, 86.8, 86.8, 87.6, 86.39999999999999, 88.2, 87.0, 85.2, -4.999999999999998, 88.2, -4.999999999999998, 86.2, -4.999999999999998, 88.8, 88.0, -4.999999999999998, 88.8, 87.4, -4.999999999999998, 88.2, 88.6, 88.8, 88.2, 87.2, -4.999999999999998, -4.999999999999998, 88.2, 86.0, 88.4, -4.999999999999998, 87.0, -4.999999999999998, -4.999999999999998, 88.6, -4.999999999999998, 86.8, -4.999999999999998, 88.6, -4.999999999999998, 87.0, 87.2, 88.4, 86.39999999999999, -4.999999999999998, 85.6, 88.8, 87.2, 89.4, 87.6, 87.6, -4.999999999999998, 87.8, 88.0, -4.999999999999998, 88.2], "episode_lengths": [11, 25, 7, 25, 10, 17, 7, 22, 16, 20, 25, 7, 9, 10, 20, 25, 15, 10, 18, 18, 23, 21, 25, 7, 6, 7, 9, 25, 10, 25, 11, 8, 25, 10, 20, 22, 15, 21, 15, 7, 18, 25, 25, 8, 16, 16, 17, 17, 13, 19, 10, 16, 25, 25, 10, 25, 20, 25, 7, 11, 25, 7, 14, 25, 10, 8, 7, 10, 15, 25, 25, 10, 21, 9, 25, 16, 25, 25, 8, 25, 17, 25, 8, 25, 16, 15, 9, 19, 25, 23, 7, 15, 4, 13, 13, 25, 12, 11, 25, 10], "policy_shared_policy_reward": [99.0, -11.0, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -10.9, 99.1, 98.4, -11.6, 99.4, -10.6, -12.100000000000001, 97.9, 98.5, -11.5, 98.1, -11.9, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 99.2, -10.8, -10.9, 99.1, 98.1, -11.9, -2.500000000000001, -2.500000000000001, 98.6, -11.4, 99.1, -10.9, 98.3, -11.700000000000001, 98.3, -11.700000000000001, 97.8, -12.200000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 99.5, -10.5, 99.4, -10.6, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -10.7, 99.3, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -11.9, 98.1, 97.9, -12.100000000000001, 98.6, -11.4, -12.0, 98.0, 98.6, -11.4, 99.4, -10.6, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, 98.5, -11.5, -11.5, 98.5, -11.6, 98.4, -11.6, 98.4, -11.2, 98.8, 98.2, -11.8, 99.1, -10.9, -11.5, 98.5, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -10.7, 99.3, 99.4, -10.6, 99.1, -10.9, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, 98.0, -12.0, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -11.5, 98.5, 98.6, -11.4, 99.2, -10.8, 98.2, -11.8, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, 99.4, -10.6, 98.6, -11.4, 99.7, -10.3, -11.2, 98.8, -11.2, 98.8, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -10.9, 99.1]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.37904347330688176, "mean_inference_ms": 1.6098695690323035, "mean_action_processing_ms": 0.08782284944397276, "mean_env_wait_ms": 0.0852116537587467, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 123000, "timesteps_this_iter": 0, "agent_timesteps_total": 246000, "timers": {"sample_time_ms": 390.156, "sample_throughput": 2563.074, "load_time_ms": 1.464, "load_throughput": 683122.526, "learn_time_ms": 104.313, "learn_throughput": 9586.494, "update_time_ms": 2.88}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 4.336808689942018e-20, "cur_lr": 0.0005000000000000001, "total_loss": 1697.3896484375, "policy_loss": -0.0026221154257655144, "vf_loss": 1697.3962768554688, "vf_explained_var": -0.0018906712532043457, "kl": 0.005138803173489137, "entropy": 0.40485226809978486, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 123000, "num_agent_steps_sampled": 246000, "num_steps_trained": 123000, "num_agent_steps_trained": 246000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 8458, "training_iteration": 123, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-25", "timestamp": 1749778585, "time_this_iter_s": 0.35612940788269043, "time_total_s": 44.896652936935425, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0183190d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 44.896652936935425, "timesteps_since_restore": 0, "iterations_since_restore": 123, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 55.28800000000001, "episode_len_mean": 16.71, "episode_media": {}, "episodes_this_iter": 59, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 27.644000000000002}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.0, -4.999999999999998, 88.8, 87.4, -4.999999999999998, 88.2, 88.6, 88.8, 88.2, 87.2, -4.999999999999998, -4.999999999999998, 88.2, 86.0, 88.4, -4.999999999999998, 87.0, -4.999999999999998, -4.999999999999998, 88.6, -4.999999999999998, 86.8, -4.999999999999998, 88.6, -4.999999999999998, 87.0, 87.2, 88.4, 86.39999999999999, -4.999999999999998, 85.6, 88.8, 87.2, 89.4, 87.6, 87.6, -4.999999999999998, 87.8, 88.0, -4.999999999999998, 88.2, -4.999999999999998, -4.999999999999998, 85.2, -4.999999999999998, 88.2, 87.0, 88.4, -4.999999999999998, 88.0, 88.4, -4.999999999999998, 87.0, -4.999999999999998, 87.4, 87.2, 88.2, 87.6, 87.8, -4.999999999999998, 88.2, -4.999999999999998, 89.4, -4.999999999999998, 85.2, 89.4, 86.6, 87.2, 89.4, -4.999999999999998, 88.8, 89.0, 89.4, 88.0, -4.999999999999998, 87.0, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, 87.4, 89.0, 85.6, 86.6, -4.999999999999998, 87.0, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, 89.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, 87.8, 88.8, 88.8], "episode_lengths": [11, 25, 7, 14, 25, 10, 8, 7, 10, 15, 25, 25, 10, 21, 9, 25, 16, 25, 25, 8, 25, 17, 25, 8, 25, 16, 15, 9, 19, 25, 23, 7, 15, 4, 13, 13, 25, 12, 11, 25, 10, 25, 25, 25, 25, 10, 16, 9, 25, 11, 9, 25, 16, 25, 14, 15, 10, 13, 12, 25, 10, 25, 4, 25, 25, 4, 18, 15, 4, 25, 7, 6, 4, 11, 25, 16, 25, 18, 25, 25, 20, 25, 14, 6, 23, 18, 25, 16, 25, 25, 20, 25, 6, 25, 25, 25, 7, 12, 7, 7], "policy_shared_policy_reward": [99.0, -11.0, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -10.7, 99.3, 99.4, -10.6, 99.1, -10.9, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, 98.0, -12.0, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -11.5, 98.5, 98.6, -11.4, 99.2, -10.8, 98.2, -11.8, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, 99.4, -10.6, 98.6, -11.4, 99.7, -10.3, -11.2, 98.8, -11.2, 98.8, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -2.500000000000001, -2.500000000000001, -10.9, 99.1, 98.5, -11.5, 99.2, -10.8, -2.500000000000001, -2.500000000000001, 99.0, -11.0, 99.2, -10.8, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -11.3, 98.7, 98.6, -11.4, 99.1, -10.9, -11.2, 98.8, -11.1, 98.9, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -12.4, 97.6, 99.7, -10.3, -11.700000000000001, 98.3, -11.4, 98.6, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -10.5, 99.5, -10.3, 99.7, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.1, -11.9, -2.500000000000001, -2.500000000000001, 98.7, -11.3, 99.5, -10.5, 97.8, -12.200000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -11.1, 98.9, -10.6, 99.4, -10.6, 99.4]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.37896176700400075, "mean_inference_ms": 1.6107563599948764, "mean_action_processing_ms": 0.08796333184874366, "mean_env_wait_ms": 0.08525439460818046, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 124000, "timesteps_this_iter": 0, "agent_timesteps_total": 248000, "timers": {"sample_time_ms": 392.247, "sample_throughput": 2549.413, "load_time_ms": 1.375, "load_throughput": 727281.303, "learn_time_ms": 103.975, "learn_throughput": 9617.709, "update_time_ms": 2.791}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 4.336808689942018e-20, "cur_lr": 0.0005000000000000001, "total_loss": 1467.3249389648438, "policy_loss": -0.0030251115560531614, "vf_loss": 1467.3318603515625, "vf_explained_var": 0.012488037347793579, "kl": 0.004293961319727824, "entropy": 0.3930322378873825, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 124000, "num_agent_steps_sampled": 248000, "num_steps_trained": 124000, "num_agent_steps_trained": 248000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 8517, "training_iteration": 124, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-25", "timestamp": 1749778585, "time_this_iter_s": 0.34862685203552246, "time_total_s": 45.24527978897095, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c9c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 45.24527978897095, "timesteps_since_restore": 0, "iterations_since_restore": 124, "perf": {"cpu_util_percent": 59.0, "ram_util_percent": 90.1}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 53.285999999999994, "episode_len_mean": 17.7, "episode_media": {}, "episodes_this_iter": 56, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 26.643}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.2, 87.6, 87.8, -4.999999999999998, 88.2, -4.999999999999998, 89.4, -4.999999999999998, 85.2, 89.4, 86.6, 87.2, 89.4, -4.999999999999998, 88.8, 89.0, 89.4, 88.0, -4.999999999999998, 87.0, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, 87.4, 89.0, 85.6, 86.6, -4.999999999999998, 87.0, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, 89.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, 87.8, 88.8, 88.8, -4.999999999999998, -4.999999999999998, 88.2, 89.0, -4.999999999999998, 88.6, 85.8, 85.4, 88.2, -4.999999999999998, 86.2, 88.8, 88.4, 87.4, 87.8, 86.39999999999999, 88.4, -4.999999999999998, -4.999999999999998, 85.4, 88.4, 85.8, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, 88.4, 86.6, 89.4, 87.0, 86.4, 85.2, 88.0, -4.999999999999998, 87.6, 86.2, 85.2, 86.8, 87.8, 88.2, -4.999999999999998, 86.0, 88.4], "episode_lengths": [10, 13, 12, 25, 10, 25, 4, 25, 25, 4, 18, 15, 4, 25, 7, 6, 4, 11, 25, 16, 25, 18, 25, 25, 20, 25, 14, 6, 23, 18, 25, 16, 25, 25, 20, 25, 6, 25, 25, 25, 7, 12, 7, 7, 25, 25, 10, 6, 25, 8, 22, 24, 10, 25, 20, 7, 9, 14, 12, 19, 9, 25, 25, 24, 9, 22, 9, 25, 25, 25, 25, 25, 17, 21, 25, 25, 25, 25, 25, 25, 11, 25, 25, 9, 18, 4, 16, 19, 25, 11, 25, 13, 20, 25, 17, 12, 10, 25, 21, 9], "policy_shared_policy_reward": [99.1, -10.9, -11.2, 98.8, -11.1, 98.9, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -12.4, 97.6, 99.7, -10.3, -11.700000000000001, 98.3, -11.4, 98.6, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -10.5, 99.5, -10.3, 99.7, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.1, -11.9, -2.500000000000001, -2.500000000000001, 98.7, -11.3, 99.5, -10.5, 97.8, -12.200000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -11.1, 98.9, -10.6, 99.4, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, 99.5, -10.5, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -12.100000000000001, 97.9, -12.3, 97.7, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -11.9, 98.1, 99.4, -10.6, 99.2, -10.8, 98.7, -11.3, 98.9, -11.1, 98.2, -11.8, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, 99.2, -10.8, -12.100000000000001, 97.9, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, 98.3, -11.700000000000001, 99.7, -10.3, 98.5, -11.5, -11.8, 98.2, -12.4, 97.6, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -11.9, 98.1, -12.4, 97.6, 98.4, -11.6, 98.9, -11.1, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 98.0, -12.0, 99.2, -10.8]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3783583435152122, "mean_inference_ms": 1.609361178521894, "mean_action_processing_ms": 0.087905109336225, "mean_env_wait_ms": 0.0852885692451293, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 125000, "timesteps_this_iter": 0, "agent_timesteps_total": 250000, "timers": {"sample_time_ms": 391.313, "sample_throughput": 2555.497, "load_time_ms": 1.364, "load_throughput": 733154.574, "learn_time_ms": 101.873, "learn_throughput": 9816.124, "update_time_ms": 2.789}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 2.168404344971009e-20, "cur_lr": 0.0005000000000000001, "total_loss": 1607.9180786132813, "policy_loss": -0.0009460060857236386, "vf_loss": 1607.9228271484376, "vf_explained_var": 0.001695650815963745, "kl": 0.002058956553365565, "entropy": 0.3793805420398712, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 125000, "num_agent_steps_sampled": 250000, "num_steps_trained": 125000, "num_agent_steps_trained": 250000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 8573, "training_iteration": 125, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-26", "timestamp": 1749778586, "time_this_iter_s": 0.3286569118499756, "time_total_s": 45.57393670082092, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018301d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 45.57393670082092, "timesteps_since_restore": 0, "iterations_since_restore": 125, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 52.267999999999994, "episode_len_mean": 18.28, "episode_media": {}, "episodes_this_iter": 55, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 26.134}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.8, 88.4, 87.4, 87.8, 86.39999999999999, 88.4, -4.999999999999998, -4.999999999999998, 85.4, 88.4, 85.8, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, 88.4, 86.6, 89.4, 87.0, 86.4, 85.2, 88.0, -4.999999999999998, 87.6, 86.2, 85.2, 86.8, 87.8, 88.2, -4.999999999999998, 86.0, 88.4, 85.4, 87.6, -4.999999999999998, 89.0, 87.0, -4.999999999999998, 86.39999999999999, -4.999999999999998, 85.6, 87.8, -4.999999999999998, -4.999999999999998, 89.0, -4.999999999999998, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, 85.8, 87.2, 88.0, 87.6, 87.2, -4.999999999999998, -4.999999999999998, 86.6, 86.8, -4.999999999999998, 87.4, 89.4, 87.2, 88.2, 87.2, -4.999999999999998, -4.999999999999998, 87.4, 86.6, 89.4, -4.999999999999998, 86.8, -4.999999999999998, 89.0, 88.2, 89.4, 88.8, -4.999999999999998, -4.999999999999998, 88.4, 85.2, -4.999999999999998, 88.0, -4.999999999999998, 87.4], "episode_lengths": [7, 9, 14, 12, 19, 9, 25, 25, 24, 9, 22, 9, 25, 25, 25, 25, 25, 17, 21, 25, 25, 25, 25, 25, 25, 11, 25, 25, 9, 18, 4, 16, 19, 25, 11, 25, 13, 20, 25, 17, 12, 10, 25, 21, 9, 24, 13, 25, 6, 16, 25, 19, 25, 23, 12, 25, 25, 6, 25, 25, 25, 25, 25, 25, 14, 22, 15, 11, 13, 15, 25, 25, 18, 17, 25, 14, 4, 15, 10, 15, 25, 25, 14, 18, 4, 25, 17, 25, 6, 10, 4, 7, 25, 25, 9, 25, 25, 11, 25, 14], "policy_shared_policy_reward": [99.4, -10.6, 99.2, -10.8, 98.7, -11.3, 98.9, -11.1, 98.2, -11.8, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, 99.2, -10.8, -12.100000000000001, 97.9, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, 98.3, -11.700000000000001, 99.7, -10.3, 98.5, -11.5, -11.8, 98.2, -12.4, 97.6, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -11.9, 98.1, -12.4, 97.6, 98.4, -11.6, 98.9, -11.1, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 98.0, -12.0, 99.2, -10.8, -12.3, 97.7, 98.8, -11.2, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -11.5, 98.5, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, 97.9, -12.100000000000001, 98.6, -11.4, 99.0, -11.0, 98.8, -11.2, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -11.6, 98.4, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -10.3, 99.7, 98.6, -11.4, -10.9, 99.1, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -11.700000000000001, 98.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, 99.5, -10.5, 99.1, -10.9, 99.7, -10.3, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -12.4, 97.6, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 98.7, -11.3]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.37836620768076074, "mean_inference_ms": 1.60981654843653, "mean_action_processing_ms": 0.08779556709221875, "mean_env_wait_ms": 0.08531328876623301, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 126000, "timesteps_this_iter": 0, "agent_timesteps_total": 252000, "timers": {"sample_time_ms": 391.019, "sample_throughput": 2557.418, "load_time_ms": 1.352, "load_throughput": 739736.155, "learn_time_ms": 102.512, "learn_throughput": 9754.914, "update_time_ms": 2.865}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.0842021724855045e-20, "cur_lr": 0.0005000000000000001, "total_loss": 1602.9310546875, "policy_loss": -0.0016502620652318, "vf_loss": 1602.9366455078125, "vf_explained_var": -0.00026115179061889646, "kl": 0.0035100129186035113, "entropy": 0.38721427917480467, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 126000, "num_agent_steps_sampled": 252000, "num_steps_trained": 126000, "num_agent_steps_trained": 252000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 8628, "training_iteration": 126, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-26", "timestamp": 1749778586, "time_this_iter_s": 0.3720731735229492, "time_total_s": 45.94600987434387, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018301e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 45.94600987434387, "timesteps_since_restore": 0, "iterations_since_restore": 126, "perf": {"cpu_util_percent": 55.2, "ram_util_percent": 90.1}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 58.006, "episode_len_mean": 16.65, "episode_media": {}, "episodes_this_iter": 62, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 29.003}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, 87.4, 85.8, 87.2, 88.0, 87.6, 87.2, -4.999999999999998, -4.999999999999998, 86.6, 86.8, -4.999999999999998, 87.4, 89.4, 87.2, 88.2, 87.2, -4.999999999999998, -4.999999999999998, 87.4, 86.6, 89.4, -4.999999999999998, 86.8, -4.999999999999998, 89.0, 88.2, 89.4, 88.8, -4.999999999999998, -4.999999999999998, 88.4, 85.2, -4.999999999999998, 88.0, -4.999999999999998, 87.4, -4.999999999999998, 89.0, 85.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, 85.2, 86.0, -4.999999999999998, -4.999999999999998, 87.0, -4.999999999999998, 86.6, 87.4, -4.999999999999998, 86.4, -4.999999999999998, 87.4, 88.8, 87.0, 85.2, 89.4, 89.0, 87.4, 87.0, 88.8, 88.2, 88.2, 86.8, 88.8, 88.8, 89.0, 86.39999999999999, 88.8, 89.0, 85.6, 87.8, 88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, 89.4, 86.8, -4.999999999999998, -4.999999999999998, 87.0, 87.8, 88.2, 88.8, 87.6, -4.999999999999998, 87.2, -4.999999999999998, 87.8, 88.6, 85.6, 88.8, -4.999999999999998], "episode_lengths": [25, 25, 14, 22, 15, 11, 13, 15, 25, 25, 18, 17, 25, 14, 4, 15, 10, 15, 25, 25, 14, 18, 4, 25, 17, 25, 6, 10, 4, 7, 25, 25, 9, 25, 25, 11, 25, 14, 25, 6, 23, 25, 25, 25, 25, 7, 25, 21, 25, 25, 16, 25, 18, 14, 25, 19, 25, 14, 7, 16, 25, 4, 6, 14, 16, 7, 10, 10, 17, 7, 7, 6, 19, 7, 6, 23, 12, 7, 25, 25, 25, 25, 10, 4, 17, 25, 25, 16, 12, 10, 7, 13, 25, 15, 25, 12, 8, 23, 7, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, 97.9, -12.100000000000001, 98.6, -11.4, 99.0, -11.0, 98.8, -11.2, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -11.6, 98.4, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -10.3, 99.7, 98.6, -11.4, -10.9, 99.1, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -11.700000000000001, 98.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, 99.5, -10.5, 99.1, -10.9, 99.7, -10.3, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -12.4, 97.6, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -12.4, 97.6, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -11.3, 98.7, 99.4, -10.6, 98.5, -11.5, 97.6, -12.4, -10.3, 99.7, 99.5, -10.5, -11.3, 98.7, 98.5, -11.5, 99.4, -10.6, 99.1, -10.9, 99.1, -10.9, 98.4, -11.6, 99.4, -10.6, 99.4, -10.6, 99.5, -10.5, 98.2, -11.8, -10.6, 99.4, 99.5, -10.5, 97.8, -12.200000000000001, 98.9, -11.1, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 99.7, -10.3, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, 98.9, -11.1, -10.9, 99.1, 99.4, -10.6, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 99.3, -10.7, 97.8, -12.200000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.37805749299051866, "mean_inference_ms": 1.6084382493636138, "mean_action_processing_ms": 0.08774435241193114, "mean_env_wait_ms": 0.08512113363393375, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 127000, "timesteps_this_iter": 0, "agent_timesteps_total": 254000, "timers": {"sample_time_ms": 393.209, "sample_throughput": 2543.177, "load_time_ms": 1.356, "load_throughput": 737434.112, "learn_time_ms": 102.172, "learn_throughput": 9787.429, "update_time_ms": 2.848}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 5.4210108624275225e-21, "cur_lr": 0.0005000000000000001, "total_loss": 1791.480517578125, "policy_loss": -0.0017762006260454654, "vf_loss": 1791.4858764648438, "vf_explained_var": 0.0001727759838104248, "kl": 0.002109095618374468, "entropy": 0.35299405455589294, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 127000, "num_agent_steps_sampled": 254000, "num_steps_trained": 127000, "num_agent_steps_trained": 254000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 8690, "training_iteration": 127, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-26", "timestamp": 1749778586, "time_this_iter_s": 0.3631753921508789, "time_total_s": 46.30918526649475, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018301ee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 46.30918526649475, "timesteps_since_restore": 0, "iterations_since_restore": 127, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 59.854, "episode_len_mean": 16.43, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 29.927}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 86.4, -4.999999999999998, 87.4, 88.8, 87.0, 85.2, 89.4, 89.0, 87.4, 87.0, 88.8, 88.2, 88.2, 86.8, 88.8, 88.8, 89.0, 86.39999999999999, 88.8, 89.0, 85.6, 87.8, 88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, 89.4, 86.8, -4.999999999999998, -4.999999999999998, 87.0, 87.8, 88.2, 88.8, 87.6, -4.999999999999998, 87.2, -4.999999999999998, 87.8, 88.6, 85.6, 88.8, -4.999999999999998, -4.999999999999998, 87.6, 87.0, -4.999999999999998, 88.0, 85.6, 86.2, -4.999999999999998, 87.2, -4.999999999999998, 86.6, -4.999999999999998, 86.2, -4.999999999999998, 87.8, 87.2, -4.999999999999998, -4.999999999999998, 88.2, 88.4, 87.4, -4.999999999999998, 87.8, -4.999999999999998, 86.2, 86.8, 86.8, 87.4, 89.4, 88.2, 86.2, -4.999999999999998, 88.0, -4.999999999999998, 86.2, 87.8, -4.999999999999998, 89.4, -4.999999999999998, 88.0, -4.999999999999998, 89.2, 88.4, -4.999999999999998, -4.999999999999998, 85.8, 88.0, 87.2, 88.4, -4.999999999999998, 88.2, 87.0, -4.999999999999998, 87.2], "episode_lengths": [25, 19, 25, 14, 7, 16, 25, 4, 6, 14, 16, 7, 10, 10, 17, 7, 7, 6, 19, 7, 6, 23, 12, 7, 25, 25, 25, 25, 10, 4, 17, 25, 25, 16, 12, 10, 7, 13, 25, 15, 25, 12, 8, 23, 7, 25, 25, 13, 16, 25, 11, 23, 20, 25, 15, 25, 18, 25, 20, 25, 12, 15, 25, 25, 10, 9, 14, 25, 12, 25, 20, 17, 17, 14, 4, 10, 20, 25, 11, 25, 20, 12, 25, 4, 25, 11, 25, 5, 9, 25, 25, 22, 11, 15, 9, 25, 10, 16, 25, 15], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -11.3, 98.7, 99.4, -10.6, 98.5, -11.5, 97.6, -12.4, -10.3, 99.7, 99.5, -10.5, -11.3, 98.7, 98.5, -11.5, 99.4, -10.6, 99.1, -10.9, 99.1, -10.9, 98.4, -11.6, 99.4, -10.6, 99.4, -10.6, 99.5, -10.5, 98.2, -11.8, -10.6, 99.4, 99.5, -10.5, 97.8, -12.200000000000001, 98.9, -11.1, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 99.7, -10.3, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, 98.9, -11.1, -10.9, 99.1, 99.4, -10.6, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 99.3, -10.7, 97.8, -12.200000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.8, -11.2, 98.5, -11.5, -2.500000000000001, -2.500000000000001, 99.0, -11.0, 97.8, -12.200000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, 99.2, -10.8, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001, 98.1, -11.9, -11.6, 98.4, -11.6, 98.4, -11.3, 98.7, -10.3, 99.7, 99.1, -10.9, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, 98.1, -11.9, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, 99.0, -11.0, -11.4, 98.6, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -11.4, 98.6]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.37757357175594336, "mean_inference_ms": 1.6076284941754369, "mean_action_processing_ms": 0.08782686244073953, "mean_env_wait_ms": 0.08508981180020711, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 128000, "timesteps_this_iter": 0, "agent_timesteps_total": 256000, "timers": {"sample_time_ms": 391.142, "sample_throughput": 2556.619, "load_time_ms": 1.317, "load_throughput": 759314.964, "learn_time_ms": 101.101, "learn_throughput": 9891.06, "update_time_ms": 2.77}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 2.7105054312137612e-21, "cur_lr": 0.0005000000000000001, "total_loss": 1572.6118896484375, "policy_loss": -0.0016681606764905154, "vf_loss": 1572.6170043945312, "vf_explained_var": 0.010012555122375488, "kl": 0.0015470181907017988, "entropy": 0.34320499897003176, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 128000, "num_agent_steps_sampled": 256000, "num_steps_trained": 128000, "num_agent_steps_trained": 256000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 8744, "training_iteration": 128, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-27", "timestamp": 1749778587, "time_this_iter_s": 0.32666468620300293, "time_total_s": 46.635849952697754, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018319e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 46.635849952697754, "timesteps_since_restore": 0, "iterations_since_restore": 128, "perf": {"cpu_util_percent": 47.8, "ram_util_percent": 90.1}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 54.154, "episode_len_mean": 17.87, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 27.076999999999998}, "custom_metrics": {}, "hist_stats": {"episode_reward": [87.2, -4.999999999999998, 86.6, -4.999999999999998, 86.2, -4.999999999999998, 87.8, 87.2, -4.999999999999998, -4.999999999999998, 88.2, 88.4, 87.4, -4.999999999999998, 87.8, -4.999999999999998, 86.2, 86.8, 86.8, 87.4, 89.4, 88.2, 86.2, -4.999999999999998, 88.0, -4.999999999999998, 86.2, 87.8, -4.999999999999998, 89.4, -4.999999999999998, 88.0, -4.999999999999998, 89.2, 88.4, -4.999999999999998, -4.999999999999998, 85.8, 88.0, 87.2, 88.4, -4.999999999999998, 88.2, 87.0, -4.999999999999998, 87.2, -4.999999999999998, 87.0, -4.999999999999998, 88.8, 87.4, -4.999999999999998, 86.4, 88.8, 87.0, 88.8, 86.2, -4.999999999999998, 87.6, 86.2, -4.999999999999998, 89.4, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, 89.4, 86.4, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.6, 89.4, 86.0, 88.8, 86.4, 88.4, 86.2, 86.0, 85.2, -4.999999999999998, -4.999999999999998, 87.6, 86.8, -4.999999999999998, 88.0, 87.2, 87.2, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, 86.0, 87.4, 89.0, -4.999999999999998, 87.6, -4.999999999999998], "episode_lengths": [15, 25, 18, 25, 20, 25, 12, 15, 25, 25, 10, 9, 14, 25, 12, 25, 20, 17, 17, 14, 4, 10, 20, 25, 11, 25, 20, 12, 25, 4, 25, 11, 25, 5, 9, 25, 25, 22, 11, 15, 9, 25, 10, 16, 25, 15, 25, 16, 25, 7, 14, 25, 19, 7, 16, 7, 20, 25, 13, 20, 25, 4, 25, 22, 25, 25, 4, 19, 25, 15, 25, 25, 25, 18, 4, 21, 7, 19, 9, 20, 21, 25, 25, 25, 13, 17, 25, 11, 15, 15, 25, 18, 25, 25, 21, 14, 6, 25, 13, 25], "policy_shared_policy_reward": [-11.4, 98.6, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, 99.2, -10.8, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001, 98.1, -11.9, -11.6, 98.4, -11.6, 98.4, -11.3, 98.7, -10.3, 99.7, 99.1, -10.9, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, 98.1, -11.9, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, 99.0, -11.0, -11.4, 98.6, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -10.6, 99.4, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -11.8, 98.2, 99.4, -10.6, 98.5, -11.5, 99.4, -10.6, -11.9, 98.1, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -11.9, 98.1, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.8, 98.2, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, 99.7, -10.3, 98.0, -12.0, 99.4, -10.6, -11.8, 98.2, 99.2, -10.8, 98.1, -11.9, -12.0, 98.0, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -11.6, 98.4, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -11.4, 98.6, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -11.3, 98.7, 99.5, -10.5, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.37749636055211844, "mean_inference_ms": 1.6080928974460544, "mean_action_processing_ms": 0.08769011423380296, "mean_env_wait_ms": 0.0850941739275435, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 129000, "timesteps_this_iter": 0, "agent_timesteps_total": 258000, "timers": {"sample_time_ms": 387.882, "sample_throughput": 2578.106, "load_time_ms": 1.223, "load_throughput": 817332.268, "learn_time_ms": 98.095, "learn_throughput": 10194.218, "update_time_ms": 2.685}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.3552527156068806e-21, "cur_lr": 0.0005000000000000001, "total_loss": 1523.556103515625, "policy_loss": -0.0010651879012584687, "vf_loss": 1523.560546875, "vf_explained_var": 0.01747947931289673, "kl": 0.0005924980449687034, "entropy": 0.3384190410375595, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 129000, "num_agent_steps_sampled": 258000, "num_steps_trained": 129000, "num_agent_steps_trained": 258000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 8798, "training_iteration": 129, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-27", "timestamp": 1749778587, "time_this_iter_s": 0.31380772590637207, "time_total_s": 46.949657678604126, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018301e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 46.949657678604126, "timesteps_since_restore": 0, "iterations_since_restore": 129, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 56.93599999999999, "episode_len_mean": 17.49, "episode_media": {}, "episodes_this_iter": 61, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 28.468000000000004}, "custom_metrics": {}, "hist_stats": {"episode_reward": [89.4, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, 89.4, 86.4, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.6, 89.4, 86.0, 88.8, 86.4, 88.4, 86.2, 86.0, 85.2, -4.999999999999998, -4.999999999999998, 87.6, 86.8, -4.999999999999998, 88.0, 87.2, 87.2, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, 86.0, 87.4, 89.0, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, -4.999999999999998, 88.8, 88.0, 88.4, 88.8, 87.4, 89.0, 88.4, 87.8, 87.0, 88.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.6, 86.4, -4.999999999999998, 88.4, 86.4, -4.999999999999998, 87.2, 85.6, 87.4, 89.4, 89.4, 89.0, 87.8, 87.6, 87.8, 86.39999999999999, 86.0, 87.2, 87.2, 85.6, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 86.8, 85.6, 88.6, 87.4, 89.4, 87.2, 86.0, 87.6, -4.999999999999998, -4.999999999999998, 87.8, -4.999999999999998, -4.999999999999998, 87.6, 87.4, -4.999999999999998, 87.6, -4.999999999999998], "episode_lengths": [4, 25, 22, 25, 25, 4, 19, 25, 15, 25, 25, 25, 18, 4, 21, 7, 19, 9, 20, 21, 25, 25, 25, 13, 17, 25, 11, 15, 15, 25, 18, 25, 25, 21, 14, 6, 25, 13, 25, 25, 23, 25, 25, 7, 11, 9, 7, 14, 6, 9, 12, 16, 10, 25, 25, 25, 25, 18, 19, 25, 9, 19, 25, 15, 23, 14, 4, 4, 6, 12, 13, 12, 19, 21, 15, 15, 23, 17, 25, 25, 25, 4, 17, 23, 8, 14, 4, 15, 21, 13, 25, 25, 12, 25, 25, 13, 14, 25, 13, 25], "policy_shared_policy_reward": [99.7, -10.3, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.8, 98.2, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, 99.7, -10.3, 98.0, -12.0, 99.4, -10.6, -11.8, 98.2, 99.2, -10.8, 98.1, -11.9, -12.0, 98.0, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -11.6, 98.4, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -11.4, 98.6, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -11.3, 98.7, 99.5, -10.5, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 99.0, -11.0, 99.2, -10.8, 99.4, -10.6, 98.7, -11.3, 99.5, -10.5, -10.8, 99.2, -11.1, 98.9, -11.5, 98.5, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -11.8, 98.2, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -12.200000000000001, 97.8, -11.3, 98.7, 99.7, -10.3, 99.7, -10.3, 99.5, -10.5, -11.1, 98.9, -11.2, 98.8, -11.1, 98.9, 98.2, -11.8, -12.0, 98.0, 98.6, -11.4, -11.4, 98.6, 97.8, -12.200000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.4, -11.6, 97.8, -12.200000000000001, 99.3, -10.7, -11.3, 98.7, 99.7, -10.3, -11.4, 98.6, -12.0, 98.0, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.37737965845275634, "mean_inference_ms": 1.607904187484125, "mean_action_processing_ms": 0.08778309943982877, "mean_env_wait_ms": 0.08504004210629229, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 130000, "timesteps_this_iter": 0, "agent_timesteps_total": 260000, "timers": {"sample_time_ms": 383.585, "sample_throughput": 2606.982, "load_time_ms": 1.1, "load_throughput": 908802.219, "learn_time_ms": 95.357, "learn_throughput": 10486.906, "update_time_ms": 2.708}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 6.776263578034403e-22, "cur_lr": 0.0005000000000000001, "total_loss": 1719.023095703125, "policy_loss": -0.002515590190887451, "vf_loss": 1719.028955078125, "vf_explained_var": 0.02096180319786072, "kl": 0.0031494807065207174, "entropy": 0.3300575137138367, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 130000, "num_agent_steps_sampled": 260000, "num_steps_trained": 130000, "num_agent_steps_trained": 260000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 8859, "training_iteration": 130, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-27", "timestamp": 1749778587, "time_this_iter_s": 0.31974220275878906, "time_total_s": 47.269399881362915, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5ee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 47.269399881362915, "timesteps_since_restore": 0, "iterations_since_restore": 130, "perf": {"cpu_util_percent": 56.2, "ram_util_percent": 90.1}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 60.70799999999999, "episode_len_mean": 16.67, "episode_media": {}, "episodes_this_iter": 62, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 30.353999999999996}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 87.2, 85.6, 87.4, 89.4, 89.4, 89.0, 87.8, 87.6, 87.8, 86.39999999999999, 86.0, 87.2, 87.2, 85.6, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 86.8, 85.6, 88.6, 87.4, 89.4, 87.2, 86.0, 87.6, -4.999999999999998, -4.999999999999998, 87.8, -4.999999999999998, -4.999999999999998, 87.6, 87.4, -4.999999999999998, 87.6, -4.999999999999998, 87.4, 85.6, 89.4, -4.999999999999998, 86.2, 87.4, 88.8, 86.8, 85.2, 88.0, 87.8, 88.2, 89.4, -4.999999999999998, 86.2, 88.8, 86.4, 89.4, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, 86.8, 85.8, -4.999999999999998, 89.4, 86.8, -4.999999999999998, 88.8, 87.4, -4.999999999999998, 89.4, -4.999999999999998, 87.4, 88.0, -4.999999999999998, 89.4, 87.8, -4.999999999999998, 87.6, 86.6, 86.8, -4.999999999999998, 86.2, 86.39999999999999, -4.999999999999998, -4.999999999999998, 89.4, 87.6, -4.999999999999998, 86.8, 86.2, 89.4, 87.2, 88.0, -4.999999999999998, 89.4, 85.8, -4.999999999999998], "episode_lengths": [25, 15, 23, 14, 4, 4, 6, 12, 13, 12, 19, 21, 15, 15, 23, 17, 25, 25, 25, 4, 17, 23, 8, 14, 4, 15, 21, 13, 25, 25, 12, 25, 25, 13, 14, 25, 13, 25, 14, 23, 4, 25, 20, 14, 7, 17, 25, 11, 12, 10, 4, 25, 20, 7, 19, 4, 11, 25, 25, 25, 25, 25, 13, 17, 22, 25, 4, 17, 25, 7, 14, 25, 4, 25, 14, 11, 25, 4, 12, 25, 13, 18, 17, 25, 20, 19, 25, 25, 4, 13, 25, 17, 20, 4, 15, 11, 25, 4, 22, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -11.4, 98.6, -12.200000000000001, 97.8, -11.3, 98.7, 99.7, -10.3, 99.7, -10.3, 99.5, -10.5, -11.1, 98.9, -11.2, 98.8, -11.1, 98.9, 98.2, -11.8, -12.0, 98.0, 98.6, -11.4, -11.4, 98.6, 97.8, -12.200000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.4, -11.6, 97.8, -12.200000000000001, 99.3, -10.7, -11.3, 98.7, 99.7, -10.3, -11.4, 98.6, -12.0, 98.0, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -11.3, 98.7, 97.8, -12.200000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.9, 98.1, 98.7, -11.3, 99.4, -10.6, 98.4, -11.6, 97.6, -12.4, 99.0, -11.0, 98.9, -11.1, -10.9, 99.1, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.9, 98.1, 99.4, -10.6, -11.8, 98.2, 99.7, -10.3, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -11.6, 98.4, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.4, -11.6, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -11.3, 98.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -11.0, 99.0, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -11.700000000000001, 98.3, 98.4, -11.6, -2.500000000000001, -2.500000000000001, 98.1, -11.9, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 98.1, -11.9, 99.7, -10.3, -11.4, 98.6, -11.0, 99.0, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3768849185709369, "mean_inference_ms": 1.6054360238636338, "mean_action_processing_ms": 0.0875125735027645, "mean_env_wait_ms": 0.08487878315088793, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 131000, "timesteps_this_iter": 0, "agent_timesteps_total": 262000, "timers": {"sample_time_ms": 380.045, "sample_throughput": 2631.269, "load_time_ms": 1.164, "load_throughput": 859294.831, "learn_time_ms": 95.752, "learn_throughput": 10443.617, "update_time_ms": 2.756}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 3.3881317890172015e-22, "cur_lr": 0.0005000000000000001, "total_loss": 1722.3114501953125, "policy_loss": -0.004012404876993969, "vf_loss": 1722.3183471679688, "vf_explained_var": 0.02101646065711975, "kl": 0.00756920490786972, "entropy": 0.29158066511154174, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 131000, "num_agent_steps_sampled": 262000, "num_steps_trained": 131000, "num_agent_steps_trained": 262000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 8921, "training_iteration": 131, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-28", "timestamp": 1749778588, "time_this_iter_s": 0.3599388599395752, "time_total_s": 47.62933874130249, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018224430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 47.62933874130249, "timesteps_since_restore": 0, "iterations_since_restore": 131, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 46.80999999999999, "episode_len_mean": 18.51, "episode_media": {}, "episodes_this_iter": 48, "policy_reward_min": {"shared_policy": -12.200000000000001}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 23.405}, "custom_metrics": {}, "hist_stats": {"episode_reward": [87.8, 88.2, 89.4, -4.999999999999998, 86.2, 88.8, 86.4, 89.4, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, 86.8, 85.8, -4.999999999999998, 89.4, 86.8, -4.999999999999998, 88.8, 87.4, -4.999999999999998, 89.4, -4.999999999999998, 87.4, 88.0, -4.999999999999998, 89.4, 87.8, -4.999999999999998, 87.6, 86.6, 86.8, -4.999999999999998, 86.2, 86.39999999999999, -4.999999999999998, -4.999999999999998, 89.4, 87.6, -4.999999999999998, 86.8, 86.2, 89.4, 87.2, 88.0, -4.999999999999998, 89.4, 85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, 86.6, 89.4, 85.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, 86.6, 87.4, 86.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, 87.0, 89.0, 87.2, -4.999999999999998, 87.2, -4.999999999999998, 89.4, 87.0, 86.0, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, 88.0, 86.4, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998], "episode_lengths": [12, 10, 4, 25, 20, 7, 19, 4, 11, 25, 25, 25, 25, 25, 13, 17, 22, 25, 4, 17, 25, 7, 14, 25, 4, 25, 14, 11, 25, 4, 12, 25, 13, 18, 17, 25, 20, 19, 25, 25, 4, 13, 25, 17, 20, 4, 15, 11, 25, 4, 22, 25, 25, 25, 21, 18, 4, 23, 25, 25, 25, 14, 18, 14, 19, 25, 25, 25, 14, 16, 6, 15, 25, 15, 25, 4, 16, 21, 25, 25, 22, 25, 25, 25, 25, 25, 25, 19, 25, 25, 25, 10, 11, 19, 25, 25, 9, 25, 25, 25], "policy_shared_policy_reward": [98.9, -11.1, -10.9, 99.1, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.9, 98.1, 99.4, -10.6, -11.8, 98.2, 99.7, -10.3, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -11.6, 98.4, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.4, -11.6, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -11.3, 98.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -11.0, 99.0, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -11.700000000000001, 98.3, 98.4, -11.6, -2.500000000000001, -2.500000000000001, 98.1, -11.9, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 98.1, -11.9, 99.7, -10.3, -11.4, 98.6, -11.0, 99.0, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -11.700000000000001, 98.3, 99.7, -10.3, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -11.700000000000001, 98.3, -11.3, 98.7, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -11.5, 98.5, 99.5, -10.5, -11.4, 98.6, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.5, 98.5, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 99.0, -11.0, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3772063919904889, "mean_inference_ms": 1.6087913590933973, "mean_action_processing_ms": 0.08765928382147592, "mean_env_wait_ms": 0.08520857037140787, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 132000, "timesteps_this_iter": 0, "agent_timesteps_total": 264000, "timers": {"sample_time_ms": 379.627, "sample_throughput": 2634.162, "load_time_ms": 1.176, "load_throughput": 850495.58, "learn_time_ms": 96.089, "learn_throughput": 10407.018, "update_time_ms": 2.843}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 3.3881317890172015e-22, "cur_lr": 0.0005000000000000001, "total_loss": 1137.7607116699219, "policy_loss": -0.0031260281801223757, "vf_loss": 1137.7669189453125, "vf_explained_var": 0.033073204755783084, "kl": 0.0028027249055349148, "entropy": 0.3102137178182602, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 132000, "num_agent_steps_sampled": 264000, "num_steps_trained": 132000, "num_agent_steps_trained": 264000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 8969, "training_iteration": 132, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-28", "timestamp": 1749778588, "time_this_iter_s": 0.34763383865356445, "time_total_s": 47.976972579956055, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018224f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 47.976972579956055, "timesteps_since_restore": 0, "iterations_since_restore": 132, "perf": {"cpu_util_percent": 51.9, "ram_util_percent": 90.1}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 37.396, "episode_len_mean": 20.48, "episode_media": {}, "episodes_this_iter": 49, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 18.698}, "custom_metrics": {}, "hist_stats": {"episode_reward": [89.4, 85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, 86.6, 89.4, 85.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, 86.6, 87.4, 86.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, 87.0, 89.0, 87.2, -4.999999999999998, 87.2, -4.999999999999998, 89.4, 87.0, 86.0, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, 88.0, 86.4, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.2, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, 85.2, -4.999999999999998, 86.0, -4.999999999999998, 88.8, 86.0, 89.4, 85.6, 86.0, 89.4, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.4, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, 89.4, 86.39999999999999, 85.8, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998], "episode_lengths": [4, 22, 25, 25, 25, 21, 18, 4, 23, 25, 25, 25, 14, 18, 14, 19, 25, 25, 25, 14, 16, 6, 15, 25, 15, 25, 4, 16, 21, 25, 25, 22, 25, 25, 25, 25, 25, 25, 19, 25, 25, 25, 10, 11, 19, 25, 25, 9, 25, 25, 25, 25, 25, 25, 25, 25, 24, 25, 25, 25, 21, 25, 7, 21, 4, 23, 21, 4, 25, 15, 25, 25, 25, 13, 25, 11, 25, 25, 24, 25, 25, 25, 19, 13, 25, 25, 25, 14, 4, 19, 22, 25, 25, 4, 25, 25, 25, 11, 25, 25], "policy_shared_policy_reward": [99.7, -10.3, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -11.700000000000001, 98.3, 99.7, -10.3, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -11.700000000000001, 98.3, -11.3, 98.7, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -11.5, 98.5, 99.5, -10.5, -11.4, 98.6, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.5, 98.5, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 99.0, -11.0, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -12.0, 98.0, 99.7, -10.3, -12.200000000000001, 97.8, -12.0, 98.0, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, 99.7, -10.3, 98.2, -11.8, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3760903722054424, "mean_inference_ms": 1.6054405076804659, "mean_action_processing_ms": 0.08756804442562494, "mean_env_wait_ms": 0.08506352108043697, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 133000, "timesteps_this_iter": 0, "agent_timesteps_total": 266000, "timers": {"sample_time_ms": 380.551, "sample_throughput": 2627.768, "load_time_ms": 1.22, "load_throughput": 819488.101, "learn_time_ms": 93.118, "learn_throughput": 10739.049, "update_time_ms": 2.863}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.6940658945086008e-22, "cur_lr": 0.0005000000000000001, "total_loss": 1210.2222717285156, "policy_loss": -0.0013689350336790085, "vf_loss": 1210.226708984375, "vf_explained_var": 0.029478740692138673, "kl": 0.0030287583485535175, "entropy": 0.30726078152656555, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 133000, "num_agent_steps_sampled": 266000, "num_steps_trained": 133000, "num_agent_steps_trained": 266000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 9018, "training_iteration": 133, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-29", "timestamp": 1749778589, "time_this_iter_s": 0.33133506774902344, "time_total_s": 48.30830764770508, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018319670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 48.30830764770508, "timesteps_since_restore": 0, "iterations_since_restore": 133, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 41.22, "episode_len_mean": 19.4, "episode_media": {}, "episodes_this_iter": 53, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 20.61}, "custom_metrics": {}, "hist_stats": {"episode_reward": [85.2, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, 85.2, -4.999999999999998, 86.0, -4.999999999999998, 88.8, 86.0, 89.4, 85.6, 86.0, 89.4, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.4, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, 89.4, 86.39999999999999, 85.8, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 87.0, 87.2, 85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 89.4, 87.4, -4.999999999999998, 87.0, -4.999999999999998, 88.0, 88.8, 88.8, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, 89.4, -4.999999999999998, 87.8, 87.2, 87.4, -4.999999999999998, 87.4, -4.999999999999998, 89.4, 86.8, -4.999999999999998, 88.2, 88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, 86.0, 87.4, -4.999999999999998, -4.999999999999998, 85.4, 86.8, -4.999999999999998, -4.999999999999998, 89.4], "episode_lengths": [25, 25, 25, 24, 25, 25, 25, 21, 25, 7, 21, 4, 23, 21, 4, 25, 15, 25, 25, 25, 13, 25, 11, 25, 25, 24, 25, 25, 25, 19, 13, 25, 25, 25, 14, 4, 19, 22, 25, 25, 4, 25, 25, 25, 11, 25, 25, 25, 4, 25, 16, 15, 22, 25, 25, 25, 4, 25, 25, 4, 14, 25, 16, 25, 11, 7, 7, 13, 25, 25, 25, 15, 4, 25, 12, 15, 14, 25, 14, 25, 4, 17, 25, 10, 7, 25, 25, 25, 25, 25, 21, 21, 14, 25, 25, 24, 17, 25, 25, 4], "policy_shared_policy_reward": [-12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -12.0, 98.0, 99.7, -10.3, -12.200000000000001, 97.8, -12.0, 98.0, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, 99.7, -10.3, 98.2, -11.8, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -11.4, 98.6, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -11.0, 99.0, 99.4, -10.6, 99.4, -10.6, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -11.4, 98.6, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -10.9, 99.1, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -12.0, 98.0, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.37610283399984484, "mean_inference_ms": 1.6067618018028684, "mean_action_processing_ms": 0.08757530158077287, "mean_env_wait_ms": 0.08511624200843376, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 134000, "timesteps_this_iter": 0, "agent_timesteps_total": 268000, "timers": {"sample_time_ms": 377.513, "sample_throughput": 2648.914, "load_time_ms": 1.221, "load_throughput": 819312.015, "learn_time_ms": 92.773, "learn_throughput": 10779.03, "update_time_ms": 2.863}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 8.470329472543004e-23, "cur_lr": 0.0005000000000000001, "total_loss": 1232.0560424804687, "policy_loss": -0.0017959418706595897, "vf_loss": 1232.0609985351562, "vf_explained_var": 0.031536996364593506, "kl": 0.0018421666806226256, "entropy": 0.3172618418931961, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 134000, "num_agent_steps_sampled": 268000, "num_steps_trained": 134000, "num_agent_steps_trained": 268000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 9071, "training_iteration": 134, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-29", "timestamp": 1749778589, "time_this_iter_s": 0.3540503978729248, "time_total_s": 48.662358045578, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 48.662358045578, "timesteps_since_restore": 0, "iterations_since_restore": 134, "perf": {"cpu_util_percent": 51.1, "ram_util_percent": 90.1}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 40.391999999999996, "episode_len_mean": 19.03, "episode_media": {}, "episodes_this_iter": 52, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 20.195999999999998}, "custom_metrics": {}, "hist_stats": {"episode_reward": [85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 89.4, 87.4, -4.999999999999998, 87.0, -4.999999999999998, 88.0, 88.8, 88.8, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, 89.4, -4.999999999999998, 87.8, 87.2, 87.4, -4.999999999999998, 87.4, -4.999999999999998, 89.4, 86.8, -4.999999999999998, 88.2, 88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, 86.0, 87.4, -4.999999999999998, -4.999999999999998, 85.4, 86.8, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 88.0, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, 86.2, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, 87.2, 87.8, 87.0, 86.6, -4.999999999999998, 89.4, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.6, 89.4, 85.6, -4.999999999999998, 86.8, 87.0, 88.4, 89.4, -4.999999999999998, -4.999999999999998, 89.4, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 89.4, -4.999999999999998], "episode_lengths": [22, 25, 25, 25, 4, 25, 25, 4, 14, 25, 16, 25, 11, 7, 7, 13, 25, 25, 25, 15, 4, 25, 12, 15, 14, 25, 14, 25, 4, 17, 25, 10, 7, 25, 25, 25, 25, 25, 21, 21, 14, 25, 25, 24, 17, 25, 25, 4, 25, 11, 17, 25, 25, 25, 25, 25, 25, 25, 22, 25, 20, 25, 25, 14, 25, 25, 25, 11, 25, 15, 12, 16, 18, 25, 4, 25, 4, 25, 25, 25, 25, 25, 18, 4, 23, 25, 17, 16, 9, 4, 25, 25, 4, 25, 25, 25, 25, 4, 4, 25], "policy_shared_policy_reward": [-12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -11.0, 99.0, 99.4, -10.6, 99.4, -10.6, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -11.4, 98.6, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -10.9, 99.1, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -12.0, 98.0, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.0, 99.0, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -11.1, 98.9, -11.5, 98.5, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -10.3, 99.7, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -11.5, 98.5, 99.2, -10.8, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.37603428799292415, "mean_inference_ms": 1.607285671338916, "mean_action_processing_ms": 0.08761245949635281, "mean_env_wait_ms": 0.08509846051700387, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 135000, "timesteps_this_iter": 0, "agent_timesteps_total": 270000, "timers": {"sample_time_ms": 377.276, "sample_throughput": 2650.581, "load_time_ms": 1.126, "load_throughput": 888115.697, "learn_time_ms": 93.869, "learn_throughput": 10653.131, "update_time_ms": 2.804}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 4.235164736271502e-23, "cur_lr": 0.0005000000000000001, "total_loss": 1119.614697265625, "policy_loss": -0.001192256435751915, "vf_loss": 1119.6192016601562, "vf_explained_var": 0.034115320444107054, "kl": 0.002395996040040238, "entropy": 0.33069544434547427, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 135000, "num_agent_steps_sampled": 270000, "num_steps_trained": 135000, "num_agent_steps_trained": 270000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 9123, "training_iteration": 135, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-29", "timestamp": 1749778589, "time_this_iter_s": 0.3379333019256592, "time_total_s": 49.00029134750366, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5ee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 49.00029134750366, "timesteps_since_restore": 0, "iterations_since_restore": 135, "perf": {"cpu_util_percent": 59.9, "ram_util_percent": 89.8}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 41.248000000000005, "episode_len_mean": 19.26, "episode_media": {}, "episodes_this_iter": 52, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 20.623999999999995}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, 86.2, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, 87.2, 87.8, 87.0, 86.6, -4.999999999999998, 89.4, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.6, 89.4, 85.6, -4.999999999999998, 86.8, 87.0, 88.4, 89.4, -4.999999999999998, -4.999999999999998, 89.4, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 89.4, -4.999999999999998, -4.999999999999998, 85.2, 88.4, -4.999999999999998, 87.8, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, 88.2, 86.0, 86.8, -4.999999999999998, 87.4, 87.6, 85.2, -4.999999999999998, -4.999999999999998, 86.8, 88.6, -4.999999999999998, 85.2, 89.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.8, 89.4, -4.999999999999998, 87.8, 89.4, 86.8, 85.8, -4.999999999999998, 87.0, -4.999999999999998, -4.999999999999998, 87.4, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, 85.4, 87.0, -4.999999999999998], "episode_lengths": [25, 25, 25, 25, 25, 25, 22, 25, 20, 25, 25, 14, 25, 25, 25, 11, 25, 15, 12, 16, 18, 25, 4, 25, 4, 25, 25, 25, 25, 25, 18, 4, 23, 25, 17, 16, 9, 4, 25, 25, 4, 25, 25, 25, 25, 4, 4, 25, 25, 25, 9, 25, 12, 11, 25, 25, 25, 25, 9, 25, 10, 21, 17, 25, 14, 13, 25, 25, 25, 17, 8, 25, 25, 4, 4, 25, 25, 25, 12, 4, 25, 12, 4, 17, 22, 25, 16, 25, 25, 14, 8, 25, 25, 25, 25, 14, 25, 24, 16, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -11.1, 98.9, -11.5, 98.5, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -10.3, 99.7, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -11.5, 98.5, 99.2, -10.8, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.6, -12.4, 99.2, -10.8, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -12.0, 98.0, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -11.3, 98.7, 98.8, -11.2, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -12.4, 97.6, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.1, 98.9, 99.7, -10.3, -11.6, 98.4, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -11.5, 98.5, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.37558351263251, "mean_inference_ms": 1.6060641193780225, "mean_action_processing_ms": 0.08752332696907628, "mean_env_wait_ms": 0.0849975124107649, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 136000, "timesteps_this_iter": 0, "agent_timesteps_total": 272000, "timers": {"sample_time_ms": 375.81, "sample_throughput": 2660.916, "load_time_ms": 1.099, "load_throughput": 910241.976, "learn_time_ms": 91.301, "learn_throughput": 10952.787, "update_time_ms": 2.773}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 2.117582368135751e-23, "cur_lr": 0.0005000000000000001, "total_loss": 1329.8416748046875, "policy_loss": -0.0023923471570014955, "vf_loss": 1329.847607421875, "vf_explained_var": 0.02457118034362793, "kl": 0.002895353613426188, "entropy": 0.35615930557250974, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 136000, "num_agent_steps_sampled": 272000, "num_steps_trained": 136000, "num_agent_steps_trained": 272000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 9175, "training_iteration": 136, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-30", "timestamp": 1749778590, "time_this_iter_s": 0.3209109306335449, "time_total_s": 49.32120227813721, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018319670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 49.32120227813721, "timesteps_since_restore": 0, "iterations_since_restore": 136, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 41.152, "episode_len_mean": 19.74, "episode_media": {}, "episodes_this_iter": 48, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 20.576}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 85.2, 88.4, -4.999999999999998, 87.8, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, 88.2, 86.0, 86.8, -4.999999999999998, 87.4, 87.6, 85.2, -4.999999999999998, -4.999999999999998, 86.8, 88.6, -4.999999999999998, 85.2, 89.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.8, 89.4, -4.999999999999998, 87.8, 89.4, 86.8, 85.8, -4.999999999999998, 87.0, -4.999999999999998, -4.999999999999998, 87.4, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, 85.4, 87.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, 85.2, 86.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, 89.4, 87.4, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, 86.8, 89.0, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, 87.8, -4.999999999999998, 86.39999999999999, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, 88.2, 88.8, 86.6, 86.0, 86.6, 85.4, 85.8], "episode_lengths": [25, 25, 9, 25, 12, 11, 25, 25, 25, 25, 9, 25, 10, 21, 17, 25, 14, 13, 25, 25, 25, 17, 8, 25, 25, 4, 4, 25, 25, 25, 12, 4, 25, 12, 4, 17, 22, 25, 16, 25, 25, 14, 8, 25, 25, 25, 25, 14, 25, 24, 16, 25, 25, 25, 25, 25, 25, 24, 25, 25, 19, 25, 25, 25, 25, 25, 11, 25, 4, 14, 25, 15, 25, 25, 17, 25, 25, 17, 6, 25, 13, 25, 25, 25, 14, 25, 12, 25, 19, 25, 25, 7, 25, 10, 7, 18, 21, 18, 24, 22], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, 97.6, -12.4, 99.2, -10.8, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -12.0, 98.0, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -11.3, 98.7, 98.8, -11.2, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -12.4, 97.6, 99.7, -10.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.1, 98.9, 99.7, -10.3, -11.6, 98.4, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.4, -11.6, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 99.4, -10.6, -11.700000000000001, 98.3, -12.0, 98.0, -11.700000000000001, 98.3, 97.7, -12.3, -12.100000000000001, 97.9]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3750246139313426, "mean_inference_ms": 1.6041859754328511, "mean_action_processing_ms": 0.08738268649686141, "mean_env_wait_ms": 0.08492813989508416, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 137000, "timesteps_this_iter": 0, "agent_timesteps_total": 274000, "timers": {"sample_time_ms": 369.796, "sample_throughput": 2704.196, "load_time_ms": 1.06, "load_throughput": 943494.32, "learn_time_ms": 88.898, "learn_throughput": 11248.797, "update_time_ms": 2.712}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.0587911840678755e-23, "cur_lr": 0.0005000000000000001, "total_loss": 1127.4908569335937, "policy_loss": -0.00047182291746139526, "vf_loss": 1127.4943603515626, "vf_explained_var": 0.04019121527671814, "kl": 0.003405706445680412, "entropy": 0.30241588950157167, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 137000, "num_agent_steps_sampled": 274000, "num_steps_trained": 137000, "num_agent_steps_trained": 274000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 9223, "training_iteration": 137, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-30", "timestamp": 1749778590, "time_this_iter_s": 0.3137850761413574, "time_total_s": 49.634987354278564, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182248b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 49.634987354278564, "timesteps_since_restore": 0, "iterations_since_restore": 137, "perf": {"cpu_util_percent": 56.5, "ram_util_percent": 89.8}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 43.06399999999999, "episode_len_mean": 19.2, "episode_media": {}, "episodes_this_iter": 55, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 21.532000000000004}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, 85.2, 86.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, 89.4, 87.4, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, 86.8, 89.0, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, 87.8, -4.999999999999998, 86.39999999999999, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, 88.2, 88.8, 86.6, 86.0, 86.6, 85.4, 85.8, -4.999999999999998, 86.6, 87.0, -4.999999999999998, 86.4, 85.8, -4.999999999999998, 89.0, -4.999999999999998, -4.999999999999998, 88.0, 89.4, 87.4, -4.999999999999998, -4.999999999999998, 89.4, 87.6, -4.999999999999998, 85.4, 88.6, 89.4, 86.4, 89.4, -4.999999999999998, 85.6, 89.4, -4.999999999999998, 85.8, 89.4, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, 86.0, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 89.4, 86.0, -4.999999999999998, -4.999999999999998, 89.4, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998], "episode_lengths": [25, 25, 24, 25, 25, 19, 25, 25, 25, 25, 25, 11, 25, 4, 14, 25, 15, 25, 25, 17, 25, 25, 17, 6, 25, 13, 25, 25, 25, 14, 25, 12, 25, 19, 25, 25, 7, 25, 10, 7, 18, 21, 18, 24, 22, 25, 18, 16, 25, 19, 22, 25, 6, 25, 25, 11, 4, 14, 25, 25, 4, 13, 25, 24, 8, 4, 19, 4, 25, 23, 4, 25, 22, 4, 14, 25, 25, 25, 10, 21, 25, 4, 25, 25, 4, 21, 25, 25, 4, 14, 25, 25, 25, 24, 25, 4, 25, 25, 24, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.4, -11.6, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 99.4, -10.6, -11.700000000000001, 98.3, -12.0, 98.0, -11.700000000000001, 98.3, 97.7, -12.3, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, 99.7, -10.3, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -10.7, 99.3, 99.7, -10.3, -11.8, 98.2, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, 99.7, -10.3, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 98.0, -12.0, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3751140811570239, "mean_inference_ms": 1.6056140990230292, "mean_action_processing_ms": 0.0875025972538413, "mean_env_wait_ms": 0.08499661341455333, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 138000, "timesteps_this_iter": 0, "agent_timesteps_total": 276000, "timers": {"sample_time_ms": 367.423, "sample_throughput": 2721.656, "load_time_ms": 1.057, "load_throughput": 945770.722, "learn_time_ms": 88.819, "learn_throughput": 11258.804, "update_time_ms": 2.749}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 5.2939559203393774e-24, "cur_lr": 0.0005000000000000001, "total_loss": 1233.4458312988281, "policy_loss": -0.003162139654159546, "vf_loss": 1233.4523071289063, "vf_explained_var": 0.01881972551345825, "kl": 0.0038387137581542773, "entropy": 0.3331185519695282, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 138000, "num_agent_steps_sampled": 276000, "num_steps_trained": 138000, "num_agent_steps_trained": 276000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 9278, "training_iteration": 138, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-30", "timestamp": 1749778590, "time_this_iter_s": 0.3293421268463135, "time_total_s": 49.96432948112488, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018224f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 49.96432948112488, "timesteps_since_restore": 0, "iterations_since_restore": 138, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 39.330000000000005, "episode_len_mean": 19.83, "episode_media": {}, "episodes_this_iter": 47, "policy_reward_min": {"shared_policy": -12.3}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 19.665}, "custom_metrics": {}, "hist_stats": {"episode_reward": [87.0, -4.999999999999998, 86.4, 85.8, -4.999999999999998, 89.0, -4.999999999999998, -4.999999999999998, 88.0, 89.4, 87.4, -4.999999999999998, -4.999999999999998, 89.4, 87.6, -4.999999999999998, 85.4, 88.6, 89.4, 86.4, 89.4, -4.999999999999998, 85.6, 89.4, -4.999999999999998, 85.8, 89.4, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, 86.0, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 89.4, 86.0, -4.999999999999998, -4.999999999999998, 89.4, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, 85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, 87.0, 86.6, -4.999999999999998, 85.4, -4.999999999999998, -4.999999999999998, 87.8, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 86.2, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.4, 86.8, 89.4, 85.6, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, 88.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998], "episode_lengths": [16, 25, 19, 22, 25, 6, 25, 25, 11, 4, 14, 25, 25, 4, 13, 25, 24, 8, 4, 19, 4, 25, 23, 4, 25, 22, 4, 14, 25, 25, 25, 10, 21, 25, 4, 25, 25, 4, 21, 25, 25, 4, 14, 25, 25, 25, 24, 25, 4, 25, 25, 24, 25, 25, 25, 25, 11, 22, 25, 25, 25, 9, 16, 18, 25, 24, 25, 25, 12, 18, 25, 25, 25, 25, 17, 20, 25, 25, 24, 25, 25, 25, 19, 17, 4, 23, 25, 25, 23, 25, 10, 25, 25, 25, 25, 17, 14, 25, 25, 25], "policy_shared_policy_reward": [98.5, -11.5, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, 99.7, -10.3, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -10.7, 99.3, 99.7, -10.3, -11.8, 98.2, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, 99.7, -10.3, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 98.0, -12.0, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -11.5, 98.5, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -11.6, 98.4, 99.7, -10.3, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3748800089488127, "mean_inference_ms": 1.6050570206444577, "mean_action_processing_ms": 0.08744515147021542, "mean_env_wait_ms": 0.08493405908721467, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 139000, "timesteps_this_iter": 0, "agent_timesteps_total": 278000, "timers": {"sample_time_ms": 372.62, "sample_throughput": 2683.696, "load_time_ms": 1.054, "load_throughput": 948980.497, "learn_time_ms": 91.766, "learn_throughput": 10897.302, "update_time_ms": 3.036}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 2.6469779601696887e-24, "cur_lr": 0.0005000000000000001, "total_loss": 1093.5734375, "policy_loss": -0.0014378526248037815, "vf_loss": 1093.5779541015625, "vf_explained_var": 0.03765758275985718, "kl": 0.004292537725973225, "entropy": 0.30499866902828215, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 139000, "num_agent_steps_sampled": 278000, "num_steps_trained": 139000, "num_agent_steps_trained": 278000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 9325, "training_iteration": 139, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-31", "timestamp": 1749778591, "time_this_iter_s": 0.39170145988464355, "time_total_s": 50.35603094100952, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018301e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 50.35603094100952, "timesteps_since_restore": 0, "iterations_since_restore": 139, "perf": {"cpu_util_percent": 63.4, "ram_util_percent": 89.7}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 30.054000000000002, "episode_len_mean": 21.11, "episode_media": {}, "episodes_this_iter": 47, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 15.026999999999997}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, 85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, 87.0, 86.6, -4.999999999999998, 85.4, -4.999999999999998, -4.999999999999998, 87.8, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 86.2, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.4, 86.8, 89.4, 85.6, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, 88.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.0, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.6, 89.4, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, 85.2, -4.999999999999998, 86.0, 85.2, 88.8, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, 87.0, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4], "episode_lengths": [25, 4, 25, 25, 24, 25, 25, 25, 25, 11, 22, 25, 25, 25, 9, 16, 18, 25, 24, 25, 25, 12, 18, 25, 25, 25, 25, 17, 20, 25, 25, 24, 25, 25, 25, 19, 17, 4, 23, 25, 25, 23, 25, 10, 25, 25, 25, 25, 17, 14, 25, 25, 25, 16, 25, 25, 4, 25, 25, 25, 18, 4, 25, 25, 4, 25, 25, 25, 14, 25, 25, 25, 21, 25, 7, 25, 25, 4, 25, 25, 25, 25, 4, 25, 4, 25, 25, 22, 25, 25, 16, 25, 13, 25, 25, 25, 25, 25, 25, 14], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -11.5, 98.5, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -11.6, 98.4, 99.7, -10.3, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -12.4, 97.6, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3743388237331105, "mean_inference_ms": 1.6035684039774205, "mean_action_processing_ms": 0.08728301383483444, "mean_env_wait_ms": 0.08490246294023159, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 140000, "timesteps_this_iter": 0, "agent_timesteps_total": 280000, "timers": {"sample_time_ms": 375.992, "sample_throughput": 2659.634, "load_time_ms": 1.131, "load_throughput": 884482.402, "learn_time_ms": 92.499, "learn_throughput": 10810.87, "update_time_ms": 3.01}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.3234889800848444e-24, "cur_lr": 0.0005000000000000001, "total_loss": 806.1582763671875, "policy_loss": -0.0028757691383361817, "vf_loss": 806.1645446777344, "vf_explained_var": 0.031944119930267335, "kl": 0.0058495574276645704, "entropy": 0.33854037523269653, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 140000, "num_agent_steps_sampled": 280000, "num_steps_trained": 140000, "num_agent_steps_trained": 280000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 9372, "training_iteration": 140, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-31", "timestamp": 1749778591, "time_this_iter_s": 0.3302133083343506, "time_total_s": 50.68624424934387, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c9af0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 50.68624424934387, "timesteps_since_restore": 0, "iterations_since_restore": 140, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 33.814, "episode_len_mean": 20.35, "episode_media": {}, "episodes_this_iter": 51, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 16.907}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, 87.0, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.6, 89.4, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, 85.2, -4.999999999999998, 86.0, 85.2, 88.8, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, 87.0, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, 87.2, 87.4, 87.2, 86.4, 87.2, 87.8, -4.999999999999998, 87.0, 88.6, -4.999999999999998, 87.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, 87.0, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.6, -4.999999999999998, 86.6, 86.8, 87.4, 86.0, -4.999999999999998, 86.0, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, 85.8, 87.8, 89.4, -4.999999999999998, -4.999999999999998, 87.2, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998], "episode_lengths": [25, 25, 16, 25, 25, 4, 25, 25, 25, 18, 4, 25, 25, 4, 25, 25, 25, 14, 25, 25, 25, 21, 25, 7, 25, 25, 4, 25, 25, 25, 25, 4, 25, 4, 25, 25, 22, 25, 25, 16, 25, 13, 25, 25, 25, 25, 25, 25, 14, 25, 15, 14, 15, 19, 15, 12, 25, 16, 8, 25, 12, 25, 25, 25, 22, 16, 15, 25, 25, 25, 25, 18, 25, 18, 17, 14, 21, 25, 21, 25, 4, 25, 25, 25, 25, 17, 25, 22, 12, 4, 25, 25, 15, 8, 25, 25, 25, 25, 25, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -12.4, 97.6, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -11.3, 98.7, -11.4, 98.6, -11.8, 98.2, -11.4, 98.6, -11.1, 98.9, -2.500000000000001, -2.500000000000001, 98.5, -11.5, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -11.5, 98.5, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -11.6, 98.4, 98.7, -11.3, -12.0, 98.0, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -11.1, 98.9, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.6, -11.4, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.37403364601447875, "mean_inference_ms": 1.602741557170789, "mean_action_processing_ms": 0.08722770288793878, "mean_env_wait_ms": 0.08477825768483994, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 141000, "timesteps_this_iter": 0, "agent_timesteps_total": 282000, "timers": {"sample_time_ms": 375.252, "sample_throughput": 2664.875, "load_time_ms": 1.037, "load_throughput": 964496.056, "learn_time_ms": 91.551, "learn_throughput": 10922.863, "update_time_ms": 2.972}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.3234889800848444e-24, "cur_lr": 0.0005000000000000001, "total_loss": 1219.4625854492188, "policy_loss": -0.0013520166277885437, "vf_loss": 1219.467041015625, "vf_explained_var": 0.04133688807487488, "kl": 0.0028846805354671547, "entropy": 0.31182033717632296, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 141000, "num_agent_steps_sampled": 282000, "num_steps_trained": 141000, "num_agent_steps_trained": 282000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 9423, "training_iteration": 141, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-32", "timestamp": 1749778592, "time_this_iter_s": 0.33115649223327637, "time_total_s": 51.01740074157715, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182f4550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 51.01740074157715, "timesteps_since_restore": 0, "iterations_since_restore": 141, "perf": {"cpu_util_percent": 53.8, "ram_util_percent": 89.7}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 42.111999999999995, "episode_len_mean": 19.45, "episode_media": {}, "episodes_this_iter": 51, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 21.055999999999997}, "custom_metrics": {}, "hist_stats": {"episode_reward": [87.4, 87.2, 86.4, 87.2, 87.8, -4.999999999999998, 87.0, 88.6, -4.999999999999998, 87.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, 87.0, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.6, -4.999999999999998, 86.6, 86.8, 87.4, 86.0, -4.999999999999998, 86.0, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, 85.8, 87.8, 89.4, -4.999999999999998, -4.999999999999998, 87.2, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, 88.2, 88.2, -4.999999999999998, 89.4, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.2, 85.4, -4.999999999999998, 89.4, 87.8, 85.6, 86.39999999999999, 85.2, 87.0, 87.8, -4.999999999999998, 86.2, -4.999999999999998, 89.4, -4.999999999999998, 87.8, 87.4, 88.4, 87.4, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 89.0, 88.6, 89.0, 86.8, 88.2, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998], "episode_lengths": [14, 15, 19, 15, 12, 25, 16, 8, 25, 12, 25, 25, 25, 22, 16, 15, 25, 25, 25, 25, 18, 25, 18, 17, 14, 21, 25, 21, 25, 4, 25, 25, 25, 25, 17, 25, 22, 12, 4, 25, 25, 15, 8, 25, 25, 25, 25, 25, 25, 25, 25, 22, 25, 10, 10, 25, 4, 21, 25, 25, 25, 25, 25, 25, 25, 25, 24, 25, 4, 12, 23, 19, 25, 16, 12, 25, 20, 25, 4, 25, 12, 14, 9, 14, 25, 25, 4, 25, 6, 8, 6, 17, 10, 25, 14, 25, 25, 25, 25, 25], "policy_shared_policy_reward": [-11.3, 98.7, -11.4, 98.6, -11.8, 98.2, -11.4, 98.6, -11.1, 98.9, -2.500000000000001, -2.500000000000001, 98.5, -11.5, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -11.5, 98.5, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -11.6, 98.4, 98.7, -11.3, -12.0, 98.0, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -11.1, 98.9, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.6, -11.4, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.4, 97.6, 97.7, -12.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.1, 98.9, -12.200000000000001, 97.8, 98.2, -11.8, -12.4, 97.6, -11.5, 98.5, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -11.3, 98.7, 99.2, -10.8, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.5, -10.5, 99.3, -10.7, 99.5, -10.5, 98.4, -11.6, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3738053872598265, "mean_inference_ms": 1.6021370086980187, "mean_action_processing_ms": 0.0872353840602594, "mean_env_wait_ms": 0.08469728586452183, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 142000, "timesteps_this_iter": 0, "agent_timesteps_total": 284000, "timers": {"sample_time_ms": 373.041, "sample_throughput": 2680.67, "load_time_ms": 0.996, "load_throughput": 1003806.242, "learn_time_ms": 91.04, "learn_throughput": 10984.123, "update_time_ms": 2.846}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 6.617444900424222e-25, "cur_lr": 0.0005000000000000001, "total_loss": 1211.8315795898438, "policy_loss": -0.0020829562563449144, "vf_loss": 1211.8369018554688, "vf_explained_var": 0.03595651984214783, "kl": 0.0029518272920030066, "entropy": 0.32125351428985593, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 142000, "num_agent_steps_sampled": 284000, "num_steps_trained": 142000, "num_agent_steps_trained": 284000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 9474, "training_iteration": 142, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-32", "timestamp": 1749778592, "time_this_iter_s": 0.33792614936828613, "time_total_s": 51.355326890945435, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018224dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 51.355326890945435, "timesteps_since_restore": 0, "iterations_since_restore": 142, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 43.042, "episode_len_mean": 19.31, "episode_media": {}, "episodes_this_iter": 53, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 21.521}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.2, 88.2, -4.999999999999998, 89.4, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.2, 85.4, -4.999999999999998, 89.4, 87.8, 85.6, 86.39999999999999, 85.2, 87.0, 87.8, -4.999999999999998, 86.2, -4.999999999999998, 89.4, -4.999999999999998, 87.8, 87.4, 88.4, 87.4, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 89.0, 88.6, 89.0, 86.8, 88.2, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.6, 86.8, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, 85.4, -4.999999999999998, 85.4, 88.8, -4.999999999999998, 88.2, -4.999999999999998, 86.2, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.6, -4.999999999999998, 87.8, 87.0, 86.6, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, 85.2, -4.999999999999998, -4.999999999999998, 86.39999999999999, 88.2, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, 87.2, -4.999999999999998, 85.2, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, 87.4, 87.8, 89.4, -4.999999999999998, 87.0], "episode_lengths": [10, 10, 25, 4, 21, 25, 25, 25, 25, 25, 25, 25, 25, 24, 25, 4, 12, 23, 19, 25, 16, 12, 25, 20, 25, 4, 25, 12, 14, 9, 14, 25, 25, 4, 25, 6, 8, 6, 17, 10, 25, 14, 25, 25, 25, 25, 25, 8, 17, 25, 25, 7, 25, 24, 25, 24, 7, 25, 10, 25, 20, 25, 25, 17, 25, 25, 25, 8, 25, 12, 16, 18, 25, 25, 22, 25, 25, 25, 25, 19, 10, 25, 25, 4, 25, 25, 25, 14, 15, 25, 25, 25, 25, 20, 25, 14, 12, 4, 25, 16], "policy_shared_policy_reward": [99.1, -10.9, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.4, 97.6, 97.7, -12.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.1, 98.9, -12.200000000000001, 97.8, 98.2, -11.8, -12.4, 97.6, -11.5, 98.5, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -11.3, 98.7, 99.2, -10.8, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.5, -10.5, 99.3, -10.7, 99.5, -10.5, 98.4, -11.6, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -12.3, 97.7, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -11.5, 98.5, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.2, -11.8, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -11.1, 98.9, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.5, 98.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3735438422090094, "mean_inference_ms": 1.6104250059779524, "mean_action_processing_ms": 0.08724756207328899, "mean_env_wait_ms": 0.08472622995245366, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 143000, "timesteps_this_iter": 0, "agent_timesteps_total": 286000, "timers": {"sample_time_ms": 448.469, "sample_throughput": 2229.81, "load_time_ms": 0.941, "load_throughput": 1062306.309, "learn_time_ms": 92.911, "learn_throughput": 10763.015, "update_time_ms": 2.977}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 3.308722450212111e-25, "cur_lr": 0.0005000000000000001, "total_loss": 1228.8467895507813, "policy_loss": -0.002597867138683796, "vf_loss": 1228.8527221679688, "vf_explained_var": 0.04041336178779602, "kl": 0.003811983991408377, "entropy": 0.33274541795253754, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 143000, "num_agent_steps_sampled": 286000, "num_steps_trained": 143000, "num_agent_steps_trained": 286000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 9527, "training_iteration": 143, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-33", "timestamp": 1749778593, "time_this_iter_s": 1.1074743270874023, "time_total_s": 52.46280121803284, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5af0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 52.46280121803284, "timesteps_since_restore": 0, "iterations_since_restore": 143, "perf": {"cpu_util_percent": 34.55, "ram_util_percent": 89.9}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 43.96199999999999, "episode_len_mean": 19.22, "episode_media": {}, "episodes_this_iter": 53, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 21.981000000000005}, "custom_metrics": {}, "hist_stats": {"episode_reward": [85.4, -4.999999999999998, 85.4, 88.8, -4.999999999999998, 88.2, -4.999999999999998, 86.2, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.6, -4.999999999999998, 87.8, 87.0, 86.6, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, 85.2, -4.999999999999998, -4.999999999999998, 86.39999999999999, 88.2, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, 87.2, -4.999999999999998, 85.2, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, 87.4, 87.8, 89.4, -4.999999999999998, 87.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 87.8, 88.8, 87.0, -4.999999999999998, 85.8, -4.999999999999998, 88.2, 86.0, -4.999999999999998, 86.0, -4.999999999999998, 88.8, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, 88.8, -4.999999999999998, 89.4, -4.999999999999998, 87.0, -4.999999999999998, 85.4, -4.999999999999998, 88.2, 85.8, 86.4, -4.999999999999998, -4.999999999999998, 87.2, 86.6, -4.999999999999998, 88.6, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, 88.2, 85.6, 86.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 87.4, 89.4, 88.2], "episode_lengths": [24, 25, 24, 7, 25, 10, 25, 20, 25, 25, 17, 25, 25, 25, 8, 25, 12, 16, 18, 25, 25, 22, 25, 25, 25, 25, 19, 10, 25, 25, 4, 25, 25, 25, 14, 15, 25, 25, 25, 25, 20, 25, 14, 12, 4, 25, 16, 25, 25, 25, 4, 12, 7, 16, 25, 22, 25, 10, 21, 25, 21, 25, 7, 14, 25, 25, 25, 15, 7, 25, 4, 25, 16, 25, 24, 25, 10, 22, 19, 25, 25, 15, 18, 25, 8, 8, 25, 25, 25, 7, 10, 23, 19, 25, 25, 25, 4, 14, 4, 10], "policy_shared_policy_reward": [-12.3, 97.7, -2.500000000000001, -2.500000000000001, -12.3, 97.7, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -11.5, 98.5, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.2, -11.8, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -11.1, 98.9, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.1, 98.9, 99.4, -10.6, -11.5, 98.5, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -12.100000000000001, 97.9, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 99.1, -10.9, -12.200000000000001, 97.8, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.3, 98.7, 99.7, -10.3, 99.1, -10.9]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3733297825430363, "mean_inference_ms": 1.6158689490298264, "mean_action_processing_ms": 0.08732916817528281, "mean_env_wait_ms": 0.08482367079895713, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 144000, "timesteps_this_iter": 0, "agent_timesteps_total": 288000, "timers": {"sample_time_ms": 450.77, "sample_throughput": 2218.425, "load_time_ms": 1.053, "load_throughput": 949259.704, "learn_time_ms": 92.929, "learn_throughput": 10760.889, "update_time_ms": 2.977}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.6543612251060554e-25, "cur_lr": 0.0005000000000000001, "total_loss": 1292.0259033203124, "policy_loss": -0.0019222408533096313, "vf_loss": 1292.0312255859376, "vf_explained_var": 0.022538357973098756, "kl": 0.002219016503226978, "entropy": 0.33629830181598663, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 144000, "num_agent_steps_sampled": 288000, "num_steps_trained": 144000, "num_agent_steps_trained": 288000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 9580, "training_iteration": 144, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-34", "timestamp": 1749778594, "time_this_iter_s": 0.3544464111328125, "time_total_s": 52.81724762916565, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 52.81724762916565, "timesteps_since_restore": 0, "iterations_since_restore": 144, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 53.352000000000004, "episode_len_mean": 17.37, "episode_media": {}, "episodes_this_iter": 59, "policy_reward_min": {"shared_policy": -12.3}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 26.676}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 86.0, -4.999999999999998, 88.8, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, 88.8, -4.999999999999998, 89.4, -4.999999999999998, 87.0, -4.999999999999998, 85.4, -4.999999999999998, 88.2, 85.8, 86.4, -4.999999999999998, -4.999999999999998, 87.2, 86.6, -4.999999999999998, 88.6, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, 88.2, 85.6, 86.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 87.4, 89.4, 88.2, 87.0, -4.999999999999998, 86.2, 89.4, 87.8, -4.999999999999998, 86.6, -4.999999999999998, 88.2, -4.999999999999998, 89.4, 89.4, -4.999999999999998, 88.2, 86.2, 89.4, 86.8, 87.4, 89.4, -4.999999999999998, 86.8, 88.2, -4.999999999999998, -4.999999999999998, 86.4, -4.999999999999998, -4.999999999999998, 87.6, -4.999999999999998, 88.4, 88.6, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, 87.8, 87.6, 86.4, 89.4, 87.8, -4.999999999999998, 86.4, 88.6, -4.999999999999998, 87.2, 88.2, 87.4, 89.4, -4.999999999999998, 86.4, 87.0, 85.8, 86.8, 86.2, 86.4, 87.8, -4.999999999999998, -4.999999999999998, 88.6], "episode_lengths": [25, 21, 25, 7, 14, 25, 25, 25, 15, 7, 25, 4, 25, 16, 25, 24, 25, 10, 22, 19, 25, 25, 15, 18, 25, 8, 8, 25, 25, 25, 7, 10, 23, 19, 25, 25, 25, 4, 14, 4, 10, 16, 25, 20, 4, 12, 25, 18, 25, 10, 25, 4, 4, 25, 10, 20, 4, 17, 14, 4, 25, 17, 10, 25, 25, 19, 25, 25, 13, 25, 9, 8, 25, 25, 17, 25, 12, 13, 19, 4, 12, 25, 19, 8, 25, 15, 10, 14, 4, 25, 19, 16, 22, 17, 20, 19, 12, 25, 25, 8], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -12.100000000000001, 97.9, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 99.1, -10.9, -12.200000000000001, 97.8, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.3, 98.7, 99.7, -10.3, 99.1, -10.9, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -11.9, 98.1, 99.7, -10.3, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.9, 99.1, 98.1, -11.9, 99.7, -10.3, -11.6, 98.4, -11.3, 98.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, 99.2, -10.8, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -11.2, 98.8, -11.8, 98.2, 99.7, -10.3, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -11.8, 98.2, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -11.4, 98.6, 99.1, -10.9, 98.7, -11.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -11.5, 98.5, 97.9, -12.100000000000001, -11.6, 98.4, -11.9, 98.1, -11.8, 98.2, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3726269859863742, "mean_inference_ms": 1.6127886039176087, "mean_action_processing_ms": 0.08729488295365866, "mean_env_wait_ms": 0.08487131411742294, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 145000, "timesteps_this_iter": 0, "agent_timesteps_total": 290000, "timers": {"sample_time_ms": 449.784, "sample_throughput": 2223.291, "load_time_ms": 1.095, "load_throughput": 913194.862, "learn_time_ms": 93.974, "learn_throughput": 10641.191, "update_time_ms": 3.064}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 8.271806125530277e-26, "cur_lr": 0.0005000000000000001, "total_loss": 1651.06103515625, "policy_loss": -0.0035339832305908204, "vf_loss": 1651.0676513671874, "vf_explained_var": 0.0252169132232666, "kl": 0.005265637703702986, "entropy": 0.30732648372650145, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 145000, "num_agent_steps_sampled": 290000, "num_steps_trained": 145000, "num_agent_steps_trained": 290000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 9639, "training_iteration": 145, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-34", "timestamp": 1749778594, "time_this_iter_s": 0.34058547019958496, "time_total_s": 53.157833099365234, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c9b80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 53.157833099365234, "timesteps_since_restore": 0, "iterations_since_restore": 145, "perf": {"cpu_util_percent": 35.2, "ram_util_percent": 90.0}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 61.516000000000005, "episode_len_mean": 17.14, "episode_media": {}, "episodes_this_iter": 58, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 30.757999999999996}, "custom_metrics": {}, "hist_stats": {"episode_reward": [87.4, 89.4, -4.999999999999998, 86.8, 88.2, -4.999999999999998, -4.999999999999998, 86.4, -4.999999999999998, -4.999999999999998, 87.6, -4.999999999999998, 88.4, 88.6, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, 87.8, 87.6, 86.4, 89.4, 87.8, -4.999999999999998, 86.4, 88.6, -4.999999999999998, 87.2, 88.2, 87.4, 89.4, -4.999999999999998, 86.4, 87.0, 85.8, 86.8, 86.2, 86.4, 87.8, -4.999999999999998, -4.999999999999998, 88.6, -4.999999999999998, 89.0, 85.8, -4.999999999999998, 87.6, 86.2, -4.999999999999998, 88.0, 88.2, 86.39999999999999, 87.0, 85.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, 88.6, 87.4, -4.999999999999998, 89.4, 88.0, 87.6, -4.999999999999998, 86.4, 85.6, 89.4, 88.2, -4.999999999999998, 88.0, 86.8, -4.999999999999998, -4.999999999999998, 88.0, 87.4, 85.2, 87.4, -4.999999999999998, 85.2, 85.2, -4.999999999999998, 88.0, 87.8, -4.999999999999998, 85.4, 89.4, 88.2, 86.4, 88.0, 86.2, 86.8, 89.4, 88.6, 87.0, 86.39999999999999, 86.0, 86.2, 88.6, 86.8], "episode_lengths": [14, 4, 25, 17, 10, 25, 25, 19, 25, 25, 13, 25, 9, 8, 25, 25, 17, 25, 12, 13, 19, 4, 12, 25, 19, 8, 25, 15, 10, 14, 4, 25, 19, 16, 22, 17, 20, 19, 12, 25, 25, 8, 25, 6, 22, 25, 13, 20, 25, 11, 10, 19, 16, 23, 25, 25, 25, 11, 8, 14, 25, 4, 11, 13, 25, 19, 23, 4, 10, 25, 11, 17, 25, 25, 11, 14, 25, 14, 25, 25, 25, 25, 11, 12, 25, 24, 4, 10, 19, 11, 20, 17, 4, 8, 16, 19, 21, 20, 8, 17], "policy_shared_policy_reward": [-11.3, 98.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, 99.2, -10.8, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -11.2, 98.8, -11.8, 98.2, 99.7, -10.3, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -11.8, 98.2, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -11.4, 98.6, 99.1, -10.9, 98.7, -11.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -11.5, 98.5, 97.9, -12.100000000000001, -11.6, 98.4, -11.9, 98.1, -11.8, 98.2, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -11.9, 98.1, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -10.9, 99.1, 98.2, -11.8, -11.5, 98.5, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, 99.3, -10.7, -11.3, 98.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.0, -11.0, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -11.8, 98.2, 97.8, -12.200000000000001, -10.3, 99.7, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, 98.7, -11.3, 97.6, -12.4, -11.3, 98.7, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -11.0, 99.0, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -12.3, 97.7, 99.7, -10.3, 99.1, -10.9, -11.8, 98.2, 99.0, -11.0, 98.1, -11.9, -11.6, 98.4, -10.3, 99.7, 99.3, -10.7, -11.5, 98.5, 98.2, -11.8, 98.0, -12.0, -11.9, 98.1, 99.3, -10.7, 98.4, -11.6]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.37248149292170907, "mean_inference_ms": 1.6112682281630917, "mean_action_processing_ms": 0.08733411693024223, "mean_env_wait_ms": 0.08482608069481508, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 146000, "timesteps_this_iter": 0, "agent_timesteps_total": 292000, "timers": {"sample_time_ms": 451.252, "sample_throughput": 2216.059, "load_time_ms": 1.102, "load_throughput": 907681.188, "learn_time_ms": 95.473, "learn_throughput": 10474.202, "update_time_ms": 3.243}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 8.271806125530277e-26, "cur_lr": 0.0005000000000000001, "total_loss": 1871.6319091796875, "policy_loss": -0.0035876378417015074, "vf_loss": 1871.639208984375, "vf_explained_var": 0.016814029216766356, "kl": 0.0069419706106496285, "entropy": 0.37075550854206085, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 146000, "num_agent_steps_sampled": 292000, "num_steps_trained": 146000, "num_agent_steps_trained": 292000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 9697, "training_iteration": 146, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-34", "timestamp": 1749778594, "time_this_iter_s": 0.34287595748901367, "time_total_s": 53.50070905685425, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018319700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 53.50070905685425, "timesteps_since_restore": 0, "iterations_since_restore": 146, "perf": {"cpu_util_percent": 56.4, "ram_util_percent": 90.0}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 54.94, "episode_len_mean": 18.45, "episode_media": {}, "episodes_this_iter": 49, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 27.47}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.0, 88.2, 86.39999999999999, 87.0, 85.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, 88.6, 87.4, -4.999999999999998, 89.4, 88.0, 87.6, -4.999999999999998, 86.4, 85.6, 89.4, 88.2, -4.999999999999998, 88.0, 86.8, -4.999999999999998, -4.999999999999998, 88.0, 87.4, 85.2, 87.4, -4.999999999999998, 85.2, 85.2, -4.999999999999998, 88.0, 87.8, -4.999999999999998, 85.4, 89.4, 88.2, 86.4, 88.0, 86.2, 86.8, 89.4, 88.6, 87.0, 86.39999999999999, 86.0, 86.2, 88.6, 86.8, 86.2, 87.0, 85.6, -4.999999999999998, 88.4, 86.4, 87.8, 85.6, 85.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, 87.0, -4.999999999999998, 88.0, 87.8, -4.999999999999998, 87.8, -4.999999999999998, 87.4, -4.999999999999998, 87.0, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, 86.8, 85.8, 88.6, -4.999999999999998, -4.999999999999998, 87.4, 88.0, 86.8, -4.999999999999998, -4.999999999999998, 86.8], "episode_lengths": [11, 10, 19, 16, 23, 25, 25, 25, 11, 8, 14, 25, 4, 11, 13, 25, 19, 23, 4, 10, 25, 11, 17, 25, 25, 11, 14, 25, 14, 25, 25, 25, 25, 11, 12, 25, 24, 4, 10, 19, 11, 20, 17, 4, 8, 16, 19, 21, 20, 8, 17, 20, 16, 23, 25, 9, 19, 12, 23, 23, 25, 25, 25, 25, 25, 25, 11, 25, 25, 16, 25, 11, 12, 25, 12, 25, 14, 25, 16, 9, 25, 25, 25, 17, 25, 25, 25, 25, 22, 17, 22, 8, 25, 25, 14, 11, 17, 25, 25, 17], "policy_shared_policy_reward": [99.0, -11.0, -10.9, 99.1, 98.2, -11.8, -11.5, 98.5, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, 99.3, -10.7, -11.3, 98.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 99.0, -11.0, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -11.8, 98.2, 97.8, -12.200000000000001, -10.3, 99.7, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, 98.7, -11.3, 97.6, -12.4, -11.3, 98.7, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -11.0, 99.0, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -12.3, 97.7, 99.7, -10.3, 99.1, -10.9, -11.8, 98.2, 99.0, -11.0, 98.1, -11.9, -11.6, 98.4, -10.3, 99.7, 99.3, -10.7, -11.5, 98.5, 98.2, -11.8, 98.0, -12.0, -11.9, 98.1, 99.3, -10.7, 98.4, -11.6, 98.1, -11.9, -11.5, 98.5, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -11.8, 98.2, -11.1, 98.9, -12.200000000000001, 97.8, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -11.5, 98.5, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -11.6, 98.4, -12.100000000000001, 97.9, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, 99.0, -11.0, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.37259108450185946, "mean_inference_ms": 1.6122305018054164, "mean_action_processing_ms": 0.08731093879346409, "mean_env_wait_ms": 0.08482277965022972, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 147000, "timesteps_this_iter": 0, "agent_timesteps_total": 294000, "timers": {"sample_time_ms": 453.869, "sample_throughput": 2203.279, "load_time_ms": 1.215, "load_throughput": 823171.158, "learn_time_ms": 97.841, "learn_throughput": 10220.701, "update_time_ms": 3.311}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 8.271806125530277e-26, "cur_lr": 0.0005000000000000001, "total_loss": 1295.9028198242188, "policy_loss": -0.0007289638742804527, "vf_loss": 1295.9071533203125, "vf_explained_var": 0.020189476013183594, "kl": 0.002255635983318083, "entropy": 0.3556429147720337, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 147000, "num_agent_steps_sampled": 294000, "num_steps_trained": 147000, "num_agent_steps_trained": 294000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 9746, "training_iteration": 147, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-35", "timestamp": 1749778595, "time_this_iter_s": 0.3454771041870117, "time_total_s": 53.84618616104126, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f50d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 53.84618616104126, "timesteps_since_restore": 0, "iterations_since_restore": 147, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 43.886, "episode_len_mean": 19.6, "episode_media": {}, "episodes_this_iter": 53, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 21.943}, "custom_metrics": {}, "hist_stats": {"episode_reward": [85.6, -4.999999999999998, 88.4, 86.4, 87.8, 85.6, 85.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, 87.0, -4.999999999999998, 88.0, 87.8, -4.999999999999998, 87.8, -4.999999999999998, 87.4, -4.999999999999998, 87.0, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, 86.8, 85.8, 88.6, -4.999999999999998, -4.999999999999998, 87.4, 88.0, 86.8, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, 87.0, 87.8, -4.999999999999998, 88.4, 88.6, -4.999999999999998, 86.8, -4.999999999999998, 89.4, 85.6, -4.999999999999998, -4.999999999999998, 87.0, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, 88.8, 86.0, 88.2, -4.999999999999998, 85.2, 85.6, -4.999999999999998, -4.999999999999998, 88.6, 88.6, 88.0, 86.0, -4.999999999999998, -4.999999999999998, 86.4, -4.999999999999998, 89.4, -4.999999999999998, 88.6, 87.8, 85.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, 87.0, 88.0, -4.999999999999998, -4.999999999999998, 87.8, 86.6, 87.8, 86.6], "episode_lengths": [23, 25, 9, 19, 12, 23, 23, 25, 25, 25, 25, 25, 25, 11, 25, 25, 16, 25, 11, 12, 25, 12, 25, 14, 25, 16, 9, 25, 25, 25, 17, 25, 25, 25, 25, 22, 17, 22, 8, 25, 25, 14, 11, 17, 25, 25, 17, 25, 25, 16, 12, 25, 9, 8, 25, 17, 25, 4, 23, 25, 25, 16, 25, 15, 25, 25, 7, 21, 10, 25, 25, 23, 25, 25, 8, 8, 11, 21, 25, 25, 19, 25, 4, 25, 8, 12, 24, 25, 25, 25, 25, 22, 16, 11, 25, 25, 12, 18, 12, 18], "policy_shared_policy_reward": [-12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -11.8, 98.2, -11.1, 98.9, -12.200000000000001, 97.8, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -11.5, 98.5, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -11.6, 98.4, -12.100000000000001, 97.9, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, 99.0, -11.0, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -11.1, 98.9, -2.500000000000001, -2.500000000000001, 99.2, -10.8, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 98.0, -12.0, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 99.3, -10.7, 99.0, -11.0, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -11.1, 98.9, 97.7, -12.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -11.5, 98.5, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -11.700000000000001, 98.3, -11.1, 98.9, -11.700000000000001, 98.3]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3721205167313789, "mean_inference_ms": 1.6134371539054237, "mean_action_processing_ms": 0.08709593536314608, "mean_env_wait_ms": 0.08469599398764187, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 148000, "timesteps_this_iter": 0, "agent_timesteps_total": 296000, "timers": {"sample_time_ms": 457.406, "sample_throughput": 2186.24, "load_time_ms": 1.237, "load_throughput": 808524.944, "learn_time_ms": 97.922, "learn_throughput": 10212.176, "update_time_ms": 3.335}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 4.1359030627651386e-26, "cur_lr": 0.0005000000000000001, "total_loss": 1402.5962890625, "policy_loss": -0.0023107573390007017, "vf_loss": 1402.6022705078126, "vf_explained_var": 0.0182081937789917, "kl": 0.0038157167203044296, "entropy": 0.36274469792842867, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 148000, "num_agent_steps_sampled": 296000, "num_steps_trained": 148000, "num_agent_steps_trained": 296000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 9799, "training_iteration": 148, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-35", "timestamp": 1749778595, "time_this_iter_s": 0.3369121551513672, "time_total_s": 54.18309831619263, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 54.18309831619263, "timesteps_since_restore": 0, "iterations_since_restore": 148, "perf": {"cpu_util_percent": 55.8, "ram_util_percent": 90.0}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 44.836000000000006, "episode_len_mean": 19.36, "episode_media": {}, "episodes_this_iter": 49, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 22.418000000000003}, "custom_metrics": {}, "hist_stats": {"episode_reward": [87.0, 87.8, -4.999999999999998, 88.4, 88.6, -4.999999999999998, 86.8, -4.999999999999998, 89.4, 85.6, -4.999999999999998, -4.999999999999998, 87.0, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, 88.8, 86.0, 88.2, -4.999999999999998, 85.2, 85.6, -4.999999999999998, -4.999999999999998, 88.6, 88.6, 88.0, 86.0, -4.999999999999998, -4.999999999999998, 86.4, -4.999999999999998, 89.4, -4.999999999999998, 88.6, 87.8, 85.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, 87.0, 88.0, -4.999999999999998, -4.999999999999998, 87.8, 86.6, 87.8, 86.6, 87.0, 85.2, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, 87.6, 87.2, 86.6, -4.999999999999998, 87.4, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.6, 87.0, 87.8, -4.999999999999998, -4.999999999999998, 87.4, 88.2, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, 85.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, -4.999999999999998, 88.8, 85.6, -4.999999999999998, -4.999999999999998, 88.6, 86.4, -4.999999999999998, -4.999999999999998, 86.6], "episode_lengths": [16, 12, 25, 9, 8, 25, 17, 25, 4, 23, 25, 25, 16, 25, 15, 25, 25, 7, 21, 10, 25, 25, 23, 25, 25, 8, 8, 11, 21, 25, 25, 19, 25, 4, 25, 8, 12, 24, 25, 25, 25, 25, 22, 16, 11, 25, 25, 12, 18, 12, 18, 16, 25, 25, 17, 25, 25, 13, 15, 18, 25, 14, 21, 25, 25, 25, 25, 13, 25, 25, 25, 18, 16, 12, 25, 25, 14, 10, 25, 9, 25, 25, 9, 25, 24, 4, 25, 25, 25, 13, 25, 7, 23, 25, 25, 8, 19, 25, 25, 18], "policy_shared_policy_reward": [-11.5, 98.5, -11.1, 98.9, -2.500000000000001, -2.500000000000001, 99.2, -10.8, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 98.0, -12.0, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 99.3, -10.7, 99.0, -11.0, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -11.1, 98.9, 97.7, -12.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -11.5, 98.5, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -11.700000000000001, 98.3, -11.1, 98.9, -11.700000000000001, 98.3, -11.5, 98.5, -12.4, 97.6, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -11.4, 98.6, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -11.5, 98.5, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -12.3, 97.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.37189459668043523, "mean_inference_ms": 1.6131539899554952, "mean_action_processing_ms": 0.08705718386196928, "mean_env_wait_ms": 0.08467447098763696, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 149000, "timesteps_this_iter": 0, "agent_timesteps_total": 298000, "timers": {"sample_time_ms": 453.353, "sample_throughput": 2205.787, "load_time_ms": 1.253, "load_throughput": 797881.601, "learn_time_ms": 97.869, "learn_throughput": 10217.696, "update_time_ms": 3.147}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 2.0679515313825693e-26, "cur_lr": 0.0005000000000000001, "total_loss": 1162.261962890625, "policy_loss": -0.002733180671930313, "vf_loss": 1162.2681640625, "vf_explained_var": 0.036407476663589476, "kl": 0.0043373750252901685, "entropy": 0.3451618790626526, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 149000, "num_agent_steps_sampled": 298000, "num_steps_trained": 149000, "num_agent_steps_trained": 298000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 9848, "training_iteration": 149, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-35", "timestamp": 1749778595, "time_this_iter_s": 0.3545522689819336, "time_total_s": 54.53765058517456, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 54.53765058517456, "timesteps_since_restore": 0, "iterations_since_restore": 149, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 39.202000000000005, "episode_len_mean": 20.47, "episode_media": {}, "episodes_this_iter": 52, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 19.601}, "custom_metrics": {}, "hist_stats": {"episode_reward": [85.2, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, 87.6, 87.2, 86.6, -4.999999999999998, 87.4, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.6, 87.0, 87.8, -4.999999999999998, -4.999999999999998, 87.4, 88.2, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, 85.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, -4.999999999999998, 88.8, 85.6, -4.999999999999998, -4.999999999999998, 88.6, 86.4, -4.999999999999998, -4.999999999999998, 86.6, -4.999999999999998, 87.6, 85.4, 85.8, -4.999999999999998, -4.999999999999998, 86.6, 86.0, -4.999999999999998, 86.4, 89.2, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 85.2, -4.999999999999998, -4.999999999999998, 86.6, -4.999999999999998, 86.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, 88.6, 85.2, -4.999999999999998, 87.2, -4.999999999999998, 88.4, -4.999999999999998, 89.0, 88.4, 87.0, -4.999999999999998, 85.2, -4.999999999999998, 86.0, 87.8, 87.4], "episode_lengths": [25, 25, 17, 25, 25, 13, 15, 18, 25, 14, 21, 25, 25, 25, 25, 13, 25, 25, 25, 18, 16, 12, 25, 25, 14, 10, 25, 9, 25, 25, 9, 25, 24, 4, 25, 25, 25, 13, 25, 7, 23, 25, 25, 8, 19, 25, 25, 18, 25, 13, 24, 22, 25, 25, 18, 21, 25, 19, 5, 25, 21, 25, 25, 25, 25, 25, 25, 17, 25, 25, 25, 25, 25, 17, 25, 25, 25, 18, 25, 20, 25, 25, 25, 7, 8, 25, 25, 15, 25, 9, 25, 6, 9, 16, 25, 25, 25, 21, 12, 14], "policy_shared_policy_reward": [-12.4, 97.6, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -11.4, 98.6, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -11.5, 98.5, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -12.3, 97.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -12.3, 97.7, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -10.4, 99.6, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 97.6, -12.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 99.3, -10.7, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -10.5, 99.5, 99.2, -10.8, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -11.1, 98.9, -11.3, 98.7]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.37165218139941714, "mean_inference_ms": 1.6121010497316541, "mean_action_processing_ms": 0.08700181617915635, "mean_env_wait_ms": 0.08463880529514517, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 150000, "timesteps_this_iter": 0, "agent_timesteps_total": 300000, "timers": {"sample_time_ms": 452.723, "sample_throughput": 2208.854, "load_time_ms": 1.253, "load_throughput": 798200.468, "learn_time_ms": 99.029, "learn_throughput": 10098.031, "update_time_ms": 3.208}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.0339757656912847e-26, "cur_lr": 0.0005000000000000001, "total_loss": 1346.0542724609375, "policy_loss": -0.004074887931346893, "vf_loss": 1346.0617431640626, "vf_explained_var": 0.024375414848327635, "kl": 0.004858709464745381, "entropy": 0.3428057998418808, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 150000, "num_agent_steps_sampled": 300000, "num_steps_trained": 150000, "num_agent_steps_trained": 300000, "num_steps_trained_this_iter": 0}, "evaluation": {"episode_reward_max": 88.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 22.42, "episode_len_mean": 23.2, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"shared_policy": -12.3}, "policy_reward_max": {"shared_policy": 99.2}, "policy_reward_mean": {"shared_policy": 11.209999999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, 88.4, -4.999999999999998], "episode_lengths": [25, 25, 25, 24, 25, 25, 25, 24, 9, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, 99.2, -10.8, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18205580773291646, "mean_inference_ms": 1.3037618104513589, "mean_action_processing_ms": 0.04559832733946961, "mean_env_wait_ms": 0.04230420310775955, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "done": false, "episodes_total": 9900, "training_iteration": 150, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-36", "timestamp": 1749778596, "time_this_iter_s": 0.7256207466125488, "time_total_s": 55.26327133178711, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f51f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 55.26327133178711, "timesteps_since_restore": 0, "iterations_since_restore": 150, "perf": {"cpu_util_percent": 57.4, "ram_util_percent": 89.9}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 37.388000000000005, "episode_len_mean": 20.52, "episode_media": {}, "episodes_this_iter": 48, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 18.694000000000003}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 87.6, 85.4, 85.8, -4.999999999999998, -4.999999999999998, 86.6, 86.0, -4.999999999999998, 86.4, 89.2, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 85.2, -4.999999999999998, -4.999999999999998, 86.6, -4.999999999999998, 86.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, 88.6, 85.2, -4.999999999999998, 87.2, -4.999999999999998, 88.4, -4.999999999999998, 89.0, 88.4, 87.0, -4.999999999999998, 85.2, -4.999999999999998, 86.0, 87.8, 87.4, 86.8, -4.999999999999998, 89.4, -4.999999999999998, 89.0, -4.999999999999998, 88.8, -4.999999999999998, -4.999999999999998, 85.4, 87.0, 86.4, 88.8, 85.4, 85.8, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, 88.8, 88.6, -4.999999999999998, -4.999999999999998, 85.2, 88.4], "episode_lengths": [25, 13, 24, 22, 25, 25, 18, 21, 25, 19, 5, 25, 21, 25, 25, 25, 25, 25, 25, 17, 25, 25, 25, 25, 25, 17, 25, 25, 25, 18, 25, 20, 25, 25, 25, 7, 8, 25, 25, 15, 25, 9, 25, 6, 9, 16, 25, 25, 25, 21, 12, 14, 17, 25, 4, 25, 6, 25, 7, 25, 25, 24, 16, 19, 7, 24, 22, 25, 4, 25, 25, 25, 25, 22, 25, 25, 25, 20, 25, 25, 25, 25, 25, 25, 4, 25, 25, 25, 10, 25, 25, 25, 15, 25, 7, 8, 25, 25, 25, 9], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, 98.8, -11.2, -12.3, 97.7, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -10.4, 99.6, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 97.6, -12.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 99.3, -10.7, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -10.5, 99.5, 99.2, -10.8, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -11.1, 98.9, -11.3, 98.7, 98.4, -11.6, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -11.5, 98.5, -11.8, 98.2, 99.4, -10.6, -12.3, 97.7, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.4, 97.6, 99.2, -10.8]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3709335151439211, "mean_inference_ms": 1.6159667229992314, "mean_action_processing_ms": 0.08688698146467554, "mean_env_wait_ms": 0.08454629585670691, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 151000, "timesteps_this_iter": 0, "agent_timesteps_total": 302000, "timers": {"sample_time_ms": 594.974, "sample_throughput": 1680.745, "load_time_ms": 1.327, "load_throughput": 753747.619, "learn_time_ms": 99.8, "learn_throughput": 10020.012, "update_time_ms": 3.262}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 5.169878828456423e-27, "cur_lr": 0.0005000000000000001, "total_loss": 1032.044012451172, "policy_loss": -0.0022795207798480986, "vf_loss": 1032.0497192382813, "vf_explained_var": 0.039431655406951906, "kl": 0.002834970115067792, "entropy": 0.34363667070865633, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 151000, "num_agent_steps_sampled": 302000, "num_steps_trained": 151000, "num_agent_steps_trained": 302000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 9948, "training_iteration": 151, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-38", "timestamp": 1749778598, "time_this_iter_s": 1.3345487117767334, "time_total_s": 56.59782004356384, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018301e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 56.59782004356384, "timesteps_since_restore": 0, "iterations_since_restore": 151, "perf": {"cpu_util_percent": 22.15, "ram_util_percent": 90.0}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 39.34, "episode_len_mean": 19.78, "episode_media": {}, "episodes_this_iter": 50, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 19.669999999999998}, "custom_metrics": {}, "hist_stats": {"episode_reward": [87.8, 87.4, 86.8, -4.999999999999998, 89.4, -4.999999999999998, 89.0, -4.999999999999998, 88.8, -4.999999999999998, -4.999999999999998, 85.4, 87.0, 86.4, 88.8, 85.4, 85.8, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, 88.8, 88.6, -4.999999999999998, -4.999999999999998, 85.2, 88.4, -4.999999999999998, 85.8, 86.4, -4.999999999999998, 88.8, 86.0, 88.4, -4.999999999999998, -4.999999999999998, 87.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, 85.8, -4.999999999999998, 88.6, 88.4, 85.8, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, 87.8, -4.999999999999998, -4.999999999999998, 87.8, 86.6, 86.6, 86.6, -4.999999999999998, 88.2, 86.6, 87.8, -4.999999999999998, 85.2, -4.999999999999998, 86.6, 89.4, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998], "episode_lengths": [12, 14, 17, 25, 4, 25, 6, 25, 7, 25, 25, 24, 16, 19, 7, 24, 22, 25, 4, 25, 25, 25, 25, 22, 25, 25, 25, 20, 25, 25, 25, 25, 25, 25, 4, 25, 25, 25, 10, 25, 25, 25, 15, 25, 7, 8, 25, 25, 25, 9, 25, 22, 19, 25, 7, 21, 9, 25, 25, 12, 25, 25, 25, 25, 25, 25, 25, 7, 22, 25, 8, 9, 22, 14, 25, 25, 25, 25, 25, 9, 12, 25, 25, 12, 18, 18, 18, 25, 10, 18, 12, 25, 25, 25, 18, 4, 25, 25, 11, 25], "policy_shared_policy_reward": [-11.1, 98.9, -11.3, 98.7, 98.4, -11.6, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.5, 99.5, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -11.5, 98.5, -11.8, 98.2, 99.4, -10.6, -12.3, 97.7, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.4, 97.6, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -11.8, 98.2, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -12.0, 98.0, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 99.2, -10.8, -12.100000000000001, 97.9, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -11.700000000000001, 98.3, 98.3, -11.700000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -11.700000000000001, 98.3, -11.1, 98.9, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3704888593721992, "mean_inference_ms": 1.6239214568118674, "mean_action_processing_ms": 0.08692273410088626, "mean_env_wait_ms": 0.0844400498848603, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 152000, "timesteps_this_iter": 0, "agent_timesteps_total": 304000, "timers": {"sample_time_ms": 654.534, "sample_throughput": 1527.805, "load_time_ms": 1.433, "load_throughput": 697771.419, "learn_time_ms": 99.712, "learn_throughput": 10028.882, "update_time_ms": 3.182}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 2.5849394142282116e-27, "cur_lr": 0.0005000000000000001, "total_loss": 1250.6603271484375, "policy_loss": -0.0029878383211325854, "vf_loss": 1250.666796875, "vf_explained_var": 0.025391751527786256, "kl": 0.0037254896217870925, "entropy": 0.3471419632434845, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 152000, "num_agent_steps_sampled": 304000, "num_steps_trained": 152000, "num_agent_steps_trained": 304000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 9998, "training_iteration": 152, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-39", "timestamp": 1749778599, "time_this_iter_s": 0.9089875221252441, "time_total_s": 57.50680756568909, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018224a60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 57.50680756568909, "timesteps_since_restore": 0, "iterations_since_restore": 152, "perf": {"cpu_util_percent": 22.4, "ram_util_percent": 90.15}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 43.943999999999996, "episode_len_mean": 19.31, "episode_media": {}, "episodes_this_iter": 55, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 21.971999999999998}, "custom_metrics": {}, "hist_stats": {"episode_reward": [86.0, 88.4, -4.999999999999998, -4.999999999999998, 87.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, 85.8, -4.999999999999998, 88.6, 88.4, 85.8, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, 87.8, -4.999999999999998, -4.999999999999998, 87.8, 86.6, 86.6, 86.6, -4.999999999999998, 88.2, 86.6, 87.8, -4.999999999999998, 85.2, -4.999999999999998, 86.6, 89.4, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, 87.8, 87.0, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, 85.4, 88.6, 88.4, 85.8, 88.8, -4.999999999999998, -4.999999999999998, 87.8, -4.999999999999998, -4.999999999999998, 88.8, 87.0, 88.4, 86.6, -4.999999999999998, 85.4, 86.6, 89.4, 86.2, 88.4, 88.4, -4.999999999999998, -4.999999999999998, 86.8, 88.8, -4.999999999999998, 88.8, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 85.4, 86.6, 89.4, 85.4, 88.6, -4.999999999999998], "episode_lengths": [21, 9, 25, 25, 12, 25, 25, 25, 25, 25, 25, 25, 7, 22, 25, 8, 9, 22, 14, 25, 25, 25, 25, 25, 9, 12, 25, 25, 12, 18, 18, 18, 25, 10, 18, 12, 25, 25, 25, 18, 4, 25, 25, 11, 25, 25, 22, 25, 12, 16, 25, 25, 22, 25, 25, 24, 8, 9, 22, 7, 25, 25, 12, 25, 25, 7, 16, 9, 18, 25, 24, 18, 4, 20, 9, 9, 25, 25, 17, 7, 25, 7, 8, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 17, 24, 18, 4, 24, 8, 25], "policy_shared_policy_reward": [-12.0, 98.0, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 99.2, -10.8, -12.100000000000001, 97.9, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -11.700000000000001, 98.3, 98.3, -11.700000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -11.700000000000001, 98.3, -11.1, 98.9, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -11.1, 98.9, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, 99.3, -10.7, 99.2, -10.8, 97.9, -12.100000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -11.5, 98.5, 99.2, -10.8, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -11.700000000000001, 98.3, 99.7, -10.3, -11.9, 98.1, 99.2, -10.8, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.4, -11.6, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.4, -11.6, 97.7, -12.3, 98.3, -11.700000000000001, 99.7, -10.3, 97.7, -12.3, 99.3, -10.7, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.37060209916956993, "mean_inference_ms": 1.6309846716103413, "mean_action_processing_ms": 0.08711592301637765, "mean_env_wait_ms": 0.08458949785566026, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 153000, "timesteps_this_iter": 0, "agent_timesteps_total": 306000, "timers": {"sample_time_ms": 646.179, "sample_throughput": 1547.559, "load_time_ms": 1.367, "load_throughput": 731760.355, "learn_time_ms": 100.589, "learn_throughput": 9941.404, "update_time_ms": 3.135}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.2924697071141058e-27, "cur_lr": 0.0005000000000000001, "total_loss": 1453.0022827148437, "policy_loss": -0.0013279594480991364, "vf_loss": 1453.0069946289063, "vf_explained_var": 0.018781375885009766, "kl": 0.002264641434440051, "entropy": 0.3353485196828842, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 153000, "num_agent_steps_sampled": 306000, "num_steps_trained": 153000, "num_agent_steps_trained": 306000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 10053, "training_iteration": 153, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-40", "timestamp": 1749778600, "time_this_iter_s": 1.0366168022155762, "time_total_s": 58.54342436790466, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018224670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 58.54342436790466, "timesteps_since_restore": 0, "iterations_since_restore": 153, "perf": {"cpu_util_percent": 30.6, "ram_util_percent": 90.4}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 42.11600000000001, "episode_len_mean": 19.43, "episode_media": {}, "episodes_this_iter": 49, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 21.057999999999996}, "custom_metrics": {}, "hist_stats": {"episode_reward": [87.0, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, 85.4, 88.6, 88.4, 85.8, 88.8, -4.999999999999998, -4.999999999999998, 87.8, -4.999999999999998, -4.999999999999998, 88.8, 87.0, 88.4, 86.6, -4.999999999999998, 85.4, 86.6, 89.4, 86.2, 88.4, 88.4, -4.999999999999998, -4.999999999999998, 86.8, 88.8, -4.999999999999998, 88.8, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 85.4, 86.6, 89.4, 85.4, 88.6, -4.999999999999998, 85.6, 85.4, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, 86.0, -4.999999999999998, 85.8, -4.999999999999998, 88.8, 87.2, 85.6, 88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.39999999999999, 87.8, -4.999999999999998, 87.4, -4.999999999999998, 88.4, -4.999999999999998, 88.8, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, 87.4, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, 88.4, 88.8], "episode_lengths": [16, 25, 25, 22, 25, 25, 24, 8, 9, 22, 7, 25, 25, 12, 25, 25, 7, 16, 9, 18, 25, 24, 18, 4, 20, 9, 9, 25, 25, 17, 7, 25, 7, 8, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 17, 24, 18, 4, 24, 8, 25, 23, 24, 21, 25, 25, 25, 25, 25, 25, 9, 21, 25, 22, 25, 7, 15, 23, 7, 25, 25, 25, 25, 25, 19, 12, 25, 14, 25, 9, 25, 7, 9, 25, 25, 25, 7, 25, 14, 25, 9, 25, 25, 25, 25, 25, 17, 25, 9, 7], "policy_shared_policy_reward": [98.5, -11.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, 99.3, -10.7, 99.2, -10.8, 97.9, -12.100000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -11.5, 98.5, 99.2, -10.8, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -11.700000000000001, 98.3, 99.7, -10.3, -11.9, 98.1, 99.2, -10.8, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.4, -11.6, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.4, -11.6, 97.7, -12.3, 98.3, -11.700000000000001, 99.7, -10.3, 97.7, -12.3, 99.3, -10.7, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, 97.7, -12.3, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -12.0, 98.0, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -11.4, 98.6, -12.200000000000001, 97.8, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -11.1, 98.9, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, 99.2, -10.8, 99.4, -10.6]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3703572296664261, "mean_inference_ms": 1.632194117557252, "mean_action_processing_ms": 0.08711635767968502, "mean_env_wait_ms": 0.08466400672485029, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 154000, "timesteps_this_iter": 0, "agent_timesteps_total": 308000, "timers": {"sample_time_ms": 645.599, "sample_throughput": 1548.948, "load_time_ms": 1.34, "load_throughput": 746091.752, "learn_time_ms": 101.535, "learn_throughput": 9848.803, "update_time_ms": 3.12}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 6.462348535570529e-28, "cur_lr": 0.0005000000000000001, "total_loss": 1082.4164611816407, "policy_loss": -0.0054943164810538295, "vf_loss": 1082.4256958007813, "vf_explained_var": 0.015905773639678954, "kl": 0.010289598484540674, "entropy": 0.3716688334941864, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 154000, "num_agent_steps_sampled": 308000, "num_steps_trained": 154000, "num_agent_steps_trained": 308000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 10102, "training_iteration": 154, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-40", "timestamp": 1749778600, "time_this_iter_s": 0.35699939727783203, "time_total_s": 58.900423765182495, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c9550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 58.900423765182495, "timesteps_since_restore": 0, "iterations_since_restore": 154, "perf": {"cpu_util_percent": 35.1, "ram_util_percent": 90.3}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 41.184000000000005, "episode_len_mean": 19.58, "episode_media": {}, "episodes_this_iter": 52, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 20.592}, "custom_metrics": {}, "hist_stats": {"episode_reward": [85.4, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, 86.0, -4.999999999999998, 85.8, -4.999999999999998, 88.8, 87.2, 85.6, 88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.39999999999999, 87.8, -4.999999999999998, 87.4, -4.999999999999998, 88.4, -4.999999999999998, 88.8, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, 87.4, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, -4.999999999999998, 88.4, 88.8, -4.999999999999998, 86.2, -4.999999999999998, 86.6, -4.999999999999998, 87.2, 87.8, 87.8, -4.999999999999998, 87.6, 85.8, -4.999999999999998, 88.8, -4.999999999999998, 89.4, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.2, 88.8, -4.999999999999998, -4.999999999999998, 86.6, -4.999999999999998, 85.4, -4.999999999999998, 86.6, 86.6, -4.999999999999998, 88.4, 85.2, -4.999999999999998, 85.8, 88.4, 86.2, 86.4, -4.999999999999998, 87.8, -4.999999999999998, 85.8, -4.999999999999998, 88.8, 89.0, -4.999999999999998, 89.4, -4.999999999999998, 87.4, 87.2, -4.999999999999998], "episode_lengths": [24, 21, 25, 25, 25, 25, 25, 25, 9, 21, 25, 22, 25, 7, 15, 23, 7, 25, 25, 25, 25, 25, 19, 12, 25, 14, 25, 9, 25, 7, 9, 25, 25, 25, 7, 25, 14, 25, 9, 25, 25, 25, 25, 25, 17, 25, 9, 7, 25, 20, 25, 18, 25, 15, 12, 12, 25, 13, 22, 25, 7, 25, 4, 25, 9, 25, 25, 25, 25, 25, 7, 25, 25, 18, 25, 24, 25, 18, 18, 25, 9, 25, 25, 22, 9, 20, 19, 25, 12, 25, 22, 25, 7, 6, 25, 4, 25, 14, 15, 25], "policy_shared_policy_reward": [97.7, -12.3, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -12.0, 98.0, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -11.4, 98.6, -12.200000000000001, 97.8, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -11.1, 98.9, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, 99.2, -10.8, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 98.1, -11.9, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -11.1, 98.9, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -11.2, 98.8, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.6, -12.4, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -12.4, 97.6, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, 99.2, -10.8, 98.1, -11.9, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -11.4, 98.6, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3699429007472943, "mean_inference_ms": 1.6291730511258045, "mean_action_processing_ms": 0.08689904291604529, "mean_env_wait_ms": 0.08451835119210617, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 155000, "timesteps_this_iter": 0, "agent_timesteps_total": 310000, "timers": {"sample_time_ms": 646.522, "sample_throughput": 1546.737, "load_time_ms": 1.302, "load_throughput": 768271.971, "learn_time_ms": 101.466, "learn_throughput": 9855.549, "update_time_ms": 3.1}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 6.462348535570529e-28, "cur_lr": 0.0005000000000000001, "total_loss": 1387.3701904296875, "policy_loss": -0.0011598337441682816, "vf_loss": 1387.37470703125, "vf_explained_var": 0.032471340894699094, "kl": 0.0018355623286328004, "entropy": 0.33694553971290586, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 155000, "num_agent_steps_sampled": 310000, "num_steps_trained": 155000, "num_agent_steps_trained": 310000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 10154, "training_iteration": 155, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-40", "timestamp": 1749778600, "time_this_iter_s": 0.3368542194366455, "time_total_s": 59.23727798461914, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f54c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 59.23727798461914, "timesteps_since_restore": 0, "iterations_since_restore": 155, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 55.941999999999986, "episode_len_mean": 17.95, "episode_media": {}, "episodes_this_iter": 59, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 27.971}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 88.8, -4.999999999999998, 89.4, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.2, 88.8, -4.999999999999998, -4.999999999999998, 86.6, -4.999999999999998, 85.4, -4.999999999999998, 86.6, 86.6, -4.999999999999998, 88.4, 85.2, -4.999999999999998, 85.8, 88.4, 86.2, 86.4, -4.999999999999998, 87.8, -4.999999999999998, 85.8, -4.999999999999998, 88.8, 89.0, -4.999999999999998, 89.4, -4.999999999999998, 87.4, 87.2, -4.999999999999998, 88.8, 86.4, -4.999999999999998, 88.8, 88.6, 88.8, 85.4, 87.2, 87.8, 86.2, 87.6, 89.4, 87.4, -4.999999999999998, 88.8, 86.8, 88.4, 88.4, 85.4, 86.0, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, 88.8, 85.8, -4.999999999999998, 86.8, 86.8, 85.8, -4.999999999999998, 86.39999999999999, 89.4, -4.999999999999998, 86.2, 87.2, 86.4, 88.6, 87.2, -4.999999999999998, 86.2, 88.2, 86.2, -4.999999999999998, 87.8, 88.4, 88.8, -4.999999999999998, -4.999999999999998, 85.8, 87.2, 86.6, 85.4, -4.999999999999998, -4.999999999999998, 87.4, 87.0], "episode_lengths": [25, 7, 25, 4, 25, 9, 25, 25, 25, 25, 25, 7, 25, 25, 18, 25, 24, 25, 18, 18, 25, 9, 25, 25, 22, 9, 20, 19, 25, 12, 25, 22, 25, 7, 6, 25, 4, 25, 14, 15, 25, 7, 19, 25, 7, 8, 7, 24, 15, 12, 20, 13, 4, 14, 25, 7, 17, 9, 9, 24, 21, 15, 25, 25, 25, 25, 7, 7, 22, 25, 17, 17, 22, 25, 19, 4, 25, 20, 15, 19, 8, 15, 25, 20, 10, 20, 25, 12, 9, 7, 25, 25, 22, 15, 18, 24, 25, 25, 14, 16], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.6, -12.4, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -12.4, 97.6, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, 99.2, -10.8, 98.1, -11.9, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -11.4, 98.6, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -11.8, 98.2, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -10.7, 99.3, 99.4, -10.6, 97.7, -12.3, -11.4, 98.6, -11.1, 98.9, -11.9, 98.1, 98.8, -11.2, -10.3, 99.7, -11.3, 98.7, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -11.6, 98.4, 99.2, -10.8, 99.2, -10.8, -12.3, 97.7, -12.0, 98.0, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 99.4, -10.6, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 98.4, -11.6, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, 98.2, -11.8, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -11.4, 98.6, -11.8, 98.2, 99.3, -10.7, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -11.9, 98.1, 99.1, -10.9, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -11.1, 98.9, 99.2, -10.8, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -11.4, 98.6, -11.700000000000001, 98.3, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -11.5, 98.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.36950616549156223, "mean_inference_ms": 1.6273985715598829, "mean_action_processing_ms": 0.0869347384102533, "mean_env_wait_ms": 0.08454054974914033, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 156000, "timesteps_this_iter": 0, "agent_timesteps_total": 312000, "timers": {"sample_time_ms": 646.24, "sample_throughput": 1547.413, "load_time_ms": 1.3, "load_throughput": 769145.456, "learn_time_ms": 101.734, "learn_throughput": 9829.515, "update_time_ms": 3.211}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 3.2311742677852645e-28, "cur_lr": 0.0005000000000000001, "total_loss": 1916.872412109375, "policy_loss": -0.004135630279779434, "vf_loss": 1916.8796020507812, "vf_explained_var": 0.015806013345718385, "kl": 0.00598701200705527, "entropy": 0.30812470614910126, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 156000, "num_agent_steps_sampled": 312000, "num_steps_trained": 156000, "num_agent_steps_trained": 312000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 10213, "training_iteration": 156, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-41", "timestamp": 1749778601, "time_this_iter_s": 0.34482502937316895, "time_total_s": 59.58210301399231, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c99d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 59.58210301399231, "timesteps_since_restore": 0, "iterations_since_restore": 156, "perf": {"cpu_util_percent": 54.6, "ram_util_percent": 90.3}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 58.703999999999986, "episode_len_mean": 17.67, "episode_media": {}, "episodes_this_iter": 56, "policy_reward_min": {"shared_policy": -12.3}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 29.351999999999997}, "custom_metrics": {}, "hist_stats": {"episode_reward": [86.8, 88.4, 88.4, 85.4, 86.0, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, 88.8, 85.8, -4.999999999999998, 86.8, 86.8, 85.8, -4.999999999999998, 86.39999999999999, 89.4, -4.999999999999998, 86.2, 87.2, 86.4, 88.6, 87.2, -4.999999999999998, 86.2, 88.2, 86.2, -4.999999999999998, 87.8, 88.4, 88.8, -4.999999999999998, -4.999999999999998, 85.8, 87.2, 86.6, 85.4, -4.999999999999998, -4.999999999999998, 87.4, 87.0, 86.6, -4.999999999999998, 87.0, 87.4, 87.4, 87.8, 87.8, 88.4, 88.8, 87.6, -4.999999999999998, 88.8, 88.0, -4.999999999999998, 85.8, 86.8, 87.8, 89.0, 87.6, -4.999999999999998, 88.4, 88.2, 89.4, -4.999999999999998, 86.39999999999999, 87.0, 86.2, 87.8, 87.2, 89.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, 85.4, 88.0, 86.6, -4.999999999999998, 88.0, 88.4, 86.2, -4.999999999999998, 88.8, -4.999999999999998, -4.999999999999998, 86.0, 86.4, -4.999999999999998, 87.4, 86.4], "episode_lengths": [17, 9, 9, 24, 21, 15, 25, 25, 25, 25, 7, 7, 22, 25, 17, 17, 22, 25, 19, 4, 25, 20, 15, 19, 8, 15, 25, 20, 10, 20, 25, 12, 9, 7, 25, 25, 22, 15, 18, 24, 25, 25, 14, 16, 18, 25, 16, 14, 14, 12, 12, 9, 7, 13, 25, 7, 11, 25, 22, 17, 12, 6, 13, 25, 9, 10, 4, 25, 19, 16, 20, 12, 15, 6, 25, 25, 25, 25, 25, 7, 25, 25, 24, 25, 24, 11, 18, 25, 11, 9, 20, 25, 7, 25, 25, 21, 19, 25, 14, 19], "policy_shared_policy_reward": [-11.6, 98.4, 99.2, -10.8, 99.2, -10.8, -12.3, 97.7, -12.0, 98.0, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 99.4, -10.6, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 98.4, -11.6, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, 98.2, -11.8, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -11.4, 98.6, -11.8, 98.2, 99.3, -10.7, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -11.9, 98.1, 99.1, -10.9, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -11.1, 98.9, 99.2, -10.8, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -11.4, 98.6, -11.700000000000001, 98.3, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -11.5, 98.5, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -11.3, 98.7, -11.3, 98.7, -11.1, 98.9, 98.9, -11.1, 99.2, -10.8, -10.6, 99.4, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -11.6, 98.4, -11.1, 98.9, 99.5, -10.5, 98.8, -11.2, -2.500000000000001, -2.500000000000001, 99.2, -10.8, 99.1, -10.9, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -11.5, 98.5, -11.9, 98.1, 98.9, -11.1, -11.4, 98.6, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -11.0, 99.0, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, 99.2, -10.8, 98.1, -11.9, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -11.8, 98.2, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -11.8, 98.2]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.36940927903012555, "mean_inference_ms": 1.6285049012178572, "mean_action_processing_ms": 0.08707635668515995, "mean_env_wait_ms": 0.0845022464826933, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 157000, "timesteps_this_iter": 0, "agent_timesteps_total": 314000, "timers": {"sample_time_ms": 647.618, "sample_throughput": 1544.12, "load_time_ms": 1.302, "load_throughput": 768159.408, "learn_time_ms": 101.504, "learn_throughput": 9851.815, "update_time_ms": 3.179}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 3.2311742677852645e-28, "cur_lr": 0.0005000000000000001, "total_loss": 1630.7991577148437, "policy_loss": -0.002415262907743454, "vf_loss": 1630.8045166015625, "vf_explained_var": 0.011653977632522582, "kl": 0.002465399996382267, "entropy": 0.29733340442180634, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 157000, "num_agent_steps_sampled": 314000, "num_steps_trained": 157000, "num_agent_steps_trained": 314000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 10269, "training_iteration": 157, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-41", "timestamp": 1749778601, "time_this_iter_s": 0.36336708068847656, "time_total_s": 59.945470094680786, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018224a60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 59.945470094680786, "timesteps_since_restore": 0, "iterations_since_restore": 157, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 55.126, "episode_len_mean": 17.52, "episode_media": {}, "episodes_this_iter": 60, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 27.563000000000002}, "custom_metrics": {}, "hist_stats": {"episode_reward": [87.8, 89.0, 87.6, -4.999999999999998, 88.4, 88.2, 89.4, -4.999999999999998, 86.39999999999999, 87.0, 86.2, 87.8, 87.2, 89.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, 85.4, 88.0, 86.6, -4.999999999999998, 88.0, 88.4, 86.2, -4.999999999999998, 88.8, -4.999999999999998, -4.999999999999998, 86.0, 86.4, -4.999999999999998, 87.4, 86.4, -4.999999999999998, 89.4, 89.0, -4.999999999999998, -4.999999999999998, 87.4, 87.4, 86.8, 89.4, 85.6, -4.999999999999998, 87.4, 88.8, -4.999999999999998, -4.999999999999998, 85.6, 86.8, -4.999999999999998, -4.999999999999998, 88.2, 89.4, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 86.2, 86.6, 86.6, 89.4, 87.8, 87.4, 88.2, 86.0, 85.2, 86.4, 87.0, 86.8, -4.999999999999998, -4.999999999999998, 85.4, 89.4, -4.999999999999998, 89.4, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, 86.8, 89.4, 86.4, 87.0, 87.6, 89.4, 87.0, -4.999999999999998, 89.4, 88.0, -4.999999999999998, 85.8, -4.999999999999998], "episode_lengths": [12, 6, 13, 25, 9, 10, 4, 25, 19, 16, 20, 12, 15, 6, 25, 25, 25, 25, 25, 7, 25, 25, 24, 25, 24, 11, 18, 25, 11, 9, 20, 25, 7, 25, 25, 21, 19, 25, 14, 19, 25, 4, 6, 25, 25, 14, 14, 17, 4, 23, 25, 14, 7, 25, 25, 23, 17, 25, 25, 10, 4, 25, 4, 25, 25, 20, 18, 18, 4, 12, 14, 10, 21, 25, 19, 16, 17, 25, 25, 24, 4, 25, 4, 25, 18, 25, 25, 17, 4, 19, 16, 13, 4, 16, 25, 4, 11, 25, 22, 25], "policy_shared_policy_reward": [-11.1, 98.9, 99.5, -10.5, 98.8, -11.2, -2.500000000000001, -2.500000000000001, 99.2, -10.8, 99.1, -10.9, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -11.5, 98.5, -11.9, 98.1, 98.9, -11.1, -11.4, 98.6, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -11.0, 99.0, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, 99.2, -10.8, 98.1, -11.9, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -11.8, 98.2, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -11.3, 98.7, 98.4, -11.6, 99.7, -10.3, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -11.700000000000001, 98.3, -11.700000000000001, 98.3, -10.3, 99.7, -11.1, 98.9, -11.3, 98.7, -10.9, 99.1, -12.0, 98.0, -12.4, 97.6, -11.8, 98.2, 98.5, -11.5, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 99.7, -10.3, -11.8, 98.2, -11.5, 98.5, -11.2, 98.8, -10.3, 99.7, -11.5, 98.5, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3691966006611955, "mean_inference_ms": 1.6305410334738892, "mean_action_processing_ms": 0.08714002904407966, "mean_env_wait_ms": 0.08450641029934283, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 158000, "timesteps_this_iter": 0, "agent_timesteps_total": 316000, "timers": {"sample_time_ms": 647.486, "sample_throughput": 1544.436, "load_time_ms": 1.306, "load_throughput": 765467.752, "learn_time_ms": 101.619, "learn_throughput": 9840.663, "update_time_ms": 3.165}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.6155871338926323e-28, "cur_lr": 0.0005000000000000001, "total_loss": 1714.51171875, "policy_loss": -0.00322820843430236, "vf_loss": 1714.5179077148437, "vf_explained_var": 0.0272807240486145, "kl": 0.0029967757585166233, "entropy": 0.29536756575107576, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 158000, "num_agent_steps_sampled": 316000, "num_steps_trained": 158000, "num_agent_steps_trained": 316000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 10329, "training_iteration": 158, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-41", "timestamp": 1749778601, "time_this_iter_s": 0.33893656730651855, "time_total_s": 60.284406661987305, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018301ca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 60.284406661987305, "timesteps_since_restore": 0, "iterations_since_restore": 158, "perf": {"cpu_util_percent": 50.7, "ram_util_percent": 90.3}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 45.832, "episode_len_mean": 18.89, "episode_media": {}, "episodes_this_iter": 48, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 22.916}, "custom_metrics": {}, "hist_stats": {"episode_reward": [89.4, 85.6, -4.999999999999998, 87.4, 88.8, -4.999999999999998, -4.999999999999998, 85.6, 86.8, -4.999999999999998, -4.999999999999998, 88.2, 89.4, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 86.2, 86.6, 86.6, 89.4, 87.8, 87.4, 88.2, 86.0, 85.2, 86.4, 87.0, 86.8, -4.999999999999998, -4.999999999999998, 85.4, 89.4, -4.999999999999998, 89.4, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, 86.8, 89.4, 86.4, 87.0, 87.6, 89.4, 87.0, -4.999999999999998, 89.4, 88.0, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, 88.8, -4.999999999999998, 87.2, 86.6, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, -4.999999999999998, 88.8, 89.4, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, 89.4, -4.999999999999998, 87.0, 85.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, 85.2, -4.999999999999998, 87.0, 87.4, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, 86.0, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998], "episode_lengths": [4, 23, 25, 14, 7, 25, 25, 23, 17, 25, 25, 10, 4, 25, 4, 25, 25, 20, 18, 18, 4, 12, 14, 10, 21, 25, 19, 16, 17, 25, 25, 24, 4, 25, 4, 25, 18, 25, 25, 17, 4, 19, 16, 13, 4, 16, 25, 4, 11, 25, 22, 25, 25, 25, 25, 25, 11, 7, 25, 15, 18, 25, 4, 25, 25, 25, 20, 25, 25, 7, 4, 18, 25, 25, 25, 23, 25, 4, 25, 16, 24, 25, 25, 25, 23, 25, 25, 25, 16, 14, 25, 25, 14, 25, 25, 21, 4, 25, 25, 25], "policy_shared_policy_reward": [99.7, -10.3, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -11.700000000000001, 98.3, -11.700000000000001, 98.3, -10.3, 99.7, -11.1, 98.9, -11.3, 98.7, -10.9, 99.1, -12.0, 98.0, -12.4, 97.6, -11.8, 98.2, 98.5, -11.5, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 99.7, -10.3, -11.8, 98.2, -11.5, 98.5, -11.2, 98.8, -10.3, 99.7, -11.5, 98.5, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -10.3, 99.7, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.5, 98.5, 97.7, -12.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.36936166830994355, "mean_inference_ms": 1.6305213269033647, "mean_action_processing_ms": 0.08701996388219145, "mean_env_wait_ms": 0.08453322412822381, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 159000, "timesteps_this_iter": 0, "agent_timesteps_total": 318000, "timers": {"sample_time_ms": 646.036, "sample_throughput": 1547.902, "load_time_ms": 1.299, "load_throughput": 769851.327, "learn_time_ms": 101.26, "learn_throughput": 9875.582, "update_time_ms": 3.319}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 8.077935669463161e-29, "cur_lr": 0.0005000000000000001, "total_loss": 1069.7713195800782, "policy_loss": -0.00017890892922878265, "vf_loss": 1069.7747314453125, "vf_explained_var": 0.032608962059020995, "kl": 0.0015223468459408807, "entropy": 0.3258593797683716, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 159000, "num_agent_steps_sampled": 318000, "num_steps_trained": 159000, "num_agent_steps_trained": 318000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 10377, "training_iteration": 159, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-42", "timestamp": 1749778602, "time_this_iter_s": 0.34169912338256836, "time_total_s": 60.62610578536987, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb01821bd30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 60.62610578536987, "timesteps_since_restore": 0, "iterations_since_restore": 159, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 45.757999999999996, "episode_len_mean": 19.26, "episode_media": {}, "episodes_this_iter": 56, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 22.879}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.0, 88.8, -4.999999999999998, 87.2, 86.6, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, -4.999999999999998, 88.8, 89.4, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, 89.4, -4.999999999999998, 87.0, 85.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, 85.2, -4.999999999999998, 87.0, 87.4, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, 86.0, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 89.2, -4.999999999999998, 87.0, 86.4, 87.0, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.6, 87.6, 87.4, 87.0, 85.8, 89.4, -4.999999999999998, 86.39999999999999, 89.4, 89.4, 88.2, 85.2, 85.4, 87.8, 89.4, 86.2, 85.8, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, 87.8, 88.6, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 87.2, -4.999999999999998, 85.4, -4.999999999999998, 87.2, 86.4, 87.0], "episode_lengths": [11, 7, 25, 15, 18, 25, 4, 25, 25, 25, 20, 25, 25, 7, 4, 18, 25, 25, 25, 23, 25, 4, 25, 16, 24, 25, 25, 25, 23, 25, 25, 25, 16, 14, 25, 25, 14, 25, 25, 21, 4, 25, 25, 25, 15, 25, 13, 25, 25, 25, 25, 17, 5, 25, 16, 19, 16, 21, 25, 25, 25, 25, 23, 13, 14, 16, 22, 4, 25, 19, 4, 4, 10, 25, 24, 12, 4, 20, 22, 4, 25, 25, 25, 20, 12, 8, 25, 18, 25, 25, 25, 4, 25, 15, 25, 24, 25, 15, 19, 16], "policy_shared_policy_reward": [99.0, -11.0, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -10.3, 99.7, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.5, 98.5, 97.7, -12.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -11.8, 98.2, -11.5, 98.5, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -11.2, 98.8, -11.3, 98.7, -11.5, 98.5, -12.100000000000001, 97.9, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 98.2, -11.8, 99.7, -10.3, -10.3, 99.7, -10.9, 99.1, 97.6, -12.4, -12.3, 97.7, -11.1, 98.9, 99.7, -10.3, -11.9, 98.1, 97.9, -12.100000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, 98.9, -11.1, -10.7, 99.3, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -11.8, 98.2, -11.5, 98.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.36912736702840804, "mean_inference_ms": 1.6293187002506928, "mean_action_processing_ms": 0.08695083719876175, "mean_env_wait_ms": 0.08441708060657226, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 160000, "timesteps_this_iter": 0, "agent_timesteps_total": 320000, "timers": {"sample_time_ms": 646.941, "sample_throughput": 1545.737, "load_time_ms": 1.231, "load_throughput": 812141.35, "learn_time_ms": 101.275, "learn_throughput": 9874.085, "update_time_ms": 3.239}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 4.0389678347315807e-29, "cur_lr": 0.0005000000000000001, "total_loss": 1581.2811889648438, "policy_loss": -0.0008382204920053482, "vf_loss": 1581.28515625, "vf_explained_var": 0.025969606637954713, "kl": 0.0009080030508562764, "entropy": 0.3096002578735352, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 160000, "num_agent_steps_sampled": 320000, "num_steps_trained": 160000, "num_agent_steps_trained": 320000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 10433, "training_iteration": 160, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-42", "timestamp": 1749778602, "time_this_iter_s": 0.3467438220977783, "time_total_s": 60.97284960746765, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb01821bf70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 60.97284960746765, "timesteps_since_restore": 0, "iterations_since_restore": 160, "perf": {"cpu_util_percent": 53.1, "ram_util_percent": 90.4}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 58.718, "episode_len_mean": 17.6, "episode_media": {}, "episodes_this_iter": 56, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 29.359}, "custom_metrics": {}, "hist_stats": {"episode_reward": [87.0, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.6, 87.6, 87.4, 87.0, 85.8, 89.4, -4.999999999999998, 86.39999999999999, 89.4, 89.4, 88.2, 85.2, 85.4, 87.8, 89.4, 86.2, 85.8, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, 87.8, 88.6, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 87.2, -4.999999999999998, 85.4, -4.999999999999998, 87.2, 86.4, 87.0, 89.4, 89.4, -4.999999999999998, 85.2, 86.2, 89.2, 89.4, 86.6, 87.0, 85.2, -4.999999999999998, 85.8, 86.8, -4.999999999999998, 87.0, 87.8, 89.0, 89.0, 86.8, 85.2, 88.6, 89.4, 88.2, 87.0, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 86.8, 88.0, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, 85.6, 85.4, -4.999999999999998, -4.999999999999998, 87.6, 87.0, 87.6, 88.0, -4.999999999999998, -4.999999999999998, 85.8, 87.4, -4.999999999999998, 87.0, 89.4, 87.2, 88.2, -4.999999999999998, 87.0, 86.0], "episode_lengths": [16, 21, 25, 25, 25, 25, 23, 13, 14, 16, 22, 4, 25, 19, 4, 4, 10, 25, 24, 12, 4, 20, 22, 4, 25, 25, 25, 20, 12, 8, 25, 18, 25, 25, 25, 4, 25, 15, 25, 24, 25, 15, 19, 16, 4, 4, 25, 25, 20, 5, 4, 18, 16, 25, 25, 22, 17, 25, 16, 12, 6, 6, 17, 25, 8, 4, 10, 16, 25, 13, 25, 25, 4, 25, 17, 11, 25, 25, 14, 25, 23, 24, 25, 25, 13, 16, 13, 11, 25, 25, 22, 14, 25, 16, 4, 15, 10, 25, 16, 21], "policy_shared_policy_reward": [-11.5, 98.5, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -11.2, 98.8, -11.3, 98.7, -11.5, 98.5, -12.100000000000001, 97.9, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 98.2, -11.8, 99.7, -10.3, -10.3, 99.7, -10.9, 99.1, 97.6, -12.4, -12.3, 97.7, -11.1, 98.9, 99.7, -10.3, -11.9, 98.1, 97.9, -12.100000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, 98.9, -11.1, -10.7, 99.3, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -11.8, 98.2, -11.5, 98.5, -10.3, 99.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -11.9, 98.1, -10.4, 99.6, -10.3, 99.7, -11.700000000000001, 98.3, 98.5, -11.5, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -11.1, 98.9, 99.5, -10.5, 99.5, -10.5, 98.4, -11.6, -12.4, 97.6, 99.3, -10.7, 99.7, -10.3, -10.9, 99.1, -11.5, 98.5, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -11.5, 98.5, -11.2, 98.8, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -10.3, 99.7, -11.4, 98.6, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -12.0, 98.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.36859750234941, "mean_inference_ms": 1.6283321440241507, "mean_action_processing_ms": 0.08709556192331633, "mean_env_wait_ms": 0.08454652821232356, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 161000, "timesteps_this_iter": 0, "agent_timesteps_total": 322000, "timers": {"sample_time_ms": 507.492, "sample_throughput": 1970.475, "load_time_ms": 1.18, "load_throughput": 847162.997, "learn_time_ms": 100.119, "learn_throughput": 9988.162, "update_time_ms": 3.161}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 2.0194839173657903e-29, "cur_lr": 0.0005000000000000001, "total_loss": 1802.9847534179687, "policy_loss": -0.002139810100197792, "vf_loss": 1802.989697265625, "vf_explained_var": 0.027179396152496337, "kl": 0.005564521892422647, "entropy": 0.2816783219575882, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 161000, "num_agent_steps_sampled": 322000, "num_steps_trained": 161000, "num_agent_steps_trained": 322000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 10489, "training_iteration": 161, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-43", "timestamp": 1749778603, "time_this_iter_s": 0.3459513187408447, "time_total_s": 61.318800926208496, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018301ca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 61.318800926208496, "timesteps_since_restore": 0, "iterations_since_restore": 161, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 58.764, "episode_len_mean": 17.37, "episode_media": {}, "episodes_this_iter": 59, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 29.382}, "custom_metrics": {}, "hist_stats": {"episode_reward": [87.8, 89.0, 89.0, 86.8, 85.2, 88.6, 89.4, 88.2, 87.0, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 86.8, 88.0, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, 85.6, 85.4, -4.999999999999998, -4.999999999999998, 87.6, 87.0, 87.6, 88.0, -4.999999999999998, -4.999999999999998, 85.8, 87.4, -4.999999999999998, 87.0, 89.4, 87.2, 88.2, -4.999999999999998, 87.0, 86.0, 86.0, -4.999999999999998, 86.0, -4.999999999999998, 89.4, 89.4, 88.4, 87.2, 89.4, 86.2, 88.6, 87.8, 85.2, -4.999999999999998, 88.2, 87.8, 86.0, 87.0, -4.999999999999998, 86.0, 86.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, 87.2, 87.0, 87.4, 89.2, 89.4, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, 85.2, 86.4, 87.2, 87.0, 85.2, 88.2, 87.4, -4.999999999999998, -4.999999999999998, 87.2, 87.4, 88.2, 89.4, -4.999999999999998, 89.4, -4.999999999999998, 87.8, 85.8, 87.0, -4.999999999999998, 88.4], "episode_lengths": [12, 6, 6, 17, 25, 8, 4, 10, 16, 25, 13, 25, 25, 4, 25, 17, 11, 25, 25, 14, 25, 23, 24, 25, 25, 13, 16, 13, 11, 25, 25, 22, 14, 25, 16, 4, 15, 10, 25, 16, 21, 21, 25, 21, 25, 4, 4, 9, 15, 4, 20, 8, 12, 25, 25, 10, 12, 21, 16, 25, 21, 20, 25, 25, 25, 25, 24, 25, 15, 16, 14, 5, 4, 25, 9, 25, 25, 21, 25, 25, 19, 15, 16, 25, 10, 14, 25, 25, 15, 14, 10, 4, 25, 4, 25, 12, 22, 16, 25, 9], "policy_shared_policy_reward": [-11.1, 98.9, 99.5, -10.5, 99.5, -10.5, 98.4, -11.6, -12.4, 97.6, 99.3, -10.7, 99.7, -10.3, -10.9, 99.1, -11.5, 98.5, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -11.5, 98.5, -11.2, 98.8, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -10.3, 99.7, -11.4, 98.6, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -12.0, 98.0, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.7, -10.3, 99.2, -10.8, -11.4, 98.6, 99.7, -10.3, -11.9, 98.1, -10.7, 99.3, -11.1, 98.9, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -11.1, 98.9, -12.0, 98.0, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -11.5, 98.5, -11.3, 98.7, -10.4, 99.6, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -11.8, 98.2, -11.4, 98.6, -11.5, 98.5, -12.4, 97.6, -10.9, 99.1, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -11.3, 98.7, -10.9, 99.1, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -12.100000000000001, 97.9, -11.5, 98.5, -2.500000000000001, -2.500000000000001, 99.2, -10.8]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.36847899953167923, "mean_inference_ms": 1.63446106125584, "mean_action_processing_ms": 0.08690090606344687, "mean_env_wait_ms": 0.08443528107859866, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 162000, "timesteps_this_iter": 0, "agent_timesteps_total": 324000, "timers": {"sample_time_ms": 542.613, "sample_throughput": 1842.935, "load_time_ms": 1.171, "load_throughput": 853889.251, "learn_time_ms": 99.918, "learn_throughput": 10008.213, "update_time_ms": 3.23}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 2.0194839173657903e-29, "cur_lr": 0.0005000000000000001, "total_loss": 1702.3958740234375, "policy_loss": -0.00084473118185997, "vf_loss": 1702.3997802734375, "vf_explained_var": 0.028634113073349, "kl": 0.0029492827153094316, "entropy": 0.3127616435289383, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 162000, "num_agent_steps_sampled": 324000, "num_steps_trained": 162000, "num_agent_steps_trained": 324000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 10548, "training_iteration": 162, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-44", "timestamp": 1749778604, "time_this_iter_s": 1.2809696197509766, "time_total_s": 62.59977054595947, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018224670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 62.59977054595947, "timesteps_since_restore": 0, "iterations_since_restore": 162, "perf": {"cpu_util_percent": 39.95, "ram_util_percent": 90.4}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 56.686000000000014, "episode_len_mean": 18.74, "episode_media": {}, "episodes_this_iter": 51, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 28.343000000000004}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.6, 87.8, 85.2, -4.999999999999998, 88.2, 87.8, 86.0, 87.0, -4.999999999999998, 86.0, 86.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, 87.2, 87.0, 87.4, 89.2, 89.4, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, 85.2, 86.4, 87.2, 87.0, 85.2, 88.2, 87.4, -4.999999999999998, -4.999999999999998, 87.2, 87.4, 88.2, 89.4, -4.999999999999998, 89.4, -4.999999999999998, 87.8, 85.8, 87.0, -4.999999999999998, 88.4, 87.4, 85.2, 86.6, -4.999999999999998, 86.2, 87.8, -4.999999999999998, -4.999999999999998, 86.8, 86.2, 87.0, -4.999999999999998, 87.8, 86.8, 86.0, 88.0, -4.999999999999998, 89.2, -4.999999999999998, -4.999999999999998, 86.6, 87.2, -4.999999999999998, 87.0, -4.999999999999998, -4.999999999999998, 87.8, 85.2, -4.999999999999998, 86.6, 86.0, 86.0, 88.6, 87.6, 87.8, 88.4, -4.999999999999998, 86.0, 86.0, -4.999999999999998, -4.999999999999998, 87.2, 86.2, 87.6, 87.0, -4.999999999999998, 86.6, 85.6, 85.6, -4.999999999999998, -4.999999999999998], "episode_lengths": [8, 12, 25, 25, 10, 12, 21, 16, 25, 21, 20, 25, 25, 25, 25, 24, 25, 15, 16, 14, 5, 4, 25, 9, 25, 25, 21, 25, 25, 19, 15, 16, 25, 10, 14, 25, 25, 15, 14, 10, 4, 25, 4, 25, 12, 22, 16, 25, 9, 14, 25, 18, 25, 20, 12, 25, 25, 17, 20, 16, 25, 12, 17, 21, 11, 25, 5, 25, 25, 18, 15, 25, 16, 25, 25, 12, 25, 25, 18, 21, 21, 8, 13, 12, 9, 25, 21, 21, 25, 25, 15, 20, 13, 16, 25, 18, 23, 23, 25, 25], "policy_shared_policy_reward": [-10.7, 99.3, -11.1, 98.9, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -11.1, 98.9, -12.0, 98.0, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -11.5, 98.5, -11.3, 98.7, -10.4, 99.6, 99.7, -10.3, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -11.8, 98.2, -11.4, 98.6, -11.5, 98.5, -12.4, 97.6, -10.9, 99.1, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -11.3, 98.7, -10.9, 99.1, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -12.100000000000001, 97.9, -11.5, 98.5, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -11.3, 98.7, -12.4, 97.6, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, 98.1, -11.9, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 98.1, -11.9, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -11.6, 98.4, 98.0, -12.0, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -12.0, 98.0, -12.0, 98.0, -10.7, 99.3, -11.2, 98.8, -11.1, 98.9, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -11.9, 98.1, 98.8, -11.2, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -12.200000000000001, 97.8, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3686982858487404, "mean_inference_ms": 1.6412570971949967, "mean_action_processing_ms": 0.08687582681225596, "mean_env_wait_ms": 0.08451055726089587, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 163000, "timesteps_this_iter": 0, "agent_timesteps_total": 326000, "timers": {"sample_time_ms": 474.311, "sample_throughput": 2108.319, "load_time_ms": 1.296, "load_throughput": 771891.494, "learn_time_ms": 99.077, "learn_throughput": 10093.11, "update_time_ms": 3.133}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.0097419586828952e-29, "cur_lr": 0.0005000000000000001, "total_loss": 1733.2084106445313, "policy_loss": -0.0022932086139917374, "vf_loss": 1733.21376953125, "vf_explained_var": 0.019866865873336793, "kl": 0.002862240646261993, "entropy": 0.31077716052532195, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 163000, "num_agent_steps_sampled": 326000, "num_steps_trained": 163000, "num_agent_steps_trained": 326000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 10599, "training_iteration": 163, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-44", "timestamp": 1749778604, "time_this_iter_s": 0.3466958999633789, "time_total_s": 62.94646644592285, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb01821b790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 62.94646644592285, "timesteps_since_restore": 0, "iterations_since_restore": 163, "perf": {"cpu_util_percent": 23.2, "ram_util_percent": 90.5}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 55.626000000000005, "episode_len_mean": 19.53, "episode_media": {}, "episodes_this_iter": 49, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 27.813000000000002}, "custom_metrics": {}, "hist_stats": {"episode_reward": [87.4, 85.2, 86.6, -4.999999999999998, 86.2, 87.8, -4.999999999999998, -4.999999999999998, 86.8, 86.2, 87.0, -4.999999999999998, 87.8, 86.8, 86.0, 88.0, -4.999999999999998, 89.2, -4.999999999999998, -4.999999999999998, 86.6, 87.2, -4.999999999999998, 87.0, -4.999999999999998, -4.999999999999998, 87.8, 85.2, -4.999999999999998, 86.6, 86.0, 86.0, 88.6, 87.6, 87.8, 88.4, -4.999999999999998, 86.0, 86.0, -4.999999999999998, -4.999999999999998, 87.2, 86.2, 87.6, 87.0, -4.999999999999998, 86.6, 85.6, 85.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, 88.6, -4.999999999999998, 85.8, 86.4, -4.999999999999998, 89.4, 86.39999999999999, 87.0, 85.4, 89.4, 86.2, 87.0, 87.8, 86.8, 86.0, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, 86.8, -4.999999999999998, 87.6, 86.8, 87.2, 87.0, 86.0, -4.999999999999998, 88.0, -4.999999999999998, 86.0, 86.4, 85.4, 87.2, 87.0, 86.4, -4.999999999999998, 85.8, -4.999999999999998, 87.4, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998], "episode_lengths": [14, 25, 18, 25, 20, 12, 25, 25, 17, 20, 16, 25, 12, 17, 21, 11, 25, 5, 25, 25, 18, 15, 25, 16, 25, 25, 12, 25, 25, 18, 21, 21, 8, 13, 12, 9, 25, 21, 21, 25, 25, 15, 20, 13, 16, 25, 18, 23, 23, 25, 25, 25, 14, 8, 25, 22, 19, 25, 4, 19, 16, 24, 4, 20, 16, 12, 17, 21, 25, 22, 25, 25, 24, 25, 17, 25, 13, 17, 15, 16, 21, 25, 11, 25, 21, 19, 24, 15, 16, 19, 25, 22, 25, 14, 15, 25, 25, 25, 25, 25], "policy_shared_policy_reward": [-11.3, 98.7, -12.4, 97.6, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, 98.1, -11.9, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 98.1, -11.9, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -11.6, 98.4, 98.0, -12.0, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -12.0, 98.0, -12.0, 98.0, -10.7, 99.3, -11.2, 98.8, -11.1, 98.9, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -11.9, 98.1, 98.8, -11.2, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -12.200000000000001, 97.8, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -11.8, 98.2, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.2, -11.8, -11.5, 98.5, -12.3, 97.7, 99.7, -10.3, -11.9, 98.1, -11.5, 98.5, -11.1, 98.9, -11.6, 98.4, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -11.6, 98.4, -11.4, 98.6, -11.5, 98.5, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -11.8, 98.2, -12.3, 97.7, -11.4, 98.6, -11.5, 98.5, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3683148740511615, "mean_inference_ms": 1.638841239478146, "mean_action_processing_ms": 0.08671269104209735, "mean_env_wait_ms": 0.08437418194231215, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 164000, "timesteps_this_iter": 0, "agent_timesteps_total": 328000, "timers": {"sample_time_ms": 472.358, "sample_throughput": 2117.038, "load_time_ms": 1.205, "load_throughput": 829717.315, "learn_time_ms": 97.822, "learn_throughput": 10222.602, "update_time_ms": 3.234}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 5.048709793414476e-30, "cur_lr": 0.0005000000000000001, "total_loss": 1620.6891235351563, "policy_loss": -0.0008467312902212143, "vf_loss": 1620.6931274414062, "vf_explained_var": 0.026701068878173827, "kl": 0.0023967191649357567, "entropy": 0.3121617615222931, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 164000, "num_agent_steps_sampled": 328000, "num_steps_trained": 164000, "num_agent_steps_trained": 328000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 10648, "training_iteration": 164, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-45", "timestamp": 1749778605, "time_this_iter_s": 0.32581448554992676, "time_total_s": 63.27228093147278, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182f4e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 63.27228093147278, "timesteps_since_restore": 0, "iterations_since_restore": 164, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 51.965999999999994, "episode_len_mean": 19.79, "episode_media": {}, "episodes_this_iter": 51, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 25.983}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 87.4, 88.6, -4.999999999999998, 85.8, 86.4, -4.999999999999998, 89.4, 86.39999999999999, 87.0, 85.4, 89.4, 86.2, 87.0, 87.8, 86.8, 86.0, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, 86.8, -4.999999999999998, 87.6, 86.8, 87.2, 87.0, 86.0, -4.999999999999998, 88.0, -4.999999999999998, 86.0, 86.4, 85.4, 87.2, 87.0, 86.4, -4.999999999999998, 85.8, -4.999999999999998, 87.4, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.6, 85.6, 86.2, -4.999999999999998, 89.4, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.6, 86.6, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, 86.4, 89.4, 89.4, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, 85.8, 87.0, 89.4, 86.6, 85.2, -4.999999999999998, 87.4, 85.2, 86.0, -4.999999999999998, 86.4, 86.0, -4.999999999999998, 87.2, 87.4, 86.8, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, 87.4, 88.2, -4.999999999999998], "episode_lengths": [25, 14, 8, 25, 22, 19, 25, 4, 19, 16, 24, 4, 20, 16, 12, 17, 21, 25, 22, 25, 25, 24, 25, 17, 25, 13, 17, 15, 16, 21, 25, 11, 25, 21, 19, 24, 15, 16, 19, 25, 22, 25, 14, 15, 25, 25, 25, 25, 25, 23, 23, 20, 25, 4, 15, 25, 25, 25, 25, 23, 18, 25, 17, 25, 25, 23, 25, 19, 4, 4, 25, 9, 25, 25, 22, 16, 4, 18, 25, 25, 14, 25, 21, 25, 19, 21, 25, 15, 14, 17, 25, 25, 20, 25, 25, 15, 25, 14, 10, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -11.3, 98.7, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -11.8, 98.2, -2.500000000000001, -2.500000000000001, 99.7, -10.3, 98.2, -11.8, -11.5, 98.5, -12.3, 97.7, 99.7, -10.3, -11.9, 98.1, -11.5, 98.5, -11.1, 98.9, -11.6, 98.4, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -11.6, 98.4, -11.4, 98.6, -11.5, 98.5, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -11.8, 98.2, -12.3, 97.7, -11.4, 98.6, -11.5, 98.5, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, 97.8, -12.200000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -11.8, 98.2, 99.7, -10.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -11.5, 98.5, 99.7, -10.3, -11.700000000000001, 98.3, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -12.4, 97.6, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -11.3, 98.7, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -11.3, 98.7, 99.1, -10.9, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.36787970310870116, "mean_inference_ms": 1.6364383883041795, "mean_action_processing_ms": 0.08668018212887406, "mean_env_wait_ms": 0.08425631625296572, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 165000, "timesteps_this_iter": 0, "agent_timesteps_total": 330000, "timers": {"sample_time_ms": 471.862, "sample_throughput": 2119.265, "load_time_ms": 1.221, "load_throughput": 819008.045, "learn_time_ms": 97.222, "learn_throughput": 10285.738, "update_time_ms": 3.227}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 2.524354896707238e-30, "cur_lr": 0.0005000000000000001, "total_loss": 1473.9548706054688, "policy_loss": -0.001628182828426361, "vf_loss": 1473.9594848632812, "vf_explained_var": 0.03449752926826477, "kl": 0.0016691180187382137, "entropy": 0.30106950998306276, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 165000, "num_agent_steps_sampled": 330000, "num_steps_trained": 165000, "num_agent_steps_trained": 330000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 10699, "training_iteration": 165, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-45", "timestamp": 1749778605, "time_this_iter_s": 0.34603333473205566, "time_total_s": 63.618314266204834, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb01821b820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 63.618314266204834, "timesteps_since_restore": 0, "iterations_since_restore": 165, "perf": {"cpu_util_percent": 52.2, "ram_util_percent": 90.5}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 38.43599999999999, "episode_len_mean": 19.79, "episode_media": {}, "episodes_this_iter": 50, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 19.218}, "custom_metrics": {}, "hist_stats": {"episode_reward": [85.6, 86.2, -4.999999999999998, 89.4, 87.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.6, 86.6, -4.999999999999998, 86.8, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, 86.4, 89.4, 89.4, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, 85.8, 87.0, 89.4, 86.6, 85.2, -4.999999999999998, 87.4, 85.2, 86.0, -4.999999999999998, 86.4, 86.0, -4.999999999999998, 87.2, 87.4, 86.8, -4.999999999999998, -4.999999999999998, 86.2, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, 87.4, 88.2, -4.999999999999998, 86.39999999999999, 87.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 89.4, 86.8, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, 89.4, 88.4, -4.999999999999998, 89.4, -4.999999999999998, 88.4, -4.999999999999998, 86.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998], "episode_lengths": [23, 20, 25, 4, 15, 25, 25, 25, 25, 23, 18, 25, 17, 25, 25, 23, 25, 19, 4, 4, 25, 9, 25, 25, 22, 16, 4, 18, 25, 25, 14, 25, 21, 25, 19, 21, 25, 15, 14, 17, 25, 25, 20, 25, 25, 15, 25, 14, 10, 25, 19, 12, 25, 25, 25, 25, 25, 16, 25, 25, 25, 11, 25, 25, 25, 25, 25, 9, 25, 4, 25, 25, 25, 4, 25, 25, 25, 25, 4, 25, 4, 17, 25, 21, 25, 25, 4, 9, 25, 4, 25, 9, 25, 19, 4, 25, 25, 25, 15, 25], "policy_shared_policy_reward": [97.8, -12.200000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -11.8, 98.2, 99.7, -10.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -11.5, 98.5, 99.7, -10.3, -11.700000000000001, 98.3, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -12.4, 97.6, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -11.3, 98.7, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -11.3, 98.7, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3677205675974028, "mean_inference_ms": 1.636583266354404, "mean_action_processing_ms": 0.08677363604704086, "mean_env_wait_ms": 0.08436007108668427, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 166000, "timesteps_this_iter": 0, "agent_timesteps_total": 332000, "timers": {"sample_time_ms": 470.614, "sample_throughput": 2124.884, "load_time_ms": 1.217, "load_throughput": 821703.628, "learn_time_ms": 96.683, "learn_throughput": 10343.07, "update_time_ms": 3.052}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.262177448353619e-30, "cur_lr": 0.0005000000000000001, "total_loss": 820.2910766601562, "policy_loss": -0.001834729313850403, "vf_loss": 820.2957275390625, "vf_explained_var": 0.02962523102760315, "kl": 0.004525056331256128, "entropy": 0.28299033343791963, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 166000, "num_agent_steps_sampled": 332000, "num_steps_trained": 166000, "num_agent_steps_trained": 332000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 10749, "training_iteration": 166, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-45", "timestamp": 1749778605, "time_this_iter_s": 0.33231258392333984, "time_total_s": 63.950626850128174, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018301dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 63.950626850128174, "timesteps_since_restore": 0, "iterations_since_restore": 166, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 33.242000000000004, "episode_len_mean": 18.7, "episode_media": {}, "episodes_this_iter": 56, "policy_reward_min": {"shared_policy": -12.200000000000001}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 16.621000000000002}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 87.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 89.4, 86.8, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, 89.4, 88.4, -4.999999999999998, 89.4, -4.999999999999998, 88.4, -4.999999999999998, 86.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 87.8, 89.4, -4.999999999999998, 87.4, 86.0, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.2, 89.4, -4.999999999999998, -4.999999999999998, 89.4, 89.4, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, -4.999999999999998, 87.0, 88.8, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, 86.8, -4.999999999999998, 89.0, 87.6, 86.8, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.6, 89.4, 86.8, -4.999999999999998], "episode_lengths": [25, 16, 25, 25, 25, 11, 25, 25, 25, 25, 25, 9, 25, 4, 25, 25, 25, 4, 25, 25, 25, 25, 4, 25, 4, 17, 25, 21, 25, 25, 4, 9, 25, 4, 25, 9, 25, 19, 4, 25, 25, 25, 15, 25, 25, 4, 25, 12, 4, 25, 14, 21, 4, 25, 25, 25, 25, 5, 4, 25, 25, 4, 4, 25, 25, 7, 25, 25, 16, 7, 4, 25, 25, 25, 25, 25, 25, 22, 17, 25, 6, 13, 17, 4, 25, 25, 25, 25, 25, 4, 4, 25, 25, 25, 25, 25, 23, 4, 17, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -12.0, 98.0, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.4, 99.6, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -10.6, 99.4, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, 98.4, -11.6, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -11.2, 98.8, 98.4, -11.6, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -10.3, 99.7, -11.6, 98.4, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.36747721149851614, "mean_inference_ms": 1.6373628731612997, "mean_action_processing_ms": 0.08677499085752088, "mean_env_wait_ms": 0.08438343919132432, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 167000, "timesteps_this_iter": 0, "agent_timesteps_total": 334000, "timers": {"sample_time_ms": 469.004, "sample_throughput": 2132.177, "load_time_ms": 1.131, "load_throughput": 884202.715, "learn_time_ms": 95.445, "learn_throughput": 10477.216, "update_time_ms": 3.073}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 6.310887241768095e-31, "cur_lr": 0.0005000000000000001, "total_loss": 922.0055419921875, "policy_loss": -0.002907455069362186, "vf_loss": 922.0113647460937, "vf_explained_var": 0.018162208795547485, "kl": 0.010269706217792596, "entropy": 0.29287895262241365, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 167000, "num_agent_steps_sampled": 334000, "num_steps_trained": 167000, "num_agent_steps_trained": 334000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 10805, "training_iteration": 167, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-46", "timestamp": 1749778606, "time_this_iter_s": 0.33049893379211426, "time_total_s": 64.28112578392029, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb01821b940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 64.28112578392029, "timesteps_since_restore": 0, "iterations_since_restore": 167, "perf": {"cpu_util_percent": 52.2, "ram_util_percent": 90.6}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 34.028, "episode_len_mean": 19.28, "episode_media": {}, "episodes_this_iter": 48, "policy_reward_min": {"shared_policy": -12.3}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 17.014}, "custom_metrics": {}, "hist_stats": {"episode_reward": [89.4, -4.999999999999998, 87.4, 86.0, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.2, 89.4, -4.999999999999998, -4.999999999999998, 89.4, 89.4, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, -4.999999999999998, 87.0, 88.8, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, 86.8, -4.999999999999998, 89.0, 87.6, 86.8, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.6, 89.4, 86.8, -4.999999999999998, 87.4, 89.4, 86.8, -4.999999999999998, 86.8, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, 89.4, -4.999999999999998, 88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, 85.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.0, -4.999999999999998, 86.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, 88.8, 87.0, -4.999999999999998, -4.999999999999998, 86.6, -4.999999999999998, 86.8, 86.2, -4.999999999999998, 89.4, -4.999999999999998], "episode_lengths": [4, 25, 14, 21, 4, 25, 25, 25, 25, 5, 4, 25, 25, 4, 4, 25, 25, 7, 25, 25, 16, 7, 4, 25, 25, 25, 25, 25, 25, 22, 17, 25, 6, 13, 17, 4, 25, 25, 25, 25, 25, 4, 4, 25, 25, 25, 25, 25, 23, 4, 17, 25, 14, 4, 17, 25, 17, 25, 4, 25, 25, 25, 25, 24, 25, 4, 25, 7, 25, 25, 25, 25, 25, 9, 23, 25, 25, 25, 25, 25, 25, 6, 25, 20, 25, 25, 25, 25, 22, 7, 16, 25, 25, 18, 25, 17, 20, 25, 4, 25], "policy_shared_policy_reward": [-10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -12.0, 98.0, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.4, 99.6, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -10.6, 99.4, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, 98.4, -11.6, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -11.2, 98.8, 98.4, -11.6, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -10.3, 99.7, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -11.3, 98.7, 99.7, -10.3, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, 99.4, -10.6, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 98.1, -11.9, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3672682009829718, "mean_inference_ms": 1.6350579815253121, "mean_action_processing_ms": 0.08664109500536529, "mean_env_wait_ms": 0.0842597513826156, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 168000, "timesteps_this_iter": 0, "agent_timesteps_total": 336000, "timers": {"sample_time_ms": 466.987, "sample_throughput": 2141.389, "load_time_ms": 1.11, "load_throughput": 901264.343, "learn_time_ms": 95.469, "learn_throughput": 10474.578, "update_time_ms": 3.059}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 6.310887241768095e-31, "cur_lr": 0.0005000000000000001, "total_loss": 813.5190856933593, "policy_loss": -0.001846674084663391, "vf_loss": 813.5237548828125, "vf_explained_var": 0.02496795654296875, "kl": 0.003848156262900612, "entropy": 0.2830399751663208, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 168000, "num_agent_steps_sampled": 336000, "num_steps_trained": 168000, "num_agent_steps_trained": 336000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 10853, "training_iteration": 168, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-46", "timestamp": 1749778606, "time_this_iter_s": 0.3362131118774414, "time_total_s": 64.61733889579773, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb01821b1f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 64.61733889579773, "timesteps_since_restore": 0, "iterations_since_restore": 168, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 30.232000000000003, "episode_len_mean": 20.22, "episode_media": {}, "episodes_this_iter": 51, "policy_reward_min": {"shared_policy": -12.3}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 15.116}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 87.4, 89.4, 86.8, -4.999999999999998, 86.8, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, 89.4, -4.999999999999998, 88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, 85.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.0, -4.999999999999998, 86.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, 88.8, 87.0, -4.999999999999998, -4.999999999999998, 86.6, -4.999999999999998, 86.8, 86.2, -4.999999999999998, 89.4, -4.999999999999998, 86.6, 89.4, -4.999999999999998, -4.999999999999998, 89.4, 86.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, 87.8, 86.2, 87.8, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 88.2, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, 87.6, 85.4, -4.999999999999998, 85.8, -4.999999999999998, 89.4, -4.999999999999998, 89.4], "episode_lengths": [25, 14, 4, 17, 25, 17, 25, 4, 25, 25, 25, 25, 24, 25, 4, 25, 7, 25, 25, 25, 25, 25, 9, 23, 25, 25, 25, 25, 25, 25, 6, 25, 20, 25, 25, 25, 25, 22, 7, 16, 25, 25, 18, 25, 17, 20, 25, 4, 25, 18, 4, 25, 25, 4, 20, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 4, 25, 25, 25, 19, 25, 25, 25, 14, 25, 25, 12, 20, 12, 25, 4, 25, 25, 10, 4, 25, 25, 25, 25, 7, 13, 24, 25, 22, 25, 4, 25, 4], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -11.3, 98.7, 99.7, -10.3, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, 99.4, -10.6, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 98.1, -11.9, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -11.9, 98.1, -11.1, 98.9, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 98.8, -11.2, 97.7, -12.3, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.36669148854069383, "mean_inference_ms": 1.633732857765134, "mean_action_processing_ms": 0.08658249369944575, "mean_env_wait_ms": 0.08422519567869123, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 169000, "timesteps_this_iter": 0, "agent_timesteps_total": 338000, "timers": {"sample_time_ms": 528.223, "sample_throughput": 1893.139, "load_time_ms": 1.178, "load_throughput": 848911.917, "learn_time_ms": 95.441, "learn_throughput": 10477.635, "update_time_ms": 2.799}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 3.1554436208840474e-31, "cur_lr": 0.0005000000000000001, "total_loss": 817.9972839355469, "policy_loss": -0.0012495443224906921, "vf_loss": 818.0015197753906, "vf_explained_var": 0.04016391634941101, "kl": 0.006897003456986184, "entropy": 0.2980509877204895, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 169000, "num_agent_steps_sampled": 338000, "num_steps_trained": 169000, "num_agent_steps_trained": 338000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 10904, "training_iteration": 169, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-47", "timestamp": 1749778607, "time_this_iter_s": 0.9491863250732422, "time_total_s": 65.56652522087097, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb01821b8b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 65.56652522087097, "timesteps_since_restore": 0, "iterations_since_restore": 169, "perf": {"cpu_util_percent": 41.2, "ram_util_percent": 90.55}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 32.983999999999995, "episode_len_mean": 19.99, "episode_media": {}, "episodes_this_iter": 51, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 16.492}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, 89.4, 86.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, 87.8, 86.2, 87.8, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 88.2, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, 87.6, 85.4, -4.999999999999998, 85.8, -4.999999999999998, 89.4, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, 85.2, 89.4, -4.999999999999998, -4.999999999999998, 87.8, 88.0, -4.999999999999998, 86.39999999999999, 87.8, 86.4, 87.6, 89.4, -4.999999999999998, 87.4, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 86.0, 87.0, -4.999999999999998, -4.999999999999998, 87.8, 85.8, -4.999999999999998, 88.6, 87.2, 87.0, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998], "episode_lengths": [25, 25, 4, 20, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 4, 25, 25, 25, 19, 25, 25, 25, 14, 25, 25, 12, 20, 12, 25, 4, 25, 25, 10, 4, 25, 25, 25, 25, 7, 13, 24, 25, 22, 25, 4, 25, 4, 25, 25, 14, 25, 25, 4, 25, 25, 12, 11, 25, 19, 12, 19, 13, 4, 25, 14, 25, 4, 25, 25, 21, 16, 25, 25, 12, 22, 25, 8, 15, 16, 25, 13, 25, 25, 25, 7, 25, 4, 25, 25, 25, 21, 25, 25, 21, 25, 25, 25, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -11.9, 98.1, -11.1, 98.9, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 98.8, -11.2, 97.7, -12.3, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -12.4, 97.6, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -11.0, 99.0, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -11.1, 98.9, -11.8, 98.2, -11.2, 98.8, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -11.4, 98.6, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3669713453406976, "mean_inference_ms": 1.639016288266646, "mean_action_processing_ms": 0.08672008255182653, "mean_env_wait_ms": 0.08432808291626387, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 170000, "timesteps_this_iter": 0, "agent_timesteps_total": 340000, "timers": {"sample_time_ms": 525.864, "sample_throughput": 1901.633, "load_time_ms": 1.385, "load_throughput": 722259.264, "learn_time_ms": 95.397, "learn_throughput": 10482.555, "update_time_ms": 2.788}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 3.1554436208840474e-31, "cur_lr": 0.0005000000000000001, "total_loss": 1078.0111511230468, "policy_loss": -0.0024178102612495422, "vf_loss": 1078.0164001464843, "vf_explained_var": 0.045285916328430174, "kl": 0.0036309121749166563, "entropy": 0.28261602520942686, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 170000, "num_agent_steps_sampled": 340000, "num_steps_trained": 170000, "num_agent_steps_trained": 340000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 10955, "training_iteration": 170, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-47", "timestamp": 1749778607, "time_this_iter_s": 0.3358185291290283, "time_total_s": 65.90234375, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018224550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 65.90234375, "timesteps_since_restore": 0, "iterations_since_restore": 170, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 34.748000000000005, "episode_len_mean": 20.19, "episode_media": {}, "episodes_this_iter": 50, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 17.374000000000002}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 87.4, -4.999999999999998, 85.2, 89.4, -4.999999999999998, -4.999999999999998, 87.8, 88.0, -4.999999999999998, 86.39999999999999, 87.8, 86.4, 87.6, 89.4, -4.999999999999998, 87.4, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, 86.0, 87.0, -4.999999999999998, -4.999999999999998, 87.8, 85.8, -4.999999999999998, 88.6, 87.2, 87.0, -4.999999999999998, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, 86.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.4, 87.0, 88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, 88.6, 89.4, -4.999999999999998, -4.999999999999998, 86.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, 88.8, -4.999999999999998, 86.4, -4.999999999999998, -4.999999999999998, 89.4, 85.8, -4.999999999999998, 85.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, 87.8, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, 87.8, -4.999999999999998, 87.8, -4.999999999999998], "episode_lengths": [25, 14, 25, 25, 4, 25, 25, 12, 11, 25, 19, 12, 19, 13, 4, 25, 14, 25, 4, 25, 25, 21, 16, 25, 25, 12, 22, 25, 8, 15, 16, 25, 13, 25, 25, 25, 7, 25, 4, 25, 25, 25, 21, 25, 25, 21, 25, 25, 25, 25, 25, 25, 19, 16, 7, 25, 25, 25, 25, 14, 25, 8, 4, 25, 25, 19, 25, 25, 25, 25, 25, 25, 25, 25, 20, 7, 25, 19, 25, 25, 4, 22, 25, 23, 25, 25, 25, 7, 12, 18, 25, 25, 25, 25, 25, 24, 12, 25, 12, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -12.4, 97.6, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -11.0, 99.0, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -11.1, 98.9, -11.8, 98.2, -11.2, 98.8, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -11.4, 98.6, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -11.5, 98.5, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -11.1, 98.9, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3667578531742936, "mean_inference_ms": 1.6382668575653383, "mean_action_processing_ms": 0.08664732495762963, "mean_env_wait_ms": 0.0842494370673643, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 171000, "timesteps_this_iter": 0, "agent_timesteps_total": 342000, "timers": {"sample_time_ms": 524.326, "sample_throughput": 1907.209, "load_time_ms": 1.431, "load_throughput": 698608.215, "learn_time_ms": 96.205, "learn_throughput": 10394.422, "update_time_ms": 2.821}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.5777218104420237e-31, "cur_lr": 0.0005000000000000001, "total_loss": 918.3230346679687, "policy_loss": -0.001909327507019043, "vf_loss": 918.32783203125, "vf_explained_var": 0.025054186582565308, "kl": 0.002719874472557704, "entropy": 0.28908167481422425, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 171000, "num_agent_steps_sampled": 342000, "num_steps_trained": 171000, "num_agent_steps_trained": 342000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 11005, "training_iteration": 171, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-48", "timestamp": 1749778608, "time_this_iter_s": 0.34255433082580566, "time_total_s": 66.2448980808258, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c9c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 66.2448980808258, "timesteps_since_restore": 0, "iterations_since_restore": 171, "perf": {"cpu_util_percent": 41.4, "ram_util_percent": 90.6}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 36.647999999999996, "episode_len_mean": 19.71, "episode_media": {}, "episodes_this_iter": 50, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 18.324}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, 86.4, 87.0, 88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, 88.6, 89.4, -4.999999999999998, -4.999999999999998, 86.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.2, 88.8, -4.999999999999998, 86.4, -4.999999999999998, -4.999999999999998, 89.4, 85.8, -4.999999999999998, 85.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, 87.8, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, 87.8, -4.999999999999998, 87.8, -4.999999999999998, 88.0, 89.4, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 86.2, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, 89.4, -4.999999999999998, 87.0, -4.999999999999998, 87.0, 88.8, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 86.2, 89.4, -4.999999999999998, 85.8, 89.4, 85.4, -4.999999999999998, 88.8, 86.6, 88.8, 86.2, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, 85.2, -4.999999999999998, 88.4, 87.2, -4.999999999999998, 86.6], "episode_lengths": [25, 25, 19, 16, 7, 25, 25, 25, 25, 14, 25, 8, 4, 25, 25, 19, 25, 25, 25, 25, 25, 25, 25, 25, 20, 7, 25, 19, 25, 25, 4, 22, 25, 23, 25, 25, 25, 7, 12, 18, 25, 25, 25, 25, 25, 24, 12, 25, 12, 25, 11, 4, 25, 25, 4, 25, 20, 25, 4, 25, 25, 25, 25, 25, 25, 23, 25, 4, 25, 16, 25, 16, 7, 25, 14, 25, 25, 4, 25, 20, 4, 25, 22, 4, 24, 25, 7, 18, 7, 20, 25, 25, 9, 25, 25, 25, 9, 15, 25, 18], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -11.5, 98.5, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -11.1, 98.9, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, 98.5, -11.5, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, 99.7, -10.3, 97.7, -12.3, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -11.700000000000001, 98.3, -10.6, 99.4, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3661103077812949, "mean_inference_ms": 1.6344600288634503, "mean_action_processing_ms": 0.08648889960017785, "mean_env_wait_ms": 0.08403727341886671, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 172000, "timesteps_this_iter": 0, "agent_timesteps_total": 344000, "timers": {"sample_time_ms": 431.375, "sample_throughput": 2318.171, "load_time_ms": 1.37, "load_throughput": 729774.159, "learn_time_ms": 97.076, "learn_throughput": 10301.239, "update_time_ms": 2.968}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 7.888609052210118e-32, "cur_lr": 0.0005000000000000001, "total_loss": 1153.5306884765625, "policy_loss": -0.0018071189522743225, "vf_loss": 1153.5354064941407, "vf_explained_var": 0.005935114622116089, "kl": 0.003648600616775151, "entropy": 0.2933944761753082, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 172000, "num_agent_steps_sampled": 344000, "num_steps_trained": 172000, "num_agent_steps_trained": 344000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 11055, "training_iteration": 172, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-48", "timestamp": 1749778608, "time_this_iter_s": 0.345822811126709, "time_total_s": 66.59072089195251, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 66.59072089195251, "timesteps_since_restore": 0, "iterations_since_restore": 172, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 42.11599999999999, "episode_len_mean": 19.43, "episode_media": {}, "episodes_this_iter": 51, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 21.058000000000003}, "custom_metrics": {}, "hist_stats": {"episode_reward": [89.4, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 86.2, -4.999999999999998, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, 89.4, -4.999999999999998, 87.0, -4.999999999999998, 87.0, 88.8, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 86.2, 89.4, -4.999999999999998, 85.8, 89.4, 85.4, -4.999999999999998, 88.8, 86.6, 88.8, 86.2, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, 85.2, -4.999999999999998, 88.4, 87.2, -4.999999999999998, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, -4.999999999999998, 86.8, 85.4, 88.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.6, -4.999999999999998, 88.8, 89.4, 85.4, 85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, 85.8, 89.4, 87.8, -4.999999999999998, -4.999999999999998, 86.4, 87.6, 86.4, -4.999999999999998, 88.2, 85.8, -4.999999999999998, -4.999999999999998, 85.6, 85.8, 89.4, 89.4, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, 87.0, 86.4], "episode_lengths": [4, 25, 25, 4, 25, 20, 25, 4, 25, 25, 25, 25, 25, 25, 23, 25, 4, 25, 16, 25, 16, 7, 25, 14, 25, 25, 4, 25, 20, 4, 25, 22, 4, 24, 25, 7, 18, 7, 20, 25, 25, 9, 25, 25, 25, 9, 15, 25, 18, 25, 25, 25, 25, 11, 25, 17, 24, 10, 25, 25, 25, 16, 25, 25, 25, 25, 25, 18, 25, 7, 4, 24, 22, 25, 25, 25, 24, 22, 4, 12, 25, 25, 19, 13, 19, 25, 10, 22, 25, 25, 23, 22, 4, 4, 25, 14, 25, 25, 16, 19], "policy_shared_policy_reward": [-10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, 98.5, -11.5, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, 99.7, -10.3, 97.7, -12.3, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -11.700000000000001, 98.3, -10.6, 99.4, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 97.7, -12.3, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -10.3, 99.7, -12.3, 97.7, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -12.100000000000001, 97.9, 99.7, -10.3, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -11.2, 98.8, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -12.100000000000001, 97.9, 99.7, -10.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -11.8, 98.2]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.36601004398235715, "mean_inference_ms": 1.6347171025740062, "mean_action_processing_ms": 0.08652939323009036, "mean_env_wait_ms": 0.08408057983632872, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 173000, "timesteps_this_iter": 0, "agent_timesteps_total": 346000, "timers": {"sample_time_ms": 431.131, "sample_throughput": 2319.48, "load_time_ms": 1.265, "load_throughput": 790721.665, "learn_time_ms": 96.733, "learn_throughput": 10337.714, "update_time_ms": 2.969}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 3.944304526105059e-32, "cur_lr": 0.0005000000000000001, "total_loss": 1336.6584228515626, "policy_loss": -0.0017878860235214233, "vf_loss": 1336.6633056640626, "vf_explained_var": 0.008828091621398925, "kl": 0.003449203289497227, "entropy": 0.30723042190074923, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 173000, "num_agent_steps_sampled": 346000, "num_steps_trained": 173000, "num_agent_steps_trained": 346000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 11106, "training_iteration": 173, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-49", "timestamp": 1749778609, "time_this_iter_s": 0.33139777183532715, "time_total_s": 66.92211866378784, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c99d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 66.92211866378784, "timesteps_since_restore": 0, "iterations_since_restore": 173, "perf": {"cpu_util_percent": 50.5, "ram_util_percent": 90.6}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 49.27800000000001, "episode_len_mean": 19.7, "episode_media": {}, "episodes_this_iter": 52, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 24.638999999999996}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 88.0, -4.999999999999998, 86.8, 85.4, 88.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.6, -4.999999999999998, 88.8, 89.4, 85.4, 85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, 85.8, 89.4, 87.8, -4.999999999999998, -4.999999999999998, 86.4, 87.6, 86.4, -4.999999999999998, 88.2, 85.8, -4.999999999999998, -4.999999999999998, 85.6, 85.8, 89.4, 89.4, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, 87.0, 86.4, -4.999999999999998, 87.2, 86.0, 85.8, 85.4, 86.4, -4.999999999999998, 89.4, 85.4, -4.999999999999998, 87.6, -4.999999999999998, 86.39999999999999, -4.999999999999998, 85.2, -4.999999999999998, 88.4, -4.999999999999998, 85.8, 88.8, -4.999999999999998, 85.2, 88.8, 87.6, 89.4, -4.999999999999998, 87.8, 85.6, -4.999999999999998, -4.999999999999998, 87.2, 85.6, 88.0, -4.999999999999998, 85.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.4, 86.0, 85.4, 87.0, 89.4, 87.4, 85.8, -4.999999999999998, -4.999999999999998, 85.6, 87.6, 88.6, -4.999999999999998], "episode_lengths": [25, 11, 25, 17, 24, 10, 25, 25, 25, 16, 25, 25, 25, 25, 25, 18, 25, 7, 4, 24, 22, 25, 25, 25, 24, 22, 4, 12, 25, 25, 19, 13, 19, 25, 10, 22, 25, 25, 23, 22, 4, 4, 25, 14, 25, 25, 16, 19, 25, 15, 21, 22, 24, 19, 25, 4, 24, 25, 13, 25, 19, 25, 25, 25, 9, 25, 22, 7, 25, 25, 7, 13, 4, 25, 12, 23, 25, 25, 15, 23, 11, 25, 24, 25, 25, 25, 25, 19, 21, 24, 16, 4, 14, 22, 25, 25, 23, 13, 8, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 97.7, -12.3, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -10.3, 99.7, -12.3, 97.7, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -12.100000000000001, 97.9, 99.7, -10.3, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -11.2, 98.8, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -12.100000000000001, 97.9, 99.7, -10.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -12.0, 98.0, -12.100000000000001, 97.9, -12.3, 97.7, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -12.3, 97.7, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -12.4, 97.6, 99.4, -10.6, -11.2, 98.8, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.1, 98.9, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -12.200000000000001, 97.8, -11.0, 99.0, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -12.0, 98.0, 97.7, -12.3, -11.5, 98.5, -10.3, 99.7, -11.3, 98.7, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -11.2, 98.8, 99.3, -10.7, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3660506406836091, "mean_inference_ms": 1.6369078216822217, "mean_action_processing_ms": 0.08671010249614294, "mean_env_wait_ms": 0.08421785812245557, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 174000, "timesteps_this_iter": 0, "agent_timesteps_total": 348000, "timers": {"sample_time_ms": 431.008, "sample_throughput": 2320.141, "load_time_ms": 1.261, "load_throughput": 793024.012, "learn_time_ms": 97.781, "learn_throughput": 10226.949, "update_time_ms": 2.87}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.9721522630525296e-32, "cur_lr": 0.0005000000000000001, "total_loss": 1714.9424072265624, "policy_loss": -0.0006804121658205986, "vf_loss": 1714.9464111328125, "vf_explained_var": 0.006594336032867432, "kl": 0.003289391352570392, "entropy": 0.3365450292825699, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 174000, "num_agent_steps_sampled": 348000, "num_steps_trained": 174000, "num_agent_steps_trained": 348000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 11158, "training_iteration": 174, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-49", "timestamp": 1749778609, "time_this_iter_s": 0.34272146224975586, "time_total_s": 67.2648401260376, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 67.2648401260376, "timesteps_since_restore": 0, "iterations_since_restore": 174, "perf": {"cpu_util_percent": 56.6, "ram_util_percent": 90.6}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 51.292, "episode_len_mean": 18.65, "episode_media": {}, "episodes_this_iter": 56, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 25.646000000000004}, "custom_metrics": {}, "hist_stats": {"episode_reward": [85.4, -4.999999999999998, 87.6, -4.999999999999998, 86.39999999999999, -4.999999999999998, 85.2, -4.999999999999998, 88.4, -4.999999999999998, 85.8, 88.8, -4.999999999999998, 85.2, 88.8, 87.6, 89.4, -4.999999999999998, 87.8, 85.6, -4.999999999999998, -4.999999999999998, 87.2, 85.6, 88.0, -4.999999999999998, 85.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.4, 86.0, 85.4, 87.0, 89.4, 87.4, 85.8, -4.999999999999998, -4.999999999999998, 85.6, 87.6, 88.6, -4.999999999999998, 85.8, 87.8, 85.6, 87.2, 87.8, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 87.2, -4.999999999999998, 89.4, 88.4, -4.999999999999998, 86.0, 88.0, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, 89.4, 88.6, 88.2, -4.999999999999998, -4.999999999999998, 88.2, 89.4, 88.4, 86.6, 86.2, 86.6, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, 88.6, 87.2, 87.0, 89.4, 87.4, 87.2, 86.6, -4.999999999999998, -4.999999999999998, 88.4, 86.4, -4.999999999999998, -4.999999999999998, 87.6, -4.999999999999998, 86.2, -4.999999999999998, -4.999999999999998, -4.999999999999998], "episode_lengths": [24, 25, 13, 25, 19, 25, 25, 25, 9, 25, 22, 7, 25, 25, 7, 13, 4, 25, 12, 23, 25, 25, 15, 23, 11, 25, 24, 25, 25, 25, 25, 19, 21, 24, 16, 4, 14, 22, 25, 25, 23, 13, 8, 25, 22, 12, 23, 15, 12, 25, 25, 4, 25, 15, 25, 4, 9, 25, 21, 11, 25, 25, 9, 25, 4, 8, 10, 25, 25, 10, 4, 9, 18, 20, 18, 17, 25, 25, 25, 24, 25, 8, 15, 16, 4, 14, 15, 18, 25, 25, 9, 19, 25, 25, 13, 25, 20, 25, 25, 25], "policy_shared_policy_reward": [-12.3, 97.7, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -12.4, 97.6, 99.4, -10.6, -11.2, 98.8, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.1, 98.9, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -12.200000000000001, 97.8, -11.0, 99.0, -2.500000000000001, -2.500000000000001, 97.7, -12.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -12.0, 98.0, 97.7, -12.3, -11.5, 98.5, -10.3, 99.7, -11.3, 98.7, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -11.2, 98.8, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -11.1, 98.9, 97.8, -12.200000000000001, -11.4, 98.6, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.3, -10.7, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 99.7, -10.3, 99.2, -10.8, 98.3, -11.700000000000001, 98.1, -11.9, -11.700000000000001, 98.3, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -11.4, 98.6, -11.5, 98.5, 99.7, -10.3, -11.3, 98.7, 98.6, -11.4, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.36579038330808267, "mean_inference_ms": 1.6368912782098834, "mean_action_processing_ms": 0.08680684833304643, "mean_env_wait_ms": 0.0842935022355369, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 175000, "timesteps_this_iter": 0, "agent_timesteps_total": 350000, "timers": {"sample_time_ms": 432.36, "sample_throughput": 2312.889, "load_time_ms": 1.364, "load_throughput": 733193.022, "learn_time_ms": 98.369, "learn_throughput": 10165.777, "update_time_ms": 2.846}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 9.860761315262648e-33, "cur_lr": 0.0005000000000000001, "total_loss": 1477.294287109375, "policy_loss": -0.0014447838068008423, "vf_loss": 1477.2986572265625, "vf_explained_var": 0.019594258069992064, "kl": 0.003708454706695541, "entropy": 0.29725967943668363, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 175000, "num_agent_steps_sampled": 350000, "num_steps_trained": 175000, "num_agent_steps_trained": 350000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 11214, "training_iteration": 175, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-49", "timestamp": 1749778609, "time_this_iter_s": 0.35048842430114746, "time_total_s": 67.61532855033875, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018301dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 67.61532855033875, "timesteps_since_restore": 0, "iterations_since_restore": 175, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 56.001999999999995, "episode_len_mean": 17.65, "episode_media": {}, "episodes_this_iter": 58, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 28.000999999999994}, "custom_metrics": {}, "hist_stats": {"episode_reward": [86.0, 88.0, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, 89.4, 88.6, 88.2, -4.999999999999998, -4.999999999999998, 88.2, 89.4, 88.4, 86.6, 86.2, 86.6, 86.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, 88.6, 87.2, 87.0, 89.4, 87.4, 87.2, 86.6, -4.999999999999998, -4.999999999999998, 88.4, 86.4, -4.999999999999998, -4.999999999999998, 87.6, -4.999999999999998, 86.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, 86.0, 89.4, -4.999999999999998, 86.2, 86.39999999999999, -4.999999999999998, 85.8, 85.2, 87.2, 87.0, 87.6, 85.6, 87.4, 88.8, 88.2, -4.999999999999998, 88.2, 88.4, 88.8, 85.8, -4.999999999999998, -4.999999999999998, 88.6, 86.8, 87.4, 87.0, 89.4, -4.999999999999998, 86.8, 85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.6, 86.2, 87.8, 86.8, -4.999999999999998, 87.6, 86.4, 87.4, -4.999999999999998, 85.2, 89.2, 87.2, 87.6, 89.4, -4.999999999999998, 88.8, 87.2, 86.2, 87.8, -4.999999999999998], "episode_lengths": [21, 11, 25, 25, 9, 25, 4, 8, 10, 25, 25, 10, 4, 9, 18, 20, 18, 17, 25, 25, 25, 24, 25, 8, 15, 16, 4, 14, 15, 18, 25, 25, 9, 19, 25, 25, 13, 25, 20, 25, 25, 25, 25, 7, 25, 21, 4, 25, 20, 19, 25, 22, 25, 15, 16, 13, 23, 14, 7, 10, 25, 10, 9, 7, 22, 25, 25, 8, 17, 14, 16, 4, 25, 17, 22, 25, 25, 25, 25, 25, 8, 20, 12, 17, 25, 13, 19, 14, 25, 25, 5, 15, 13, 4, 25, 7, 15, 20, 12, 25], "policy_shared_policy_reward": [-12.0, 98.0, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 99.3, -10.7, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 99.7, -10.3, 99.2, -10.8, 98.3, -11.700000000000001, 98.1, -11.9, -11.700000000000001, 98.3, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -11.4, 98.6, -11.5, 98.5, 99.7, -10.3, -11.3, 98.7, 98.6, -11.4, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.9, 98.1, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -12.4, 97.6, -11.4, 98.6, -11.5, 98.5, -11.2, 98.8, 97.8, -12.200000000000001, -11.3, 98.7, 99.4, -10.6, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -10.9, 99.1, 99.2, -10.8, -10.6, 99.4, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -11.6, 98.4, -11.3, 98.7, -11.5, 98.5, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -11.9, 98.1, -11.1, 98.9, -11.6, 98.4, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -11.8, 98.2, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -10.4, 99.6, -11.4, 98.6, -11.2, 98.8, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -11.4, 98.6, -11.9, 98.1, -11.1, 98.9, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.36538197157898367, "mean_inference_ms": 1.6358371690991822, "mean_action_processing_ms": 0.08688230390679644, "mean_env_wait_ms": 0.08433028790136549, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 176000, "timesteps_this_iter": 0, "agent_timesteps_total": 352000, "timers": {"sample_time_ms": 433.565, "sample_throughput": 2306.461, "load_time_ms": 1.397, "load_throughput": 715922.575, "learn_time_ms": 98.633, "learn_throughput": 10138.572, "update_time_ms": 2.729}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 4.930380657631324e-33, "cur_lr": 0.0005000000000000001, "total_loss": 1868.5922607421876, "policy_loss": -0.00174553282558918, "vf_loss": 1868.597119140625, "vf_explained_var": 0.008689188957214355, "kl": 0.008775915701182945, "entropy": 0.3127999782562256, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 176000, "num_agent_steps_sampled": 352000, "num_steps_trained": 176000, "num_agent_steps_trained": 352000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 11272, "training_iteration": 176, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-50", "timestamp": 1749778610, "time_this_iter_s": 0.3404886722564697, "time_total_s": 67.95581722259521, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018224b80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 67.95581722259521, "timesteps_since_restore": 0, "iterations_since_restore": 176, "perf": {"cpu_util_percent": 58.3, "ram_util_percent": 90.5}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 51.25, "episode_len_mean": 18.86, "episode_media": {}, "episodes_this_iter": 47, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 25.625}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 86.2, 86.39999999999999, -4.999999999999998, 85.8, 85.2, 87.2, 87.0, 87.6, 85.6, 87.4, 88.8, 88.2, -4.999999999999998, 88.2, 88.4, 88.8, 85.8, -4.999999999999998, -4.999999999999998, 88.6, 86.8, 87.4, 87.0, 89.4, -4.999999999999998, 86.8, 85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.6, 86.2, 87.8, 86.8, -4.999999999999998, 87.6, 86.4, 87.4, -4.999999999999998, 85.2, 89.2, 87.2, 87.6, 89.4, -4.999999999999998, 88.8, 87.2, 86.2, 87.8, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, 85.4, -4.999999999999998, -4.999999999999998, 86.8, 89.4, -4.999999999999998, 86.0, -4.999999999999998, 87.4, 88.4, 87.2, 88.6, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, 88.8, -4.999999999999998, 85.2, 85.4, 87.6, -4.999999999999998, 87.0, -4.999999999999998, 87.2, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, 87.0, -4.999999999999998, 85.6, 88.0, 85.6, -4.999999999999998, -4.999999999999998], "episode_lengths": [25, 20, 19, 25, 22, 25, 15, 16, 13, 23, 14, 7, 10, 25, 10, 9, 7, 22, 25, 25, 8, 17, 14, 16, 4, 25, 17, 22, 25, 25, 25, 25, 25, 8, 20, 12, 17, 25, 13, 19, 14, 25, 25, 5, 15, 13, 4, 25, 7, 15, 20, 12, 25, 25, 14, 25, 24, 25, 25, 17, 4, 25, 21, 25, 14, 9, 15, 8, 25, 11, 25, 25, 25, 22, 7, 25, 25, 24, 13, 25, 16, 25, 15, 8, 25, 25, 25, 25, 25, 25, 25, 22, 25, 16, 25, 23, 11, 23, 25, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -11.9, 98.1, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -12.4, 97.6, -11.4, 98.6, -11.5, 98.5, -11.2, 98.8, 97.8, -12.200000000000001, -11.3, 98.7, 99.4, -10.6, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -10.9, 99.1, 99.2, -10.8, -10.6, 99.4, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -11.6, 98.4, -11.3, 98.7, -11.5, 98.5, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -11.9, 98.1, -11.1, 98.9, -11.6, 98.4, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -11.8, 98.2, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -12.4, 97.6, -10.4, 99.6, -11.4, 98.6, -11.2, 98.8, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -11.4, 98.6, -11.9, 98.1, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -11.3, 98.7, 99.2, -10.8, -11.4, 98.6, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -10.6, 99.4, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -12.3, 97.7, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -11.0, 99.0, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.36577901049005235, "mean_inference_ms": 1.6368355113777922, "mean_action_processing_ms": 0.08675082731036352, "mean_env_wait_ms": 0.08427208746442172, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 177000, "timesteps_this_iter": 0, "agent_timesteps_total": 354000, "timers": {"sample_time_ms": 435.275, "sample_throughput": 2297.396, "load_time_ms": 1.382, "load_throughput": 723717.367, "learn_time_ms": 98.367, "learn_throughput": 10166.006, "update_time_ms": 2.709}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 4.930380657631324e-33, "cur_lr": 0.0005000000000000001, "total_loss": 1219.9765991210938, "policy_loss": -0.0012742944061756134, "vf_loss": 1219.9807250976562, "vf_explained_var": 0.024799996614456178, "kl": 0.004586350129971129, "entropy": 0.2879846602678299, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 177000, "num_agent_steps_sampled": 354000, "num_steps_trained": 177000, "num_agent_steps_trained": 354000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 11319, "training_iteration": 177, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-50", "timestamp": 1749778610, "time_this_iter_s": 0.33936357498168945, "time_total_s": 68.2951807975769, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018224040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 68.2951807975769, "timesteps_since_restore": 0, "iterations_since_restore": 177, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 40.14399999999999, "episode_len_mean": 20.27, "episode_media": {}, "episodes_this_iter": 50, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 20.072}, "custom_metrics": {}, "hist_stats": {"episode_reward": [86.2, 87.8, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, 85.4, -4.999999999999998, -4.999999999999998, 86.8, 89.4, -4.999999999999998, 86.0, -4.999999999999998, 87.4, 88.4, 87.2, 88.6, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, 88.8, -4.999999999999998, 85.2, 85.4, 87.6, -4.999999999999998, 87.0, -4.999999999999998, 87.2, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, 87.0, -4.999999999999998, 85.6, 88.0, 85.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.0, 87.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 85.6, 88.8, 87.4, 86.2, 87.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.0, 85.6, -4.999999999999998, 88.6, 85.8, 86.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.6, -4.999999999999998, 87.0, 85.6, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, 88.6, 88.8, 88.6, 87.2, -4.999999999999998, 88.0], "episode_lengths": [20, 12, 25, 25, 14, 25, 24, 25, 25, 17, 4, 25, 21, 25, 14, 9, 15, 8, 25, 11, 25, 25, 25, 22, 7, 25, 25, 24, 13, 25, 16, 25, 15, 8, 25, 25, 25, 25, 25, 25, 25, 22, 25, 16, 25, 23, 11, 23, 25, 25, 25, 16, 12, 25, 25, 25, 25, 25, 25, 25, 25, 17, 23, 7, 14, 20, 12, 25, 25, 25, 16, 23, 25, 8, 22, 19, 25, 25, 25, 8, 25, 16, 23, 25, 14, 25, 25, 24, 25, 25, 25, 15, 25, 25, 8, 7, 8, 15, 25, 11], "policy_shared_policy_reward": [-11.9, 98.1, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -11.3, 98.7, 99.2, -10.8, -11.4, 98.6, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -10.6, 99.4, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -12.3, 97.7, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -11.0, 99.0, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -12.200000000000001, 97.8, -10.6, 99.4, -11.3, 98.7, -11.9, 98.1, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -12.100000000000001, 97.9, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -10.6, 99.4, 99.3, -10.7, 98.6, -11.4, -2.500000000000001, -2.500000000000001, 99.0, -11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.36532684806521154, "mean_inference_ms": 1.6343241775359478, "mean_action_processing_ms": 0.08658377679458734, "mean_env_wait_ms": 0.08420614679448266, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 178000, "timesteps_this_iter": 0, "agent_timesteps_total": 356000, "timers": {"sample_time_ms": 435.907, "sample_throughput": 2294.069, "load_time_ms": 1.381, "load_throughput": 724229.72, "learn_time_ms": 99.042, "learn_throughput": 10096.711, "update_time_ms": 2.67}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 2.465190328815662e-33, "cur_lr": 0.0005000000000000001, "total_loss": 1240.644677734375, "policy_loss": -0.002298713196069002, "vf_loss": 1240.6500854492188, "vf_explained_var": 0.01242493987083435, "kl": 0.004450506779867691, "entropy": 0.30606781244277953, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 178000, "num_agent_steps_sampled": 356000, "num_steps_trained": 178000, "num_agent_steps_trained": 356000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 11369, "training_iteration": 178, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-51", "timestamp": 1749778611, "time_this_iter_s": 0.34676671028137207, "time_total_s": 68.64194750785828, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018301ca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 68.64194750785828, "timesteps_since_restore": 0, "iterations_since_restore": 178, "perf": {"cpu_util_percent": 57.4, "ram_util_percent": 90.6}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 43.91999999999999, "episode_len_mean": 19.43, "episode_media": {}, "episodes_this_iter": 53, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 21.96}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 86.8, 85.6, 88.8, 87.4, 86.2, 87.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.0, 85.6, -4.999999999999998, 88.6, 85.8, 86.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.6, -4.999999999999998, 87.0, 85.6, -4.999999999999998, 87.4, -4.999999999999998, -4.999999999999998, 85.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, 88.6, 88.8, 88.6, 87.2, -4.999999999999998, 88.0, -4.999999999999998, 88.4, 86.4, 85.2, 89.4, -4.999999999999998, -4.999999999999998, 85.6, 87.2, 86.4, 87.2, -4.999999999999998, -4.999999999999998, 89.4, 88.8, 87.2, -4.999999999999998, 88.2, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, 85.4, 88.8, 86.0, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, 88.8, 88.0, 85.4, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, 85.2, 89.4, 88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.0, 87.2, 87.2, 86.2, 89.4, -4.999999999999998], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 17, 23, 7, 14, 20, 12, 25, 25, 25, 16, 23, 25, 8, 22, 19, 25, 25, 25, 8, 25, 16, 23, 25, 14, 25, 25, 24, 25, 25, 25, 15, 25, 25, 8, 7, 8, 15, 25, 11, 25, 9, 19, 25, 4, 25, 25, 23, 15, 19, 15, 25, 25, 4, 7, 15, 25, 10, 25, 25, 23, 25, 24, 7, 21, 25, 11, 25, 25, 22, 25, 25, 10, 25, 7, 11, 24, 25, 25, 7, 25, 25, 4, 7, 25, 25, 25, 16, 15, 15, 20, 4, 25], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -12.200000000000001, 97.8, -10.6, 99.4, -11.3, 98.7, -11.9, 98.1, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -12.100000000000001, 97.9, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -10.6, 99.4, 99.3, -10.7, 98.6, -11.4, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -11.8, 98.2, -12.4, 97.6, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, -11.4, 98.6, -11.8, 98.2, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.6, 99.4, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, 97.7, -12.3, 99.4, -10.6, -12.0, 98.0, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -10.6, 99.4, 99.0, -11.0, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -12.4, 97.6, 99.7, -10.3, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -11.4, 98.6, -11.4, 98.6, -11.9, 98.1, -10.3, 99.7, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3651771764080832, "mean_inference_ms": 1.6344278691341811, "mean_action_processing_ms": 0.08658493327407188, "mean_env_wait_ms": 0.08424806129705263, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 179000, "timesteps_this_iter": 0, "agent_timesteps_total": 358000, "timers": {"sample_time_ms": 375.674, "sample_throughput": 2661.882, "load_time_ms": 1.307, "load_throughput": 765286.186, "learn_time_ms": 96.969, "learn_throughput": 10312.543, "update_time_ms": 2.655}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.232595164407831e-33, "cur_lr": 0.0005000000000000001, "total_loss": 1480.2103515625, "policy_loss": -0.002255157753825188, "vf_loss": 1480.2156616210937, "vf_explained_var": 0.015091341733932496, "kl": 0.003975159207560086, "entropy": 0.30826561748981474, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 179000, "num_agent_steps_sampled": 358000, "num_steps_trained": 179000, "num_agent_steps_trained": 358000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 11422, "training_iteration": 179, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-51", "timestamp": 1749778611, "time_this_iter_s": 0.31581592559814453, "time_total_s": 68.95776343345642, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018224280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 68.95776343345642, "timesteps_since_restore": 0, "iterations_since_restore": 179, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 56.077999999999996, "episode_len_mean": 17.27, "episode_media": {}, "episodes_this_iter": 62, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 28.039}, "custom_metrics": {}, "hist_stats": {"episode_reward": [87.2, -4.999999999999998, 88.2, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, 85.4, 88.8, 86.0, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, 88.8, 88.0, 85.4, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, 85.2, 89.4, 88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.0, 87.2, 87.2, 86.2, 89.4, -4.999999999999998, 88.6, 88.6, 86.8, 85.4, 89.4, 88.8, 86.39999999999999, 86.8, 86.39999999999999, 88.2, 87.0, 86.4, 88.8, 86.6, -4.999999999999998, 86.6, 88.8, 87.2, -4.999999999999998, 86.8, -4.999999999999998, 88.2, 89.4, -4.999999999999998, 85.8, -4.999999999999998, 87.0, 85.2, 88.6, 86.2, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, 88.6, -4.999999999999998, 88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, 86.6, -4.999999999999998, 87.8, 88.8, 87.8, 86.39999999999999, -4.999999999999998, -4.999999999999998, 88.2, 88.2, 88.4, 86.39999999999999, 89.2, -4.999999999999998, 87.8, 88.8, 89.4, 86.0, 87.4, -4.999999999999998], "episode_lengths": [15, 25, 10, 25, 25, 23, 25, 24, 7, 21, 25, 11, 25, 25, 22, 25, 25, 10, 25, 7, 11, 24, 25, 25, 7, 25, 25, 4, 7, 25, 25, 25, 16, 15, 15, 20, 4, 25, 8, 8, 17, 24, 4, 7, 19, 17, 19, 10, 16, 19, 7, 18, 25, 18, 7, 15, 25, 17, 25, 10, 4, 25, 22, 25, 16, 25, 8, 20, 13, 25, 25, 25, 7, 8, 25, 7, 25, 25, 25, 10, 18, 25, 12, 7, 12, 19, 25, 25, 10, 10, 9, 19, 5, 25, 12, 7, 4, 21, 14, 25], "policy_shared_policy_reward": [98.6, -11.4, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, 97.7, -12.3, 99.4, -10.6, -12.0, 98.0, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -10.6, 99.4, 99.0, -11.0, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -12.4, 97.6, 99.7, -10.3, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -11.4, 98.6, -11.4, 98.6, -11.9, 98.1, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -10.7, 99.3, -11.6, 98.4, -12.3, 97.7, -10.3, 99.7, -10.6, 99.4, 98.2, -11.8, -11.6, 98.4, 98.2, -11.8, -10.9, 99.1, -11.5, 98.5, -11.8, 98.2, -10.6, 99.4, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -10.6, 99.4, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -12.4, 97.6, -10.7, 99.3, -11.9, 98.1, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.6, 99.4, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -11.1, 98.9, 99.4, -10.6, -11.1, 98.9, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -10.9, 99.1, 99.2, -10.8, 98.2, -11.8, -10.4, 99.6, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 99.4, -10.6, -10.3, 99.7, -12.0, 98.0, -11.3, 98.7, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.36485729849896126, "mean_inference_ms": 1.6334975546007398, "mean_action_processing_ms": 0.08658073631794766, "mean_env_wait_ms": 0.08421076905690615, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 180000, "timesteps_this_iter": 0, "agent_timesteps_total": 360000, "timers": {"sample_time_ms": 374.761, "sample_throughput": 2668.371, "load_time_ms": 1.097, "load_throughput": 911507.987, "learn_time_ms": 97.377, "learn_throughput": 10269.339, "update_time_ms": 2.675}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 6.162975822039155e-34, "cur_lr": 0.0005000000000000001, "total_loss": 1894.0939819335938, "policy_loss": -0.0028634995222091677, "vf_loss": 1894.1001098632812, "vf_explained_var": 0.013013172149658202, "kl": 0.00303975557577596, "entropy": 0.32488390803337097, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 180000, "num_agent_steps_sampled": 360000, "num_steps_trained": 180000, "num_agent_steps_trained": 360000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 11484, "training_iteration": 180, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-51", "timestamp": 1749778611, "time_this_iter_s": 0.34548187255859375, "time_total_s": 69.30324530601501, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018301dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 69.30324530601501, "timesteps_since_restore": 0, "iterations_since_restore": 180, "perf": {"cpu_util_percent": 55.9, "ram_util_percent": 90.6}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 56.118, "episode_len_mean": 17.07, "episode_media": {}, "episodes_this_iter": 60, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 28.059}, "custom_metrics": {}, "hist_stats": {"episode_reward": [89.4, -4.999999999999998, 85.8, -4.999999999999998, 87.0, 85.2, 88.6, 86.2, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, 88.6, -4.999999999999998, 88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.2, 86.6, -4.999999999999998, 87.8, 88.8, 87.8, 86.39999999999999, -4.999999999999998, -4.999999999999998, 88.2, 88.2, 88.4, 86.39999999999999, 89.2, -4.999999999999998, 87.8, 88.8, 89.4, 86.0, 87.4, -4.999999999999998, 85.4, 88.0, 88.8, 89.4, 86.8, 85.4, 86.4, 88.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.6, 87.4, 86.6, 88.2, 86.4, -4.999999999999998, 85.8, 88.4, -4.999999999999998, 88.8, -4.999999999999998, 88.8, 85.8, -4.999999999999998, -4.999999999999998, 86.39999999999999, -4.999999999999998, -4.999999999999998, 85.4, 88.8, -4.999999999999998, 88.0, 88.8, 87.8, 86.4, 87.2, 86.6, 85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, 87.0, 87.6, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, 87.8, 87.6, -4.999999999999998, -4.999999999999998, 89.4, 87.4, 88.8, 87.2, -4.999999999999998, 88.6, 88.8], "episode_lengths": [4, 25, 22, 25, 16, 25, 8, 20, 13, 25, 25, 25, 7, 8, 25, 7, 25, 25, 25, 10, 18, 25, 12, 7, 12, 19, 25, 25, 10, 10, 9, 19, 5, 25, 12, 7, 4, 21, 14, 25, 24, 11, 7, 4, 17, 24, 19, 10, 25, 25, 25, 8, 14, 18, 10, 19, 25, 22, 9, 25, 7, 25, 7, 22, 25, 25, 19, 25, 25, 24, 7, 25, 11, 7, 12, 19, 15, 18, 22, 25, 25, 25, 14, 16, 13, 25, 25, 9, 25, 12, 13, 25, 25, 4, 14, 7, 15, 25, 8, 7], "policy_shared_policy_reward": [-10.3, 99.7, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -12.4, 97.6, -10.7, 99.3, -11.9, 98.1, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.6, 99.4, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -11.1, 98.9, 99.4, -10.6, -11.1, 98.9, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -10.9, 99.1, 99.2, -10.8, 98.2, -11.8, -10.4, 99.6, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 99.4, -10.6, -10.3, 99.7, -12.0, 98.0, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -11.0, 99.0, -10.6, 99.4, -10.3, 99.7, 98.4, -11.6, -12.3, 97.7, -11.8, 98.2, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 98.7, -11.3, -11.700000000000001, 98.3, -10.9, 99.1, -11.8, 98.2, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -11.0, 99.0, 99.4, -10.6, -11.1, 98.9, -11.8, 98.2, 98.6, -11.4, -11.700000000000001, 98.3, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -11.5, 98.5, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 98.7, -11.3, 99.4, -10.6, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -10.7, 99.3, 99.4, -10.6]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3643656739758242, "mean_inference_ms": 1.631378112961392, "mean_action_processing_ms": 0.08655572619254254, "mean_env_wait_ms": 0.08410736601825435, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 181000, "timesteps_this_iter": 0, "agent_timesteps_total": 362000, "timers": {"sample_time_ms": 375.981, "sample_throughput": 2659.71, "load_time_ms": 1.03, "load_throughput": 971240.94, "learn_time_ms": 97.255, "learn_throughput": 10282.223, "update_time_ms": 2.707}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 3.0814879110195775e-34, "cur_lr": 0.0005000000000000001, "total_loss": 1723.5230834960937, "policy_loss": -0.0028233008459210398, "vf_loss": 1723.529150390625, "vf_explained_var": 0.022923362255096436, "kl": 0.0050257412052630455, "entropy": 0.32276299595832825, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 181000, "num_agent_steps_sampled": 362000, "num_steps_trained": 181000, "num_agent_steps_trained": 362000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 11544, "training_iteration": 181, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-52", "timestamp": 1749778612, "time_this_iter_s": 0.35299038887023926, "time_total_s": 69.65623569488525, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018224670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 69.65623569488525, "timesteps_since_restore": 0, "iterations_since_restore": 181, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 60.705999999999996, "episode_len_mean": 16.68, "episode_media": {}, "episodes_this_iter": 61, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 30.353}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 88.8, 85.8, -4.999999999999998, -4.999999999999998, 86.39999999999999, -4.999999999999998, -4.999999999999998, 85.4, 88.8, -4.999999999999998, 88.0, 88.8, 87.8, 86.4, 87.2, 86.6, 85.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.4, 87.0, 87.6, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, 87.8, 87.6, -4.999999999999998, -4.999999999999998, 89.4, 87.4, 88.8, 87.2, -4.999999999999998, 88.6, 88.8, 86.0, 87.0, 87.4, 88.8, 86.2, 87.4, 85.2, 89.4, 86.6, 85.8, -4.999999999999998, -4.999999999999998, 85.6, 86.6, 87.4, 88.6, 88.6, 88.6, 85.8, -4.999999999999998, -4.999999999999998, 88.8, 87.8, 88.2, 89.4, 88.8, 86.0, 88.6, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.6, 85.2, -4.999999999999998, 88.2, -4.999999999999998, 87.8, 88.8, -4.999999999999998, 86.6, 87.0, 86.2, 87.2, 87.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, 88.8, 87.0, 88.4, 85.8, 89.0, 87.2, 88.0, 86.4, 87.8, 87.4], "episode_lengths": [25, 7, 22, 25, 25, 19, 25, 25, 24, 7, 25, 11, 7, 12, 19, 15, 18, 22, 25, 25, 25, 14, 16, 13, 25, 25, 9, 25, 12, 13, 25, 25, 4, 14, 7, 15, 25, 8, 7, 21, 16, 14, 7, 20, 14, 25, 4, 18, 22, 25, 25, 23, 18, 14, 8, 8, 8, 22, 25, 25, 7, 12, 10, 4, 7, 21, 8, 8, 25, 25, 25, 8, 25, 25, 10, 25, 12, 7, 25, 18, 16, 20, 15, 14, 4, 25, 25, 25, 25, 9, 7, 16, 9, 22, 6, 15, 11, 19, 12, 14], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, 99.4, -10.6, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -11.0, 99.0, 99.4, -10.6, -11.1, 98.9, -11.8, 98.2, 98.6, -11.4, -11.700000000000001, 98.3, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -11.5, 98.5, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 98.7, -11.3, 99.4, -10.6, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -10.7, 99.3, 99.4, -10.6, -12.0, 98.0, 98.5, -11.5, -11.3, 98.7, 99.4, -10.6, -11.9, 98.1, 98.7, -11.3, -12.4, 97.6, -10.3, 99.7, -11.700000000000001, 98.3, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -11.700000000000001, 98.3, -11.3, 98.7, 99.3, -10.7, 99.3, -10.7, -10.7, 99.3, -12.100000000000001, 97.9, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 98.9, -11.1, -10.9, 99.1, -10.3, 99.7, 99.4, -10.6, -12.0, 98.0, -10.7, 99.3, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -11.5, 98.5, -11.9, 98.1, -11.4, 98.6, 98.7, -11.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -10.6, 99.4, -11.5, 98.5, 99.2, -10.8, 97.9, -12.100000000000001, -10.5, 99.5, -11.4, 98.6, -11.0, 99.0, -11.8, 98.2, -11.1, 98.9, 98.7, -11.3]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3643034210085931, "mean_inference_ms": 1.631663099238874, "mean_action_processing_ms": 0.0866283193141636, "mean_env_wait_ms": 0.08405484105708454, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 182000, "timesteps_this_iter": 0, "agent_timesteps_total": 364000, "timers": {"sample_time_ms": 377.38, "sample_throughput": 2649.851, "load_time_ms": 1.122, "load_throughput": 891248.38, "learn_time_ms": 97.689, "learn_throughput": 10236.564, "update_time_ms": 2.502}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 3.0814879110195775e-34, "cur_lr": 0.0005000000000000001, "total_loss": 1951.2110107421875, "policy_loss": -0.0023228682577610014, "vf_loss": 1951.21650390625, "vf_explained_var": 0.008730214834213258, "kl": 0.0028609179018555418, "entropy": 0.31710735261440276, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 182000, "num_agent_steps_sampled": 364000, "num_steps_trained": 182000, "num_agent_steps_trained": 364000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 11605, "training_iteration": 182, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-52", "timestamp": 1749778612, "time_this_iter_s": 0.3674180507659912, "time_total_s": 70.02365374565125, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018224040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 70.02365374565125, "timesteps_since_restore": 0, "iterations_since_restore": 182, "perf": {"cpu_util_percent": 51.5, "ram_util_percent": 90.6}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 60.86999999999999, "episode_len_mean": 15.86, "episode_media": {}, "episodes_this_iter": 64, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 30.435}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.8, 86.0, 88.6, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.6, 85.2, -4.999999999999998, 88.2, -4.999999999999998, 87.8, 88.8, -4.999999999999998, 86.6, 87.0, 86.2, 87.2, 87.4, 89.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, 88.8, 87.0, 88.4, 85.8, 89.0, 87.2, 88.0, 86.4, 87.8, 87.4, -4.999999999999998, 89.0, 88.2, 88.0, -4.999999999999998, -4.999999999999998, 87.2, -4.999999999999998, -4.999999999999998, 88.4, 89.2, 89.4, 88.6, 87.6, 87.0, 88.0, 88.0, 87.6, 86.4, -4.999999999999998, 87.4, 86.6, 86.8, -4.999999999999998, 85.6, 88.2, 88.8, -4.999999999999998, 88.0, 89.4, 85.2, 87.8, 88.8, 87.2, 89.0, 88.8, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, 89.4, 89.4, -4.999999999999998, 87.4, 88.4, -4.999999999999998, -4.999999999999998, 85.4, 87.0, 86.8, 88.8, 88.8, -4.999999999999998, 86.39999999999999, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, 89.4, 89.4, -4.999999999999998, 89.4, 87.0], "episode_lengths": [7, 21, 8, 8, 25, 25, 25, 8, 25, 25, 10, 25, 12, 7, 25, 18, 16, 20, 15, 14, 4, 25, 25, 25, 25, 9, 7, 16, 9, 22, 6, 15, 11, 19, 12, 14, 25, 6, 10, 11, 25, 25, 15, 25, 25, 9, 5, 4, 8, 13, 16, 11, 11, 13, 19, 25, 14, 18, 17, 25, 23, 10, 7, 25, 11, 4, 25, 12, 7, 15, 6, 7, 25, 25, 23, 25, 4, 4, 25, 14, 9, 25, 25, 24, 16, 17, 7, 7, 25, 19, 18, 25, 25, 25, 11, 4, 4, 25, 4, 16], "policy_shared_policy_reward": [99.4, -10.6, -12.0, 98.0, -10.7, 99.3, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, 98.9, -11.1, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -11.5, 98.5, -11.9, 98.1, -11.4, 98.6, 98.7, -11.3, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -10.6, 99.4, -11.5, 98.5, 99.2, -10.8, 97.9, -12.100000000000001, -10.5, 99.5, -11.4, 98.6, -11.0, 99.0, -11.8, 98.2, -11.1, 98.9, 98.7, -11.3, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -10.9, 99.1, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -10.4, 99.6, -10.3, 99.7, 99.3, -10.7, -11.2, 98.8, -11.5, 98.5, -11.0, 99.0, 99.0, -11.0, -11.2, 98.8, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -11.700000000000001, 98.3, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -10.9, 99.1, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -10.3, 99.7, 97.6, -12.4, -11.1, 98.9, 99.4, -10.6, -11.4, 98.6, 99.5, -10.5, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.3, 98.7, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -11.5, 98.5, -11.6, 98.4, -10.6, 99.4, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.5, 98.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.36447443595194484, "mean_inference_ms": 1.6311976095796923, "mean_action_processing_ms": 0.08652156464266128, "mean_env_wait_ms": 0.08399077032046924, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 183000, "timesteps_this_iter": 0, "agent_timesteps_total": 366000, "timers": {"sample_time_ms": 379.524, "sample_throughput": 2634.878, "load_time_ms": 1.133, "load_throughput": 882454.029, "learn_time_ms": 98.943, "learn_throughput": 10106.808, "update_time_ms": 2.507}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.5407439555097888e-34, "cur_lr": 0.0005000000000000001, "total_loss": 1722.3239624023438, "policy_loss": -0.0019712671637535095, "vf_loss": 1722.32880859375, "vf_explained_var": 0.016399890184402466, "kl": 0.002590090601356021, "entropy": 0.2878531217575073, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 183000, "num_agent_steps_sampled": 366000, "num_steps_trained": 183000, "num_agent_steps_trained": 366000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 11669, "training_iteration": 183, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-52", "timestamp": 1749778612, "time_this_iter_s": 0.35917162895202637, "time_total_s": 70.38282537460327, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb01825cd30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 70.38282537460327, "timesteps_since_restore": 0, "iterations_since_restore": 183, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 65.38199999999999, "episode_len_mean": 15.85, "episode_media": {}, "episodes_this_iter": 62, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 32.691}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.8, -4.999999999999998, 88.0, 89.4, 85.2, 87.8, 88.8, 87.2, 89.0, 88.8, -4.999999999999998, -4.999999999999998, 85.6, -4.999999999999998, 89.4, 89.4, -4.999999999999998, 87.4, 88.4, -4.999999999999998, -4.999999999999998, 85.4, 87.0, 86.8, 88.8, 88.8, -4.999999999999998, 86.39999999999999, 86.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, 89.4, 89.4, -4.999999999999998, 89.4, 87.0, 87.4, -4.999999999999998, 87.0, 87.8, 87.8, 85.8, -4.999999999999998, -4.999999999999998, 87.0, 88.8, 86.6, 88.2, 87.4, -4.999999999999998, 87.6, 87.6, 85.8, 87.0, 89.4, 88.0, 87.8, 88.8, -4.999999999999998, 88.8, 88.6, 86.4, 85.6, 86.2, 88.0, 88.6, -4.999999999999998, 88.2, 88.2, 87.2, 86.4, 86.2, 89.2, 89.0, 87.4, -4.999999999999998, 85.4, 87.4, 88.0, 86.39999999999999, 89.4, 88.2, 87.2, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, 87.4, 86.2, -4.999999999999998, 86.0, 88.0, 89.0, 86.4, 86.2, -4.999999999999998, 86.4], "episode_lengths": [7, 25, 11, 4, 25, 12, 7, 15, 6, 7, 25, 25, 23, 25, 4, 4, 25, 14, 9, 25, 25, 24, 16, 17, 7, 7, 25, 19, 18, 25, 25, 25, 11, 4, 4, 25, 4, 16, 14, 25, 16, 12, 12, 22, 25, 25, 16, 7, 18, 10, 14, 25, 13, 13, 22, 16, 4, 11, 12, 7, 25, 7, 8, 19, 23, 20, 11, 8, 25, 10, 10, 15, 19, 20, 5, 6, 14, 25, 24, 14, 11, 19, 4, 10, 15, 14, 25, 25, 25, 15, 14, 20, 25, 21, 11, 6, 19, 20, 25, 19], "policy_shared_policy_reward": [-10.6, 99.4, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -10.3, 99.7, 97.6, -12.4, -11.1, 98.9, 99.4, -10.6, -11.4, 98.6, 99.5, -10.5, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -11.3, 98.7, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -11.5, 98.5, -11.6, 98.4, -10.6, 99.4, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -10.3, 99.7, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.5, 98.5, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -11.5, 98.5, 98.9, -11.1, -11.1, 98.9, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -10.6, 99.4, -11.700000000000001, 98.3, -10.9, 99.1, 98.7, -11.3, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -11.2, 98.8, -12.100000000000001, 97.9, -11.5, 98.5, -10.3, 99.7, -11.0, 99.0, 98.9, -11.1, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -10.6, 99.4, 99.3, -10.7, -11.8, 98.2, -12.200000000000001, 97.8, -11.9, 98.1, -11.0, 99.0, 99.3, -10.7, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -10.9, 99.1, -11.4, 98.6, -11.8, 98.2, -11.9, 98.1, -10.4, 99.6, -10.5, 99.5, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -11.3, 98.7, 99.0, -11.0, 98.2, -11.8, -10.3, 99.7, 99.1, -10.9, -11.4, 98.6, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -11.3, 98.7, 98.1, -11.9, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -11.0, 99.0, 99.5, -10.5, -11.8, 98.2, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -11.8, 98.2]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3647432367863558, "mean_inference_ms": 1.6320656386092849, "mean_action_processing_ms": 0.08657889488536505, "mean_env_wait_ms": 0.08404257218737697, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 184000, "timesteps_this_iter": 0, "agent_timesteps_total": 368000, "timers": {"sample_time_ms": 382.698, "sample_throughput": 2613.029, "load_time_ms": 1.133, "load_throughput": 882974.191, "learn_time_ms": 98.755, "learn_throughput": 10126.111, "update_time_ms": 2.519}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 7.703719777548944e-35, "cur_lr": 0.0005000000000000001, "total_loss": 2029.5805419921876, "policy_loss": -0.003338930755853653, "vf_loss": 2029.5871704101562, "vf_explained_var": 0.005932319164276123, "kl": 0.006554804029320005, "entropy": 0.33134600818157195, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 184000, "num_agent_steps_sampled": 368000, "num_steps_trained": 184000, "num_agent_steps_trained": 368000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 11731, "training_iteration": 184, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-53", "timestamp": 1749778613, "time_this_iter_s": 0.35673069953918457, "time_total_s": 70.73955607414246, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb01825cf70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 70.73955607414246, "timesteps_since_restore": 0, "iterations_since_restore": 184, "perf": {"cpu_util_percent": 50.5, "ram_util_percent": 90.5}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 69.09400000000001, "episode_len_mean": 15.33, "episode_media": {}, "episodes_this_iter": 70, "policy_reward_min": {"shared_policy": -12.3}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 34.547000000000004}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.2, 87.2, 86.4, 86.2, 89.2, 89.0, 87.4, -4.999999999999998, 85.4, 87.4, 88.0, 86.39999999999999, 89.4, 88.2, 87.2, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.2, 87.4, 86.2, -4.999999999999998, 86.0, 88.0, 89.0, 86.4, 86.2, -4.999999999999998, 86.4, -4.999999999999998, 86.8, 87.8, -4.999999999999998, 88.8, 85.6, -4.999999999999998, 86.2, 87.8, 86.8, 87.4, -4.999999999999998, -4.999999999999998, 89.2, 88.4, 89.4, 87.2, -4.999999999999998, 86.8, 86.8, -4.999999999999998, 89.4, 89.2, 88.8, 88.2, 86.8, 88.4, 88.6, 86.8, 88.2, 88.2, 86.2, 89.4, 89.4, 87.2, 88.8, 87.2, 89.4, 88.2, 88.6, 86.0, 87.2, 85.6, 87.4, 88.2, -4.999999999999998, 88.0, 88.2, 86.6, 89.2, -4.999999999999998, 86.8, -4.999999999999998, 87.4, -4.999999999999998, 87.0, -4.999999999999998, 87.4, 88.8, 86.8, 86.4, -4.999999999999998, 88.6, 87.4, 85.8, 88.0, 87.0, 89.2, 88.6, -4.999999999999998], "episode_lengths": [10, 15, 19, 20, 5, 6, 14, 25, 24, 14, 11, 19, 4, 10, 15, 14, 25, 25, 25, 15, 14, 20, 25, 21, 11, 6, 19, 20, 25, 19, 25, 17, 12, 25, 7, 23, 25, 20, 12, 17, 14, 25, 25, 5, 9, 4, 15, 25, 17, 17, 25, 4, 5, 7, 10, 17, 9, 8, 17, 10, 10, 20, 4, 4, 15, 7, 15, 4, 10, 8, 21, 15, 23, 14, 10, 25, 11, 10, 18, 5, 25, 17, 25, 14, 25, 16, 25, 14, 7, 17, 19, 25, 8, 14, 22, 11, 16, 5, 8, 25], "policy_shared_policy_reward": [-10.9, 99.1, -11.4, 98.6, -11.8, 98.2, -11.9, 98.1, -10.4, 99.6, -10.5, 99.5, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -11.3, 98.7, 99.0, -11.0, 98.2, -11.8, -10.3, 99.7, 99.1, -10.9, -11.4, 98.6, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -11.3, 98.7, 98.1, -11.9, -2.500000000000001, -2.500000000000001, -12.0, 98.0, -11.0, 99.0, 99.5, -10.5, -11.8, 98.2, -11.9, 98.1, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -11.9, 98.1, 98.9, -11.1, -11.6, 98.4, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.4, 99.6, 99.2, -10.8, -10.3, 99.7, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -10.4, 99.6, -10.6, 99.4, -10.9, 99.1, -11.6, 98.4, 99.2, -10.8, 99.3, -10.7, -11.6, 98.4, -10.9, 99.1, 99.1, -10.9, -11.9, 98.1, -10.3, 99.7, -10.3, 99.7, -11.4, 98.6, -10.6, 99.4, 98.6, -11.4, -10.3, 99.7, -10.9, 99.1, 99.3, -10.7, -12.0, 98.0, 98.6, -11.4, 97.8, -12.200000000000001, -11.3, 98.7, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -10.9, 99.1, -11.700000000000001, 98.3, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -2.500000000000001, -2.500000000000001, 98.7, -11.3, 99.4, -10.6, -11.6, 98.4, -11.8, 98.2, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 98.7, -11.3, -12.100000000000001, 97.9, -11.0, 99.0, -11.5, 98.5, -10.4, 99.6, 99.3, -10.7, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.364815114632424, "mean_inference_ms": 1.6329651941574008, "mean_action_processing_ms": 0.08659158753950176, "mean_env_wait_ms": 0.08418767110846137, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 185000, "timesteps_this_iter": 0, "agent_timesteps_total": 370000, "timers": {"sample_time_ms": 382.644, "sample_throughput": 2613.397, "load_time_ms": 1.103, "load_throughput": 906602.11, "learn_time_ms": 98.793, "learn_throughput": 10122.157, "update_time_ms": 2.564}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 7.703719777548944e-35, "cur_lr": 0.0005000000000000001, "total_loss": 2072.2567626953123, "policy_loss": -0.0019410165026783944, "vf_loss": 2072.2618041992187, "vf_explained_var": 0.008625364303588868, "kl": 0.0034435405967585984, "entropy": 0.3120892345905304, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 185000, "num_agent_steps_sampled": 370000, "num_steps_trained": 185000, "num_agent_steps_trained": 370000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 11801, "training_iteration": 185, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-53", "timestamp": 1749778613, "time_this_iter_s": 0.3521111011505127, "time_total_s": 71.09166717529297, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb01825cb80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 71.09166717529297, "timesteps_since_restore": 0, "iterations_since_restore": 185, "perf": {"cpu_util_percent": 55.0, "ram_util_percent": 90.5}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 68.21, "episode_len_mean": 15.24, "episode_media": {}, "episodes_this_iter": 62, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 34.105}, "custom_metrics": {}, "hist_stats": {"episode_reward": [89.4, 89.4, 87.2, 88.8, 87.2, 89.4, 88.2, 88.6, 86.0, 87.2, 85.6, 87.4, 88.2, -4.999999999999998, 88.0, 88.2, 86.6, 89.2, -4.999999999999998, 86.8, -4.999999999999998, 87.4, -4.999999999999998, 87.0, -4.999999999999998, 87.4, 88.8, 86.8, 86.4, -4.999999999999998, 88.6, 87.4, 85.8, 88.0, 87.0, 89.2, 88.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, 88.2, 87.2, 88.6, 87.0, 86.4, 87.2, 88.8, 89.4, -4.999999999999998, 85.2, 88.4, 87.4, 86.4, 88.8, 86.0, 89.4, -4.999999999999998, 88.4, -4.999999999999998, 89.2, 86.39999999999999, -4.999999999999998, 88.6, 86.6, 87.4, -4.999999999999998, -4.999999999999998, 88.6, 87.2, -4.999999999999998, 85.6, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, 88.2, 87.0, -4.999999999999998, 88.6, 88.0, 86.8, 85.2, 87.6, 88.4, 87.4, 87.2, 87.4, 86.2, 86.6, 88.8, 87.6, 89.2, 89.2, 88.4, 87.2, 88.6, -4.999999999999998, 85.4, 88.0], "episode_lengths": [4, 4, 15, 7, 15, 4, 10, 8, 21, 15, 23, 14, 10, 25, 11, 10, 18, 5, 25, 17, 25, 14, 25, 16, 25, 14, 7, 17, 19, 25, 8, 14, 22, 11, 16, 5, 8, 25, 25, 25, 9, 10, 15, 8, 16, 19, 15, 7, 4, 25, 25, 9, 14, 19, 7, 21, 4, 25, 9, 25, 5, 19, 25, 8, 18, 14, 25, 25, 8, 15, 25, 23, 25, 25, 9, 25, 10, 16, 25, 8, 11, 17, 25, 13, 9, 14, 15, 14, 20, 18, 7, 13, 5, 5, 9, 15, 8, 25, 24, 11], "policy_shared_policy_reward": [-10.3, 99.7, -10.3, 99.7, -11.4, 98.6, -10.6, 99.4, 98.6, -11.4, -10.3, 99.7, -10.9, 99.1, 99.3, -10.7, -12.0, 98.0, 98.6, -11.4, 97.8, -12.200000000000001, -11.3, 98.7, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -10.9, 99.1, -11.700000000000001, 98.3, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -2.500000000000001, -2.500000000000001, 98.7, -11.3, 99.4, -10.6, -11.6, 98.4, -11.8, 98.2, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 98.7, -11.3, -12.100000000000001, 97.9, -11.0, 99.0, -11.5, 98.5, -10.4, 99.6, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -10.9, 99.1, -11.4, 98.6, 99.3, -10.7, -11.5, 98.5, -11.8, 98.2, 98.6, -11.4, 99.4, -10.6, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -12.4, 97.6, 99.2, -10.8, 98.7, -11.3, -11.8, 98.2, 99.4, -10.6, -12.0, 98.0, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -10.4, 99.6, 98.2, -11.8, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -11.700000000000001, 98.3, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -10.9, 99.1, 98.5, -11.5, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -11.0, 99.0, -11.6, 98.4, 97.6, -12.4, -11.2, 98.8, 99.2, -10.8, 98.7, -11.3, -11.4, 98.6, 98.7, -11.3, 98.1, -11.9, -11.700000000000001, 98.3, 99.4, -10.6, -11.2, 98.8, -10.4, 99.6, -10.4, 99.6, -10.8, 99.2, 98.6, -11.4, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -11.0, 99.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.36449441631404483, "mean_inference_ms": 1.6306073150892288, "mean_action_processing_ms": 0.08634628508076507, "mean_env_wait_ms": 0.08407897340347492, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 186000, "timesteps_this_iter": 0, "agent_timesteps_total": 372000, "timers": {"sample_time_ms": 382.471, "sample_throughput": 2614.576, "load_time_ms": 1.072, "load_throughput": 932606.395, "learn_time_ms": 99.25, "learn_throughput": 10075.523, "update_time_ms": 2.57}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 3.851859888774472e-35, "cur_lr": 0.0005000000000000001, "total_loss": 1907.9088500976563, "policy_loss": -0.002794298157095909, "vf_loss": 1907.9153686523437, "vf_explained_var": 0.01027430295944214, "kl": 0.002886094703482378, "entropy": 0.3666890233755112, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 186000, "num_agent_steps_sampled": 372000, "num_steps_trained": 186000, "num_agent_steps_trained": 372000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 11863, "training_iteration": 186, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-54", "timestamp": 1749778614, "time_this_iter_s": 0.3428068161010742, "time_total_s": 71.43447399139404, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb01825caf0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 71.43447399139404, "timesteps_since_restore": 0, "iterations_since_restore": 186, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 61.59599999999998, "episode_len_mean": 16.74, "episode_media": {}, "episodes_this_iter": 56, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 30.798}, "custom_metrics": {}, "hist_stats": {"episode_reward": [89.4, -4.999999999999998, 88.4, -4.999999999999998, 89.2, 86.39999999999999, -4.999999999999998, 88.6, 86.6, 87.4, -4.999999999999998, -4.999999999999998, 88.6, 87.2, -4.999999999999998, 85.6, -4.999999999999998, -4.999999999999998, 88.4, -4.999999999999998, 88.2, 87.0, -4.999999999999998, 88.6, 88.0, 86.8, 85.2, 87.6, 88.4, 87.4, 87.2, 87.4, 86.2, 86.6, 88.8, 87.6, 89.2, 89.2, 88.4, 87.2, 88.6, -4.999999999999998, 85.4, 88.0, 86.0, 86.6, 85.8, 87.8, -4.999999999999998, 86.6, -4.999999999999998, 86.2, -4.999999999999998, 87.2, 85.4, 86.6, 88.8, 87.8, 87.4, 86.8, -4.999999999999998, -4.999999999999998, 88.2, 88.0, 86.0, -4.999999999999998, 88.8, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, 85.8, 86.8, 88.8, -4.999999999999998, 87.8, 85.6, -4.999999999999998, -4.999999999999998, 87.6, 87.8, -4.999999999999998, 87.4, 88.0, 87.2, 89.2, -4.999999999999998, 89.2, 87.4, -4.999999999999998, 88.8, 87.4, 85.4, 89.4, 89.2, 88.8, 85.4, -4.999999999999998, -4.999999999999998, 86.4], "episode_lengths": [4, 25, 9, 25, 5, 19, 25, 8, 18, 14, 25, 25, 8, 15, 25, 23, 25, 25, 9, 25, 10, 16, 25, 8, 11, 17, 25, 13, 9, 14, 15, 14, 20, 18, 7, 13, 5, 5, 9, 15, 8, 25, 24, 11, 21, 18, 22, 12, 25, 18, 25, 20, 25, 15, 24, 18, 7, 12, 14, 17, 25, 25, 10, 11, 21, 25, 7, 25, 25, 14, 25, 22, 17, 7, 25, 12, 23, 25, 25, 13, 12, 25, 14, 11, 15, 5, 25, 5, 14, 25, 7, 14, 24, 4, 5, 7, 24, 25, 25, 19], "policy_shared_policy_reward": [-10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -10.4, 99.6, 98.2, -11.8, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -11.700000000000001, 98.3, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -11.4, 98.6, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -10.9, 99.1, 98.5, -11.5, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -11.0, 99.0, -11.6, 98.4, 97.6, -12.4, -11.2, 98.8, 99.2, -10.8, 98.7, -11.3, -11.4, 98.6, 98.7, -11.3, 98.1, -11.9, -11.700000000000001, 98.3, 99.4, -10.6, -11.2, 98.8, -10.4, 99.6, -10.4, 99.6, -10.8, 99.2, 98.6, -11.4, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -12.3, 97.7, -11.0, 99.0, -12.0, 98.0, -11.700000000000001, 98.3, -12.100000000000001, 97.9, -11.1, 98.9, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, 98.1, -11.9, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -12.3, 97.7, 98.3, -11.700000000000001, -10.6, 99.4, 98.9, -11.1, 98.7, -11.3, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 99.0, -11.0, -12.0, 98.0, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -11.6, 98.4, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -11.1, 98.9, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, 98.9, -11.1, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -11.0, 99.0, 98.6, -11.4, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -10.6, 99.4, 98.7, -11.3, 97.7, -12.3, -10.3, 99.7, -10.4, 99.6, 99.4, -10.6, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.36445817999223296, "mean_inference_ms": 1.6321976838385397, "mean_action_processing_ms": 0.08661534366141424, "mean_env_wait_ms": 0.08422675179714342, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 187000, "timesteps_this_iter": 0, "agent_timesteps_total": 374000, "timers": {"sample_time_ms": 381.871, "sample_throughput": 2618.682, "load_time_ms": 1.185, "load_throughput": 843992.273, "learn_time_ms": 101.035, "learn_throughput": 9897.523, "update_time_ms": 2.574}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.925929944387236e-35, "cur_lr": 0.0005000000000000001, "total_loss": 1666.6345703125, "policy_loss": -0.0030613331124186515, "vf_loss": 1666.6410034179687, "vf_explained_var": 0.024236255884170534, "kl": 0.005702425231807961, "entropy": 0.3372198402881622, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 187000, "num_agent_steps_sampled": 374000, "num_steps_trained": 187000, "num_agent_steps_trained": 374000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 11919, "training_iteration": 187, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-54", "timestamp": 1749778614, "time_this_iter_s": 0.3535177707672119, "time_total_s": 71.78799176216125, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb01825c0d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 71.78799176216125, "timesteps_since_restore": 0, "iterations_since_restore": 187, "perf": {"cpu_util_percent": 57.8, "ram_util_percent": 90.5}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 56.196000000000005, "episode_len_mean": 16.68, "episode_media": {}, "episodes_this_iter": 63, "policy_reward_min": {"shared_policy": -12.3}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 28.098000000000003}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.0, 86.0, -4.999999999999998, 88.8, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, 85.8, 86.8, 88.8, -4.999999999999998, 87.8, 85.6, -4.999999999999998, -4.999999999999998, 87.6, 87.8, -4.999999999999998, 87.4, 88.0, 87.2, 89.2, -4.999999999999998, 89.2, 87.4, -4.999999999999998, 88.8, 87.4, 85.4, 89.4, 89.2, 88.8, 85.4, -4.999999999999998, -4.999999999999998, 86.4, -4.999999999999998, 88.6, 87.6, 86.39999999999999, 88.8, 86.0, 85.6, 89.4, 87.0, 85.8, 85.4, -4.999999999999998, 89.4, 87.6, 89.2, -4.999999999999998, 87.8, -4.999999999999998, -4.999999999999998, 88.0, 88.8, 88.8, 88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, 88.2, -4.999999999999998, 88.6, 86.8, 88.0, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, 88.6, 88.0, 89.4, 88.2, 86.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.2, 87.0, 88.6, 88.0, 86.2, -4.999999999999998, 87.4, 88.8, -4.999999999999998, 86.6, 88.6, 85.6, 87.6, -4.999999999999998], "episode_lengths": [11, 21, 25, 7, 25, 25, 14, 25, 22, 17, 7, 25, 12, 23, 25, 25, 13, 12, 25, 14, 11, 15, 5, 25, 5, 14, 25, 7, 14, 24, 4, 5, 7, 24, 25, 25, 19, 25, 8, 13, 19, 7, 21, 23, 4, 16, 22, 24, 25, 4, 13, 5, 25, 12, 25, 25, 11, 7, 7, 7, 25, 25, 25, 25, 7, 25, 25, 25, 11, 10, 25, 8, 17, 11, 25, 9, 25, 25, 8, 11, 4, 10, 19, 25, 25, 25, 5, 16, 8, 11, 20, 25, 14, 7, 25, 18, 8, 23, 13, 25], "policy_shared_policy_reward": [99.0, -11.0, -12.0, 98.0, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -12.100000000000001, 97.9, -11.6, 98.4, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -11.1, 98.9, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, 98.9, -11.1, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -11.0, 99.0, 98.6, -11.4, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -10.6, 99.4, 98.7, -11.3, 97.7, -12.3, -10.3, 99.7, -10.4, 99.6, 99.4, -10.6, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -11.2, 98.8, 98.2, -11.8, -10.6, 99.4, 98.0, -12.0, 97.8, -12.200000000000001, -10.3, 99.7, 98.5, -11.5, 97.9, -12.100000000000001, -12.3, 97.7, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 98.8, -11.2, -10.4, 99.6, -2.500000000000001, -2.500000000000001, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, 99.4, -10.6, -10.6, 99.4, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -11.6, 98.4, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 99.0, -11.0, -10.3, 99.7, -10.9, 99.1, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -11.5, 98.5, -10.7, 99.3, -11.0, 99.0, -11.9, 98.1, -2.500000000000001, -2.500000000000001, 98.7, -11.3, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, 99.3, -10.7, 97.8, -12.200000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3645852028579678, "mean_inference_ms": 1.6316777332980996, "mean_action_processing_ms": 0.08651598847992387, "mean_env_wait_ms": 0.08416134572582055, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 188000, "timesteps_this_iter": 0, "agent_timesteps_total": 376000, "timers": {"sample_time_ms": 383.516, "sample_throughput": 2607.451, "load_time_ms": 1.202, "load_throughput": 831790.58, "learn_time_ms": 100.898, "learn_throughput": 9910.961, "update_time_ms": 2.613}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.925929944387236e-35, "cur_lr": 0.0005000000000000001, "total_loss": 1679.8497192382813, "policy_loss": -0.004767822427675128, "vf_loss": 1679.8583251953125, "vf_explained_var": 0.007513129711151123, "kl": 0.011602304031731504, "entropy": 0.3820524334907532, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 188000, "num_agent_steps_sampled": 376000, "num_steps_trained": 188000, "num_agent_steps_trained": 376000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 11982, "training_iteration": 188, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-54", "timestamp": 1749778614, "time_this_iter_s": 0.34510350227355957, "time_total_s": 72.13309526443481, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb01825c820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 72.13309526443481, "timesteps_since_restore": 0, "iterations_since_restore": 188, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 63.54600000000001, "episode_len_mean": 16.01, "episode_media": {}, "episodes_this_iter": 64, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 31.773000000000003}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.8, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.0, 88.2, -4.999999999999998, 88.6, 86.8, 88.0, -4.999999999999998, 88.4, -4.999999999999998, -4.999999999999998, 88.6, 88.0, 89.4, 88.2, 86.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.2, 87.0, 88.6, 88.0, 86.2, -4.999999999999998, 87.4, 88.8, -4.999999999999998, 86.6, 88.6, 85.6, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.4, 89.4, 85.6, -4.999999999999998, 87.6, 88.6, 87.8, 86.2, 87.6, 89.2, 87.0, 85.4, 87.0, 88.0, 88.8, 89.2, 87.6, 88.4, -4.999999999999998, 86.8, 88.0, 85.6, 86.6, 87.0, -4.999999999999998, 85.2, 86.6, 86.6, 87.2, 88.0, -4.999999999999998, 88.2, -4.999999999999998, 88.6, 88.6, 86.6, 88.6, -4.999999999999998, -4.999999999999998, 88.6, 85.2, 88.2, 88.2, 88.6, 86.0, 86.8, 85.2, 88.6, -4.999999999999998, -4.999999999999998, 85.8, 87.6, 87.8, 88.8, 88.0, 89.4, 88.2, 88.8, 85.6, -4.999999999999998, 88.2], "episode_lengths": [7, 25, 25, 25, 11, 10, 25, 8, 17, 11, 25, 9, 25, 25, 8, 11, 4, 10, 19, 25, 25, 25, 5, 16, 8, 11, 20, 25, 14, 7, 25, 18, 8, 23, 13, 25, 25, 25, 25, 9, 4, 23, 25, 13, 8, 12, 20, 13, 5, 16, 24, 16, 11, 7, 5, 13, 9, 25, 17, 11, 23, 18, 16, 25, 25, 18, 18, 15, 11, 25, 10, 25, 8, 8, 18, 8, 25, 25, 8, 25, 10, 10, 8, 21, 17, 25, 8, 25, 25, 22, 13, 12, 7, 11, 4, 10, 7, 23, 25, 10], "policy_shared_policy_reward": [99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -11.6, 98.4, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 99.0, -11.0, -10.3, 99.7, -10.9, 99.1, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -11.5, 98.5, -10.7, 99.3, -11.0, 99.0, -11.9, 98.1, -2.500000000000001, -2.500000000000001, 98.7, -11.3, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, 99.3, -10.7, 97.8, -12.200000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -10.3, 99.7, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, -11.2, 98.8, 99.3, -10.7, -11.1, 98.9, -11.9, 98.1, -11.2, 98.8, -10.4, 99.6, -11.5, 98.5, -12.3, 97.7, 98.5, -11.5, 99.0, -11.0, -10.6, 99.4, -10.4, 99.6, -11.2, 98.8, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -11.6, 98.4, 99.0, -11.0, 97.8, -12.200000000000001, -11.700000000000001, 98.3, -11.5, 98.5, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -11.700000000000001, 98.3, -11.700000000000001, 98.3, 98.6, -11.4, -11.0, 99.0, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 99.3, -10.7, 98.3, -11.700000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -12.4, 97.6, -10.9, 99.1, -10.9, 99.1, -10.7, 99.3, 98.0, -12.0, -11.6, 98.4, -12.4, 97.6, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, 98.8, -11.2, -11.1, 98.9, -10.6, 99.4, -11.0, 99.0, -10.3, 99.7, -10.9, 99.1, 99.4, -10.6, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.364538714481144, "mean_inference_ms": 1.6303082983467234, "mean_action_processing_ms": 0.08636445763568182, "mean_env_wait_ms": 0.0840384147639759, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 189000, "timesteps_this_iter": 0, "agent_timesteps_total": 378000, "timers": {"sample_time_ms": 383.964, "sample_throughput": 2604.413, "load_time_ms": 1.306, "load_throughput": 765859.11, "learn_time_ms": 103.04, "learn_throughput": 9704.971, "update_time_ms": 2.674}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.925929944387236e-35, "cur_lr": 0.0005000000000000001, "total_loss": 2091.2809204101563, "policy_loss": -0.0036085762083530428, "vf_loss": 2091.2877563476563, "vf_explained_var": 0.014462369680404662, "kl": 0.007343417435571142, "entropy": 0.3274208247661591, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 189000, "num_agent_steps_sampled": 378000, "num_steps_trained": 189000, "num_agent_steps_trained": 378000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 12046, "training_iteration": 189, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-55", "timestamp": 1749778615, "time_this_iter_s": 0.341167688369751, "time_total_s": 72.47426295280457, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018301e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 72.47426295280457, "timesteps_since_restore": 0, "iterations_since_restore": 189, "perf": {"cpu_util_percent": 57.7, "ram_util_percent": 90.5}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 65.406, "episode_len_mean": 15.73, "episode_media": {}, "episodes_this_iter": 62, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 32.702999999999996}, "custom_metrics": {}, "hist_stats": {"episode_reward": [87.0, -4.999999999999998, 85.2, 86.6, 86.6, 87.2, 88.0, -4.999999999999998, 88.2, -4.999999999999998, 88.6, 88.6, 86.6, 88.6, -4.999999999999998, -4.999999999999998, 88.6, 85.2, 88.2, 88.2, 88.6, 86.0, 86.8, 85.2, 88.6, -4.999999999999998, -4.999999999999998, 85.8, 87.6, 87.8, 88.8, 88.0, 89.4, 88.2, 88.8, 85.6, -4.999999999999998, 88.2, 88.2, 87.2, 86.39999999999999, -4.999999999999998, 88.2, 88.8, 87.8, -4.999999999999998, -4.999999999999998, 88.0, 88.8, 88.6, 89.2, -4.999999999999998, 88.2, 89.4, -4.999999999999998, 88.2, -4.999999999999998, -4.999999999999998, 88.2, 86.8, -4.999999999999998, 87.2, 88.6, 87.4, 88.6, -4.999999999999998, 87.4, 85.6, 88.0, 86.6, 88.6, -4.999999999999998, 88.8, 89.4, 87.0, 85.6, 88.8, 89.0, 88.6, 86.0, 88.8, -4.999999999999998, 87.6, -4.999999999999998, 88.6, 88.8, -4.999999999999998, 86.6, 88.6, -4.999999999999998, -4.999999999999998, 87.6, 86.0, 87.0, 85.6, 89.2, 85.8, 86.6, -4.999999999999998, 85.8], "episode_lengths": [16, 25, 25, 18, 18, 15, 11, 25, 10, 25, 8, 8, 18, 8, 25, 25, 8, 25, 10, 10, 8, 21, 17, 25, 8, 25, 25, 22, 13, 12, 7, 11, 4, 10, 7, 23, 25, 10, 10, 15, 19, 25, 10, 7, 12, 25, 25, 11, 7, 8, 5, 25, 10, 4, 25, 10, 25, 25, 10, 17, 25, 15, 8, 14, 8, 25, 14, 23, 11, 18, 8, 25, 7, 4, 16, 23, 7, 6, 8, 21, 7, 25, 13, 25, 8, 7, 25, 18, 8, 25, 25, 13, 21, 16, 23, 5, 22, 18, 25, 22], "policy_shared_policy_reward": [-11.5, 98.5, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -11.700000000000001, 98.3, -11.700000000000001, 98.3, 98.6, -11.4, -11.0, 99.0, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 99.3, -10.7, 98.3, -11.700000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -12.4, 97.6, -10.9, 99.1, -10.9, 99.1, -10.7, 99.3, 98.0, -12.0, -11.6, 98.4, -12.4, 97.6, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, 98.8, -11.2, -11.1, 98.9, -10.6, 99.4, -11.0, 99.0, -10.3, 99.7, -10.9, 99.1, 99.4, -10.6, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, 99.1, -10.9, -11.4, 98.6, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -10.9, 99.1, 99.4, -10.6, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.0, 99.0, 99.4, -10.6, -10.7, 99.3, -10.4, 99.6, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -11.4, 98.6, 99.3, -10.7, 98.7, -11.3, 99.3, -10.7, -2.500000000000001, -2.500000000000001, 98.7, -11.3, 97.8, -12.200000000000001, -11.0, 99.0, -11.700000000000001, 98.3, 99.3, -10.7, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 99.7, -10.3, 98.5, -11.5, 97.8, -12.200000000000001, -10.6, 99.4, -10.5, 99.5, 99.3, -10.7, 98.0, -12.0, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -12.0, 98.0, -11.5, 98.5, 97.8, -12.200000000000001, -10.4, 99.6, -12.100000000000001, 97.9, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3641917504548655, "mean_inference_ms": 1.6287743852938774, "mean_action_processing_ms": 0.08646889645590043, "mean_env_wait_ms": 0.0839154934615726, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 190000, "timesteps_this_iter": 0, "agent_timesteps_total": 380000, "timers": {"sample_time_ms": 386.661, "sample_throughput": 2586.245, "load_time_ms": 1.322, "load_throughput": 756220.972, "learn_time_ms": 102.62, "learn_throughput": 9744.711, "update_time_ms": 2.684}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.925929944387236e-35, "cur_lr": 0.0005000000000000001, "total_loss": 1816.5924194335937, "policy_loss": -0.002315923571586609, "vf_loss": 1816.5984985351563, "vf_explained_var": 0.006673210859298706, "kl": 0.006803525236755381, "entropy": 0.38182816505432127, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 190000, "num_agent_steps_sampled": 380000, "num_steps_trained": 190000, "num_agent_steps_trained": 380000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 12108, "training_iteration": 190, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-55", "timestamp": 1749778615, "time_this_iter_s": 0.35018372535705566, "time_total_s": 72.82444667816162, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb01825c8b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 72.82444667816162, "timesteps_since_restore": 0, "iterations_since_restore": 190, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 68.15, "episode_len_mean": 15.54, "episode_media": {}, "episodes_this_iter": 66, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 34.075}, "custom_metrics": {}, "hist_stats": {"episode_reward": [87.4, 85.6, 88.0, 86.6, 88.6, -4.999999999999998, 88.8, 89.4, 87.0, 85.6, 88.8, 89.0, 88.6, 86.0, 88.8, -4.999999999999998, 87.6, -4.999999999999998, 88.6, 88.8, -4.999999999999998, 86.6, 88.6, -4.999999999999998, -4.999999999999998, 87.6, 86.0, 87.0, 85.6, 89.2, 85.8, 86.6, -4.999999999999998, 85.8, -4.999999999999998, 86.2, -4.999999999999998, 87.4, 88.2, 86.8, 88.6, 87.0, 85.4, 88.4, 85.2, -4.999999999999998, -4.999999999999998, 88.6, 85.6, 88.6, 86.8, -4.999999999999998, 89.0, 86.8, -4.999999999999998, 87.6, 89.0, 86.2, 88.4, 88.8, 87.8, 88.8, 86.0, 85.2, 88.8, 88.6, -4.999999999999998, 88.8, 88.8, -4.999999999999998, 88.6, 86.6, -4.999999999999998, 89.4, 86.8, 87.8, 89.2, 86.0, 85.4, 88.6, 88.8, -4.999999999999998, 89.4, 85.6, 88.0, 88.2, 86.4, -4.999999999999998, 88.8, 87.8, -4.999999999999998, -4.999999999999998, 86.2, 88.6, 88.0, 89.4, 86.6, 88.0, 88.4, -4.999999999999998], "episode_lengths": [14, 23, 11, 18, 8, 25, 7, 4, 16, 23, 7, 6, 8, 21, 7, 25, 13, 25, 8, 7, 25, 18, 8, 25, 25, 13, 21, 16, 23, 5, 22, 18, 25, 22, 25, 20, 25, 14, 10, 17, 8, 16, 24, 9, 25, 25, 25, 8, 23, 8, 17, 25, 6, 17, 25, 13, 6, 20, 9, 7, 12, 7, 21, 25, 7, 8, 25, 7, 7, 25, 8, 18, 25, 4, 17, 12, 5, 21, 24, 8, 7, 25, 4, 23, 11, 10, 19, 25, 7, 12, 25, 25, 20, 8, 11, 4, 18, 11, 9, 25], "policy_shared_policy_reward": [98.7, -11.3, 97.8, -12.200000000000001, -11.0, 99.0, -11.700000000000001, 98.3, 99.3, -10.7, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 99.7, -10.3, 98.5, -11.5, 97.8, -12.200000000000001, -10.6, 99.4, -10.5, 99.5, 99.3, -10.7, 98.0, -12.0, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -11.700000000000001, 98.3, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -12.0, 98.0, -11.5, 98.5, 97.8, -12.200000000000001, -10.4, 99.6, -12.100000000000001, 97.9, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -11.9, 98.1, -2.500000000000001, -2.500000000000001, 98.7, -11.3, 99.1, -10.9, 98.4, -11.6, 99.3, -10.7, 98.5, -11.5, 97.7, -12.3, -10.8, 99.2, -12.4, 97.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, 97.8, -12.200000000000001, -10.7, 99.3, -11.6, 98.4, -2.500000000000001, -2.500000000000001, 99.5, -10.5, -11.6, 98.4, -2.500000000000001, -2.500000000000001, 98.8, -11.2, -10.5, 99.5, -11.9, 98.1, -10.8, 99.2, 99.4, -10.6, -11.1, 98.9, 99.4, -10.6, 98.0, -12.0, -12.4, 97.6, 99.4, -10.6, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -10.6, 99.4, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.6, 98.4, 98.9, -11.1, -10.4, 99.6, 98.0, -12.0, 97.7, -12.3, 99.3, -10.7, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 97.8, -12.200000000000001, -11.0, 99.0, -10.9, 99.1, -11.8, 98.2, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.1, -11.9, 99.3, -10.7, -11.0, 99.0, -10.3, 99.7, -11.700000000000001, 98.3, -11.0, 99.0, -10.8, 99.2, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3640672235185687, "mean_inference_ms": 1.6281052573533623, "mean_action_processing_ms": 0.08640191254520146, "mean_env_wait_ms": 0.08394535658312034, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 191000, "timesteps_this_iter": 0, "agent_timesteps_total": 382000, "timers": {"sample_time_ms": 386.865, "sample_throughput": 2584.878, "load_time_ms": 1.328, "load_throughput": 752814.143, "learn_time_ms": 101.97, "learn_throughput": 9806.815, "update_time_ms": 2.643}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.925929944387236e-35, "cur_lr": 0.0005000000000000001, "total_loss": 1965.9652587890625, "policy_loss": -0.0031196173280477525, "vf_loss": 1965.9721557617188, "vf_explained_var": 0.01637588143348694, "kl": 0.0039574279551659155, "entropy": 0.3748790919780731, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 191000, "num_agent_steps_sampled": 382000, "num_steps_trained": 191000, "num_agent_steps_trained": 382000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 12174, "training_iteration": 191, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-55", "timestamp": 1749778615, "time_this_iter_s": 0.339571475982666, "time_total_s": 73.16401815414429, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb01825cca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 73.16401815414429, "timesteps_since_restore": 0, "iterations_since_restore": 191, "perf": {"cpu_util_percent": 52.1, "ram_util_percent": 90.5}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 73.79799999999999, "episode_len_mean": 14.36, "episode_media": {}, "episodes_this_iter": 70, "policy_reward_min": {"shared_policy": -12.3}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 36.899}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.6, 86.6, -4.999999999999998, 89.4, 86.8, 87.8, 89.2, 86.0, 85.4, 88.6, 88.8, -4.999999999999998, 89.4, 85.6, 88.0, 88.2, 86.4, -4.999999999999998, 88.8, 87.8, -4.999999999999998, -4.999999999999998, 86.2, 88.6, 88.0, 89.4, 86.6, 88.0, 88.4, -4.999999999999998, 88.8, 85.4, 87.4, 87.4, -4.999999999999998, 88.2, 88.4, -4.999999999999998, 88.0, 87.8, 86.8, 88.4, 85.8, 85.6, 85.4, 87.6, 89.4, 87.2, 87.0, 89.2, 88.4, 88.4, 88.2, 88.4, 88.8, -4.999999999999998, 88.8, 87.2, 86.4, 89.4, -4.999999999999998, 88.6, 88.2, -4.999999999999998, 87.6, 85.6, 88.8, 87.6, 88.2, 87.4, 86.0, 88.6, 86.8, 88.4, 87.6, 85.4, 87.4, -4.999999999999998, -4.999999999999998, 87.8, 86.8, 88.8, -4.999999999999998, 87.0, 88.8, 88.4, 88.8, 86.2, 88.4, 86.0, 89.0, 85.6, 88.8, 88.6, 88.8, 88.4, 88.2, 88.2, -4.999999999999998, 85.6], "episode_lengths": [8, 18, 25, 4, 17, 12, 5, 21, 24, 8, 7, 25, 4, 23, 11, 10, 19, 25, 7, 12, 25, 25, 20, 8, 11, 4, 18, 11, 9, 25, 7, 24, 14, 14, 25, 10, 9, 25, 11, 12, 17, 9, 22, 23, 24, 13, 4, 15, 16, 5, 9, 9, 10, 9, 7, 25, 7, 15, 19, 4, 25, 8, 10, 25, 13, 23, 7, 13, 10, 14, 21, 8, 17, 9, 13, 24, 14, 25, 25, 12, 17, 7, 25, 16, 7, 9, 7, 20, 9, 21, 6, 23, 7, 8, 7, 9, 10, 10, 25, 23], "policy_shared_policy_reward": [99.3, -10.7, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -11.6, 98.4, 98.9, -11.1, -10.4, 99.6, 98.0, -12.0, 97.7, -12.3, 99.3, -10.7, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -10.3, 99.7, 97.8, -12.200000000000001, -11.0, 99.0, -10.9, 99.1, -11.8, 98.2, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.1, -11.9, 99.3, -10.7, -11.0, 99.0, -10.3, 99.7, -11.700000000000001, 98.3, -11.0, 99.0, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -12.3, 97.7, 98.7, -11.3, 98.7, -11.3, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -10.8, 99.2, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -11.1, 98.9, 98.4, -11.6, 99.2, -10.8, 97.9, -12.100000000000001, 97.8, -12.200000000000001, -12.3, 97.7, 98.8, -11.2, 99.7, -10.3, -11.4, 98.6, 98.5, -11.5, -10.4, 99.6, -10.8, 99.2, 99.2, -10.8, 99.1, -10.9, -10.8, 99.2, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -11.4, 98.6, -11.8, 98.2, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -10.9, 99.1, -2.500000000000001, -2.500000000000001, 98.8, -11.2, 97.8, -12.200000000000001, -10.6, 99.4, 98.8, -11.2, -10.9, 99.1, 98.7, -11.3, -12.0, 98.0, 99.3, -10.7, -11.6, 98.4, 99.2, -10.8, -11.2, 98.8, -12.3, 97.7, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -11.6, 98.4, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 98.5, -11.5, 99.4, -10.6, 99.2, -10.8, -10.6, 99.4, -11.9, 98.1, -10.8, 99.2, 98.0, -12.0, -10.5, 99.5, 97.8, -12.200000000000001, -10.6, 99.4, 99.3, -10.7, 99.4, -10.6, 99.2, -10.8, 99.1, -10.9, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.36396008876503105, "mean_inference_ms": 1.6278407837499216, "mean_action_processing_ms": 0.08635939681380503, "mean_env_wait_ms": 0.08408869598719487, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 192000, "timesteps_this_iter": 0, "agent_timesteps_total": 384000, "timers": {"sample_time_ms": 386.846, "sample_throughput": 2585.01, "load_time_ms": 1.275, "load_throughput": 784465.932, "learn_time_ms": 100.461, "learn_throughput": 9954.092, "update_time_ms": 2.719}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 9.62964972193618e-36, "cur_lr": 0.0005000000000000001, "total_loss": 2211.4609375, "policy_loss": -0.003985801803719369, "vf_loss": 2211.468701171875, "vf_explained_var": 0.00839294195175171, "kl": 0.0036263761301226437, "entropy": 0.3832879811525345, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 192000, "num_agent_steps_sampled": 384000, "num_steps_trained": 192000, "num_agent_steps_trained": 384000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 12244, "training_iteration": 192, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-56", "timestamp": 1749778616, "time_this_iter_s": 0.35848450660705566, "time_total_s": 73.52250266075134, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb018224160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 73.52250266075134, "timesteps_since_restore": 0, "iterations_since_restore": 192, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 68.526, "episode_len_mean": 13.66, "episode_media": {}, "episodes_this_iter": 76, "policy_reward_min": {"shared_policy": -12.200000000000001}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 34.263000000000005}, "custom_metrics": {}, "hist_stats": {"episode_reward": [87.4, -4.999999999999998, -4.999999999999998, 87.8, 86.8, 88.8, -4.999999999999998, 87.0, 88.8, 88.4, 88.8, 86.2, 88.4, 86.0, 89.0, 85.6, 88.8, 88.6, 88.8, 88.4, 88.2, 88.2, -4.999999999999998, 85.6, -4.999999999999998, 88.8, 86.6, 88.8, 87.6, 88.6, 88.8, 88.6, 89.2, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, 87.0, 88.8, 88.8, 88.6, 88.2, -4.999999999999998, 88.4, 88.2, 88.4, 89.4, 88.8, 87.6, -4.999999999999998, -4.999999999999998, -4.999999999999998, 87.6, 88.8, 88.0, -4.999999999999998, 88.8, 88.8, 88.8, 89.2, 88.4, 87.8, 87.2, 87.6, 88.6, -4.999999999999998, 88.4, 85.6, -4.999999999999998, 87.0, 85.6, -4.999999999999998, -4.999999999999998, 88.8, 87.6, 88.8, 89.2, 88.8, 88.2, 87.6, 88.4, 87.8, 88.6, 88.2, 86.8, 88.4, 88.8, 87.8, 88.4, 88.2, 88.8, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, 88.6, 86.8, 89.2, -4.999999999999998, 88.2], "episode_lengths": [14, 25, 25, 12, 17, 7, 25, 16, 7, 9, 7, 20, 9, 21, 6, 23, 7, 8, 7, 9, 10, 10, 25, 23, 25, 7, 18, 7, 13, 8, 7, 8, 5, 25, 25, 25, 7, 16, 7, 7, 8, 10, 25, 9, 10, 9, 4, 7, 13, 25, 25, 25, 13, 7, 11, 25, 7, 7, 7, 5, 9, 12, 15, 13, 8, 25, 9, 23, 25, 16, 23, 25, 25, 7, 13, 7, 5, 7, 10, 13, 9, 12, 8, 10, 17, 9, 7, 12, 9, 10, 7, 25, 25, 22, 25, 8, 17, 5, 25, 10], "policy_shared_policy_reward": [-11.3, 98.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.1, 98.9, -11.6, 98.4, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 98.5, -11.5, 99.4, -10.6, 99.2, -10.8, -10.6, 99.4, -11.9, 98.1, -10.8, 99.2, 98.0, -12.0, -10.5, 99.5, 97.8, -12.200000000000001, -10.6, 99.4, 99.3, -10.7, 99.4, -10.6, 99.2, -10.8, 99.1, -10.9, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 98.3, -11.700000000000001, -10.6, 99.4, -11.2, 98.8, 99.3, -10.7, 99.4, -10.6, -10.7, 99.3, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 98.5, -11.5, -10.6, 99.4, 99.4, -10.6, -10.7, 99.3, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -10.9, 99.1, 99.2, -10.8, -10.3, 99.7, -10.6, 99.4, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.8, -11.2, 99.4, -10.6, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -10.6, 99.4, -10.6, 99.4, -10.4, 99.6, 99.2, -10.8, 98.9, -11.1, -11.4, 98.6, -11.2, 98.8, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -10.8, 99.2, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 98.8, -11.2, 99.4, -10.6, -10.4, 99.6, 99.4, -10.6, 99.1, -10.9, -11.2, 98.8, 99.2, -10.8, 98.9, -11.1, 99.3, -10.7, 99.1, -10.9, 98.4, -11.6, 99.2, -10.8, -10.6, 99.4, -11.1, 98.9, 99.2, -10.8, 99.1, -10.9, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, 98.4, -11.6, -10.4, 99.6, -2.500000000000001, -2.500000000000001, 99.1, -10.9]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3635903945948076, "mean_inference_ms": 1.6256726087345754, "mean_action_processing_ms": 0.08631816640484438, "mean_env_wait_ms": 0.083898766605352, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 193000, "timesteps_this_iter": 0, "agent_timesteps_total": 386000, "timers": {"sample_time_ms": 384.937, "sample_throughput": 2597.83, "load_time_ms": 1.249, "load_throughput": 800439.695, "learn_time_ms": 98.241, "learn_throughput": 10179.008, "update_time_ms": 2.656}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 4.81482486096809e-36, "cur_lr": 0.0005000000000000001, "total_loss": 1922.8788452148438, "policy_loss": -0.0029412996023893355, "vf_loss": 1922.8850708007812, "vf_explained_var": 0.013809293508529663, "kl": 0.004338877322301471, "entropy": 0.3210386037826538, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 193000, "num_agent_steps_sampled": 386000, "num_steps_trained": 193000, "num_agent_steps_trained": 386000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 12320, "training_iteration": 193, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-56", "timestamp": 1749778616, "time_this_iter_s": 0.3318338394165039, "time_total_s": 73.85433650016785, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c9c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 73.85433650016785, "timesteps_since_restore": 0, "iterations_since_restore": 193, "perf": {"cpu_util_percent": 50.4, "ram_util_percent": 90.4}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 70.14399999999999, "episode_len_mean": 14.59, "episode_media": {}, "episodes_this_iter": 67, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 35.071999999999996}, "custom_metrics": {}, "hist_stats": {"episode_reward": [85.6, -4.999999999999998, 87.0, 85.6, -4.999999999999998, -4.999999999999998, 88.8, 87.6, 88.8, 89.2, 88.8, 88.2, 87.6, 88.4, 87.8, 88.6, 88.2, 86.8, 88.4, 88.8, 87.8, 88.4, 88.2, 88.8, -4.999999999999998, -4.999999999999998, 85.8, -4.999999999999998, 88.6, 86.8, 89.2, -4.999999999999998, 88.2, 87.0, 89.2, 86.6, -4.999999999999998, 87.0, 88.6, 86.2, 88.4, 85.8, 87.4, 88.2, 86.6, 88.4, -4.999999999999998, 89.2, 89.2, 88.8, -4.999999999999998, -4.999999999999998, 88.8, 86.0, -4.999999999999998, 85.6, 89.2, -4.999999999999998, -4.999999999999998, 88.8, 88.8, 85.4, 89.0, 89.4, 88.2, 85.2, 87.2, 87.0, -4.999999999999998, 86.2, 86.2, 85.6, 87.4, 88.6, 88.2, 88.8, -4.999999999999998, 87.6, 89.2, 88.2, 86.39999999999999, 88.6, 88.2, -4.999999999999998, 88.2, 87.8, 85.8, 88.8, 88.8, 86.0, 88.8, 87.0, 89.2, 87.6, 88.8, 88.8, -4.999999999999998, -4.999999999999998, 86.0, 87.4], "episode_lengths": [23, 25, 16, 23, 25, 25, 7, 13, 7, 5, 7, 10, 13, 9, 12, 8, 10, 17, 9, 7, 12, 9, 10, 7, 25, 25, 22, 25, 8, 17, 5, 25, 10, 16, 5, 18, 25, 16, 8, 20, 9, 22, 14, 10, 18, 9, 25, 5, 5, 7, 25, 25, 7, 21, 25, 23, 5, 25, 25, 7, 7, 24, 6, 4, 10, 25, 15, 16, 25, 20, 20, 23, 14, 8, 10, 7, 25, 13, 5, 10, 19, 8, 10, 25, 10, 12, 22, 7, 7, 21, 7, 16, 5, 13, 7, 7, 25, 25, 21, 14], "policy_shared_policy_reward": [97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, 97.8, -12.200000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 98.8, -11.2, 99.4, -10.6, -10.4, 99.6, 99.4, -10.6, 99.1, -10.9, -11.2, 98.8, 99.2, -10.8, 98.9, -11.1, 99.3, -10.7, 99.1, -10.9, 98.4, -11.6, 99.2, -10.8, -10.6, 99.4, -11.1, 98.9, 99.2, -10.8, 99.1, -10.9, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, 98.4, -11.6, -10.4, 99.6, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -11.5, 98.5, -10.4, 99.6, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, 98.5, -11.5, 99.3, -10.7, 98.1, -11.9, 99.2, -10.8, -12.100000000000001, 97.9, -11.3, 98.7, 99.1, -10.9, 98.3, -11.700000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -10.4, 99.6, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 98.0, -12.0, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -10.6, 99.4, -12.3, 97.7, 99.5, -10.5, -10.3, 99.7, 99.1, -10.9, -12.4, 97.6, -11.4, 98.6, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -11.9, 98.1, 98.1, -11.9, 97.8, -12.200000000000001, -11.3, 98.7, 99.3, -10.7, 99.1, -10.9, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -10.4, 99.6, 99.1, -10.9, 98.2, -11.8, -10.7, 99.3, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 98.9, -11.1, 97.9, -12.100000000000001, 99.4, -10.6, -10.6, 99.4, 98.0, -12.0, -10.6, 99.4, -11.5, 98.5, -10.4, 99.6, 98.8, -11.2, 99.4, -10.6, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -11.3, 98.7]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.36402064711717885, "mean_inference_ms": 1.6269375727427973, "mean_action_processing_ms": 0.08621658497213039, "mean_env_wait_ms": 0.08392999215501465, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 194000, "timesteps_this_iter": 0, "agent_timesteps_total": 388000, "timers": {"sample_time_ms": 381.81, "sample_throughput": 2619.103, "load_time_ms": 1.296, "load_throughput": 771877.289, "learn_time_ms": 96.972, "learn_throughput": 10312.206, "update_time_ms": 2.639}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 2.407412430484045e-36, "cur_lr": 0.0005000000000000001, "total_loss": 1997.7075317382812, "policy_loss": -0.0015198379755020142, "vf_loss": 1997.7127197265625, "vf_explained_var": 0.008898866176605225, "kl": 0.006680277181862815, "entropy": 0.37004949152469635, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 194000, "num_agent_steps_sampled": 388000, "num_steps_trained": 194000, "num_agent_steps_trained": 388000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 12387, "training_iteration": 194, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-57", "timestamp": 1749778617, "time_this_iter_s": 0.3360583782196045, "time_total_s": 74.19039487838745, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c9550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 74.19039487838745, "timesteps_since_restore": 0, "iterations_since_restore": 194, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 66.432, "episode_len_mean": 15.11, "episode_media": {}, "episodes_this_iter": 62, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 33.216}, "custom_metrics": {}, "hist_stats": {"episode_reward": [89.0, 89.4, 88.2, 85.2, 87.2, 87.0, -4.999999999999998, 86.2, 86.2, 85.6, 87.4, 88.6, 88.2, 88.8, -4.999999999999998, 87.6, 89.2, 88.2, 86.39999999999999, 88.6, 88.2, -4.999999999999998, 88.2, 87.8, 85.8, 88.8, 88.8, 86.0, 88.8, 87.0, 89.2, 87.6, 88.8, 88.8, -4.999999999999998, -4.999999999999998, 86.0, 87.4, -4.999999999999998, 88.6, 88.8, 87.6, 88.0, 88.8, 87.4, 88.8, -4.999999999999998, 88.4, -4.999999999999998, 88.4, 88.8, 88.2, 87.0, -4.999999999999998, 88.0, -4.999999999999998, 85.6, 88.8, 87.8, 88.4, -4.999999999999998, 87.0, 88.4, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, 86.2, 88.2, -4.999999999999998, 89.0, 85.6, 88.8, 87.6, 88.8, 89.0, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, 87.2, 87.0, 88.0, 86.6, 86.39999999999999, -4.999999999999998, 87.0, -4.999999999999998, 85.2, -4.999999999999998, 89.2, 87.2, 88.6, 88.8, 86.2, 88.6, 89.0, 87.4, -4.999999999999998, -4.999999999999998], "episode_lengths": [6, 4, 10, 25, 15, 16, 25, 20, 20, 23, 14, 8, 10, 7, 25, 13, 5, 10, 19, 8, 10, 25, 10, 12, 22, 7, 7, 21, 7, 16, 5, 13, 7, 7, 25, 25, 21, 14, 25, 8, 7, 13, 11, 7, 14, 7, 25, 9, 25, 9, 7, 10, 16, 25, 11, 25, 23, 7, 12, 9, 25, 16, 9, 25, 25, 10, 25, 20, 10, 25, 6, 23, 7, 13, 7, 6, 25, 25, 14, 25, 15, 16, 11, 18, 19, 25, 16, 25, 25, 25, 5, 15, 8, 7, 20, 8, 6, 14, 25, 25], "policy_shared_policy_reward": [99.5, -10.5, -10.3, 99.7, 99.1, -10.9, -12.4, 97.6, -11.4, 98.6, -11.5, 98.5, -2.500000000000001, -2.500000000000001, -11.9, 98.1, 98.1, -11.9, 97.8, -12.200000000000001, -11.3, 98.7, 99.3, -10.7, 99.1, -10.9, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -11.2, 98.8, -10.4, 99.6, 99.1, -10.9, 98.2, -11.8, -10.7, 99.3, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 99.1, -10.9, 98.9, -11.1, 97.9, -12.100000000000001, 99.4, -10.6, -10.6, 99.4, 98.0, -12.0, -10.6, 99.4, -11.5, 98.5, -10.4, 99.6, 98.8, -11.2, 99.4, -10.6, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.0, -12.0, -11.3, 98.7, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -10.6, 99.4, 98.8, -11.2, -11.0, 99.0, -10.6, 99.4, 98.7, -11.3, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -10.6, 99.4, -10.9, 99.1, 98.5, -11.5, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, 99.4, -10.6, 98.9, -11.1, -10.8, 99.2, -2.500000000000001, -2.500000000000001, 98.5, -11.5, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, 98.1, -11.9, 99.1, -10.9, -2.500000000000001, -2.500000000000001, 99.5, -10.5, 97.8, -12.200000000000001, 99.4, -10.6, -11.2, 98.8, 99.4, -10.6, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -11.5, 98.5, 99.0, -11.0, -11.700000000000001, 98.3, 98.2, -11.8, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -11.4, 98.6, 99.3, -10.7, 99.4, -10.6, 98.1, -11.9, 99.3, -10.7, 99.5, -10.5, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3642417064350494, "mean_inference_ms": 1.6271043797583422, "mean_action_processing_ms": 0.08629439506375616, "mean_env_wait_ms": 0.08398595450760002, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 195000, "timesteps_this_iter": 0, "agent_timesteps_total": 390000, "timers": {"sample_time_ms": 379.518, "sample_throughput": 2634.922, "load_time_ms": 1.271, "load_throughput": 786864.776, "learn_time_ms": 96.344, "learn_throughput": 10379.51, "update_time_ms": 2.621}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 2.407412430484045e-36, "cur_lr": 0.0005000000000000001, "total_loss": 1694.8493896484374, "policy_loss": -0.0040125658153556286, "vf_loss": 1694.8570190429687, "vf_explained_var": 0.017697298526763917, "kl": 0.006330930951744751, "entropy": 0.36286934912204744, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 195000, "num_agent_steps_sampled": 390000, "num_steps_trained": 195000, "num_agent_steps_trained": 390000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 12449, "training_iteration": 195, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-57", "timestamp": 1749778617, "time_this_iter_s": 0.3388800621032715, "time_total_s": 74.52927494049072, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5af0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 74.52927494049072, "timesteps_since_restore": 0, "iterations_since_restore": 195, "perf": {"cpu_util_percent": 54.2, "ram_util_percent": 90.4}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 65.68399999999998, "episode_len_mean": 14.34, "episode_media": {}, "episodes_this_iter": 74, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 32.842}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.8, 89.0, -4.999999999999998, -4.999999999999998, 87.4, -4.999999999999998, 87.2, 87.0, 88.0, 86.6, 86.39999999999999, -4.999999999999998, 87.0, -4.999999999999998, 85.2, -4.999999999999998, 89.2, 87.2, 88.6, 88.8, 86.2, 88.6, 89.0, 87.4, -4.999999999999998, -4.999999999999998, -4.999999999999998, 88.8, 85.6, 89.4, 88.6, -4.999999999999998, 88.4, -4.999999999999998, 86.6, 88.4, -4.999999999999998, -4.999999999999998, 88.6, -4.999999999999998, 88.8, 88.8, -4.999999999999998, 85.6, 88.4, 88.4, 88.8, 88.8, -4.999999999999998, 86.4, -4.999999999999998, -4.999999999999998, 88.8, 88.2, 88.8, -4.999999999999998, 88.8, 87.2, 88.8, 89.0, 88.8, 88.8, 88.8, 88.8, 89.0, 88.4, -4.999999999999998, 86.4, 88.8, 88.6, 88.2, 88.8, 88.6, 86.2, 88.0, 88.0, 88.4, 88.8, 88.4, 86.0, 88.8, 88.6, 86.8, 88.4, -4.999999999999998, 89.2, 87.6, 85.6, 88.8, 87.6, 89.4, 88.8, 86.0, -4.999999999999998, -4.999999999999998, 88.6, -4.999999999999998, 89.2, 86.4, 87.2], "episode_lengths": [7, 6, 25, 25, 14, 25, 15, 16, 11, 18, 19, 25, 16, 25, 25, 25, 5, 15, 8, 7, 20, 8, 6, 14, 25, 25, 25, 7, 23, 4, 8, 25, 9, 25, 18, 9, 25, 25, 8, 25, 7, 7, 25, 23, 9, 9, 7, 7, 25, 19, 25, 25, 7, 10, 7, 25, 7, 15, 7, 6, 7, 7, 7, 7, 6, 9, 25, 19, 7, 8, 10, 7, 8, 20, 11, 11, 9, 7, 9, 21, 7, 8, 17, 9, 25, 5, 13, 23, 7, 13, 4, 7, 21, 25, 25, 8, 25, 5, 19, 15], "policy_shared_policy_reward": [99.4, -10.6, -10.5, 99.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.3, 98.7, -2.500000000000001, -2.500000000000001, -11.4, 98.6, -11.5, 98.5, 99.0, -11.0, -11.700000000000001, 98.3, 98.2, -11.8, -2.500000000000001, -2.500000000000001, 98.5, -11.5, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -11.4, 98.6, 99.3, -10.7, 99.4, -10.6, 98.1, -11.9, 99.3, -10.7, 99.5, -10.5, 98.7, -11.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -12.200000000000001, 97.8, -10.3, 99.7, -10.7, 99.3, -2.500000000000001, -2.500000000000001, 99.2, -10.8, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.7, 99.3, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -10.6, 99.4, -2.500000000000001, -2.500000000000001, 97.8, -12.200000000000001, -10.8, 99.2, 99.2, -10.8, 99.4, -10.6, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 99.1, -10.9, -10.6, 99.4, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -11.4, 98.6, 99.4, -10.6, 99.5, -10.5, -10.6, 99.4, 99.4, -10.6, -10.6, 99.4, -10.6, 99.4, 99.5, -10.5, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -10.6, 99.4, 99.3, -10.7, 99.1, -10.9, -10.6, 99.4, -10.7, 99.3, -11.9, 98.1, 99.0, -11.0, 99.0, -11.0, -10.8, 99.2, -10.6, 99.4, 99.2, -10.8, 98.0, -12.0, -10.6, 99.4, 99.3, -10.7, 98.4, -11.6, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -11.2, 98.8, -12.200000000000001, 97.8, 99.4, -10.6, -11.2, 98.8, -10.3, 99.7, -10.6, 99.4, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -11.8, 98.2, 98.6, -11.4]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.36412676212604056, "mean_inference_ms": 1.6269407753853131, "mean_action_processing_ms": 0.08623611731303449, "mean_env_wait_ms": 0.08403223719685622, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 196000, "timesteps_this_iter": 0, "agent_timesteps_total": 392000, "timers": {"sample_time_ms": 379.032, "sample_throughput": 2638.297, "load_time_ms": 1.297, "load_throughput": 770742.572, "learn_time_ms": 95.566, "learn_throughput": 10463.964, "update_time_ms": 2.616}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 2.407412430484045e-36, "cur_lr": 0.0005000000000000001, "total_loss": 1903.1248901367187, "policy_loss": -0.002180720865726471, "vf_loss": 1903.1302978515625, "vf_explained_var": 0.02874838709831238, "kl": 0.004062307739070547, "entropy": 0.3240397542715073, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 196000, "num_agent_steps_sampled": 392000, "num_steps_trained": 196000, "num_agent_steps_trained": 392000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 12523, "training_iteration": 196, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-57", "timestamp": 1749778617, "time_this_iter_s": 0.336500883102417, "time_total_s": 74.86577582359314, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5ee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 74.86577582359314, "timesteps_since_restore": 0, "iterations_since_restore": 196, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 69.464, "episode_len_mean": 13.48, "episode_media": {}, "episodes_this_iter": 74, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 34.732}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.0, 88.0, 88.4, 88.8, 88.4, 86.0, 88.8, 88.6, 86.8, 88.4, -4.999999999999998, 89.2, 87.6, 85.6, 88.8, 87.6, 89.4, 88.8, 86.0, -4.999999999999998, -4.999999999999998, 88.6, -4.999999999999998, 89.2, 86.4, 87.2, -4.999999999999998, -4.999999999999998, 88.4, 88.4, 88.4, 88.8, 88.6, 88.8, -4.999999999999998, 87.2, 89.2, 87.4, 88.8, 89.2, -4.999999999999998, 88.8, -4.999999999999998, 87.8, 88.4, 89.2, 88.8, 88.2, -4.999999999999998, -4.999999999999998, 86.4, 89.2, 89.4, -4.999999999999998, 88.8, 88.8, -4.999999999999998, 86.6, 86.6, 87.8, 86.6, 85.2, -4.999999999999998, 87.2, 86.6, -4.999999999999998, 89.2, -4.999999999999998, -4.999999999999998, 88.8, -4.999999999999998, 89.2, 88.0, 87.4, 89.2, 87.0, 88.8, 89.4, 88.8, 86.8, 87.4, 88.8, 87.0, 86.8, -4.999999999999998, 88.8, 88.0, 88.8, 88.4, 88.4, -4.999999999999998, 88.8, 88.2, 87.4, 88.6, 88.8, 88.0, 88.4, 86.2, 88.8], "episode_lengths": [11, 11, 9, 7, 9, 21, 7, 8, 17, 9, 25, 5, 13, 23, 7, 13, 4, 7, 21, 25, 25, 8, 25, 5, 19, 15, 25, 25, 9, 9, 9, 7, 8, 7, 25, 15, 5, 14, 7, 5, 25, 7, 25, 12, 9, 5, 7, 10, 25, 25, 19, 5, 4, 25, 7, 7, 25, 18, 18, 12, 18, 25, 25, 15, 18, 25, 5, 25, 25, 7, 25, 5, 11, 14, 5, 16, 7, 4, 7, 17, 14, 7, 16, 17, 25, 7, 11, 7, 9, 9, 25, 7, 10, 14, 8, 7, 11, 9, 20, 7], "policy_shared_policy_reward": [99.0, -11.0, 99.0, -11.0, -10.8, 99.2, -10.6, 99.4, 99.2, -10.8, 98.0, -12.0, -10.6, 99.4, 99.3, -10.7, 98.4, -11.6, 99.2, -10.8, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -11.2, 98.8, -12.200000000000001, 97.8, 99.4, -10.6, -11.2, 98.8, -10.3, 99.7, -10.6, 99.4, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -11.8, 98.2, 98.6, -11.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.8, 99.2, 99.2, -10.8, 99.2, -10.8, 99.4, -10.6, 99.3, -10.7, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -10.4, 99.6, -11.3, 98.7, 99.4, -10.6, -10.4, 99.6, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -11.1, 98.9, 99.2, -10.8, -10.4, 99.6, 99.4, -10.6, -10.9, 99.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.8, 98.2, -10.4, 99.6, -10.3, 99.7, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -10.6, 99.4, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, 98.3, -11.700000000000001, -11.1, 98.9, 98.3, -11.700000000000001, 97.6, -12.4, -2.500000000000001, -2.500000000000001, -11.4, 98.6, 98.3, -11.700000000000001, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -11.0, 99.0, -11.3, 98.7, -10.4, 99.6, 98.5, -11.5, 99.4, -10.6, -10.3, 99.7, 99.4, -10.6, 98.4, -11.6, -11.3, 98.7, 99.4, -10.6, 98.5, -11.5, -11.6, 98.4, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 99.0, -11.0, 99.4, -10.6, 99.2, -10.8, 99.2, -10.8, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -10.9, 99.1, 98.7, -11.3, -10.7, 99.3, 99.4, -10.6, 99.0, -11.0, 99.2, -10.8, 98.1, -11.9, 99.4, -10.6]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.36371186087011537, "mean_inference_ms": 1.6244757309448297, "mean_action_processing_ms": 0.08621772249554105, "mean_env_wait_ms": 0.08396766124412432, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 197000, "timesteps_this_iter": 0, "agent_timesteps_total": 394000, "timers": {"sample_time_ms": 378.028, "sample_throughput": 2645.309, "load_time_ms": 1.289, "load_throughput": 776047.514, "learn_time_ms": 95.263, "learn_throughput": 10497.218, "update_time_ms": 2.659}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.2037062152420225e-36, "cur_lr": 0.0005000000000000001, "total_loss": 1929.5310791015625, "policy_loss": -0.0028560828417539597, "vf_loss": 1929.5373901367188, "vf_explained_var": 0.018508368730545045, "kl": 0.00538224620927581, "entropy": 0.3486409306526184, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 197000, "num_agent_steps_sampled": 394000, "num_steps_trained": 197000, "num_agent_steps_trained": 394000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 12597, "training_iteration": 197, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-58", "timestamp": 1749778618, "time_this_iter_s": 0.34905028343200684, "time_total_s": 75.21482610702515, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182249d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 75.21482610702515, "timesteps_since_restore": 0, "iterations_since_restore": 197, "perf": {"cpu_util_percent": 53.3, "ram_util_percent": 90.4}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 70.376, "episode_len_mean": 13.43, "episode_media": {}, "episodes_this_iter": 73, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 35.187999999999995}, "custom_metrics": {}, "hist_stats": {"episode_reward": [87.4, 89.2, 87.0, 88.8, 89.4, 88.8, 86.8, 87.4, 88.8, 87.0, 86.8, -4.999999999999998, 88.8, 88.0, 88.8, 88.4, 88.4, -4.999999999999998, 88.8, 88.2, 87.4, 88.6, 88.8, 88.0, 88.4, 86.2, 88.8, -4.999999999999998, 88.8, -4.999999999999998, 88.8, -4.999999999999998, 88.4, 88.0, 88.2, 85.2, 86.4, 88.8, -4.999999999999998, 88.8, 86.4, 85.8, 88.8, -4.999999999999998, -4.999999999999998, 88.2, 87.4, 88.2, 88.6, 86.2, 87.6, 88.8, 89.2, 86.4, 88.8, 88.6, 88.8, 88.8, 88.8, 87.6, 88.8, 88.8, 88.8, -4.999999999999998, 88.8, 88.8, -4.999999999999998, -4.999999999999998, 88.0, 85.2, 86.6, 88.6, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, 85.6, 88.8, -4.999999999999998, 88.8, 88.8, -4.999999999999998, 88.8, 88.8, 88.6, 87.4, 89.4, -4.999999999999998, 88.4, 86.39999999999999, -4.999999999999998, -4.999999999999998, 86.8, 88.8, 88.4, 88.8, 86.0, 88.6, 88.8, 88.6], "episode_lengths": [14, 5, 16, 7, 4, 7, 17, 14, 7, 16, 17, 25, 7, 11, 7, 9, 9, 25, 7, 10, 14, 8, 7, 11, 9, 20, 7, 25, 7, 25, 7, 25, 9, 11, 10, 25, 19, 7, 25, 7, 19, 22, 7, 25, 25, 10, 14, 10, 8, 20, 13, 7, 5, 19, 7, 8, 7, 7, 7, 13, 7, 7, 7, 25, 7, 7, 25, 25, 11, 25, 18, 8, 25, 25, 10, 25, 23, 7, 25, 7, 7, 25, 7, 7, 8, 14, 4, 25, 9, 19, 25, 25, 17, 7, 9, 7, 21, 8, 7, 8], "policy_shared_policy_reward": [-11.3, 98.7, -10.4, 99.6, 98.5, -11.5, 99.4, -10.6, -10.3, 99.7, 99.4, -10.6, 98.4, -11.6, -11.3, 98.7, 99.4, -10.6, 98.5, -11.5, -11.6, 98.4, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 99.0, -11.0, 99.4, -10.6, 99.2, -10.8, 99.2, -10.8, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -10.9, 99.1, 98.7, -11.3, -10.7, 99.3, 99.4, -10.6, 99.0, -11.0, 99.2, -10.8, 98.1, -11.9, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, 99.2, -10.8, 99.0, -11.0, -10.9, 99.1, -12.4, 97.6, -11.8, 98.2, -10.6, 99.4, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -11.8, 98.2, 97.9, -12.100000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, 98.7, -11.3, 99.1, -10.9, 99.3, -10.7, -11.9, 98.1, 98.8, -11.2, 99.4, -10.6, -10.4, 99.6, -11.8, 98.2, 99.4, -10.6, 99.3, -10.7, 99.4, -10.6, 99.4, -10.6, 99.4, -10.6, 98.8, -11.2, 99.4, -10.6, 99.4, -10.6, -10.6, 99.4, -2.500000000000001, -2.500000000000001, 99.4, -10.6, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -12.4, 97.6, -11.700000000000001, 98.3, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -10.6, 99.4, 99.4, -10.6, 99.3, -10.7, 98.7, -11.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.8, 99.2, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -10.6, 99.4, 99.2, -10.8, -10.6, 99.4, -12.0, 98.0, 99.3, -10.7, -10.6, 99.4, 99.3, -10.7]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3634841838890515, "mean_inference_ms": 1.622762293638129, "mean_action_processing_ms": 0.08635145259169807, "mean_env_wait_ms": 0.08389451326469326, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 198000, "timesteps_this_iter": 0, "agent_timesteps_total": 396000, "timers": {"sample_time_ms": 378.002, "sample_throughput": 2645.491, "load_time_ms": 1.302, "load_throughput": 768286.044, "learn_time_ms": 95.298, "learn_throughput": 10493.394, "update_time_ms": 2.672}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.2037062152420225e-36, "cur_lr": 0.0005000000000000001, "total_loss": 1784.6428955078125, "policy_loss": -0.0037170622497797014, "vf_loss": 1784.6500732421875, "vf_explained_var": 0.05668044090270996, "kl": 0.010068000529071242, "entropy": 0.3462294965982437, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 198000, "num_agent_steps_sampled": 396000, "num_steps_trained": 198000, "num_agent_steps_trained": 396000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 12670, "training_iteration": 198, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-58", "timestamp": 1749778618, "time_this_iter_s": 0.34380435943603516, "time_total_s": 75.55863046646118, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0181f5af0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 75.55863046646118, "timesteps_since_restore": 0, "iterations_since_restore": 198, "perf": {"cpu_util_percent": 57.1, "ram_util_percent": 90.4}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 64.73, "episode_len_mean": 14.6, "episode_media": {}, "episodes_this_iter": 68, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 32.365}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.0, 85.2, 86.6, 88.6, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, 85.6, 88.8, -4.999999999999998, 88.8, 88.8, -4.999999999999998, 88.8, 88.8, 88.6, 87.4, 89.4, -4.999999999999998, 88.4, 86.39999999999999, -4.999999999999998, -4.999999999999998, 86.8, 88.8, 88.4, 88.8, 86.0, 88.6, 88.8, 88.6, -4.999999999999998, 88.8, 89.2, 88.6, 89.2, -4.999999999999998, 86.39999999999999, 89.2, 89.2, 89.2, 89.4, 86.0, 86.4, 88.6, 89.2, -4.999999999999998, 88.4, -4.999999999999998, 88.8, 89.2, 87.0, 89.2, 85.8, 89.4, -4.999999999999998, 88.8, 85.8, -4.999999999999998, 87.2, 89.2, 88.8, 86.4, 86.0, -4.999999999999998, -4.999999999999998, 88.8, 85.2, 88.4, -4.999999999999998, 89.4, 88.6, 88.4, 86.2, 87.6, -4.999999999999998, -4.999999999999998, 86.6, 89.2, 89.2, 88.0, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, 87.4, 87.4, 86.4, 86.0, 87.0, 86.6, -4.999999999999998, -4.999999999999998, 88.8, 89.2, 87.8, 88.8, 87.8, -4.999999999999998], "episode_lengths": [11, 25, 18, 8, 25, 25, 10, 25, 23, 7, 25, 7, 7, 25, 7, 7, 8, 14, 4, 25, 9, 19, 25, 25, 17, 7, 9, 7, 21, 8, 7, 8, 25, 7, 5, 8, 5, 25, 19, 5, 5, 5, 4, 21, 19, 8, 5, 25, 9, 25, 7, 5, 16, 5, 22, 4, 25, 7, 22, 25, 15, 5, 7, 19, 21, 25, 25, 7, 25, 9, 25, 4, 8, 9, 20, 13, 25, 25, 18, 5, 5, 11, 25, 8, 25, 25, 14, 14, 19, 21, 16, 18, 25, 25, 7, 5, 12, 7, 12, 25], "policy_shared_policy_reward": [99.0, -11.0, -12.4, 97.6, -11.700000000000001, 98.3, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.1, -10.9, -2.500000000000001, -2.500000000000001, -12.200000000000001, 97.8, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -10.6, 99.4, 99.4, -10.6, 99.3, -10.7, 98.7, -11.3, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.8, 99.2, 98.2, -11.8, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.6, 98.4, -10.6, 99.4, 99.2, -10.8, -10.6, 99.4, -12.0, 98.0, 99.3, -10.7, -10.6, 99.4, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -10.4, 99.6, -10.7, 99.3, -10.4, 99.6, -2.500000000000001, -2.500000000000001, 98.2, -11.8, -10.4, 99.6, -10.4, 99.6, -10.4, 99.6, -10.3, 99.7, -12.0, 98.0, -11.8, 98.2, 99.3, -10.7, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -10.8, 99.2, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -10.4, 99.6, -11.5, 98.5, -10.4, 99.6, -12.100000000000001, 97.9, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.6, 99.4, 97.9, -12.100000000000001, -2.500000000000001, -2.500000000000001, 98.6, -11.4, -10.4, 99.6, -10.6, 99.4, -11.8, 98.2, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -12.4, 97.6, 99.2, -10.8, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -10.7, 99.3, 99.2, -10.8, -11.9, 98.1, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -10.4, 99.6, -10.4, 99.6, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -11.3, 98.7, -11.8, 98.2, 98.0, -12.0, 98.5, -11.5, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -10.4, 99.6, 98.9, -11.1, -10.6, 99.4, 98.9, -11.1, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.36399279567303, "mean_inference_ms": 1.6237892014067545, "mean_action_processing_ms": 0.08619173523840264, "mean_env_wait_ms": 0.08391057705581793, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 199000, "timesteps_this_iter": 0, "agent_timesteps_total": 398000, "timers": {"sample_time_ms": 378.646, "sample_throughput": 2640.993, "load_time_ms": 1.236, "load_throughput": 808852.377, "learn_time_ms": 95.108, "learn_throughput": 10514.335, "update_time_ms": 2.666}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.2037062152420225e-36, "cur_lr": 0.0005000000000000001, "total_loss": 1813.7731323242188, "policy_loss": -0.005828424915671348, "vf_loss": 1813.7832397460938, "vf_explained_var": 0.0157276451587677, "kl": 0.008134060919569207, "entropy": 0.42684171795845033, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 199000, "num_agent_steps_sampled": 398000, "num_steps_trained": 199000, "num_agent_steps_trained": 398000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 12738, "training_iteration": 199, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-59", "timestamp": 1749778619, "time_this_iter_s": 0.35165882110595703, "time_total_s": 75.91028928756714, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182c9af0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 75.91028928756714, "timesteps_since_restore": 0, "iterations_since_restore": 199, "perf": {}}
{"episode_reward_max": 89.4, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 54.494, "episode_len_mean": 16.17, "episode_media": {}, "episodes_this_iter": 62, "policy_reward_min": {"shared_policy": -12.4}, "policy_reward_max": {"shared_policy": 99.7}, "policy_reward_mean": {"shared_policy": 27.247}, "custom_metrics": {}, "hist_stats": {"episode_reward": [88.8, 86.4, 86.0, -4.999999999999998, -4.999999999999998, 88.8, 85.2, 88.4, -4.999999999999998, 89.4, 88.6, 88.4, 86.2, 87.6, -4.999999999999998, -4.999999999999998, 86.6, 89.2, 89.2, 88.0, -4.999999999999998, 88.6, -4.999999999999998, -4.999999999999998, 87.4, 87.4, 86.4, 86.0, 87.0, 86.6, -4.999999999999998, -4.999999999999998, 88.8, 89.2, 87.8, 88.8, 87.8, -4.999999999999998, -4.999999999999998, 87.0, 88.0, 85.6, 86.6, 88.8, -4.999999999999998, 88.0, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, -4.999999999999998, 89.2, 87.6, 87.8, 88.8, 86.8, -4.999999999999998, 89.2, -4.999999999999998, 89.2, 88.4, 89.0, -4.999999999999998, -4.999999999999998, 88.2, -4.999999999999998, 88.6, 88.6, -4.999999999999998, 87.2, 85.2, 88.8, 88.8, 88.2, 89.4, -4.999999999999998, 88.8, 87.6, 88.4, -4.999999999999998, 88.0, -4.999999999999998, 86.2, 89.4, 88.8, -4.999999999999998, -4.999999999999998, 89.4, -4.999999999999998, 89.2, 88.8, -4.999999999999998, -4.999999999999998, 85.2, -4.999999999999998, 89.2, 88.8, -4.999999999999998, -4.999999999999998], "episode_lengths": [7, 19, 21, 25, 25, 7, 25, 9, 25, 4, 8, 9, 20, 13, 25, 25, 18, 5, 5, 11, 25, 8, 25, 25, 14, 14, 19, 21, 16, 18, 25, 25, 7, 5, 12, 7, 12, 25, 25, 16, 11, 23, 18, 7, 25, 11, 25, 25, 25, 25, 25, 25, 5, 13, 12, 7, 17, 25, 5, 25, 5, 9, 6, 25, 25, 10, 25, 8, 8, 25, 15, 25, 7, 7, 10, 4, 25, 7, 13, 9, 25, 11, 25, 20, 4, 7, 25, 25, 4, 25, 5, 7, 25, 25, 25, 25, 5, 7, 25, 25], "policy_shared_policy_reward": [-10.6, 99.4, -11.8, 98.2, -12.0, 98.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 99.4, -10.6, -12.4, 97.6, 99.2, -10.8, -2.500000000000001, -2.500000000000001, 99.7, -10.3, -10.7, 99.3, 99.2, -10.8, -11.9, 98.1, 98.8, -11.2, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.3, -11.700000000000001, -10.4, 99.6, -10.4, 99.6, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 99.3, -10.7, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 98.7, -11.3, -11.3, 98.7, -11.8, 98.2, 98.0, -12.0, 98.5, -11.5, -11.700000000000001, 98.3, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.6, 99.4, -10.4, 99.6, 98.9, -11.1, -10.6, 99.4, 98.9, -11.1, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -11.5, 98.5, -11.0, 99.0, -12.200000000000001, 97.8, 98.3, -11.700000000000001, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -11.0, 99.0, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.4, 99.6, 98.8, -11.2, 98.9, -11.1, 99.4, -10.6, -11.6, 98.4, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -2.500000000000001, -2.500000000000001, -10.4, 99.6, 99.2, -10.8, 99.5, -10.5, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.9, 99.1, -2.500000000000001, -2.500000000000001, 99.3, -10.7, 99.3, -10.7, -2.500000000000001, -2.500000000000001, 98.6, -11.4, 97.6, -12.4, 99.4, -10.6, 99.4, -10.6, 99.1, -10.9, 99.7, -10.3, -2.500000000000001, -2.500000000000001, -10.6, 99.4, 98.8, -11.2, 99.2, -10.8, -2.500000000000001, -2.500000000000001, 99.0, -11.0, -2.500000000000001, -2.500000000000001, 98.1, -11.9, -10.3, 99.7, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, -10.3, 99.7, -2.500000000000001, -2.500000000000001, -10.4, 99.6, 99.4, -10.6, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001, 97.6, -12.4, -2.500000000000001, -2.500000000000001, -10.4, 99.6, -10.6, 99.4, -2.500000000000001, -2.500000000000001, -2.500000000000001, -2.500000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.36428963597396113, "mean_inference_ms": 1.6257518376108009, "mean_action_processing_ms": 0.08634060551510565, "mean_env_wait_ms": 0.08395783123634967, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 10, "timesteps_total": 200000, "timesteps_this_iter": 0, "agent_timesteps_total": 400000, "timers": {"sample_time_ms": 377.78, "sample_throughput": 2647.045, "load_time_ms": 1.299, "load_throughput": 769992.657, "learn_time_ms": 95.553, "learn_throughput": 10465.379, "update_time_ms": 2.571}, "info": {"learner": {"shared_policy": {"learner_stats": {"cur_kl_coeff": 1.2037062152420225e-36, "cur_lr": 0.0005000000000000001, "total_loss": 1327.872900390625, "policy_loss": -0.0016264155507087707, "vf_loss": 1327.8786254882812, "vf_explained_var": 0.06660350561141967, "kl": 0.0031466596061420216, "entropy": 0.4147790938615799, "entropy_coeff": 0.009999999999999998}}}, "num_steps_sampled": 200000, "num_agent_steps_sampled": 400000, "num_steps_trained": 200000, "num_agent_steps_trained": 400000, "num_steps_trained_this_iter": 0}, "evaluation": {"episode_reward_max": 88.8, "episode_reward_min": -4.999999999999998, "episode_reward_mean": 69.58, "episode_len_mean": 12.9, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"shared_policy": -11.6}, "policy_reward_max": {"shared_policy": 99.4}, "policy_reward_mean": {"shared_policy": 34.79}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.999999999999998, 88.4, 86.8, -4.999999999999998, 88.2, 88.8, 88.8, 88.8, 88.8, 87.2], "episode_lengths": [25, 9, 17, 25, 10, 7, 7, 7, 7, 15], "policy_shared_policy_reward": [-2.500000000000001, -2.500000000000001, 99.2, -10.8, 98.4, -11.6, -2.500000000000001, -2.500000000000001, -10.9, 99.1, 99.4, -10.6, 99.4, -10.6, 99.4, -10.6, -10.6, 99.4, 98.6, -11.4]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18597001197354107, "mean_inference_ms": 1.2961554047245305, "mean_action_processing_ms": 0.04531937157547715, "mean_env_wait_ms": 0.042000072914481955, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "done": true, "episodes_total": 12800, "training_iteration": 200, "trial_id": "ad802_00000", "experiment_id": "e05250b9b90e419bb90c42ff098a9722", "date": "2025-06-13_01-36-59", "timestamp": 1749778619, "time_this_iter_s": 0.5520856380462646, "time_total_s": 76.4623749256134, "pid": 10868, "hostname": "8b71eeb421a9", "node_ip": "172.17.0.2", "config": {"num_workers": 10, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "soccer_marl", "env_args": {"map_name": "soccer", "continuous_actions": false, "render_mode": "None", "max_cycles": 25}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": false, "local_mode": false, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 10, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 10, "num_sgd_iter": 5, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "config": {"algo_args": {"use_gae": true, "lambda": 0.95, "kl_coeff": 0.2, "batch_episode": 64, "num_sgd_iter": 10, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.02, "clip_param": 0.3, "vf_clip_param": 20.0, "batch_mode": "complete_episodes"}, "env_args": {"max_cycles": 500}}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0.], [6. 6. 6. 6. 6.], (5,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"soccer": {"description": "Soccer PettingZoo Env", "team_prefix": ["team_0_", "team_1_"], "all_agents_one_policy": true, "one_agent_one_policy": false}}, "agent_name_ls": ["player_A", "player_B"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "soccer_marl_soccer", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fb0182243a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 76.4623749256134, "timesteps_since_restore": 0, "iterations_since_restore": 200, "perf": {"cpu_util_percent": 57.3, "ram_util_percent": 90.4}}
